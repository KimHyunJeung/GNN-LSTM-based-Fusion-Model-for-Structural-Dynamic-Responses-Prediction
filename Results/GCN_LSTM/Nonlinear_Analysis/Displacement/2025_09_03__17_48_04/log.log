2025/09/03 17:48:04 : 

** GPU Info **
2025/09/03 17:48:04 : ====================================================================================================
2025/09/03 17:48:04 : My GPU is NVIDIA L40
2025/09/03 17:48:04 : ====================================================================================================
2025/09/03 17:48:26 : 

** Load Data **
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : Response Type: Displacement
2025/09/03 17:48:26 : Train dataset: ['./Data/Nonlinear_Analysis/train/ChiChi_DBE', './Data/Nonlinear_Analysis/train/NGAWest2_DBE', './Data/Nonlinear_Analysis/train/ChiChi_MCE', './Data/Nonlinear_Analysis/train/NGAWest2_MCE']
2025/09/03 17:48:26 : Eval dataset: ['./Data/Nonlinear_Analysis/eval/ChiChi_DBE', './Data/Nonlinear_Analysis/eval/NGAWest2_DBE', './Data/Nonlinear_Analysis/eval/ChiChi_MCE', './Data/Nonlinear_Analysis/eval/NGAWest2_MCE']
2025/09/03 17:48:26 : # of effective train data: 20
2025/09/03 17:48:26 : # of effective eval data: 20
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : 

** Get Normalization Dictionary **
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : 
normalization dictionary: 
{'x': {'XYZ_gridline_num': tensor(8.), 'XYZ_grid_index': tensor(7.), 'period': tensor(1.3262), 'DOF': tensor(1.), 'mass': tensor(0.0255), 'XYZ_inertia': tensor(255288.), 'XYZ_mode_shape': tensor(1.8960)}, 'ground_motion': tensor(10479.9434), 'y': tensor(241.7000), 'edge_attr': {'S_y': tensor(3687090.), 'S_z': tensor(3687090.), 'area': tensor(30774.), 'element_length': tensor(8000.)}, 'response_type': 'Displacement'}
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : 

** Model Info **
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : GCN_LSTM(
  (GCN_Encoder): GCN_Encoder(
    (relu): ReLU()
    (dropout): Dropout(p=0.2, inplace=False)
    (conv1): GCNConv(15, 128)
    (conv2): GCNConv(128, 256)
    (conv3): GCNConv(256, 128)
  )
  (LSTM): LSTM(
    (lstm): LSTM(138, 128, num_layers=2, batch_first=True, dropout=0.2)
    (fc_out): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=8, bias=True)
    )
  )
)
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : 

** Train **
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 :   Packed Mode = True
2025/09/03 17:48:26 :   Compression Rate of Ground Motion = 10
2025/09/03 17:48:26 :   Compression Rate of Response Sequence  = 1
2025/09/03 17:48:26 :   Compressed Seqence Length  = 2000
2025/09/03 17:48:26 :   Num Epochs = 1000
2025/09/03 17:48:26 :   Num Train Examples = 20
2025/09/03 17:48:26 :   Num Eval Examples = 20
2025/09/03 17:48:26 :   Batch Size = 5
2025/09/03 17:48:26 :   Evaluation Interval = 5
2025/09/03 17:48:26 :   Plot Interval = 1000
2025/09/03 17:48:26 : ====================================================================================================
2025/09/03 17:48:26 : Epoch: 000, Train_Loss: 0.01111140
2025/09/03 17:48:27 : Epoch: 001, Train_Loss: 0.01044847
2025/09/03 17:48:27 : Epoch: 002, Train_Loss: 0.01012405
2025/09/03 17:48:27 : Epoch: 003, Train_Loss: 0.01002000
2025/09/03 17:48:28 : Epoch: 004, Train_Loss: 0.00997762
2025/09/03 17:48:28 : Epoch: 004, Eval_Loss: 0.00649657
2025/09/03 17:48:28 : Epoch: 004, Save the best checkpoint
2025/09/03 17:48:28 : Epoch: 005, Train_Loss: 0.00996832
2025/09/03 17:48:29 : Epoch: 006, Train_Loss: 0.00993079
2025/09/03 17:48:29 : Epoch: 007, Train_Loss: 0.00992144
2025/09/03 17:48:30 : Epoch: 008, Train_Loss: 0.00987257
2025/09/03 17:48:30 : Epoch: 009, Train_Loss: 0.00976256
2025/09/03 17:48:30 : Epoch: 009, Eval_Loss: 0.00629269
2025/09/03 17:48:30 : Epoch: 009, Save the best checkpoint
2025/09/03 17:48:30 : Epoch: 010, Train_Loss: 0.00989722
2025/09/03 17:48:31 : Epoch: 011, Train_Loss: 0.00987998
2025/09/03 17:48:31 : Epoch: 012, Train_Loss: 0.00974277
2025/09/03 17:48:32 : Epoch: 013, Train_Loss: 0.00979163
2025/09/03 17:48:32 : Epoch: 014, Train_Loss: 0.00964207
2025/09/03 17:48:32 : Epoch: 014, Eval_Loss: 0.00606662
2025/09/03 17:48:32 : Epoch: 014, Save the best checkpoint
2025/09/03 17:48:32 : Epoch: 015, Train_Loss: 0.00932835
2025/09/03 17:48:33 : Epoch: 016, Train_Loss: 0.00947460
2025/09/03 17:48:33 : Epoch: 017, Train_Loss: 0.00934740
2025/09/03 17:48:34 : Epoch: 018, Train_Loss: 0.00921080
2025/09/03 17:48:34 : Epoch: 019, Train_Loss: 0.00909004
2025/09/03 17:48:34 : Epoch: 019, Eval_Loss: 0.00607673
2025/09/03 17:48:35 : Epoch: 020, Train_Loss: 0.00901004
2025/09/03 17:48:35 : Epoch: 021, Train_Loss: 0.00901532
2025/09/03 17:48:35 : Epoch: 022, Train_Loss: 0.00912345
2025/09/03 17:48:36 : Epoch: 023, Train_Loss: 0.00889106
2025/09/03 17:48:36 : Epoch: 024, Train_Loss: 0.00903261
2025/09/03 17:48:36 : Epoch: 024, Eval_Loss: 0.00588864
2025/09/03 17:48:36 : Epoch: 024, Save the best checkpoint
2025/09/03 17:48:37 : Epoch: 025, Train_Loss: 0.00902068
2025/09/03 17:48:37 : Epoch: 026, Train_Loss: 0.00866028
2025/09/03 17:48:37 : Epoch: 027, Train_Loss: 0.00882150
2025/09/03 17:48:38 : Epoch: 028, Train_Loss: 0.00909878
2025/09/03 17:48:38 : Epoch: 029, Train_Loss: 0.00908795
2025/09/03 17:48:38 : Epoch: 029, Eval_Loss: 0.00591141
2025/09/03 17:48:39 : Epoch: 030, Train_Loss: 0.00876126
2025/09/03 17:48:39 : Epoch: 031, Train_Loss: 0.00920917
2025/09/03 17:48:39 : Epoch: 032, Train_Loss: 0.00880959
2025/09/03 17:48:40 : Epoch: 033, Train_Loss: 0.00903251
2025/09/03 17:48:40 : Epoch: 034, Train_Loss: 0.00874415
2025/09/03 17:48:40 : Epoch: 034, Eval_Loss: 0.00590813
2025/09/03 17:48:41 : Epoch: 035, Train_Loss: 0.00905096
2025/09/03 17:48:41 : Epoch: 036, Train_Loss: 0.00905477
2025/09/03 17:48:41 : Epoch: 037, Train_Loss: 0.00888814
2025/09/03 17:48:42 : Epoch: 038, Train_Loss: 0.00857352
2025/09/03 17:48:42 : Epoch: 039, Train_Loss: 0.00852101
2025/09/03 17:48:42 : Epoch: 039, Eval_Loss: 0.00582330
2025/09/03 17:48:42 : Epoch: 039, Save the best checkpoint
2025/09/03 17:48:43 : Epoch: 040, Train_Loss: 0.00860703
2025/09/03 17:48:43 : Epoch: 041, Train_Loss: 0.00864073
2025/09/03 17:48:44 : Epoch: 042, Train_Loss: 0.00838725
2025/09/03 17:48:44 : Epoch: 043, Train_Loss: 0.00853062
2025/09/03 17:48:44 : Epoch: 044, Train_Loss: 0.00826604
2025/09/03 17:48:44 : Epoch: 044, Eval_Loss: 0.00577383
2025/09/03 17:48:44 : Epoch: 044, Save the best checkpoint
2025/09/03 17:48:45 : Epoch: 045, Train_Loss: 0.00844430
2025/09/03 17:48:45 : Epoch: 046, Train_Loss: 0.00781549
2025/09/03 17:48:46 : Epoch: 047, Train_Loss: 0.00728539
2025/09/03 17:48:46 : Epoch: 048, Train_Loss: 0.00908400
2025/09/03 17:48:46 : Epoch: 049, Train_Loss: 0.00970252
2025/09/03 17:48:47 : Epoch: 049, Eval_Loss: 0.00631556
2025/09/03 17:48:47 : Epoch: 050, Train_Loss: 0.00972448
2025/09/03 17:48:47 : Epoch: 051, Train_Loss: 0.00959952
2025/09/03 17:48:48 : Epoch: 052, Train_Loss: 0.00934112
2025/09/03 17:48:48 : Epoch: 053, Train_Loss: 0.00930952
2025/09/03 17:48:48 : Epoch: 054, Train_Loss: 0.00839720
2025/09/03 17:48:49 : Epoch: 054, Eval_Loss: 0.00579881
2025/09/03 17:48:49 : Epoch: 055, Train_Loss: 0.00876399
2025/09/03 17:48:49 : Epoch: 056, Train_Loss: 0.00993871
2025/09/03 17:48:50 : Epoch: 057, Train_Loss: 0.00938566
2025/09/03 17:48:50 : Epoch: 058, Train_Loss: 0.00949357
2025/09/03 17:48:51 : Epoch: 059, Train_Loss: 0.00951659
2025/09/03 17:48:51 : Epoch: 059, Eval_Loss: 0.00612857
2025/09/03 17:48:51 : Epoch: 060, Train_Loss: 0.00936694
2025/09/03 17:48:51 : Epoch: 061, Train_Loss: 0.00920734
2025/09/03 17:48:52 : Epoch: 062, Train_Loss: 0.00904638
2025/09/03 17:48:52 : Epoch: 063, Train_Loss: 0.00891613
2025/09/03 17:48:53 : Epoch: 064, Train_Loss: 0.00881358
2025/09/03 17:48:53 : Epoch: 064, Eval_Loss: 0.00579146
2025/09/03 17:48:53 : Epoch: 065, Train_Loss: 0.00868742
2025/09/03 17:48:54 : Epoch: 066, Train_Loss: 0.00851127
2025/09/03 17:48:54 : Epoch: 067, Train_Loss: 0.00827306
2025/09/03 17:48:54 : Epoch: 068, Train_Loss: 0.00788363
2025/09/03 17:48:55 : Epoch: 069, Train_Loss: 0.00792446
2025/09/03 17:48:55 : Epoch: 069, Eval_Loss: 0.00626092
2025/09/03 17:48:55 : Epoch: 070, Train_Loss: 0.00836646
2025/09/03 17:48:56 : Epoch: 071, Train_Loss: 0.00803809
2025/09/03 17:48:56 : Epoch: 072, Train_Loss: 0.00772349
2025/09/03 17:48:56 : Epoch: 073, Train_Loss: 0.00770238
2025/09/03 17:48:57 : Epoch: 074, Train_Loss: 0.00782318
2025/09/03 17:48:57 : Epoch: 074, Eval_Loss: 0.00604688
2025/09/03 17:48:57 : Epoch: 075, Train_Loss: 0.00779814
2025/09/03 17:48:58 : Epoch: 076, Train_Loss: 0.00817927
2025/09/03 17:48:58 : Epoch: 077, Train_Loss: 0.00798948
2025/09/03 17:48:58 : Epoch: 078, Train_Loss: 0.00745301
2025/09/03 17:48:59 : Epoch: 079, Train_Loss: 0.00788636
2025/09/03 17:48:59 : Epoch: 079, Eval_Loss: 0.00538073
2025/09/03 17:48:59 : Epoch: 079, Save the best checkpoint
2025/09/03 17:48:59 : Epoch: 080, Train_Loss: 0.00710916
2025/09/03 17:49:00 : Epoch: 081, Train_Loss: 0.00854103
2025/09/03 17:49:00 : Epoch: 082, Train_Loss: 0.00904848
2025/09/03 17:49:01 : Epoch: 083, Train_Loss: 0.00911636
2025/09/03 17:49:01 : Epoch: 084, Train_Loss: 0.00859553
2025/09/03 17:49:01 : Epoch: 084, Eval_Loss: 0.00635811
2025/09/03 17:49:01 : Epoch: 085, Train_Loss: 0.00919507
2025/09/03 17:49:02 : Epoch: 086, Train_Loss: 0.00869149
2025/09/03 17:49:02 : Epoch: 087, Train_Loss: 0.00818526
2025/09/03 17:49:03 : Epoch: 088, Train_Loss: 0.00788508
2025/09/03 17:49:03 : Epoch: 089, Train_Loss: 0.00775186
2025/09/03 17:49:03 : Epoch: 089, Eval_Loss: 0.00607168
2025/09/03 17:49:03 : Epoch: 090, Train_Loss: 0.00743980
2025/09/03 17:49:04 : Epoch: 091, Train_Loss: 0.00756890
2025/09/03 17:49:04 : Epoch: 092, Train_Loss: 0.00724280
2025/09/03 17:49:05 : Epoch: 093, Train_Loss: 0.00703307
2025/09/03 17:49:05 : Epoch: 094, Train_Loss: 0.00679322
2025/09/03 17:49:05 : Epoch: 094, Eval_Loss: 0.00662170
2025/09/03 17:49:06 : Epoch: 095, Train_Loss: 0.00762888
2025/09/03 17:49:06 : Epoch: 096, Train_Loss: 0.00744367
2025/09/03 17:49:06 : Epoch: 097, Train_Loss: 0.00706811
2025/09/03 17:49:07 : Epoch: 098, Train_Loss: 0.00657425
2025/09/03 17:49:07 : Epoch: 099, Train_Loss: 0.00699053
2025/09/03 17:49:07 : Epoch: 099, Eval_Loss: 0.00613083
2025/09/03 17:49:08 : Epoch: 100, Train_Loss: 0.00770308
2025/09/03 17:49:08 : Epoch: 101, Train_Loss: 0.00735886
2025/09/03 17:49:08 : Epoch: 102, Train_Loss: 0.00723162
2025/09/03 17:49:09 : Epoch: 103, Train_Loss: 0.00748020
2025/09/03 17:49:09 : Epoch: 104, Train_Loss: 0.00764081
2025/09/03 17:49:09 : Epoch: 104, Eval_Loss: 0.00614825
2025/09/03 17:49:10 : Epoch: 105, Train_Loss: 0.00820492
2025/09/03 17:49:10 : Epoch: 106, Train_Loss: 0.00778863
2025/09/03 17:49:10 : Epoch: 107, Train_Loss: 0.00775725
2025/09/03 17:49:11 : Epoch: 108, Train_Loss: 0.00741748
2025/09/03 17:49:11 : Epoch: 109, Train_Loss: 0.00804108
2025/09/03 17:49:11 : Epoch: 109, Eval_Loss: 0.00583786
2025/09/03 17:49:12 : Epoch: 110, Train_Loss: 0.00826089
2025/09/03 17:49:12 : Epoch: 111, Train_Loss: 0.00784595
2025/09/03 17:49:13 : Epoch: 112, Train_Loss: 0.00747135
2025/09/03 17:49:13 : Epoch: 113, Train_Loss: 0.00735384
2025/09/03 17:49:13 : Epoch: 114, Train_Loss: 0.00696954
2025/09/03 17:49:13 : Epoch: 114, Eval_Loss: 0.00586394
2025/09/03 17:49:14 : Epoch: 115, Train_Loss: 0.00683710
2025/09/03 17:49:14 : Epoch: 116, Train_Loss: 0.00788459
2025/09/03 17:49:15 : Epoch: 117, Train_Loss: 0.00772551
2025/09/03 17:49:15 : Epoch: 118, Train_Loss: 0.00735267
2025/09/03 17:49:15 : Epoch: 119, Train_Loss: 0.00701425
2025/09/03 17:49:16 : Epoch: 119, Eval_Loss: 0.00702426
2025/09/03 17:49:16 : Epoch: 120, Train_Loss: 0.00693669
2025/09/03 17:49:16 : Epoch: 121, Train_Loss: 0.00644436
2025/09/03 17:49:17 : Epoch: 122, Train_Loss: 0.00634672
2025/09/03 17:49:17 : Epoch: 123, Train_Loss: 0.00698800
2025/09/03 17:49:17 : Epoch: 124, Train_Loss: 0.00907914
2025/09/03 17:49:18 : Epoch: 124, Eval_Loss: 0.00618514
2025/09/03 17:49:18 : Epoch: 125, Train_Loss: 0.00843742
2025/09/03 17:49:18 : Epoch: 126, Train_Loss: 0.00854418
2025/09/03 17:49:19 : Epoch: 127, Train_Loss: 0.00764820
2025/09/03 17:49:19 : Epoch: 128, Train_Loss: 0.00718358
2025/09/03 17:49:20 : Epoch: 129, Train_Loss: 0.00660967
2025/09/03 17:49:20 : Epoch: 129, Eval_Loss: 0.00673124
2025/09/03 17:49:20 : Epoch: 130, Train_Loss: 0.00677328
2025/09/03 17:49:20 : Epoch: 131, Train_Loss: 0.00666999
2025/09/03 17:49:21 : Epoch: 132, Train_Loss: 0.00730772
2025/09/03 17:49:21 : Epoch: 133, Train_Loss: 0.00639930
2025/09/03 17:49:22 : Epoch: 134, Train_Loss: 0.00633959
2025/09/03 17:49:22 : Epoch: 134, Eval_Loss: 0.00664519
2025/09/03 17:49:22 : Epoch: 135, Train_Loss: 0.00700348
2025/09/03 17:49:22 : Epoch: 136, Train_Loss: 0.00719171
2025/09/03 17:49:23 : Epoch: 137, Train_Loss: 0.00713652
2025/09/03 17:49:23 : Epoch: 138, Train_Loss: 0.00581021
2025/09/03 17:49:24 : Epoch: 139, Train_Loss: 0.00669230
2025/09/03 17:49:24 : Epoch: 139, Eval_Loss: 0.00520203
2025/09/03 17:49:24 : Epoch: 139, Save the best checkpoint
2025/09/03 17:49:24 : Epoch: 140, Train_Loss: 0.00584169
2025/09/03 17:49:25 : Epoch: 141, Train_Loss: 0.00659167
2025/09/03 17:49:25 : Epoch: 142, Train_Loss: 0.00594338
2025/09/03 17:49:25 : Epoch: 143, Train_Loss: 0.00614081
2025/09/03 17:49:26 : Epoch: 144, Train_Loss: 0.00642319
2025/09/03 17:49:26 : Epoch: 144, Eval_Loss: 0.00628087
2025/09/03 17:49:26 : Epoch: 145, Train_Loss: 0.00647510
2025/09/03 17:49:27 : Epoch: 146, Train_Loss: 0.00564095
2025/09/03 17:49:27 : Epoch: 147, Train_Loss: 0.00536837
2025/09/03 17:49:27 : Epoch: 148, Train_Loss: 0.00515824
2025/09/03 17:49:28 : Epoch: 149, Train_Loss: 0.00642293
2025/09/03 17:49:28 : Epoch: 149, Eval_Loss: 0.00564076
2025/09/03 17:49:28 : Epoch: 150, Train_Loss: 0.00639907
2025/09/03 17:49:29 : Epoch: 151, Train_Loss: 0.00665105
2025/09/03 17:49:29 : Epoch: 152, Train_Loss: 0.00579578
2025/09/03 17:49:29 : Epoch: 153, Train_Loss: 0.00586926
2025/09/03 17:49:30 : Epoch: 154, Train_Loss: 0.00545909
2025/09/03 17:49:30 : Epoch: 154, Eval_Loss: 0.00734181
2025/09/03 17:49:30 : Epoch: 155, Train_Loss: 0.00528397
2025/09/03 17:49:31 : Epoch: 156, Train_Loss: 0.00490059
2025/09/03 17:49:31 : Epoch: 157, Train_Loss: 0.00511294
2025/09/03 17:49:32 : Epoch: 158, Train_Loss: 0.00528418
2025/09/03 17:49:32 : Epoch: 159, Train_Loss: 0.00487645
2025/09/03 17:49:32 : Epoch: 159, Eval_Loss: 0.00626763
2025/09/03 17:49:32 : Epoch: 160, Train_Loss: 0.00587223
2025/09/03 17:49:33 : Epoch: 161, Train_Loss: 0.00585480
2025/09/03 17:49:33 : Epoch: 162, Train_Loss: 0.00630896
2025/09/03 17:49:34 : Epoch: 163, Train_Loss: 0.00600305
2025/09/03 17:49:34 : Epoch: 164, Train_Loss: 0.00567716
2025/09/03 17:49:34 : Epoch: 164, Eval_Loss: 0.00797634
2025/09/03 17:49:35 : Epoch: 165, Train_Loss: 0.00520369
2025/09/03 17:49:35 : Epoch: 166, Train_Loss: 0.00527894
2025/09/03 17:49:35 : Epoch: 167, Train_Loss: 0.00535546
2025/09/03 17:49:36 : Epoch: 168, Train_Loss: 0.00524763
2025/09/03 17:49:36 : Epoch: 169, Train_Loss: 0.00480800
2025/09/03 17:49:36 : Epoch: 169, Eval_Loss: 0.00600023
2025/09/03 17:49:37 : Epoch: 170, Train_Loss: 0.00683789
2025/09/03 17:49:37 : Epoch: 171, Train_Loss: 0.00778437
2025/09/03 17:49:37 : Epoch: 172, Train_Loss: 0.00732047
2025/09/03 17:49:38 : Epoch: 173, Train_Loss: 0.00640226
2025/09/03 17:49:38 : Epoch: 174, Train_Loss: 0.00589814
2025/09/03 17:49:38 : Epoch: 174, Eval_Loss: 0.00696432
2025/09/03 17:49:39 : Epoch: 175, Train_Loss: 0.00526063
2025/09/03 17:49:39 : Epoch: 176, Train_Loss: 0.00814355
2025/09/03 17:49:39 : Epoch: 177, Train_Loss: 0.00702047
2025/09/03 17:49:40 : Epoch: 178, Train_Loss: 0.00707856
2025/09/03 17:49:40 : Epoch: 179, Train_Loss: 0.00670220
2025/09/03 17:49:40 : Epoch: 179, Eval_Loss: 0.00657612
2025/09/03 17:49:41 : Epoch: 180, Train_Loss: 0.00631977
2025/09/03 17:49:41 : Epoch: 181, Train_Loss: 0.00575067
2025/09/03 17:49:42 : Epoch: 182, Train_Loss: 0.00661551
2025/09/03 17:49:42 : Epoch: 183, Train_Loss: 0.00745119
2025/09/03 17:49:42 : Epoch: 184, Train_Loss: 0.00646472
2025/09/03 17:49:42 : Epoch: 184, Eval_Loss: 0.01060257
2025/09/03 17:49:43 : Epoch: 185, Train_Loss: 0.00638602
2025/09/03 17:49:43 : Epoch: 186, Train_Loss: 0.00704623
2025/09/03 17:49:44 : Epoch: 187, Train_Loss: 0.00636225
2025/09/03 17:49:44 : Epoch: 188, Train_Loss: 0.00541105
2025/09/03 17:49:44 : Epoch: 189, Train_Loss: 0.00619988
2025/09/03 17:49:44 : Epoch: 189, Eval_Loss: 0.00513239
2025/09/03 17:49:44 : Epoch: 189, Save the best checkpoint
2025/09/03 17:49:45 : Epoch: 190, Train_Loss: 0.00622880
2025/09/03 17:49:45 : Epoch: 191, Train_Loss: 0.00635940
2025/09/03 17:49:46 : Epoch: 192, Train_Loss: 0.00544163
2025/09/03 17:49:46 : Epoch: 193, Train_Loss: 0.00561030
2025/09/03 17:49:46 : Epoch: 194, Train_Loss: 0.00496359
2025/09/03 17:49:47 : Epoch: 194, Eval_Loss: 0.00764467
2025/09/03 17:49:47 : Epoch: 195, Train_Loss: 0.00491483
2025/09/03 17:49:47 : Epoch: 196, Train_Loss: 0.00543141
2025/09/03 17:49:48 : Epoch: 197, Train_Loss: 0.00613033
2025/09/03 17:49:48 : Epoch: 198, Train_Loss: 0.00562053
2025/09/03 17:49:48 : Epoch: 199, Train_Loss: 0.00587850
2025/09/03 17:49:49 : Epoch: 199, Eval_Loss: 0.00733203
2025/09/03 17:49:49 : Epoch: 200, Train_Loss: 0.00590612
2025/09/03 17:49:49 : Epoch: 201, Train_Loss: 0.00512698
2025/09/03 17:49:50 : Epoch: 202, Train_Loss: 0.00486560
2025/09/03 17:49:50 : Epoch: 203, Train_Loss: 0.00679282
2025/09/03 17:49:51 : Epoch: 204, Train_Loss: 0.00670421
2025/09/03 17:49:51 : Epoch: 204, Eval_Loss: 0.00674002
2025/09/03 17:49:51 : Epoch: 205, Train_Loss: 0.00643804
2025/09/03 17:49:51 : Epoch: 206, Train_Loss: 0.00650427
2025/09/03 17:49:52 : Epoch: 207, Train_Loss: 0.00593569
2025/09/03 17:49:52 : Epoch: 208, Train_Loss: 0.00600736
2025/09/03 17:49:53 : Epoch: 209, Train_Loss: 0.00561043
2025/09/03 17:49:53 : Epoch: 209, Eval_Loss: 0.00798252
2025/09/03 17:49:53 : Epoch: 210, Train_Loss: 0.00546130
2025/09/03 17:49:54 : Epoch: 211, Train_Loss: 0.00526356
2025/09/03 17:49:54 : Epoch: 212, Train_Loss: 0.00485570
2025/09/03 17:49:54 : Epoch: 213, Train_Loss: 0.00460056
2025/09/03 17:49:55 : Epoch: 214, Train_Loss: 0.00575412
2025/09/03 17:49:55 : Epoch: 214, Eval_Loss: 0.00609312
2025/09/03 17:49:55 : Epoch: 215, Train_Loss: 0.00736834
2025/09/03 17:49:56 : Epoch: 216, Train_Loss: 0.00965405
2025/09/03 17:49:56 : Epoch: 217, Train_Loss: 0.00864274
2025/09/03 17:49:56 : Epoch: 218, Train_Loss: 0.00862272
2025/09/03 17:49:57 : Epoch: 219, Train_Loss: 0.00835239
2025/09/03 17:49:57 : Epoch: 219, Eval_Loss: 0.00600926
2025/09/03 17:49:57 : Epoch: 220, Train_Loss: 0.00771902
2025/09/03 17:49:58 : Epoch: 221, Train_Loss: 0.00744107
2025/09/03 17:49:58 : Epoch: 222, Train_Loss: 0.00713847
2025/09/03 17:49:58 : Epoch: 223, Train_Loss: 0.00664377
2025/09/03 17:49:59 : Epoch: 224, Train_Loss: 0.00619420
2025/09/03 17:49:59 : Epoch: 224, Eval_Loss: 0.00624712
2025/09/03 17:49:59 : Epoch: 225, Train_Loss: 0.00608244
2025/09/03 17:50:00 : Epoch: 226, Train_Loss: 0.00626232
2025/09/03 17:50:00 : Epoch: 227, Train_Loss: 0.00681114
2025/09/03 17:50:01 : Epoch: 228, Train_Loss: 0.00647076
2025/09/03 17:50:01 : Epoch: 229, Train_Loss: 0.00642026
2025/09/03 17:50:01 : Epoch: 229, Eval_Loss: 0.00559311
2025/09/03 17:50:01 : Epoch: 230, Train_Loss: 0.00577805
2025/09/03 17:50:02 : Epoch: 231, Train_Loss: 0.00512166
2025/09/03 17:50:02 : Epoch: 232, Train_Loss: 0.00558711
2025/09/03 17:50:03 : Epoch: 233, Train_Loss: 0.00730031
2025/09/03 17:50:03 : Epoch: 234, Train_Loss: 0.00690122
2025/09/03 17:50:03 : Epoch: 234, Eval_Loss: 0.00570931
2025/09/03 17:50:03 : Epoch: 235, Train_Loss: 0.00680287
2025/09/03 17:50:04 : Epoch: 236, Train_Loss: 0.00654430
2025/09/03 17:50:04 : Epoch: 237, Train_Loss: 0.00592289
2025/09/03 17:50:05 : Epoch: 238, Train_Loss: 0.00582085
2025/09/03 17:50:05 : Epoch: 239, Train_Loss: 0.00585822
2025/09/03 17:50:05 : Epoch: 239, Eval_Loss: 0.00504025
2025/09/03 17:50:05 : Epoch: 239, Save the best checkpoint
2025/09/03 17:50:06 : Epoch: 240, Train_Loss: 0.00570605
2025/09/03 17:50:06 : Epoch: 241, Train_Loss: 0.00490076
2025/09/03 17:50:06 : Epoch: 242, Train_Loss: 0.00446789
2025/09/03 17:50:07 : Epoch: 243, Train_Loss: 0.00676582
2025/09/03 17:50:07 : Epoch: 244, Train_Loss: 0.00696743
2025/09/03 17:50:07 : Epoch: 244, Eval_Loss: 0.00757606
2025/09/03 17:50:08 : Epoch: 245, Train_Loss: 0.00737126
2025/09/03 17:50:08 : Epoch: 246, Train_Loss: 0.00678469
2025/09/03 17:50:08 : Epoch: 247, Train_Loss: 0.00649716
2025/09/03 17:50:09 : Epoch: 248, Train_Loss: 0.00604452
2025/09/03 17:50:09 : Epoch: 249, Train_Loss: 0.00551432
2025/09/03 17:50:09 : Epoch: 249, Eval_Loss: 0.00573529
2025/09/03 17:50:10 : Epoch: 250, Train_Loss: 0.00513842
2025/09/03 17:50:10 : Epoch: 251, Train_Loss: 0.00454785
2025/09/03 17:50:10 : Epoch: 252, Train_Loss: 0.00452375
2025/09/03 17:50:11 : Epoch: 253, Train_Loss: 0.00474885
2025/09/03 17:50:11 : Epoch: 254, Train_Loss: 0.00452599
2025/09/03 17:50:11 : Epoch: 254, Eval_Loss: 0.00579841
2025/09/03 17:50:12 : Epoch: 255, Train_Loss: 0.00450130
2025/09/03 17:50:12 : Epoch: 256, Train_Loss: 0.00502895
2025/09/03 17:50:13 : Epoch: 257, Train_Loss: 0.00522194
2025/09/03 17:50:13 : Epoch: 258, Train_Loss: 0.00560341
2025/09/03 17:50:13 : Epoch: 259, Train_Loss: 0.00550948
2025/09/03 17:50:13 : Epoch: 259, Eval_Loss: 0.00634489
2025/09/03 17:50:14 : Epoch: 260, Train_Loss: 0.00510853
2025/09/03 17:50:14 : Epoch: 261, Train_Loss: 0.00473468
2025/09/03 17:50:15 : Epoch: 262, Train_Loss: 0.00558292
2025/09/03 17:50:15 : Epoch: 263, Train_Loss: 0.00566786
2025/09/03 17:50:15 : Epoch: 264, Train_Loss: 0.00507062
2025/09/03 17:50:16 : Epoch: 264, Eval_Loss: 0.00714638
2025/09/03 17:50:16 : Epoch: 265, Train_Loss: 0.00440958
2025/09/03 17:50:16 : Epoch: 266, Train_Loss: 0.00442717
2025/09/03 17:50:17 : Epoch: 267, Train_Loss: 0.00393612
2025/09/03 17:50:17 : Epoch: 268, Train_Loss: 0.00384879
2025/09/03 17:50:17 : Epoch: 269, Train_Loss: 0.00368774
2025/09/03 17:50:18 : Epoch: 269, Eval_Loss: 0.00708902
2025/09/03 17:50:18 : Epoch: 270, Train_Loss: 0.00383710
2025/09/03 17:50:18 : Epoch: 271, Train_Loss: 0.00413482
2025/09/03 17:50:19 : Epoch: 272, Train_Loss: 0.00479237
2025/09/03 17:50:19 : Epoch: 273, Train_Loss: 0.00431988
2025/09/03 17:50:20 : Epoch: 274, Train_Loss: 0.00382379
2025/09/03 17:50:20 : Epoch: 274, Eval_Loss: 0.00684167
2025/09/03 17:50:20 : Epoch: 275, Train_Loss: 0.00408764
2025/09/03 17:50:20 : Epoch: 276, Train_Loss: 0.00494231
2025/09/03 17:50:21 : Epoch: 277, Train_Loss: 0.00560881
2025/09/03 17:50:21 : Epoch: 278, Train_Loss: 0.00602151
2025/09/03 17:50:22 : Epoch: 279, Train_Loss: 0.00564588
2025/09/03 17:50:22 : Epoch: 279, Eval_Loss: 0.00701696
2025/09/03 17:50:22 : Epoch: 280, Train_Loss: 0.00462263
2025/09/03 17:50:23 : Epoch: 281, Train_Loss: 0.00433803
2025/09/03 17:50:23 : Epoch: 282, Train_Loss: 0.00426855
2025/09/03 17:50:23 : Epoch: 283, Train_Loss: 0.00426813
2025/09/03 17:50:24 : Epoch: 284, Train_Loss: 0.00400957
2025/09/03 17:50:24 : Epoch: 284, Eval_Loss: 0.00658458
2025/09/03 17:50:24 : Epoch: 285, Train_Loss: 0.00494504
2025/09/03 17:50:25 : Epoch: 286, Train_Loss: 0.00413128
2025/09/03 17:50:25 : Epoch: 287, Train_Loss: 0.00423113
2025/09/03 17:50:25 : Epoch: 288, Train_Loss: 0.00411427
2025/09/03 17:50:26 : Epoch: 289, Train_Loss: 0.00485895
2025/09/03 17:50:26 : Epoch: 289, Eval_Loss: 0.00642348
2025/09/03 17:50:26 : Epoch: 290, Train_Loss: 0.00484242
2025/09/03 17:50:27 : Epoch: 291, Train_Loss: 0.00404547
2025/09/03 17:50:27 : Epoch: 292, Train_Loss: 0.00462646
2025/09/03 17:50:27 : Epoch: 293, Train_Loss: 0.00432949
2025/09/03 17:50:28 : Epoch: 294, Train_Loss: 0.00412987
2025/09/03 17:50:28 : Epoch: 294, Eval_Loss: 0.00611026
2025/09/03 17:50:28 : Epoch: 295, Train_Loss: 0.00549996
2025/09/03 17:50:29 : Epoch: 296, Train_Loss: 0.00567007
2025/09/03 17:50:29 : Epoch: 297, Train_Loss: 0.00584475
2025/09/03 17:50:29 : Epoch: 298, Train_Loss: 0.00540281
2025/09/03 17:50:30 : Epoch: 299, Train_Loss: 0.00510446
2025/09/03 17:50:30 : Epoch: 299, Eval_Loss: 0.00719401
2025/09/03 17:50:30 : Epoch: 300, Train_Loss: 0.00512721
2025/09/03 17:50:31 : Epoch: 301, Train_Loss: 0.00528034
2025/09/03 17:50:31 : Epoch: 302, Train_Loss: 0.00460045
2025/09/03 17:50:32 : Epoch: 303, Train_Loss: 0.00681718
2025/09/03 17:50:32 : Epoch: 304, Train_Loss: 0.00537288
2025/09/03 17:50:32 : Epoch: 304, Eval_Loss: 0.00746551
2025/09/03 17:50:32 : Epoch: 305, Train_Loss: 0.00560497
2025/09/03 17:50:33 : Epoch: 306, Train_Loss: 0.00567033
2025/09/03 17:50:33 : Epoch: 307, Train_Loss: 0.00650253
2025/09/03 17:50:34 : Epoch: 308, Train_Loss: 0.00649994
2025/09/03 17:50:34 : Epoch: 309, Train_Loss: 0.00618001
2025/09/03 17:50:34 : Epoch: 309, Eval_Loss: 0.00786517
2025/09/03 17:50:35 : Epoch: 310, Train_Loss: 0.00613224
2025/09/03 17:50:35 : Epoch: 311, Train_Loss: 0.00613846
2025/09/03 17:50:35 : Epoch: 312, Train_Loss: 0.00614393
2025/09/03 17:50:36 : Epoch: 313, Train_Loss: 0.00548459
2025/09/03 17:50:36 : Epoch: 314, Train_Loss: 0.00525924
2025/09/03 17:50:36 : Epoch: 314, Eval_Loss: 0.00620272
2025/09/03 17:50:37 : Epoch: 315, Train_Loss: 0.00504049
2025/09/03 17:50:37 : Epoch: 316, Train_Loss: 0.00573133
2025/09/03 17:50:37 : Epoch: 317, Train_Loss: 0.00685671
2025/09/03 17:50:38 : Epoch: 318, Train_Loss: 0.00696421
2025/09/03 17:50:38 : Epoch: 319, Train_Loss: 0.00643641
2025/09/03 17:50:38 : Epoch: 319, Eval_Loss: 0.00688110
2025/09/03 17:50:39 : Epoch: 320, Train_Loss: 0.00626961
2025/09/03 17:50:39 : Epoch: 321, Train_Loss: 0.00620554
2025/09/03 17:50:39 : Epoch: 322, Train_Loss: 0.00614815
2025/09/03 17:50:40 : Epoch: 323, Train_Loss: 0.00597978
2025/09/03 17:50:40 : Epoch: 324, Train_Loss: 0.00559788
2025/09/03 17:50:40 : Epoch: 324, Eval_Loss: 0.00612591
2025/09/03 17:50:41 : Epoch: 325, Train_Loss: 0.00533378
2025/09/03 17:50:41 : Epoch: 326, Train_Loss: 0.00529629
2025/09/03 17:50:42 : Epoch: 327, Train_Loss: 0.00571571
2025/09/03 17:50:42 : Epoch: 328, Train_Loss: 0.00515711
2025/09/03 17:50:42 : Epoch: 329, Train_Loss: 0.00472123
2025/09/03 17:50:42 : Epoch: 329, Eval_Loss: 0.00540746
2025/09/03 17:50:43 : Epoch: 330, Train_Loss: 0.00458334
2025/09/03 17:50:43 : Epoch: 331, Train_Loss: 0.00520950
2025/09/03 17:50:44 : Epoch: 332, Train_Loss: 0.00517124
2025/09/03 17:50:44 : Epoch: 333, Train_Loss: 0.00498634
2025/09/03 17:50:44 : Epoch: 334, Train_Loss: 0.00460912
2025/09/03 17:50:44 : Epoch: 334, Eval_Loss: 0.00776858
2025/09/03 17:50:45 : Epoch: 335, Train_Loss: 0.00549864
2025/09/03 17:50:45 : Epoch: 336, Train_Loss: 0.00695026
2025/09/03 17:50:46 : Epoch: 337, Train_Loss: 0.00620587
2025/09/03 17:50:46 : Epoch: 338, Train_Loss: 0.00619812
2025/09/03 17:50:46 : Epoch: 339, Train_Loss: 0.00577923
2025/09/03 17:50:47 : Epoch: 339, Eval_Loss: 0.00669301
2025/09/03 17:50:47 : Epoch: 340, Train_Loss: 0.00563138
2025/09/03 17:50:47 : Epoch: 341, Train_Loss: 0.00526310
2025/09/03 17:50:48 : Epoch: 342, Train_Loss: 0.00498532
2025/09/03 17:50:48 : Epoch: 343, Train_Loss: 0.00483083
2025/09/03 17:50:48 : Epoch: 344, Train_Loss: 0.00401539
2025/09/03 17:50:49 : Epoch: 344, Eval_Loss: 0.00609722
2025/09/03 17:50:49 : Epoch: 345, Train_Loss: 0.00486442
2025/09/03 17:50:49 : Epoch: 346, Train_Loss: 0.00589641
2025/09/03 17:50:50 : Epoch: 347, Train_Loss: 0.00562098
2025/09/03 17:50:50 : Epoch: 348, Train_Loss: 0.00541096
2025/09/03 17:50:51 : Epoch: 349, Train_Loss: 0.00553108
2025/09/03 17:50:51 : Epoch: 349, Eval_Loss: 0.00661225
2025/09/03 17:50:51 : Epoch: 350, Train_Loss: 0.00503260
2025/09/03 17:50:51 : Epoch: 351, Train_Loss: 0.00529635
2025/09/03 17:50:52 : Epoch: 352, Train_Loss: 0.00509599
2025/09/03 17:50:52 : Epoch: 353, Train_Loss: 0.00437643
2025/09/03 17:50:53 : Epoch: 354, Train_Loss: 0.00391598
2025/09/03 17:50:53 : Epoch: 354, Eval_Loss: 0.00581521
2025/09/03 17:50:53 : Epoch: 355, Train_Loss: 0.00355522
2025/09/03 17:50:54 : Epoch: 356, Train_Loss: 0.00338236
2025/09/03 17:50:54 : Epoch: 357, Train_Loss: 0.00363938
2025/09/03 17:50:54 : Epoch: 358, Train_Loss: 0.00549139
2025/09/03 17:50:55 : Epoch: 359, Train_Loss: 0.00548521
2025/09/03 17:50:55 : Epoch: 359, Eval_Loss: 0.00750513
2025/09/03 17:50:55 : Epoch: 360, Train_Loss: 0.00539008
2025/09/03 17:50:56 : Epoch: 361, Train_Loss: 0.00544415
2025/09/03 17:50:56 : Epoch: 362, Train_Loss: 0.00482757
2025/09/03 17:50:56 : Epoch: 363, Train_Loss: 0.00463826
2025/09/03 17:50:57 : Epoch: 364, Train_Loss: 0.00430767
2025/09/03 17:50:57 : Epoch: 364, Eval_Loss: 0.00610090
2025/09/03 17:50:57 : Epoch: 365, Train_Loss: 0.00409207
2025/09/03 17:50:58 : Epoch: 366, Train_Loss: 0.00389059
2025/09/03 17:50:58 : Epoch: 367, Train_Loss: 0.00366798
2025/09/03 17:50:58 : Epoch: 368, Train_Loss: 0.00475545
2025/09/03 17:50:59 : Epoch: 369, Train_Loss: 0.00475157
2025/09/03 17:50:59 : Epoch: 369, Eval_Loss: 0.00575259
2025/09/03 17:50:59 : Epoch: 370, Train_Loss: 0.00463319
2025/09/03 17:51:00 : Epoch: 371, Train_Loss: 0.00512081
2025/09/03 17:51:00 : Epoch: 372, Train_Loss: 0.00441010
2025/09/03 17:51:00 : Epoch: 373, Train_Loss: 0.00477271
2025/09/03 17:51:01 : Epoch: 374, Train_Loss: 0.00423830
2025/09/03 17:51:01 : Epoch: 374, Eval_Loss: 0.00546495
2025/09/03 17:51:01 : Epoch: 375, Train_Loss: 0.00381631
2025/09/03 17:51:02 : Epoch: 376, Train_Loss: 0.00450426
2025/09/03 17:51:02 : Epoch: 377, Train_Loss: 0.00501977
2025/09/03 17:51:03 : Epoch: 378, Train_Loss: 0.00450775
2025/09/03 17:51:03 : Epoch: 379, Train_Loss: 0.00398458
2025/09/03 17:51:03 : Epoch: 379, Eval_Loss: 0.00641040
2025/09/03 17:51:03 : Epoch: 380, Train_Loss: 0.00409417
2025/09/03 17:51:04 : Epoch: 381, Train_Loss: 0.00510847
2025/09/03 17:51:04 : Epoch: 382, Train_Loss: 0.00605417
2025/09/03 17:51:05 : Epoch: 383, Train_Loss: 0.00503569
2025/09/03 17:51:05 : Epoch: 384, Train_Loss: 0.00461468
2025/09/03 17:51:05 : Epoch: 384, Eval_Loss: 0.00549369
2025/09/03 17:51:06 : Epoch: 385, Train_Loss: 0.00425585
2025/09/03 17:51:06 : Epoch: 386, Train_Loss: 0.00402002
2025/09/03 17:51:06 : Epoch: 387, Train_Loss: 0.00421716
2025/09/03 17:51:07 : Epoch: 388, Train_Loss: 0.00357123
2025/09/03 17:51:07 : Epoch: 389, Train_Loss: 0.00384571
2025/09/03 17:51:07 : Epoch: 389, Eval_Loss: 0.00539194
2025/09/03 17:51:08 : Epoch: 390, Train_Loss: 0.00353345
2025/09/03 17:51:08 : Epoch: 391, Train_Loss: 0.00469691
2025/09/03 17:51:08 : Epoch: 392, Train_Loss: 0.00396390
2025/09/03 17:51:09 : Epoch: 393, Train_Loss: 0.00458646
2025/09/03 17:51:09 : Epoch: 394, Train_Loss: 0.00497722
2025/09/03 17:51:09 : Epoch: 394, Eval_Loss: 0.00505050
2025/09/03 17:51:10 : Epoch: 395, Train_Loss: 0.00567271
2025/09/03 17:51:10 : Epoch: 396, Train_Loss: 0.00540376
2025/09/03 17:51:10 : Epoch: 397, Train_Loss: 0.00504032
2025/09/03 17:51:11 : Epoch: 398, Train_Loss: 0.00438866
2025/09/03 17:51:11 : Epoch: 399, Train_Loss: 0.00416288
2025/09/03 17:51:11 : Epoch: 399, Eval_Loss: 0.00562256
2025/09/03 17:51:12 : Epoch: 400, Train_Loss: 0.00426398
2025/09/03 17:51:12 : Epoch: 401, Train_Loss: 0.00359884
2025/09/03 17:51:13 : Epoch: 402, Train_Loss: 0.00349160
2025/09/03 17:51:13 : Epoch: 403, Train_Loss: 0.00341080
2025/09/03 17:51:13 : Epoch: 404, Train_Loss: 0.00311514
2025/09/03 17:51:13 : Epoch: 404, Eval_Loss: 0.00566764
2025/09/03 17:51:14 : Epoch: 405, Train_Loss: 0.00319802
2025/09/03 17:51:14 : Epoch: 406, Train_Loss: 0.00310359
2025/09/03 17:51:15 : Epoch: 407, Train_Loss: 0.00317940
2025/09/03 17:51:15 : Epoch: 408, Train_Loss: 0.00316723
2025/09/03 17:51:15 : Epoch: 409, Train_Loss: 0.00310771
2025/09/03 17:51:15 : Epoch: 409, Eval_Loss: 0.00615892
2025/09/03 17:51:16 : Epoch: 410, Train_Loss: 0.00411213
2025/09/03 17:51:16 : Epoch: 411, Train_Loss: 0.00458646
2025/09/03 17:51:17 : Epoch: 412, Train_Loss: 0.00391505
2025/09/03 17:51:17 : Epoch: 413, Train_Loss: 0.00344303
2025/09/03 17:51:17 : Epoch: 414, Train_Loss: 0.00295682
2025/09/03 17:51:18 : Epoch: 414, Eval_Loss: 0.00490782
2025/09/03 17:51:18 : Epoch: 414, Save the best checkpoint
2025/09/03 17:51:18 : Epoch: 415, Train_Loss: 0.00306362
2025/09/03 17:51:18 : Epoch: 416, Train_Loss: 0.00294910
2025/09/03 17:51:19 : Epoch: 417, Train_Loss: 0.00390718
2025/09/03 17:51:19 : Epoch: 418, Train_Loss: 0.00325102
2025/09/03 17:51:19 : Epoch: 419, Train_Loss: 0.00338045
2025/09/03 17:51:20 : Epoch: 419, Eval_Loss: 0.00507167
2025/09/03 17:51:20 : Epoch: 420, Train_Loss: 0.00335893
2025/09/03 17:51:20 : Epoch: 421, Train_Loss: 0.00336070
2025/09/03 17:51:21 : Epoch: 422, Train_Loss: 0.00415802
2025/09/03 17:51:21 : Epoch: 423, Train_Loss: 0.00459716
2025/09/03 17:51:22 : Epoch: 424, Train_Loss: 0.00407795
2025/09/03 17:51:22 : Epoch: 424, Eval_Loss: 0.00553522
2025/09/03 17:51:22 : Epoch: 425, Train_Loss: 0.00351380
2025/09/03 17:51:22 : Epoch: 426, Train_Loss: 0.00344322
2025/09/03 17:51:23 : Epoch: 427, Train_Loss: 0.00344693
2025/09/03 17:51:23 : Epoch: 428, Train_Loss: 0.00371135
2025/09/03 17:51:24 : Epoch: 429, Train_Loss: 0.00357611
2025/09/03 17:51:24 : Epoch: 429, Eval_Loss: 0.00596404
2025/09/03 17:51:24 : Epoch: 430, Train_Loss: 0.00353563
2025/09/03 17:51:24 : Epoch: 431, Train_Loss: 0.00474756
2025/09/03 17:51:25 : Epoch: 432, Train_Loss: 0.00518431
2025/09/03 17:51:25 : Epoch: 433, Train_Loss: 0.00468108
2025/09/03 17:51:26 : Epoch: 434, Train_Loss: 0.00453628
2025/09/03 17:51:26 : Epoch: 434, Eval_Loss: 0.00571097
2025/09/03 17:51:26 : Epoch: 435, Train_Loss: 0.00409870
2025/09/03 17:51:27 : Epoch: 436, Train_Loss: 0.00372503
2025/09/03 17:51:27 : Epoch: 437, Train_Loss: 0.00335731
2025/09/03 17:51:27 : Epoch: 438, Train_Loss: 0.00352926
2025/09/03 17:51:28 : Epoch: 439, Train_Loss: 0.00475290
2025/09/03 17:51:28 : Epoch: 439, Eval_Loss: 0.00557745
2025/09/03 17:51:28 : Epoch: 440, Train_Loss: 0.00422972
2025/09/03 17:51:29 : Epoch: 441, Train_Loss: 0.00386864
2025/09/03 17:51:29 : Epoch: 442, Train_Loss: 0.00342276
2025/09/03 17:51:29 : Epoch: 443, Train_Loss: 0.00338776
2025/09/03 17:51:30 : Epoch: 444, Train_Loss: 0.00342920
2025/09/03 17:51:30 : Epoch: 444, Eval_Loss: 0.00649133
2025/09/03 17:51:30 : Epoch: 445, Train_Loss: 0.00522216
2025/09/03 17:51:31 : Epoch: 446, Train_Loss: 0.00670014
2025/09/03 17:51:31 : Epoch: 447, Train_Loss: 0.00624407
2025/09/03 17:51:31 : Epoch: 448, Train_Loss: 0.00603262
2025/09/03 17:51:32 : Epoch: 449, Train_Loss: 0.00586572
2025/09/03 17:51:32 : Epoch: 449, Eval_Loss: 0.00670811
2025/09/03 17:51:32 : Epoch: 450, Train_Loss: 0.00528264
2025/09/03 17:51:33 : Epoch: 451, Train_Loss: 0.00466207
2025/09/03 17:51:33 : Epoch: 452, Train_Loss: 0.00404408
2025/09/03 17:51:34 : Epoch: 453, Train_Loss: 0.00372951
2025/09/03 17:51:34 : Epoch: 454, Train_Loss: 0.00342362
2025/09/03 17:51:34 : Epoch: 454, Eval_Loss: 0.00498547
2025/09/03 17:51:34 : Epoch: 455, Train_Loss: 0.00331120
2025/09/03 17:51:35 : Epoch: 456, Train_Loss: 0.00317320
2025/09/03 17:51:35 : Epoch: 457, Train_Loss: 0.00307902
2025/09/03 17:51:36 : Epoch: 458, Train_Loss: 0.00337758
2025/09/03 17:51:36 : Epoch: 459, Train_Loss: 0.00316189
2025/09/03 17:51:36 : Epoch: 459, Eval_Loss: 0.00630431
2025/09/03 17:51:37 : Epoch: 460, Train_Loss: 0.00346890
2025/09/03 17:51:37 : Epoch: 461, Train_Loss: 0.00379981
2025/09/03 17:51:37 : Epoch: 462, Train_Loss: 0.00412428
2025/09/03 17:51:38 : Epoch: 463, Train_Loss: 0.00407981
2025/09/03 17:51:38 : Epoch: 464, Train_Loss: 0.00333930
2025/09/03 17:51:38 : Epoch: 464, Eval_Loss: 0.00622733
2025/09/03 17:51:39 : Epoch: 465, Train_Loss: 0.00304891
2025/09/03 17:51:39 : Epoch: 466, Train_Loss: 0.00383981
2025/09/03 17:51:39 : Epoch: 467, Train_Loss: 0.00502316
2025/09/03 17:51:40 : Epoch: 468, Train_Loss: 0.00574323
2025/09/03 17:51:40 : Epoch: 469, Train_Loss: 0.00576642
2025/09/03 17:51:40 : Epoch: 469, Eval_Loss: 0.00575786
2025/09/03 17:51:41 : Epoch: 470, Train_Loss: 0.00470443
2025/09/03 17:51:41 : Epoch: 471, Train_Loss: 0.00436865
2025/09/03 17:51:41 : Epoch: 472, Train_Loss: 0.00376702
2025/09/03 17:51:42 : Epoch: 473, Train_Loss: 0.00349260
2025/09/03 17:51:42 : Epoch: 474, Train_Loss: 0.00356451
2025/09/03 17:51:42 : Epoch: 474, Eval_Loss: 0.00471450
2025/09/03 17:51:42 : Epoch: 474, Save the best checkpoint
2025/09/03 17:51:43 : Epoch: 475, Train_Loss: 0.00379928
2025/09/03 17:51:43 : Epoch: 476, Train_Loss: 0.00366962
2025/09/03 17:51:43 : Epoch: 477, Train_Loss: 0.00296413
2025/09/03 17:51:44 : Epoch: 478, Train_Loss: 0.00374443
2025/09/03 17:51:44 : Epoch: 479, Train_Loss: 0.00428604
2025/09/03 17:51:44 : Epoch: 479, Eval_Loss: 0.00496203
2025/09/03 17:51:45 : Epoch: 480, Train_Loss: 0.00352114
2025/09/03 17:51:45 : Epoch: 481, Train_Loss: 0.00387408
2025/09/03 17:51:46 : Epoch: 482, Train_Loss: 0.00382910
2025/09/03 17:51:46 : Epoch: 483, Train_Loss: 0.00461289
2025/09/03 17:51:46 : Epoch: 484, Train_Loss: 0.00359129
2025/09/03 17:51:46 : Epoch: 484, Eval_Loss: 0.00671181
2025/09/03 17:51:47 : Epoch: 485, Train_Loss: 0.00365203
2025/09/03 17:51:47 : Epoch: 486, Train_Loss: 0.00369316
2025/09/03 17:51:48 : Epoch: 487, Train_Loss: 0.00370794
2025/09/03 17:51:48 : Epoch: 488, Train_Loss: 0.00377064
2025/09/03 17:51:48 : Epoch: 489, Train_Loss: 0.00408606
2025/09/03 17:51:49 : Epoch: 489, Eval_Loss: 0.00596239
2025/09/03 17:51:49 : Epoch: 490, Train_Loss: 0.00446616
2025/09/03 17:51:49 : Epoch: 491, Train_Loss: 0.00393749
2025/09/03 17:51:50 : Epoch: 492, Train_Loss: 0.00351000
2025/09/03 17:51:50 : Epoch: 493, Train_Loss: 0.00391911
2025/09/03 17:51:50 : Epoch: 494, Train_Loss: 0.00375176
2025/09/03 17:51:51 : Epoch: 494, Eval_Loss: 0.00578017
2025/09/03 17:51:51 : Epoch: 495, Train_Loss: 0.00336622
2025/09/03 17:51:51 : Epoch: 496, Train_Loss: 0.00306689
2025/09/03 17:51:52 : Epoch: 497, Train_Loss: 0.00282342
2025/09/03 17:51:52 : Epoch: 498, Train_Loss: 0.00268004
2025/09/03 17:51:53 : Epoch: 499, Train_Loss: 0.00242916
2025/09/03 17:51:53 : Epoch: 499, Eval_Loss: 0.00612880
2025/09/03 17:51:53 : Epoch: 500, Train_Loss: 0.00258310
2025/09/03 17:51:53 : Epoch: 501, Train_Loss: 0.00243653
2025/09/03 17:51:54 : Epoch: 502, Train_Loss: 0.00262881
2025/09/03 17:51:54 : Epoch: 503, Train_Loss: 0.00270866
2025/09/03 17:51:55 : Epoch: 504, Train_Loss: 0.00271772
2025/09/03 17:51:55 : Epoch: 504, Eval_Loss: 0.00701970
2025/09/03 17:51:55 : Epoch: 505, Train_Loss: 0.00275996
2025/09/03 17:51:55 : Epoch: 506, Train_Loss: 0.00317034
2025/09/03 17:51:56 : Epoch: 507, Train_Loss: 0.00297941
2025/09/03 17:51:56 : Epoch: 508, Train_Loss: 0.00296299
2025/09/03 17:51:57 : Epoch: 509, Train_Loss: 0.00364874
2025/09/03 17:51:57 : Epoch: 509, Eval_Loss: 0.00581219
2025/09/03 17:51:57 : Epoch: 510, Train_Loss: 0.00324700
2025/09/03 17:51:58 : Epoch: 511, Train_Loss: 0.00317771
2025/09/03 17:51:58 : Epoch: 512, Train_Loss: 0.00304195
2025/09/03 17:51:58 : Epoch: 513, Train_Loss: 0.00391115
2025/09/03 17:51:59 : Epoch: 514, Train_Loss: 0.00372235
2025/09/03 17:51:59 : Epoch: 514, Eval_Loss: 0.00567114
2025/09/03 17:51:59 : Epoch: 515, Train_Loss: 0.00349535
2025/09/03 17:52:00 : Epoch: 516, Train_Loss: 0.00312496
2025/09/03 17:52:00 : Epoch: 517, Train_Loss: 0.00286473
2025/09/03 17:52:00 : Epoch: 518, Train_Loss: 0.00271124
2025/09/03 17:52:01 : Epoch: 519, Train_Loss: 0.00272416
2025/09/03 17:52:01 : Epoch: 519, Eval_Loss: 0.00452187
2025/09/03 17:52:01 : Epoch: 519, Save the best checkpoint
2025/09/03 17:52:01 : Epoch: 520, Train_Loss: 0.00280487
2025/09/03 17:52:02 : Epoch: 521, Train_Loss: 0.00363720
2025/09/03 17:52:02 : Epoch: 522, Train_Loss: 0.00444227
2025/09/03 17:52:02 : Epoch: 523, Train_Loss: 0.00383853
2025/09/03 17:52:03 : Epoch: 524, Train_Loss: 0.00347596
2025/09/03 17:52:03 : Epoch: 524, Eval_Loss: 0.00611634
2025/09/03 17:52:03 : Epoch: 525, Train_Loss: 0.00316321
2025/09/03 17:52:04 : Epoch: 526, Train_Loss: 0.00308641
2025/09/03 17:52:04 : Epoch: 527, Train_Loss: 0.00255277
2025/09/03 17:52:05 : Epoch: 528, Train_Loss: 0.00247034
2025/09/03 17:52:05 : Epoch: 529, Train_Loss: 0.00229153
2025/09/03 17:52:05 : Epoch: 529, Eval_Loss: 0.00539956
2025/09/03 17:52:05 : Epoch: 530, Train_Loss: 0.00224686
2025/09/03 17:52:06 : Epoch: 531, Train_Loss: 0.00230415
2025/09/03 17:52:06 : Epoch: 532, Train_Loss: 0.00360522
2025/09/03 17:52:07 : Epoch: 533, Train_Loss: 0.00264806
2025/09/03 17:52:07 : Epoch: 534, Train_Loss: 0.00268082
2025/09/03 17:52:07 : Epoch: 534, Eval_Loss: 0.00505416
2025/09/03 17:52:08 : Epoch: 535, Train_Loss: 0.00249820
2025/09/03 17:52:08 : Epoch: 536, Train_Loss: 0.00276492
2025/09/03 17:52:08 : Epoch: 537, Train_Loss: 0.00285453
2025/09/03 17:52:09 : Epoch: 538, Train_Loss: 0.00323071
2025/09/03 17:52:09 : Epoch: 539, Train_Loss: 0.00297967
2025/09/03 17:52:09 : Epoch: 539, Eval_Loss: 0.00542853
2025/09/03 17:52:10 : Epoch: 540, Train_Loss: 0.00258392
2025/09/03 17:52:10 : Epoch: 541, Train_Loss: 0.00244103
2025/09/03 17:52:10 : Epoch: 542, Train_Loss: 0.00243459
2025/09/03 17:52:11 : Epoch: 543, Train_Loss: 0.00270654
2025/09/03 17:52:11 : Epoch: 544, Train_Loss: 0.00397076
2025/09/03 17:52:11 : Epoch: 544, Eval_Loss: 0.00524036
2025/09/03 17:52:12 : Epoch: 545, Train_Loss: 0.00359884
2025/09/03 17:52:12 : Epoch: 546, Train_Loss: 0.00289956
2025/09/03 17:52:12 : Epoch: 547, Train_Loss: 0.00281096
2025/09/03 17:52:13 : Epoch: 548, Train_Loss: 0.00231276
2025/09/03 17:52:13 : Epoch: 549, Train_Loss: 0.00245179
2025/09/03 17:52:13 : Epoch: 549, Eval_Loss: 0.00669117
2025/09/03 17:52:14 : Epoch: 550, Train_Loss: 0.00354750
2025/09/03 17:52:14 : Epoch: 551, Train_Loss: 0.00364509
2025/09/03 17:52:15 : Epoch: 552, Train_Loss: 0.00310969
2025/09/03 17:52:15 : Epoch: 553, Train_Loss: 0.00377174
2025/09/03 17:52:15 : Epoch: 554, Train_Loss: 0.00392224
2025/09/03 17:52:15 : Epoch: 554, Eval_Loss: 0.00511012
2025/09/03 17:52:16 : Epoch: 555, Train_Loss: 0.00386097
2025/09/03 17:52:16 : Epoch: 556, Train_Loss: 0.00311626
2025/09/03 17:52:17 : Epoch: 557, Train_Loss: 0.00291374
2025/09/03 17:52:17 : Epoch: 558, Train_Loss: 0.00286817
2025/09/03 17:52:17 : Epoch: 559, Train_Loss: 0.00274912
2025/09/03 17:52:17 : Epoch: 559, Eval_Loss: 0.00665062
2025/09/03 17:52:18 : Epoch: 560, Train_Loss: 0.00302700
2025/09/03 17:52:18 : Epoch: 561, Train_Loss: 0.00295703
2025/09/03 17:52:19 : Epoch: 562, Train_Loss: 0.00264126
2025/09/03 17:52:19 : Epoch: 563, Train_Loss: 0.00285217
2025/09/03 17:52:19 : Epoch: 564, Train_Loss: 0.00348091
2025/09/03 17:52:20 : Epoch: 564, Eval_Loss: 0.00517125
2025/09/03 17:52:20 : Epoch: 565, Train_Loss: 0.00377787
2025/09/03 17:52:20 : Epoch: 566, Train_Loss: 0.00285851
2025/09/03 17:52:21 : Epoch: 567, Train_Loss: 0.00252959
2025/09/03 17:52:21 : Epoch: 568, Train_Loss: 0.00292519
2025/09/03 17:52:21 : Epoch: 569, Train_Loss: 0.00290933
2025/09/03 17:52:22 : Epoch: 569, Eval_Loss: 0.00590176
2025/09/03 17:52:22 : Epoch: 570, Train_Loss: 0.00327682
2025/09/03 17:52:22 : Epoch: 571, Train_Loss: 0.00298409
2025/09/03 17:52:23 : Epoch: 572, Train_Loss: 0.00286044
2025/09/03 17:52:23 : Epoch: 573, Train_Loss: 0.00282385
2025/09/03 17:52:24 : Epoch: 574, Train_Loss: 0.00292190
2025/09/03 17:52:24 : Epoch: 574, Eval_Loss: 0.00599672
2025/09/03 17:52:24 : Epoch: 575, Train_Loss: 0.00376074
2025/09/03 17:52:24 : Epoch: 576, Train_Loss: 0.00429900
2025/09/03 17:52:25 : Epoch: 577, Train_Loss: 0.00377648
2025/09/03 17:52:25 : Epoch: 578, Train_Loss: 0.00344228
2025/09/03 17:52:26 : Epoch: 579, Train_Loss: 0.00363100
2025/09/03 17:52:26 : Epoch: 579, Eval_Loss: 0.00535943
2025/09/03 17:52:26 : Epoch: 580, Train_Loss: 0.00310967
2025/09/03 17:52:27 : Epoch: 581, Train_Loss: 0.00293688
2025/09/03 17:52:27 : Epoch: 582, Train_Loss: 0.00409571
2025/09/03 17:52:27 : Epoch: 583, Train_Loss: 0.00425950
2025/09/03 17:52:28 : Epoch: 584, Train_Loss: 0.00413172
2025/09/03 17:52:28 : Epoch: 584, Eval_Loss: 0.00622412
2025/09/03 17:52:28 : Epoch: 585, Train_Loss: 0.00358775
2025/09/03 17:52:29 : Epoch: 586, Train_Loss: 0.00364498
2025/09/03 17:52:29 : Epoch: 587, Train_Loss: 0.00324696
2025/09/03 17:52:29 : Epoch: 588, Train_Loss: 0.00268194
2025/09/03 17:52:30 : Epoch: 589, Train_Loss: 0.00261719
2025/09/03 17:52:30 : Epoch: 589, Eval_Loss: 0.00547754
2025/09/03 17:52:30 : Epoch: 590, Train_Loss: 0.00221582
2025/09/03 17:52:31 : Epoch: 591, Train_Loss: 0.00239095
2025/09/03 17:52:31 : Epoch: 592, Train_Loss: 0.00217410
2025/09/03 17:52:31 : Epoch: 593, Train_Loss: 0.00237926
2025/09/03 17:52:32 : Epoch: 594, Train_Loss: 0.00232734
2025/09/03 17:52:32 : Epoch: 594, Eval_Loss: 0.00561240
2025/09/03 17:52:32 : Epoch: 595, Train_Loss: 0.00250600
2025/09/03 17:52:33 : Epoch: 596, Train_Loss: 0.00286531
2025/09/03 17:52:33 : Epoch: 597, Train_Loss: 0.00255532
2025/09/03 17:52:34 : Epoch: 598, Train_Loss: 0.00259946
2025/09/03 17:52:34 : Epoch: 599, Train_Loss: 0.00228466
2025/09/03 17:52:34 : Epoch: 599, Eval_Loss: 0.00563502
2025/09/03 17:52:34 : Epoch: 600, Train_Loss: 0.00226593
2025/09/03 17:52:35 : Epoch: 601, Train_Loss: 0.00210238
2025/09/03 17:52:35 : Epoch: 602, Train_Loss: 0.00211177
2025/09/03 17:52:36 : Epoch: 603, Train_Loss: 0.00201793
2025/09/03 17:52:36 : Epoch: 604, Train_Loss: 0.00201432
2025/09/03 17:52:36 : Epoch: 604, Eval_Loss: 0.00503366
2025/09/03 17:52:37 : Epoch: 605, Train_Loss: 0.00185366
2025/09/03 17:52:37 : Epoch: 606, Train_Loss: 0.00204464
2025/09/03 17:52:37 : Epoch: 607, Train_Loss: 0.00208251
2025/09/03 17:52:38 : Epoch: 608, Train_Loss: 0.00244020
2025/09/03 17:52:38 : Epoch: 609, Train_Loss: 0.00357313
2025/09/03 17:52:38 : Epoch: 609, Eval_Loss: 0.00573368
2025/09/03 17:52:39 : Epoch: 610, Train_Loss: 0.00301410
2025/09/03 17:52:39 : Epoch: 611, Train_Loss: 0.00305284
2025/09/03 17:52:39 : Epoch: 612, Train_Loss: 0.00284919
2025/09/03 17:52:40 : Epoch: 613, Train_Loss: 0.00248878
2025/09/03 17:52:40 : Epoch: 614, Train_Loss: 0.00262073
2025/09/03 17:52:40 : Epoch: 614, Eval_Loss: 0.00460281
2025/09/03 17:52:41 : Epoch: 615, Train_Loss: 0.00268994
2025/09/03 17:52:41 : Epoch: 616, Train_Loss: 0.00239412
2025/09/03 17:52:41 : Epoch: 617, Train_Loss: 0.00239606
2025/09/03 17:52:42 : Epoch: 618, Train_Loss: 0.00237798
2025/09/03 17:52:42 : Epoch: 619, Train_Loss: 0.00235606
2025/09/03 17:52:42 : Epoch: 619, Eval_Loss: 0.00692490
2025/09/03 17:52:43 : Epoch: 620, Train_Loss: 0.00296433
2025/09/03 17:52:43 : Epoch: 621, Train_Loss: 0.00298952
2025/09/03 17:52:43 : Epoch: 622, Train_Loss: 0.00299537
2025/09/03 17:52:44 : Epoch: 623, Train_Loss: 0.00275321
2025/09/03 17:52:44 : Epoch: 624, Train_Loss: 0.00300483
2025/09/03 17:52:44 : Epoch: 624, Eval_Loss: 0.00659010
2025/09/03 17:52:45 : Epoch: 625, Train_Loss: 0.00379744
2025/09/03 17:52:45 : Epoch: 626, Train_Loss: 0.00461559
2025/09/03 17:52:46 : Epoch: 627, Train_Loss: 0.00340632
2025/09/03 17:52:46 : Epoch: 628, Train_Loss: 0.00338558
2025/09/03 17:52:46 : Epoch: 629, Train_Loss: 0.00320481
2025/09/03 17:52:46 : Epoch: 629, Eval_Loss: 0.00505929
2025/09/03 17:52:47 : Epoch: 630, Train_Loss: 0.00342773
2025/09/03 17:52:47 : Epoch: 631, Train_Loss: 0.00306849
2025/09/03 17:52:48 : Epoch: 632, Train_Loss: 0.00272800
2025/09/03 17:52:48 : Epoch: 633, Train_Loss: 0.00251467
2025/09/03 17:52:48 : Epoch: 634, Train_Loss: 0.00236808
2025/09/03 17:52:49 : Epoch: 634, Eval_Loss: 0.00662611
2025/09/03 17:52:49 : Epoch: 635, Train_Loss: 0.00274584
2025/09/03 17:52:49 : Epoch: 636, Train_Loss: 0.00305086
2025/09/03 17:52:50 : Epoch: 637, Train_Loss: 0.00327738
2025/09/03 17:52:50 : Epoch: 638, Train_Loss: 0.00294014
2025/09/03 17:52:50 : Epoch: 639, Train_Loss: 0.00285947
2025/09/03 17:52:51 : Epoch: 639, Eval_Loss: 0.00646404
2025/09/03 17:52:51 : Epoch: 640, Train_Loss: 0.00276453
2025/09/03 17:52:51 : Epoch: 641, Train_Loss: 0.00324567
2025/09/03 17:52:52 : Epoch: 642, Train_Loss: 0.00322519
2025/09/03 17:52:52 : Epoch: 643, Train_Loss: 0.00310784
2025/09/03 17:52:53 : Epoch: 644, Train_Loss: 0.00272098
2025/09/03 17:52:53 : Epoch: 644, Eval_Loss: 0.00533698
2025/09/03 17:52:53 : Epoch: 645, Train_Loss: 0.00245913
2025/09/03 17:52:53 : Epoch: 646, Train_Loss: 0.00236841
2025/09/03 17:52:54 : Epoch: 647, Train_Loss: 0.00236299
2025/09/03 17:52:54 : Epoch: 648, Train_Loss: 0.00237564
2025/09/03 17:52:55 : Epoch: 649, Train_Loss: 0.00251884
2025/09/03 17:52:55 : Epoch: 649, Eval_Loss: 0.00567069
2025/09/03 17:52:55 : Epoch: 650, Train_Loss: 0.00290970
2025/09/03 17:52:55 : Epoch: 651, Train_Loss: 0.00288750
2025/09/03 17:52:56 : Epoch: 652, Train_Loss: 0.00241271
2025/09/03 17:52:56 : Epoch: 653, Train_Loss: 0.00211767
2025/09/03 17:52:57 : Epoch: 654, Train_Loss: 0.00187158
2025/09/03 17:52:57 : Epoch: 654, Eval_Loss: 0.00551247
2025/09/03 17:52:57 : Epoch: 655, Train_Loss: 0.00195316
2025/09/03 17:52:58 : Epoch: 656, Train_Loss: 0.00220328
2025/09/03 17:52:58 : Epoch: 657, Train_Loss: 0.00257197
2025/09/03 17:52:58 : Epoch: 658, Train_Loss: 0.00300472
2025/09/03 17:52:59 : Epoch: 659, Train_Loss: 0.00313964
2025/09/03 17:52:59 : Epoch: 659, Eval_Loss: 0.00514630
2025/09/03 17:52:59 : Epoch: 660, Train_Loss: 0.00270115
2025/09/03 17:53:00 : Epoch: 661, Train_Loss: 0.00237903
2025/09/03 17:53:00 : Epoch: 662, Train_Loss: 0.00215602
2025/09/03 17:53:00 : Epoch: 663, Train_Loss: 0.00216978
2025/09/03 17:53:01 : Epoch: 664, Train_Loss: 0.00304298
2025/09/03 17:53:01 : Epoch: 664, Eval_Loss: 0.00613359
2025/09/03 17:53:01 : Epoch: 665, Train_Loss: 0.00371718
2025/09/03 17:53:02 : Epoch: 666, Train_Loss: 0.00348794
2025/09/03 17:53:02 : Epoch: 667, Train_Loss: 0.00301605
2025/09/03 17:53:02 : Epoch: 668, Train_Loss: 0.00325037
2025/09/03 17:53:03 : Epoch: 669, Train_Loss: 0.00343230
2025/09/03 17:53:03 : Epoch: 669, Eval_Loss: 0.00521957
2025/09/03 17:53:03 : Epoch: 670, Train_Loss: 0.00335905
2025/09/03 17:53:04 : Epoch: 671, Train_Loss: 0.00327501
2025/09/03 17:53:04 : Epoch: 672, Train_Loss: 0.00325827
2025/09/03 17:53:05 : Epoch: 673, Train_Loss: 0.00279549
2025/09/03 17:53:05 : Epoch: 674, Train_Loss: 0.00245301
2025/09/03 17:53:05 : Epoch: 674, Eval_Loss: 0.00541013
2025/09/03 17:53:05 : Epoch: 675, Train_Loss: 0.00249677
2025/09/03 17:53:06 : Epoch: 676, Train_Loss: 0.00248487
2025/09/03 17:53:06 : Epoch: 677, Train_Loss: 0.00331204
2025/09/03 17:53:07 : Epoch: 678, Train_Loss: 0.00287708
2025/09/03 17:53:07 : Epoch: 679, Train_Loss: 0.00310880
2025/09/03 17:53:07 : Epoch: 679, Eval_Loss: 0.00505664
2025/09/03 17:53:07 : Epoch: 680, Train_Loss: 0.00309060
2025/09/03 17:53:08 : Epoch: 681, Train_Loss: 0.00267402
2025/09/03 17:53:08 : Epoch: 682, Train_Loss: 0.00244847
2025/09/03 17:53:09 : Epoch: 683, Train_Loss: 0.00240697
2025/09/03 17:53:09 : Epoch: 684, Train_Loss: 0.00214752
2025/09/03 17:53:09 : Epoch: 684, Eval_Loss: 0.00604427
2025/09/03 17:53:10 : Epoch: 685, Train_Loss: 0.00196071
2025/09/03 17:53:10 : Epoch: 686, Train_Loss: 0.00186921
2025/09/03 17:53:10 : Epoch: 687, Train_Loss: 0.00191918
2025/09/03 17:53:11 : Epoch: 688, Train_Loss: 0.00208417
2025/09/03 17:53:11 : Epoch: 689, Train_Loss: 0.00208571
2025/09/03 17:53:11 : Epoch: 689, Eval_Loss: 0.00677277
2025/09/03 17:53:12 : Epoch: 690, Train_Loss: 0.00213875
2025/09/03 17:53:12 : Epoch: 691, Train_Loss: 0.00240962
2025/09/03 17:53:12 : Epoch: 692, Train_Loss: 0.00247683
2025/09/03 17:53:13 : Epoch: 693, Train_Loss: 0.00221905
2025/09/03 17:53:13 : Epoch: 694, Train_Loss: 0.00240124
2025/09/03 17:53:13 : Epoch: 694, Eval_Loss: 0.00511603
2025/09/03 17:53:14 : Epoch: 695, Train_Loss: 0.00214474
2025/09/03 17:53:14 : Epoch: 696, Train_Loss: 0.00224425
2025/09/03 17:53:14 : Epoch: 697, Train_Loss: 0.00195576
2025/09/03 17:53:15 : Epoch: 698, Train_Loss: 0.00183004
2025/09/03 17:53:15 : Epoch: 699, Train_Loss: 0.00169230
2025/09/03 17:53:15 : Epoch: 699, Eval_Loss: 0.00565834
2025/09/03 17:53:16 : Epoch: 700, Train_Loss: 0.00174238
2025/09/03 17:53:16 : Epoch: 701, Train_Loss: 0.00165658
2025/09/03 17:53:17 : Epoch: 702, Train_Loss: 0.00166806
2025/09/03 17:53:17 : Epoch: 703, Train_Loss: 0.00169345
2025/09/03 17:53:17 : Epoch: 704, Train_Loss: 0.00177661
2025/09/03 17:53:17 : Epoch: 704, Eval_Loss: 0.00552695
2025/09/03 17:53:18 : Epoch: 705, Train_Loss: 0.00217259
2025/09/03 17:53:18 : Epoch: 706, Train_Loss: 0.00186114
2025/09/03 17:53:19 : Epoch: 707, Train_Loss: 0.00237967
2025/09/03 17:53:19 : Epoch: 708, Train_Loss: 0.00211444
2025/09/03 17:53:19 : Epoch: 709, Train_Loss: 0.00382338
2025/09/03 17:53:20 : Epoch: 709, Eval_Loss: 0.00531932
2025/09/03 17:53:20 : Epoch: 710, Train_Loss: 0.00428858
2025/09/03 17:53:20 : Epoch: 711, Train_Loss: 0.00418712
2025/09/03 17:53:21 : Epoch: 712, Train_Loss: 0.00361386
2025/09/03 17:53:21 : Epoch: 713, Train_Loss: 0.00363190
2025/09/03 17:53:21 : Epoch: 714, Train_Loss: 0.00381377
2025/09/03 17:53:22 : Epoch: 714, Eval_Loss: 0.00582435
2025/09/03 17:53:22 : Epoch: 715, Train_Loss: 0.00333216
2025/09/03 17:53:22 : Epoch: 716, Train_Loss: 0.00298282
2025/09/03 17:53:23 : Epoch: 717, Train_Loss: 0.00296861
2025/09/03 17:53:23 : Epoch: 718, Train_Loss: 0.00265012
2025/09/03 17:53:24 : Epoch: 719, Train_Loss: 0.00326482
2025/09/03 17:53:24 : Epoch: 719, Eval_Loss: 0.00616017
2025/09/03 17:53:24 : Epoch: 720, Train_Loss: 0.00356171
2025/09/03 17:53:24 : Epoch: 721, Train_Loss: 0.00338087
2025/09/03 17:53:25 : Epoch: 722, Train_Loss: 0.00280395
2025/09/03 17:53:25 : Epoch: 723, Train_Loss: 0.00236724
2025/09/03 17:53:26 : Epoch: 724, Train_Loss: 0.00294319
2025/09/03 17:53:26 : Epoch: 724, Eval_Loss: 0.00608742
2025/09/03 17:53:26 : Epoch: 725, Train_Loss: 0.00279540
2025/09/03 17:53:26 : Epoch: 726, Train_Loss: 0.00258816
2025/09/03 17:53:27 : Epoch: 727, Train_Loss: 0.00257016
2025/09/03 17:53:27 : Epoch: 728, Train_Loss: 0.00229067
2025/09/03 17:53:28 : Epoch: 729, Train_Loss: 0.00201984
2025/09/03 17:53:28 : Epoch: 729, Eval_Loss: 0.00571604
2025/09/03 17:53:28 : Epoch: 730, Train_Loss: 0.00200798
2025/09/03 17:53:29 : Epoch: 731, Train_Loss: 0.00180521
2025/09/03 17:53:29 : Epoch: 732, Train_Loss: 0.00191724
2025/09/03 17:53:29 : Epoch: 733, Train_Loss: 0.00188472
2025/09/03 17:53:30 : Epoch: 734, Train_Loss: 0.00184607
2025/09/03 17:53:30 : Epoch: 734, Eval_Loss: 0.00503419
2025/09/03 17:53:30 : Epoch: 735, Train_Loss: 0.00211071
2025/09/03 17:53:31 : Epoch: 736, Train_Loss: 0.00180943
2025/09/03 17:53:31 : Epoch: 737, Train_Loss: 0.00194055
2025/09/03 17:53:31 : Epoch: 738, Train_Loss: 0.00192858
2025/09/03 17:53:32 : Epoch: 739, Train_Loss: 0.00182054
2025/09/03 17:53:32 : Epoch: 739, Eval_Loss: 0.00654426
2025/09/03 17:53:32 : Epoch: 740, Train_Loss: 0.00181945
2025/09/03 17:53:33 : Epoch: 741, Train_Loss: 0.00160005
2025/09/03 17:53:33 : Epoch: 742, Train_Loss: 0.00163418
2025/09/03 17:53:33 : Epoch: 743, Train_Loss: 0.00171368
2025/09/03 17:53:34 : Epoch: 744, Train_Loss: 0.00183510
2025/09/03 17:53:34 : Epoch: 744, Eval_Loss: 0.00557308
2025/09/03 17:53:34 : Epoch: 745, Train_Loss: 0.00166478
2025/09/03 17:53:35 : Epoch: 746, Train_Loss: 0.00161239
2025/09/03 17:53:35 : Epoch: 747, Train_Loss: 0.00156803
2025/09/03 17:53:36 : Epoch: 748, Train_Loss: 0.00158282
2025/09/03 17:53:36 : Epoch: 749, Train_Loss: 0.00157106
2025/09/03 17:53:36 : Epoch: 749, Eval_Loss: 0.00569422
2025/09/03 17:53:36 : Epoch: 750, Train_Loss: 0.00165240
2025/09/03 17:53:37 : Epoch: 751, Train_Loss: 0.00169161
2025/09/03 17:53:37 : Epoch: 752, Train_Loss: 0.00171233
2025/09/03 17:53:38 : Epoch: 753, Train_Loss: 0.00174313
2025/09/03 17:53:38 : Epoch: 754, Train_Loss: 0.00248693
2025/09/03 17:53:38 : Epoch: 754, Eval_Loss: 0.00722424
2025/09/03 17:53:39 : Epoch: 755, Train_Loss: 0.00354565
2025/09/03 17:53:39 : Epoch: 756, Train_Loss: 0.00300280
2025/09/03 17:53:39 : Epoch: 757, Train_Loss: 0.00293707
2025/09/03 17:53:40 : Epoch: 758, Train_Loss: 0.00265606
2025/09/03 17:53:40 : Epoch: 759, Train_Loss: 0.00264551
2025/09/03 17:53:40 : Epoch: 759, Eval_Loss: 0.00534776
2025/09/03 17:53:41 : Epoch: 760, Train_Loss: 0.00240276
2025/09/03 17:53:41 : Epoch: 761, Train_Loss: 0.00220695
2025/09/03 17:53:41 : Epoch: 762, Train_Loss: 0.00200129
2025/09/03 17:53:42 : Epoch: 763, Train_Loss: 0.00182860
2025/09/03 17:53:42 : Epoch: 764, Train_Loss: 0.00211694
2025/09/03 17:53:42 : Epoch: 764, Eval_Loss: 0.00420015
2025/09/03 17:53:42 : Epoch: 764, Save the best checkpoint
2025/09/03 17:53:43 : Epoch: 765, Train_Loss: 0.00199648
2025/09/03 17:53:43 : Epoch: 766, Train_Loss: 0.00193507
2025/09/03 17:53:43 : Epoch: 767, Train_Loss: 0.00216392
2025/09/03 17:53:44 : Epoch: 768, Train_Loss: 0.00199475
2025/09/03 17:53:44 : Epoch: 769, Train_Loss: 0.00180818
2025/09/03 17:53:44 : Epoch: 769, Eval_Loss: 0.00577608
2025/09/03 17:53:45 : Epoch: 770, Train_Loss: 0.00169342
2025/09/03 17:53:45 : Epoch: 771, Train_Loss: 0.00157991
2025/09/03 17:53:46 : Epoch: 772, Train_Loss: 0.00160036
2025/09/03 17:53:46 : Epoch: 773, Train_Loss: 0.00166570
2025/09/03 17:53:46 : Epoch: 774, Train_Loss: 0.00162013
2025/09/03 17:53:46 : Epoch: 774, Eval_Loss: 0.00619325
2025/09/03 17:53:47 : Epoch: 775, Train_Loss: 0.00161384
2025/09/03 17:53:47 : Epoch: 776, Train_Loss: 0.00182988
2025/09/03 17:53:48 : Epoch: 777, Train_Loss: 0.00152347
2025/09/03 17:53:48 : Epoch: 778, Train_Loss: 0.00150241
2025/09/03 17:53:48 : Epoch: 779, Train_Loss: 0.00146807
2025/09/03 17:53:48 : Epoch: 779, Eval_Loss: 0.00586248
2025/09/03 17:53:49 : Epoch: 780, Train_Loss: 0.00141871
2025/09/03 17:53:49 : Epoch: 781, Train_Loss: 0.00137777
2025/09/03 17:53:50 : Epoch: 782, Train_Loss: 0.00127212
2025/09/03 17:53:50 : Epoch: 783, Train_Loss: 0.00144067
2025/09/03 17:53:50 : Epoch: 784, Train_Loss: 0.00172719
2025/09/03 17:53:51 : Epoch: 784, Eval_Loss: 0.00627204
2025/09/03 17:53:51 : Epoch: 785, Train_Loss: 0.00195466
2025/09/03 17:53:51 : Epoch: 786, Train_Loss: 0.00213983
2025/09/03 17:53:52 : Epoch: 787, Train_Loss: 0.00243924
2025/09/03 17:53:52 : Epoch: 788, Train_Loss: 0.00241739
2025/09/03 17:53:52 : Epoch: 789, Train_Loss: 0.00311047
2025/09/03 17:53:53 : Epoch: 789, Eval_Loss: 0.00494655
2025/09/03 17:53:53 : Epoch: 790, Train_Loss: 0.00246350
2025/09/03 17:53:53 : Epoch: 791, Train_Loss: 0.00274149
2025/09/03 17:53:54 : Epoch: 792, Train_Loss: 0.00255206
2025/09/03 17:53:54 : Epoch: 793, Train_Loss: 0.00223497
2025/09/03 17:53:55 : Epoch: 794, Train_Loss: 0.00201477
2025/09/03 17:53:55 : Epoch: 794, Eval_Loss: 0.00555665
2025/09/03 17:53:55 : Epoch: 795, Train_Loss: 0.00192588
2025/09/03 17:53:55 : Epoch: 796, Train_Loss: 0.00185444
2025/09/03 17:53:56 : Epoch: 797, Train_Loss: 0.00171910
2025/09/03 17:53:56 : Epoch: 798, Train_Loss: 0.00195956
2025/09/03 17:53:57 : Epoch: 799, Train_Loss: 0.00203719
2025/09/03 17:53:57 : Epoch: 799, Eval_Loss: 0.00553858
2025/09/03 17:53:57 : Epoch: 800, Train_Loss: 0.00169016
2025/09/03 17:53:58 : Epoch: 801, Train_Loss: 0.00162918
2025/09/03 17:53:58 : Epoch: 802, Train_Loss: 0.00172264
2025/09/03 17:53:58 : Epoch: 803, Train_Loss: 0.00176499
2025/09/03 17:53:59 : Epoch: 804, Train_Loss: 0.00169569
2025/09/03 17:53:59 : Epoch: 804, Eval_Loss: 0.00513259
2025/09/03 17:53:59 : Epoch: 805, Train_Loss: 0.00150291
2025/09/03 17:54:00 : Epoch: 806, Train_Loss: 0.00157156
2025/09/03 17:54:00 : Epoch: 807, Train_Loss: 0.00165451
2025/09/03 17:54:00 : Epoch: 808, Train_Loss: 0.00143026
2025/09/03 17:54:01 : Epoch: 809, Train_Loss: 0.00130230
2025/09/03 17:54:01 : Epoch: 809, Eval_Loss: 0.00488122
2025/09/03 17:54:01 : Epoch: 810, Train_Loss: 0.00132581
2025/09/03 17:54:02 : Epoch: 811, Train_Loss: 0.00124085
2025/09/03 17:54:02 : Epoch: 812, Train_Loss: 0.00125159
2025/09/03 17:54:02 : Epoch: 813, Train_Loss: 0.00115054
2025/09/03 17:54:03 : Epoch: 814, Train_Loss: 0.00120273
2025/09/03 17:54:03 : Epoch: 814, Eval_Loss: 0.00552945
2025/09/03 17:54:03 : Epoch: 815, Train_Loss: 0.00117440
2025/09/03 17:54:04 : Epoch: 816, Train_Loss: 0.00118341
2025/09/03 17:54:04 : Epoch: 817, Train_Loss: 0.00105166
2025/09/03 17:54:04 : Epoch: 818, Train_Loss: 0.00119417
2025/09/03 17:54:05 : Epoch: 819, Train_Loss: 0.00113562
2025/09/03 17:54:05 : Epoch: 819, Eval_Loss: 0.00519071
2025/09/03 17:54:05 : Epoch: 820, Train_Loss: 0.00119296
2025/09/03 17:54:06 : Epoch: 821, Train_Loss: 0.00108954
2025/09/03 17:54:06 : Epoch: 822, Train_Loss: 0.00129809
2025/09/03 17:54:07 : Epoch: 823, Train_Loss: 0.00158146
2025/09/03 17:54:07 : Epoch: 824, Train_Loss: 0.00147099
2025/09/03 17:54:07 : Epoch: 824, Eval_Loss: 0.00604557
2025/09/03 17:54:07 : Epoch: 825, Train_Loss: 0.00132580
2025/09/03 17:54:08 : Epoch: 826, Train_Loss: 0.00130536
2025/09/03 17:54:08 : Epoch: 827, Train_Loss: 0.00120661
2025/09/03 17:54:09 : Epoch: 828, Train_Loss: 0.00107802
2025/09/03 17:54:09 : Epoch: 829, Train_Loss: 0.00100439
2025/09/03 17:54:09 : Epoch: 829, Eval_Loss: 0.00607635
2025/09/03 17:54:10 : Epoch: 830, Train_Loss: 0.00104112
2025/09/03 17:54:10 : Epoch: 831, Train_Loss: 0.00096227
2025/09/03 17:54:10 : Epoch: 832, Train_Loss: 0.00100556
2025/09/03 17:54:11 : Epoch: 833, Train_Loss: 0.00103823
2025/09/03 17:54:11 : Epoch: 834, Train_Loss: 0.00114913
2025/09/03 17:54:11 : Epoch: 834, Eval_Loss: 0.00508253
2025/09/03 17:54:12 : Epoch: 835, Train_Loss: 0.00110423
2025/09/03 17:54:12 : Epoch: 836, Train_Loss: 0.00096860
2025/09/03 17:54:12 : Epoch: 837, Train_Loss: 0.00093425
2025/09/03 17:54:13 : Epoch: 838, Train_Loss: 0.00094710
2025/09/03 17:54:13 : Epoch: 839, Train_Loss: 0.00093107
2025/09/03 17:54:13 : Epoch: 839, Eval_Loss: 0.00577093
2025/09/03 17:54:14 : Epoch: 840, Train_Loss: 0.00101758
2025/09/03 17:54:14 : Epoch: 841, Train_Loss: 0.00100336
2025/09/03 17:54:14 : Epoch: 842, Train_Loss: 0.00096361
2025/09/03 17:54:15 : Epoch: 843, Train_Loss: 0.00099015
2025/09/03 17:54:15 : Epoch: 844, Train_Loss: 0.00094243
2025/09/03 17:54:15 : Epoch: 844, Eval_Loss: 0.00638994
2025/09/03 17:54:16 : Epoch: 845, Train_Loss: 0.00106671
2025/09/03 17:54:16 : Epoch: 846, Train_Loss: 0.00110951
2025/09/03 17:54:17 : Epoch: 847, Train_Loss: 0.00107861
2025/09/03 17:54:17 : Epoch: 848, Train_Loss: 0.00103154
2025/09/03 17:54:17 : Epoch: 849, Train_Loss: 0.00101123
2025/09/03 17:54:17 : Epoch: 849, Eval_Loss: 0.00537510
2025/09/03 17:54:18 : Epoch: 850, Train_Loss: 0.00137547
2025/09/03 17:54:18 : Epoch: 851, Train_Loss: 0.00128218
2025/09/03 17:54:19 : Epoch: 852, Train_Loss: 0.00110043
2025/09/03 17:54:19 : Epoch: 853, Train_Loss: 0.00099532
2025/09/03 17:54:19 : Epoch: 854, Train_Loss: 0.00203792
2025/09/03 17:54:20 : Epoch: 854, Eval_Loss: 0.00436908
2025/09/03 17:54:20 : Epoch: 855, Train_Loss: 0.00365862
2025/09/03 17:54:20 : Epoch: 856, Train_Loss: 0.00536653
2025/09/03 17:54:21 : Epoch: 857, Train_Loss: 0.00437861
2025/09/03 17:54:21 : Epoch: 858, Train_Loss: 0.00412813
2025/09/03 17:54:21 : Epoch: 859, Train_Loss: 0.00425125
2025/09/03 17:54:22 : Epoch: 859, Eval_Loss: 0.00461399
2025/09/03 17:54:22 : Epoch: 860, Train_Loss: 0.00388032
2025/09/03 17:54:22 : Epoch: 861, Train_Loss: 0.00262611
2025/09/03 17:54:23 : Epoch: 862, Train_Loss: 0.00299739
2025/09/03 17:54:23 : Epoch: 863, Train_Loss: 0.00288070
2025/09/03 17:54:23 : Epoch: 864, Train_Loss: 0.00268927
2025/09/03 17:54:24 : Epoch: 864, Eval_Loss: 0.00506384
2025/09/03 17:54:24 : Epoch: 865, Train_Loss: 0.00220615
2025/09/03 17:54:24 : Epoch: 866, Train_Loss: 0.00215098
2025/09/03 17:54:25 : Epoch: 867, Train_Loss: 0.00200341
2025/09/03 17:54:25 : Epoch: 868, Train_Loss: 0.00191853
2025/09/03 17:54:26 : Epoch: 869, Train_Loss: 0.00192140
2025/09/03 17:54:26 : Epoch: 869, Eval_Loss: 0.00655469
2025/09/03 17:54:26 : Epoch: 870, Train_Loss: 0.00207041
2025/09/03 17:54:26 : Epoch: 871, Train_Loss: 0.00205092
2025/09/03 17:54:27 : Epoch: 872, Train_Loss: 0.00193785
2025/09/03 17:54:27 : Epoch: 873, Train_Loss: 0.00262259
2025/09/03 17:54:28 : Epoch: 874, Train_Loss: 0.00285340
2025/09/03 17:54:28 : Epoch: 874, Eval_Loss: 0.00512933
2025/09/03 17:54:28 : Epoch: 875, Train_Loss: 0.00223789
2025/09/03 17:54:29 : Epoch: 876, Train_Loss: 0.00221780
2025/09/03 17:54:29 : Epoch: 877, Train_Loss: 0.00199704
2025/09/03 17:54:29 : Epoch: 878, Train_Loss: 0.00216158
2025/09/03 17:54:30 : Epoch: 879, Train_Loss: 0.00192707
2025/09/03 17:54:30 : Epoch: 879, Eval_Loss: 0.00510843
2025/09/03 17:54:30 : Epoch: 880, Train_Loss: 0.00224254
2025/09/03 17:54:31 : Epoch: 881, Train_Loss: 0.00192393
2025/09/03 17:54:31 : Epoch: 882, Train_Loss: 0.00169606
2025/09/03 17:54:31 : Epoch: 883, Train_Loss: 0.00166325
2025/09/03 17:54:32 : Epoch: 884, Train_Loss: 0.00159608
2025/09/03 17:54:32 : Epoch: 884, Eval_Loss: 0.00576931
2025/09/03 17:54:32 : Epoch: 885, Train_Loss: 0.00137170
2025/09/03 17:54:33 : Epoch: 886, Train_Loss: 0.00147901
2025/09/03 17:54:33 : Epoch: 887, Train_Loss: 0.00132952
2025/09/03 17:54:33 : Epoch: 888, Train_Loss: 0.00144068
2025/09/03 17:54:34 : Epoch: 889, Train_Loss: 0.00137490
2025/09/03 17:54:34 : Epoch: 889, Eval_Loss: 0.00608127
2025/09/03 17:54:34 : Epoch: 890, Train_Loss: 0.00198161
2025/09/03 17:54:35 : Epoch: 891, Train_Loss: 0.00182598
2025/09/03 17:54:35 : Epoch: 892, Train_Loss: 0.00212153
2025/09/03 17:54:36 : Epoch: 893, Train_Loss: 0.00231159
2025/09/03 17:54:36 : Epoch: 894, Train_Loss: 0.00185083
2025/09/03 17:54:36 : Epoch: 894, Eval_Loss: 0.00466107
2025/09/03 17:54:36 : Epoch: 895, Train_Loss: 0.00223082
2025/09/03 17:54:37 : Epoch: 896, Train_Loss: 0.00194650
2025/09/03 17:54:37 : Epoch: 897, Train_Loss: 0.00225743
2025/09/03 17:54:38 : Epoch: 898, Train_Loss: 0.00232573
2025/09/03 17:54:38 : Epoch: 899, Train_Loss: 0.00161596
2025/09/03 17:54:38 : Epoch: 899, Eval_Loss: 0.00526543
2025/09/03 17:54:38 : Epoch: 900, Train_Loss: 0.00155561
2025/09/03 17:54:39 : Epoch: 901, Train_Loss: 0.00155803
2025/09/03 17:54:39 : Epoch: 902, Train_Loss: 0.00232469
2025/09/03 17:54:40 : Epoch: 903, Train_Loss: 0.00144104
2025/09/03 17:54:40 : Epoch: 904, Train_Loss: 0.00144314
2025/09/03 17:54:40 : Epoch: 904, Eval_Loss: 0.00582930
2025/09/03 17:54:41 : Epoch: 905, Train_Loss: 0.00136933
2025/09/03 17:54:41 : Epoch: 906, Train_Loss: 0.00138059
2025/09/03 17:54:41 : Epoch: 907, Train_Loss: 0.00126585
2025/09/03 17:54:42 : Epoch: 908, Train_Loss: 0.00144887
2025/09/03 17:54:42 : Epoch: 909, Train_Loss: 0.00140666
2025/09/03 17:54:42 : Epoch: 909, Eval_Loss: 0.00482868
2025/09/03 17:54:43 : Epoch: 910, Train_Loss: 0.00136632
2025/09/03 17:54:43 : Epoch: 911, Train_Loss: 0.00152975
2025/09/03 17:54:43 : Epoch: 912, Train_Loss: 0.00168144
2025/09/03 17:54:44 : Epoch: 913, Train_Loss: 0.00148898
2025/09/03 17:54:44 : Epoch: 914, Train_Loss: 0.00139461
2025/09/03 17:54:44 : Epoch: 914, Eval_Loss: 0.00423134
2025/09/03 17:54:45 : Epoch: 915, Train_Loss: 0.00137706
2025/09/03 17:54:45 : Epoch: 916, Train_Loss: 0.00116932
2025/09/03 17:54:45 : Epoch: 917, Train_Loss: 0.00110604
2025/09/03 17:54:46 : Epoch: 918, Train_Loss: 0.00116366
2025/09/03 17:54:46 : Epoch: 919, Train_Loss: 0.00116862
2025/09/03 17:54:46 : Epoch: 919, Eval_Loss: 0.00633306
2025/09/03 17:54:47 : Epoch: 920, Train_Loss: 0.00127125
2025/09/03 17:54:47 : Epoch: 921, Train_Loss: 0.00138114
2025/09/03 17:54:48 : Epoch: 922, Train_Loss: 0.00130526
2025/09/03 17:54:48 : Epoch: 923, Train_Loss: 0.00132661
2025/09/03 17:54:48 : Epoch: 924, Train_Loss: 0.00143381
2025/09/03 17:54:48 : Epoch: 924, Eval_Loss: 0.00461874
2025/09/03 17:54:49 : Epoch: 925, Train_Loss: 0.00145302
2025/09/03 17:54:49 : Epoch: 926, Train_Loss: 0.00235718
2025/09/03 17:54:50 : Epoch: 927, Train_Loss: 0.00195490
2025/09/03 17:54:50 : Epoch: 928, Train_Loss: 0.00278019
2025/09/03 17:54:50 : Epoch: 929, Train_Loss: 0.00464784
2025/09/03 17:54:51 : Epoch: 929, Eval_Loss: 0.00432036
2025/09/03 17:54:51 : Epoch: 930, Train_Loss: 0.00404808
2025/09/03 17:54:51 : Epoch: 931, Train_Loss: 0.00341450
2025/09/03 17:54:52 : Epoch: 932, Train_Loss: 0.00335581
2025/09/03 17:54:52 : Epoch: 933, Train_Loss: 0.00328726
2025/09/03 17:54:52 : Epoch: 934, Train_Loss: 0.00293136
2025/09/03 17:54:53 : Epoch: 934, Eval_Loss: 0.00491641
2025/09/03 17:54:53 : Epoch: 935, Train_Loss: 0.00294241
2025/09/03 17:54:53 : Epoch: 936, Train_Loss: 0.00244771
2025/09/03 17:54:54 : Epoch: 937, Train_Loss: 0.00214693
2025/09/03 17:54:54 : Epoch: 938, Train_Loss: 0.00200845
2025/09/03 17:54:55 : Epoch: 939, Train_Loss: 0.00197456
2025/09/03 17:54:55 : Epoch: 939, Eval_Loss: 0.00550564
2025/09/03 17:54:55 : Epoch: 940, Train_Loss: 0.00175507
2025/09/03 17:54:55 : Epoch: 941, Train_Loss: 0.00195851
2025/09/03 17:54:56 : Epoch: 942, Train_Loss: 0.00206539
2025/09/03 17:54:56 : Epoch: 943, Train_Loss: 0.00180787
2025/09/03 17:54:57 : Epoch: 944, Train_Loss: 0.00200583
2025/09/03 17:54:57 : Epoch: 944, Eval_Loss: 0.00548694
2025/09/03 17:54:57 : Epoch: 945, Train_Loss: 0.00187783
2025/09/03 17:54:57 : Epoch: 946, Train_Loss: 0.00228658
2025/09/03 17:54:58 : Epoch: 947, Train_Loss: 0.00206466
2025/09/03 17:54:58 : Epoch: 948, Train_Loss: 0.00222902
2025/09/03 17:54:59 : Epoch: 949, Train_Loss: 0.00171685
2025/09/03 17:54:59 : Epoch: 949, Eval_Loss: 0.00546424
2025/09/03 17:54:59 : Epoch: 950, Train_Loss: 0.00182961
2025/09/03 17:55:00 : Epoch: 951, Train_Loss: 0.00191580
2025/09/03 17:55:00 : Epoch: 952, Train_Loss: 0.00159216
2025/09/03 17:55:00 : Epoch: 953, Train_Loss: 0.00149640
2025/09/03 17:55:01 : Epoch: 954, Train_Loss: 0.00139610
2025/09/03 17:55:01 : Epoch: 954, Eval_Loss: 0.00588831
2025/09/03 17:55:01 : Epoch: 955, Train_Loss: 0.00147679
2025/09/03 17:55:02 : Epoch: 956, Train_Loss: 0.00121711
2025/09/03 17:55:02 : Epoch: 957, Train_Loss: 0.00164040
2025/09/03 17:55:02 : Epoch: 958, Train_Loss: 0.00140876
2025/09/03 17:55:03 : Epoch: 959, Train_Loss: 0.00133058
2025/09/03 17:55:03 : Epoch: 959, Eval_Loss: 0.00518340
2025/09/03 17:55:03 : Epoch: 960, Train_Loss: 0.00127699
2025/09/03 17:55:04 : Epoch: 961, Train_Loss: 0.00112551
2025/09/03 17:55:04 : Epoch: 962, Train_Loss: 0.00115954
2025/09/03 17:55:04 : Epoch: 963, Train_Loss: 0.00129083
2025/09/03 17:55:05 : Epoch: 964, Train_Loss: 0.00147102
2025/09/03 17:55:05 : Epoch: 964, Eval_Loss: 0.00452701
2025/09/03 17:55:05 : Epoch: 965, Train_Loss: 0.00115626
2025/09/03 17:55:06 : Epoch: 966, Train_Loss: 0.00139146
2025/09/03 17:55:06 : Epoch: 967, Train_Loss: 0.00133928
2025/09/03 17:55:07 : Epoch: 968, Train_Loss: 0.00117423
2025/09/03 17:55:07 : Epoch: 969, Train_Loss: 0.00708535
2025/09/03 17:55:07 : Epoch: 969, Eval_Loss: 0.00549851
2025/09/03 17:55:07 : Epoch: 970, Train_Loss: 0.00622508
2025/09/03 17:55:08 : Epoch: 971, Train_Loss: 0.00681770
2025/09/03 17:55:08 : Epoch: 972, Train_Loss: 0.00612834
2025/09/03 17:55:09 : Epoch: 973, Train_Loss: 0.00648049
2025/09/03 17:55:09 : Epoch: 974, Train_Loss: 0.00518885
2025/09/03 17:55:09 : Epoch: 974, Eval_Loss: 0.00560174
2025/09/03 17:55:10 : Epoch: 975, Train_Loss: 0.00677358
2025/09/03 17:55:10 : Epoch: 976, Train_Loss: 0.00929717
2025/09/03 17:55:10 : Epoch: 977, Train_Loss: 0.00865347
2025/09/03 17:55:11 : Epoch: 978, Train_Loss: 0.00813650
2025/09/03 17:55:11 : Epoch: 979, Train_Loss: 0.00762483
2025/09/03 17:55:11 : Epoch: 979, Eval_Loss: 0.00588874
2025/09/03 17:55:12 : Epoch: 980, Train_Loss: 0.00708195
2025/09/03 17:55:12 : Epoch: 981, Train_Loss: 0.01057230
2025/09/03 17:55:12 : Epoch: 982, Train_Loss: 0.00975657
2025/09/03 17:55:13 : Epoch: 983, Train_Loss: 0.00872964
2025/09/03 17:55:13 : Epoch: 984, Train_Loss: 0.00770304
2025/09/03 17:55:13 : Epoch: 984, Eval_Loss: 0.00561564
2025/09/03 17:55:14 : Epoch: 985, Train_Loss: 0.00713578
2025/09/03 17:55:14 : Epoch: 986, Train_Loss: 0.00689045
2025/09/03 17:55:14 : Epoch: 987, Train_Loss: 0.00631675
2025/09/03 17:55:15 : Epoch: 988, Train_Loss: 0.00571730
2025/09/03 17:55:15 : Epoch: 989, Train_Loss: 0.00520226
2025/09/03 17:55:15 : Epoch: 989, Eval_Loss: 0.00566891
2025/09/03 17:55:16 : Epoch: 990, Train_Loss: 0.00511262
2025/09/03 17:55:16 : Epoch: 991, Train_Loss: 0.00453080
2025/09/03 17:55:16 : Epoch: 992, Train_Loss: 0.00427414
2025/09/03 17:55:17 : Epoch: 993, Train_Loss: 0.00413820
2025/09/03 17:55:17 : Epoch: 994, Train_Loss: 0.00413176
2025/09/03 17:55:17 : Epoch: 994, Eval_Loss: 0.00603318
2025/09/03 17:55:18 : Epoch: 995, Train_Loss: 0.00567635
2025/09/03 17:55:18 : Epoch: 996, Train_Loss: 0.00562320
2025/09/03 17:55:19 : Epoch: 997, Train_Loss: 0.00601100
2025/09/03 17:55:19 : Epoch: 998, Train_Loss: 0.00563746
2025/09/03 17:55:19 : Epoch: 999, Train_Loss: 0.00529748
2025/09/03 17:55:19 : Epoch: 999, Eval_Loss: 0.00568312
