2025/09/16 21:59:33 : 

** GPU Info **
2025/09/16 21:59:33 : ====================================================================================================
2025/09/16 21:59:33 : My GPU is NVIDIA L40
2025/09/16 21:59:33 : ====================================================================================================
2025/09/16 21:59:54 : 

** Load Data **
2025/09/16 21:59:54 : ====================================================================================================
2025/09/16 21:59:54 : Response Type: Displacement
2025/09/16 21:59:54 : Train dataset: ['./Data/Nonlinear_Analysis/train/ChiChi_DBE', './Data/Nonlinear_Analysis/train/NGAWest2_DBE', './Data/Nonlinear_Analysis/train/ChiChi_MCE', './Data/Nonlinear_Analysis/train/NGAWest2_MCE']
2025/09/16 21:59:54 : Eval dataset: ['./Data/Nonlinear_Analysis/eval/ChiChi_DBE', './Data/Nonlinear_Analysis/eval/NGAWest2_DBE', './Data/Nonlinear_Analysis/eval/ChiChi_MCE', './Data/Nonlinear_Analysis/eval/NGAWest2_MCE']
2025/09/16 21:59:54 : # of effective train data: 20
2025/09/16 21:59:54 : # of effective eval data: 20
2025/09/16 21:59:54 : ====================================================================================================
2025/09/16 21:59:58 : 

** Get Normalization Dictionary **
2025/09/16 21:59:58 : ====================================================================================================
2025/09/16 21:59:58 : 
normalization dictionary: 
{'x': {'XYZ_gridline_num': tensor(8.), 'XYZ_grid_index': tensor(7.), 'period': tensor(1.3262), 'DOF': tensor(1.), 'mass': tensor(0.0255), 'XYZ_inertia': tensor(255288.), 'XYZ_mode_shape': tensor(1.8960)}, 'ground_motion': tensor(10479.9434), 'y': tensor(241.7000), 'edge_attr': {'S_y': tensor(3687090.), 'S_z': tensor(3687090.), 'area': tensor(30774.), 'element_length': tensor(8000.)}, 'response_type': 'Displacement'}
2025/09/16 21:59:58 : ====================================================================================================
2025/09/16 21:59:58 : 

** Model Info **
2025/09/16 21:59:58 : ====================================================================================================
2025/09/16 21:59:58 : GCN_LSTM(
  (GCN_Encoder): GCN_Encoder(
    (relu): ReLU()
    (dropout): Dropout(p=0.2, inplace=False)
    (conv1): GCNConv(15, 512)
    (conv2): GCNConv(512, 1024)
    (conv3): GCNConv(1024, 512)
  )
  (LSTM): LSTM(
    (lstm): LSTM(522, 512, num_layers=2, batch_first=True, dropout=0.2)
    (fc_out): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=8, bias=True)
    )
  )
)
2025/09/16 21:59:58 : ====================================================================================================
2025/09/16 21:59:58 : 

** Train **
2025/09/16 21:59:58 : ====================================================================================================
2025/09/16 21:59:58 :   Packed Mode = True
2025/09/16 21:59:58 :   Compression Rate of Ground Motion = 10
2025/09/16 21:59:58 :   Compression Rate of Response Sequence  = 1
2025/09/16 21:59:58 :   Compressed Seqence Length  = 2000
2025/09/16 21:59:58 :   Num Epochs = 2000
2025/09/16 21:59:58 :   Num Train Examples = 20
2025/09/16 21:59:58 :   Num Eval Examples = 20
2025/09/16 21:59:58 :   Batch Size = 16
2025/09/16 21:59:58 :   Evaluation Interval = 5
2025/09/16 21:59:58 :   Plot Interval = 400
2025/09/16 21:59:58 : ====================================================================================================
2025/09/16 21:59:58 : Epoch: 000, Train_Loss: 0.00985058
2025/09/16 21:59:59 : Epoch: 001, Train_Loss: 0.00952906
2025/09/16 21:59:59 : Epoch: 002, Train_Loss: 0.01265377
2025/09/16 21:59:59 : Epoch: 003, Train_Loss: 0.00936704
2025/09/16 21:59:59 : Epoch: 004, Train_Loss: 0.00776231
2025/09/16 21:59:59 : Epoch: 004, Eval_Loss: 0.00524703
2025/09/16 21:59:59 : Epoch: 004, Save the best checkpoint
2025/09/16 22:00:00 : Epoch: 005, Train_Loss: 0.00856244
2025/09/16 22:00:00 : Epoch: 006, Train_Loss: 0.00876306
2025/09/16 22:00:00 : Epoch: 007, Train_Loss: 0.01112337
2025/09/16 22:00:00 : Epoch: 008, Train_Loss: 0.01028501
2025/09/16 22:00:01 : Epoch: 009, Train_Loss: 0.00976620
2025/09/16 22:00:01 : Epoch: 009, Eval_Loss: 0.00514211
2025/09/16 22:00:01 : Epoch: 009, Save the best checkpoint
2025/09/16 22:00:01 : Epoch: 010, Train_Loss: 0.01006131
2025/09/16 22:00:01 : Epoch: 011, Train_Loss: 0.00783310
2025/09/16 22:00:02 : Epoch: 012, Train_Loss: 0.01515894
2025/09/16 22:00:02 : Epoch: 013, Train_Loss: 0.00766293
2025/09/16 22:00:02 : Epoch: 014, Train_Loss: 0.00985217
2025/09/16 22:00:02 : Epoch: 014, Eval_Loss: 0.00515656
2025/09/16 22:00:02 : Epoch: 015, Train_Loss: 0.00744834
2025/09/16 22:00:03 : Epoch: 016, Train_Loss: 0.01532684
2025/09/16 22:00:03 : Epoch: 017, Train_Loss: 0.00834484
2025/09/16 22:00:03 : Epoch: 018, Train_Loss: 0.00938808
2025/09/16 22:00:03 : Epoch: 019, Train_Loss: 0.00857683
2025/09/16 22:00:03 : Epoch: 019, Eval_Loss: 0.00498135
2025/09/16 22:00:03 : Epoch: 019, Save the best checkpoint
2025/09/16 22:00:04 : Epoch: 020, Train_Loss: 0.01218669
2025/09/16 22:00:04 : Epoch: 021, Train_Loss: 0.01167396
2025/09/16 22:00:04 : Epoch: 022, Train_Loss: 0.00958224
2025/09/16 22:00:04 : Epoch: 023, Train_Loss: 0.00838004
2025/09/16 22:00:05 : Epoch: 024, Train_Loss: 0.00939552
2025/09/16 22:00:05 : Epoch: 024, Eval_Loss: 0.00499194
2025/09/16 22:00:05 : Epoch: 025, Train_Loss: 0.00925755
2025/09/16 22:00:05 : Epoch: 026, Train_Loss: 0.00781528
2025/09/16 22:00:06 : Epoch: 027, Train_Loss: 0.00927681
2025/09/16 22:00:06 : Epoch: 028, Train_Loss: 0.00877997
2025/09/16 22:00:06 : Epoch: 029, Train_Loss: 0.00739619
2025/09/16 22:00:06 : Epoch: 029, Eval_Loss: 0.00483362
2025/09/16 22:00:06 : Epoch: 029, Save the best checkpoint
2025/09/16 22:00:06 : Epoch: 030, Train_Loss: 0.00804733
2025/09/16 22:00:07 : Epoch: 031, Train_Loss: 0.00848729
2025/09/16 22:00:07 : Epoch: 032, Train_Loss: 0.00887535
2025/09/16 22:00:07 : Epoch: 033, Train_Loss: 0.00798449
2025/09/16 22:00:07 : Epoch: 034, Train_Loss: 0.00795239
2025/09/16 22:00:07 : Epoch: 034, Eval_Loss: 0.00477064
2025/09/16 22:00:07 : Epoch: 034, Save the best checkpoint
2025/09/16 22:00:08 : Epoch: 035, Train_Loss: 0.00737750
2025/09/16 22:00:08 : Epoch: 036, Train_Loss: 0.00811049
2025/09/16 22:00:08 : Epoch: 037, Train_Loss: 0.01194087
2025/09/16 22:00:08 : Epoch: 038, Train_Loss: 0.00928116
2025/09/16 22:00:09 : Epoch: 039, Train_Loss: 0.00842674
2025/09/16 22:00:09 : Epoch: 039, Eval_Loss: 0.00479958
2025/09/16 22:00:09 : Epoch: 040, Train_Loss: 0.01275131
2025/09/16 22:00:09 : Epoch: 041, Train_Loss: 0.01357956
2025/09/16 22:00:10 : Epoch: 042, Train_Loss: 0.00743922
2025/09/16 22:00:10 : Epoch: 043, Train_Loss: 0.00965115
2025/09/16 22:00:10 : Epoch: 044, Train_Loss: 0.00837368
2025/09/16 22:00:10 : Epoch: 044, Eval_Loss: 0.00498170
2025/09/16 22:00:10 : Epoch: 045, Train_Loss: 0.00859997
2025/09/16 22:00:11 : Epoch: 046, Train_Loss: 0.00746106
2025/09/16 22:00:11 : Epoch: 047, Train_Loss: 0.00794934
2025/09/16 22:00:11 : Epoch: 048, Train_Loss: 0.00923435
2025/09/16 22:00:11 : Epoch: 049, Train_Loss: 0.01178030
2025/09/16 22:00:11 : Epoch: 049, Eval_Loss: 0.00483266
2025/09/16 22:00:12 : Epoch: 050, Train_Loss: 0.00867160
2025/09/16 22:00:12 : Epoch: 051, Train_Loss: 0.00760667
2025/09/16 22:00:12 : Epoch: 052, Train_Loss: 0.00989813
2025/09/16 22:00:12 : Epoch: 053, Train_Loss: 0.00921049
2025/09/16 22:00:13 : Epoch: 054, Train_Loss: 0.00958362
2025/09/16 22:00:13 : Epoch: 054, Eval_Loss: 0.00491334
2025/09/16 22:00:13 : Epoch: 055, Train_Loss: 0.00935811
2025/09/16 22:00:13 : Epoch: 056, Train_Loss: 0.01217861
2025/09/16 22:00:13 : Epoch: 057, Train_Loss: 0.00976262
2025/09/16 22:00:14 : Epoch: 058, Train_Loss: 0.01048518
2025/09/16 22:00:14 : Epoch: 059, Train_Loss: 0.00926245
2025/09/16 22:00:14 : Epoch: 059, Eval_Loss: 0.00476797
2025/09/16 22:00:14 : Epoch: 059, Save the best checkpoint
2025/09/16 22:00:14 : Epoch: 060, Train_Loss: 0.00777951
2025/09/16 22:00:15 : Epoch: 061, Train_Loss: 0.00769552
2025/09/16 22:00:15 : Epoch: 062, Train_Loss: 0.00866529
2025/09/16 22:00:15 : Epoch: 063, Train_Loss: 0.00753524
2025/09/16 22:00:15 : Epoch: 064, Train_Loss: 0.00788903
2025/09/16 22:00:15 : Epoch: 064, Eval_Loss: 0.00466250
2025/09/16 22:00:15 : Epoch: 064, Save the best checkpoint
2025/09/16 22:00:16 : Epoch: 065, Train_Loss: 0.01097251
2025/09/16 22:00:16 : Epoch: 066, Train_Loss: 0.00857063
2025/09/16 22:00:16 : Epoch: 067, Train_Loss: 0.00963348
2025/09/16 22:00:16 : Epoch: 068, Train_Loss: 0.01057880
2025/09/16 22:00:17 : Epoch: 069, Train_Loss: 0.00776680
2025/09/16 22:00:17 : Epoch: 069, Eval_Loss: 0.00515162
2025/09/16 22:00:17 : Epoch: 070, Train_Loss: 0.01405189
2025/09/16 22:00:17 : Epoch: 071, Train_Loss: 0.00724371
2025/09/16 22:00:17 : Epoch: 072, Train_Loss: 0.00855143
2025/09/16 22:00:18 : Epoch: 073, Train_Loss: 0.00867918
2025/09/16 22:00:18 : Epoch: 074, Train_Loss: 0.00802062
2025/09/16 22:00:18 : Epoch: 074, Eval_Loss: 0.00503406
2025/09/16 22:00:18 : Epoch: 075, Train_Loss: 0.00785225
2025/09/16 22:00:18 : Epoch: 076, Train_Loss: 0.00905393
2025/09/16 22:00:19 : Epoch: 077, Train_Loss: 0.01156714
2025/09/16 22:00:19 : Epoch: 078, Train_Loss: 0.01067412
2025/09/16 22:00:19 : Epoch: 079, Train_Loss: 0.01025687
2025/09/16 22:00:19 : Epoch: 079, Eval_Loss: 0.00494751
2025/09/16 22:00:20 : Epoch: 080, Train_Loss: 0.00961859
2025/09/16 22:00:20 : Epoch: 081, Train_Loss: 0.00887192
2025/09/16 22:00:20 : Epoch: 082, Train_Loss: 0.01180709
2025/09/16 22:00:20 : Epoch: 083, Train_Loss: 0.00883431
2025/09/16 22:00:21 : Epoch: 084, Train_Loss: 0.01049144
2025/09/16 22:00:21 : Epoch: 084, Eval_Loss: 0.00491854
2025/09/16 22:00:21 : Epoch: 085, Train_Loss: 0.00922829
2025/09/16 22:00:21 : Epoch: 086, Train_Loss: 0.00725993
2025/09/16 22:00:21 : Epoch: 087, Train_Loss: 0.00967744
2025/09/16 22:00:22 : Epoch: 088, Train_Loss: 0.00799793
2025/09/16 22:00:22 : Epoch: 089, Train_Loss: 0.00672808
2025/09/16 22:00:22 : Epoch: 089, Eval_Loss: 0.00473965
2025/09/16 22:00:22 : Epoch: 090, Train_Loss: 0.01083904
2025/09/16 22:00:22 : Epoch: 091, Train_Loss: 0.00616312
2025/09/16 22:00:23 : Epoch: 092, Train_Loss: 0.01027509
2025/09/16 22:00:23 : Epoch: 093, Train_Loss: 0.00803685
2025/09/16 22:00:23 : Epoch: 094, Train_Loss: 0.00804725
2025/09/16 22:00:23 : Epoch: 094, Eval_Loss: 0.00480697
2025/09/16 22:00:24 : Epoch: 095, Train_Loss: 0.00740464
2025/09/16 22:00:24 : Epoch: 096, Train_Loss: 0.00738637
2025/09/16 22:00:24 : Epoch: 097, Train_Loss: 0.00873759
2025/09/16 22:00:24 : Epoch: 098, Train_Loss: 0.00941671
2025/09/16 22:00:25 : Epoch: 099, Train_Loss: 0.01111316
2025/09/16 22:00:25 : Epoch: 099, Eval_Loss: 0.00477711
2025/09/16 22:00:25 : Epoch: 100, Train_Loss: 0.00859622
2025/09/16 22:00:25 : Epoch: 101, Train_Loss: 0.00941118
2025/09/16 22:00:25 : Epoch: 102, Train_Loss: 0.01140956
2025/09/16 22:00:26 : Epoch: 103, Train_Loss: 0.00901352
2025/09/16 22:00:26 : Epoch: 104, Train_Loss: 0.00904145
2025/09/16 22:00:26 : Epoch: 104, Eval_Loss: 0.00492019
2025/09/16 22:00:26 : Epoch: 105, Train_Loss: 0.00733920
2025/09/16 22:00:26 : Epoch: 106, Train_Loss: 0.00915810
2025/09/16 22:00:27 : Epoch: 107, Train_Loss: 0.00915015
2025/09/16 22:00:27 : Epoch: 108, Train_Loss: 0.01185014
2025/09/16 22:00:27 : Epoch: 109, Train_Loss: 0.00828287
2025/09/16 22:00:27 : Epoch: 109, Eval_Loss: 0.00516595
2025/09/16 22:00:28 : Epoch: 110, Train_Loss: 0.01019631
2025/09/16 22:00:28 : Epoch: 111, Train_Loss: 0.00945522
2025/09/16 22:00:28 : Epoch: 112, Train_Loss: 0.01389737
2025/09/16 22:00:28 : Epoch: 113, Train_Loss: 0.00729759
2025/09/16 22:00:29 : Epoch: 114, Train_Loss: 0.00847440
2025/09/16 22:00:29 : Epoch: 114, Eval_Loss: 0.00486474
2025/09/16 22:00:29 : Epoch: 115, Train_Loss: 0.00622007
2025/09/16 22:00:29 : Epoch: 116, Train_Loss: 0.00742826
2025/09/16 22:00:29 : Epoch: 117, Train_Loss: 0.00666038
2025/09/16 22:00:30 : Epoch: 118, Train_Loss: 0.00887759
2025/09/16 22:00:30 : Epoch: 119, Train_Loss: 0.00761206
2025/09/16 22:00:30 : Epoch: 119, Eval_Loss: 0.00530736
2025/09/16 22:00:30 : Epoch: 120, Train_Loss: 0.01034818
2025/09/16 22:00:30 : Epoch: 121, Train_Loss: 0.01015384
2025/09/16 22:00:31 : Epoch: 122, Train_Loss: 0.00899005
2025/09/16 22:00:31 : Epoch: 123, Train_Loss: 0.01033349
2025/09/16 22:00:31 : Epoch: 124, Train_Loss: 0.01250243
2025/09/16 22:00:31 : Epoch: 124, Eval_Loss: 0.00502795
2025/09/16 22:00:31 : Epoch: 125, Train_Loss: 0.01175285
2025/09/16 22:00:32 : Epoch: 126, Train_Loss: 0.01167451
2025/09/16 22:00:32 : Epoch: 127, Train_Loss: 0.01128801
2025/09/16 22:00:32 : Epoch: 128, Train_Loss: 0.00839329
2025/09/16 22:00:32 : Epoch: 129, Train_Loss: 0.01210367
2025/09/16 22:00:33 : Epoch: 129, Eval_Loss: 0.00510899
2025/09/16 22:00:33 : Epoch: 130, Train_Loss: 0.01027857
2025/09/16 22:00:33 : Epoch: 131, Train_Loss: 0.00709474
2025/09/16 22:00:33 : Epoch: 132, Train_Loss: 0.00894197
2025/09/16 22:00:34 : Epoch: 133, Train_Loss: 0.01217378
2025/09/16 22:00:34 : Epoch: 134, Train_Loss: 0.00623600
2025/09/16 22:00:34 : Epoch: 134, Eval_Loss: 0.00569409
2025/09/16 22:00:34 : Epoch: 135, Train_Loss: 0.00733271
2025/09/16 22:00:34 : Epoch: 136, Train_Loss: 0.00840320
2025/09/16 22:00:35 : Epoch: 137, Train_Loss: 0.01174902
2025/09/16 22:00:35 : Epoch: 138, Train_Loss: 0.00776959
2025/09/16 22:00:35 : Epoch: 139, Train_Loss: 0.00780199
2025/09/16 22:00:35 : Epoch: 139, Eval_Loss: 0.00504655
2025/09/16 22:00:35 : Epoch: 140, Train_Loss: 0.00861447
2025/09/16 22:00:36 : Epoch: 141, Train_Loss: 0.00857116
2025/09/16 22:00:36 : Epoch: 142, Train_Loss: 0.01042342
2025/09/16 22:00:36 : Epoch: 143, Train_Loss: 0.00904232
2025/09/16 22:00:36 : Epoch: 144, Train_Loss: 0.00778924
2025/09/16 22:00:36 : Epoch: 144, Eval_Loss: 0.00648106
2025/09/16 22:00:37 : Epoch: 145, Train_Loss: 0.01396575
2025/09/16 22:00:37 : Epoch: 146, Train_Loss: 0.01001458
2025/09/16 22:00:37 : Epoch: 147, Train_Loss: 0.00656463
2025/09/16 22:00:37 : Epoch: 148, Train_Loss: 0.00897317
2025/09/16 22:00:38 : Epoch: 149, Train_Loss: 0.00668431
2025/09/16 22:00:38 : Epoch: 149, Eval_Loss: 0.00495462
2025/09/16 22:00:38 : Epoch: 150, Train_Loss: 0.00776958
2025/09/16 22:00:38 : Epoch: 151, Train_Loss: 0.00676405
2025/09/16 22:00:38 : Epoch: 152, Train_Loss: 0.00712524
2025/09/16 22:00:39 : Epoch: 153, Train_Loss: 0.00952249
2025/09/16 22:00:39 : Epoch: 154, Train_Loss: 0.01117518
2025/09/16 22:00:39 : Epoch: 154, Eval_Loss: 0.00498087
2025/09/16 22:00:39 : Epoch: 155, Train_Loss: 0.00779277
2025/09/16 22:00:40 : Epoch: 156, Train_Loss: 0.01093117
2025/09/16 22:00:40 : Epoch: 157, Train_Loss: 0.00829895
2025/09/16 22:00:40 : Epoch: 158, Train_Loss: 0.00772255
2025/09/16 22:00:40 : Epoch: 159, Train_Loss: 0.01247485
2025/09/16 22:00:40 : Epoch: 159, Eval_Loss: 0.00684539
2025/09/16 22:00:41 : Epoch: 160, Train_Loss: 0.00909858
2025/09/16 22:00:41 : Epoch: 161, Train_Loss: 0.00928911
2025/09/16 22:00:41 : Epoch: 162, Train_Loss: 0.00755291
2025/09/16 22:00:41 : Epoch: 163, Train_Loss: 0.00938005
2025/09/16 22:00:42 : Epoch: 164, Train_Loss: 0.00632552
2025/09/16 22:00:42 : Epoch: 164, Eval_Loss: 0.00556454
2025/09/16 22:00:42 : Epoch: 165, Train_Loss: 0.01026596
2025/09/16 22:00:42 : Epoch: 166, Train_Loss: 0.00750393
2025/09/16 22:00:42 : Epoch: 167, Train_Loss: 0.00811800
2025/09/16 22:00:43 : Epoch: 168, Train_Loss: 0.00764856
2025/09/16 22:00:43 : Epoch: 169, Train_Loss: 0.00760331
2025/09/16 22:00:43 : Epoch: 169, Eval_Loss: 0.00502751
2025/09/16 22:00:43 : Epoch: 170, Train_Loss: 0.00771445
2025/09/16 22:00:43 : Epoch: 171, Train_Loss: 0.01162055
2025/09/16 22:00:44 : Epoch: 172, Train_Loss: 0.00786804
2025/09/16 22:00:44 : Epoch: 173, Train_Loss: 0.00755226
2025/09/16 22:00:44 : Epoch: 174, Train_Loss: 0.01088690
2025/09/16 22:00:44 : Epoch: 174, Eval_Loss: 0.00518132
2025/09/16 22:00:45 : Epoch: 175, Train_Loss: 0.00803723
2025/09/16 22:00:45 : Epoch: 176, Train_Loss: 0.01001676
2025/09/16 22:00:45 : Epoch: 177, Train_Loss: 0.00582617
2025/09/16 22:00:45 : Epoch: 178, Train_Loss: 0.00793039
2025/09/16 22:00:46 : Epoch: 179, Train_Loss: 0.00795083
2025/09/16 22:00:46 : Epoch: 179, Eval_Loss: 0.00479680
2025/09/16 22:00:46 : Epoch: 180, Train_Loss: 0.00898476
2025/09/16 22:00:46 : Epoch: 181, Train_Loss: 0.00706239
2025/09/16 22:00:46 : Epoch: 182, Train_Loss: 0.00674052
2025/09/16 22:00:47 : Epoch: 183, Train_Loss: 0.00937894
2025/09/16 22:00:47 : Epoch: 184, Train_Loss: 0.00783614
2025/09/16 22:00:47 : Epoch: 184, Eval_Loss: 0.00473885
2025/09/16 22:00:47 : Epoch: 185, Train_Loss: 0.00647926
2025/09/16 22:00:47 : Epoch: 186, Train_Loss: 0.00741167
2025/09/16 22:00:48 : Epoch: 187, Train_Loss: 0.01158276
2025/09/16 22:00:48 : Epoch: 188, Train_Loss: 0.00749514
2025/09/16 22:00:48 : Epoch: 189, Train_Loss: 0.00685251
2025/09/16 22:00:48 : Epoch: 189, Eval_Loss: 0.00496684
2025/09/16 22:00:48 : Epoch: 190, Train_Loss: 0.00627924
2025/09/16 22:00:49 : Epoch: 191, Train_Loss: 0.00647208
2025/09/16 22:00:49 : Epoch: 192, Train_Loss: 0.00629548
2025/09/16 22:00:49 : Epoch: 193, Train_Loss: 0.00724865
2025/09/16 22:00:49 : Epoch: 194, Train_Loss: 0.00825164
2025/09/16 22:00:50 : Epoch: 194, Eval_Loss: 0.00548226
2025/09/16 22:00:50 : Epoch: 195, Train_Loss: 0.00828673
2025/09/16 22:00:50 : Epoch: 196, Train_Loss: 0.00855320
2025/09/16 22:00:50 : Epoch: 197, Train_Loss: 0.01288387
2025/09/16 22:00:51 : Epoch: 198, Train_Loss: 0.01144673
2025/09/16 22:00:51 : Epoch: 199, Train_Loss: 0.00697512
2025/09/16 22:00:51 : Epoch: 199, Eval_Loss: 0.00634280
2025/09/16 22:00:51 : Epoch: 200, Train_Loss: 0.00785473
2025/09/16 22:00:51 : Epoch: 201, Train_Loss: 0.00715976
2025/09/16 22:00:52 : Epoch: 202, Train_Loss: 0.00920262
2025/09/16 22:00:52 : Epoch: 203, Train_Loss: 0.00721848
2025/09/16 22:00:52 : Epoch: 204, Train_Loss: 0.00624108
2025/09/16 22:00:52 : Epoch: 204, Eval_Loss: 0.00559882
2025/09/16 22:00:52 : Epoch: 205, Train_Loss: 0.00700252
2025/09/16 22:00:53 : Epoch: 206, Train_Loss: 0.00662393
2025/09/16 22:00:53 : Epoch: 207, Train_Loss: 0.00689811
2025/09/16 22:00:53 : Epoch: 208, Train_Loss: 0.00821006
2025/09/16 22:00:53 : Epoch: 209, Train_Loss: 0.00787142
2025/09/16 22:00:53 : Epoch: 209, Eval_Loss: 0.00523512
2025/09/16 22:00:54 : Epoch: 210, Train_Loss: 0.00843404
2025/09/16 22:00:54 : Epoch: 211, Train_Loss: 0.01096333
2025/09/16 22:00:54 : Epoch: 212, Train_Loss: 0.00622428
2025/09/16 22:00:54 : Epoch: 213, Train_Loss: 0.00851699
2025/09/16 22:00:55 : Epoch: 214, Train_Loss: 0.00713910
2025/09/16 22:00:55 : Epoch: 214, Eval_Loss: 0.00899192
2025/09/16 22:00:55 : Epoch: 215, Train_Loss: 0.01104597
2025/09/16 22:00:55 : Epoch: 216, Train_Loss: 0.00747667
2025/09/16 22:00:55 : Epoch: 217, Train_Loss: 0.00868991
2025/09/16 22:00:56 : Epoch: 218, Train_Loss: 0.00977449
2025/09/16 22:00:56 : Epoch: 219, Train_Loss: 0.00828195
2025/09/16 22:00:56 : Epoch: 219, Eval_Loss: 0.00500564
2025/09/16 22:00:56 : Epoch: 220, Train_Loss: 0.00860389
2025/09/16 22:00:56 : Epoch: 221, Train_Loss: 0.01086175
2025/09/16 22:00:57 : Epoch: 222, Train_Loss: 0.00826392
2025/09/16 22:00:57 : Epoch: 223, Train_Loss: 0.00746063
2025/09/16 22:00:57 : Epoch: 224, Train_Loss: 0.01121042
2025/09/16 22:00:57 : Epoch: 224, Eval_Loss: 0.00497556
2025/09/16 22:00:58 : Epoch: 225, Train_Loss: 0.00642541
2025/09/16 22:00:58 : Epoch: 226, Train_Loss: 0.00736257
2025/09/16 22:00:58 : Epoch: 227, Train_Loss: 0.00602143
2025/09/16 22:00:58 : Epoch: 228, Train_Loss: 0.00784329
2025/09/16 22:00:59 : Epoch: 229, Train_Loss: 0.00882271
2025/09/16 22:00:59 : Epoch: 229, Eval_Loss: 0.00567008
2025/09/16 22:00:59 : Epoch: 230, Train_Loss: 0.00791931
2025/09/16 22:00:59 : Epoch: 231, Train_Loss: 0.01226030
2025/09/16 22:00:59 : Epoch: 232, Train_Loss: 0.00624934
2025/09/16 22:01:00 : Epoch: 233, Train_Loss: 0.00695161
2025/09/16 22:01:00 : Epoch: 234, Train_Loss: 0.00701171
2025/09/16 22:01:00 : Epoch: 234, Eval_Loss: 0.00511719
2025/09/16 22:01:00 : Epoch: 235, Train_Loss: 0.00797479
2025/09/16 22:01:00 : Epoch: 236, Train_Loss: 0.00782245
2025/09/16 22:01:01 : Epoch: 237, Train_Loss: 0.00684239
2025/09/16 22:01:01 : Epoch: 238, Train_Loss: 0.00818927
2025/09/16 22:01:01 : Epoch: 239, Train_Loss: 0.00891857
2025/09/16 22:01:01 : Epoch: 239, Eval_Loss: 0.00481709
2025/09/16 22:01:01 : Epoch: 240, Train_Loss: 0.00920299
2025/09/16 22:01:02 : Epoch: 241, Train_Loss: 0.00988563
2025/09/16 22:01:02 : Epoch: 242, Train_Loss: 0.00928084
2025/09/16 22:01:02 : Epoch: 243, Train_Loss: 0.00813054
2025/09/16 22:01:02 : Epoch: 244, Train_Loss: 0.01077698
2025/09/16 22:01:03 : Epoch: 244, Eval_Loss: 0.00501972
2025/09/16 22:01:03 : Epoch: 245, Train_Loss: 0.01228873
2025/09/16 22:01:03 : Epoch: 246, Train_Loss: 0.00752171
2025/09/16 22:01:03 : Epoch: 247, Train_Loss: 0.00715955
2025/09/16 22:01:04 : Epoch: 248, Train_Loss: 0.00695050
2025/09/16 22:01:04 : Epoch: 249, Train_Loss: 0.01019169
2025/09/16 22:01:04 : Epoch: 249, Eval_Loss: 0.00483201
2025/09/16 22:01:04 : Epoch: 250, Train_Loss: 0.00614773
2025/09/16 22:01:04 : Epoch: 251, Train_Loss: 0.00897970
2025/09/16 22:01:05 : Epoch: 252, Train_Loss: 0.00872981
2025/09/16 22:01:05 : Epoch: 253, Train_Loss: 0.00699558
2025/09/16 22:01:05 : Epoch: 254, Train_Loss: 0.00744316
2025/09/16 22:01:05 : Epoch: 254, Eval_Loss: 0.00497613
2025/09/16 22:01:05 : Epoch: 255, Train_Loss: 0.00711834
2025/09/16 22:01:06 : Epoch: 256, Train_Loss: 0.00883398
2025/09/16 22:01:06 : Epoch: 257, Train_Loss: 0.00786335
2025/09/16 22:01:06 : Epoch: 258, Train_Loss: 0.00677693
2025/09/16 22:01:06 : Epoch: 259, Train_Loss: 0.00906997
2025/09/16 22:01:06 : Epoch: 259, Eval_Loss: 0.00469515
2025/09/16 22:01:07 : Epoch: 260, Train_Loss: 0.01061300
2025/09/16 22:01:07 : Epoch: 261, Train_Loss: 0.00678376
2025/09/16 22:01:07 : Epoch: 262, Train_Loss: 0.00943910
2025/09/16 22:01:07 : Epoch: 263, Train_Loss: 0.00949989
2025/09/16 22:01:08 : Epoch: 264, Train_Loss: 0.00609485
2025/09/16 22:01:08 : Epoch: 264, Eval_Loss: 0.00509941
2025/09/16 22:01:08 : Epoch: 265, Train_Loss: 0.00681041
2025/09/16 22:01:08 : Epoch: 266, Train_Loss: 0.00540946
2025/09/16 22:01:08 : Epoch: 267, Train_Loss: 0.00632294
2025/09/16 22:01:09 : Epoch: 268, Train_Loss: 0.01269054
2025/09/16 22:01:09 : Epoch: 269, Train_Loss: 0.01007374
2025/09/16 22:01:09 : Epoch: 269, Eval_Loss: 0.00495728
2025/09/16 22:01:09 : Epoch: 270, Train_Loss: 0.00778561
2025/09/16 22:01:10 : Epoch: 271, Train_Loss: 0.00744527
2025/09/16 22:01:10 : Epoch: 272, Train_Loss: 0.00542573
2025/09/16 22:01:10 : Epoch: 273, Train_Loss: 0.00853796
2025/09/16 22:01:10 : Epoch: 274, Train_Loss: 0.00593912
2025/09/16 22:01:10 : Epoch: 274, Eval_Loss: 0.00509195
2025/09/16 22:01:11 : Epoch: 275, Train_Loss: 0.00787208
2025/09/16 22:01:11 : Epoch: 276, Train_Loss: 0.00721224
2025/09/16 22:01:11 : Epoch: 277, Train_Loss: 0.01203034
2025/09/16 22:01:11 : Epoch: 278, Train_Loss: 0.00732180
2025/09/16 22:01:12 : Epoch: 279, Train_Loss: 0.01124819
2025/09/16 22:01:12 : Epoch: 279, Eval_Loss: 0.00881231
2025/09/16 22:01:12 : Epoch: 280, Train_Loss: 0.00805057
2025/09/16 22:01:12 : Epoch: 281, Train_Loss: 0.00686597
2025/09/16 22:01:12 : Epoch: 282, Train_Loss: 0.00802818
2025/09/16 22:01:13 : Epoch: 283, Train_Loss: 0.00921211
2025/09/16 22:01:13 : Epoch: 284, Train_Loss: 0.00743464
2025/09/16 22:01:13 : Epoch: 284, Eval_Loss: 0.00602687
2025/09/16 22:01:13 : Epoch: 285, Train_Loss: 0.00680019
2025/09/16 22:01:13 : Epoch: 286, Train_Loss: 0.00577975
2025/09/16 22:01:14 : Epoch: 287, Train_Loss: 0.00593252
2025/09/16 22:01:14 : Epoch: 288, Train_Loss: 0.00739247
2025/09/16 22:01:14 : Epoch: 289, Train_Loss: 0.00753068
2025/09/16 22:01:14 : Epoch: 289, Eval_Loss: 0.00606465
2025/09/16 22:01:14 : Epoch: 290, Train_Loss: 0.00614822
2025/09/16 22:01:15 : Epoch: 291, Train_Loss: 0.00590164
2025/09/16 22:01:15 : Epoch: 292, Train_Loss: 0.00488416
2025/09/16 22:01:15 : Epoch: 293, Train_Loss: 0.00486458
2025/09/16 22:01:15 : Epoch: 294, Train_Loss: 0.00602365
2025/09/16 22:01:15 : Epoch: 294, Eval_Loss: 0.00992222
2025/09/16 22:01:16 : Epoch: 295, Train_Loss: 0.00865636
2025/09/16 22:01:16 : Epoch: 296, Train_Loss: 0.00649887
2025/09/16 22:01:16 : Epoch: 297, Train_Loss: 0.00832298
2025/09/16 22:01:16 : Epoch: 298, Train_Loss: 0.01164111
2025/09/16 22:01:17 : Epoch: 299, Train_Loss: 0.00633720
2025/09/16 22:01:17 : Epoch: 299, Eval_Loss: 0.00440583
2025/09/16 22:01:17 : Epoch: 299, Save the best checkpoint
2025/09/16 22:01:17 : Epoch: 300, Train_Loss: 0.00599159
2025/09/16 22:01:17 : Epoch: 301, Train_Loss: 0.00938700
2025/09/16 22:01:18 : Epoch: 302, Train_Loss: 0.01126293
2025/09/16 22:01:18 : Epoch: 303, Train_Loss: 0.00702997
2025/09/16 22:01:18 : Epoch: 304, Train_Loss: 0.00631949
2025/09/16 22:01:18 : Epoch: 304, Eval_Loss: 0.00482153
2025/09/16 22:01:18 : Epoch: 305, Train_Loss: 0.00755583
2025/09/16 22:01:19 : Epoch: 306, Train_Loss: 0.00561753
2025/09/16 22:01:19 : Epoch: 307, Train_Loss: 0.00682805
2025/09/16 22:01:19 : Epoch: 308, Train_Loss: 0.00533250
2025/09/16 22:01:19 : Epoch: 309, Train_Loss: 0.00954111
2025/09/16 22:01:19 : Epoch: 309, Eval_Loss: 0.00491612
2025/09/16 22:01:20 : Epoch: 310, Train_Loss: 0.01092401
2025/09/16 22:01:20 : Epoch: 311, Train_Loss: 0.00918527
2025/09/16 22:01:20 : Epoch: 312, Train_Loss: 0.00682410
2025/09/16 22:01:20 : Epoch: 313, Train_Loss: 0.00906072
2025/09/16 22:01:21 : Epoch: 314, Train_Loss: 0.00680241
2025/09/16 22:01:21 : Epoch: 314, Eval_Loss: 0.00495485
2025/09/16 22:01:21 : Epoch: 315, Train_Loss: 0.00913503
2025/09/16 22:01:21 : Epoch: 316, Train_Loss: 0.00601818
2025/09/16 22:01:22 : Epoch: 317, Train_Loss: 0.00796835
2025/09/16 22:01:22 : Epoch: 318, Train_Loss: 0.00680602
2025/09/16 22:01:22 : Epoch: 319, Train_Loss: 0.00690588
2025/09/16 22:01:22 : Epoch: 319, Eval_Loss: 0.00466555
2025/09/16 22:01:22 : Epoch: 320, Train_Loss: 0.01075279
2025/09/16 22:01:23 : Epoch: 321, Train_Loss: 0.00717229
2025/09/16 22:01:23 : Epoch: 322, Train_Loss: 0.00652625
2025/09/16 22:01:23 : Epoch: 323, Train_Loss: 0.00557568
2025/09/16 22:01:23 : Epoch: 324, Train_Loss: 0.00587616
2025/09/16 22:01:23 : Epoch: 324, Eval_Loss: 0.00470197
2025/09/16 22:01:24 : Epoch: 325, Train_Loss: 0.00670169
2025/09/16 22:01:24 : Epoch: 326, Train_Loss: 0.00633002
2025/09/16 22:01:24 : Epoch: 327, Train_Loss: 0.01081990
2025/09/16 22:01:24 : Epoch: 328, Train_Loss: 0.00604935
2025/09/16 22:01:25 : Epoch: 329, Train_Loss: 0.00767072
2025/09/16 22:01:25 : Epoch: 329, Eval_Loss: 0.00454316
2025/09/16 22:01:25 : Epoch: 330, Train_Loss: 0.00611333
2025/09/16 22:01:25 : Epoch: 331, Train_Loss: 0.00582510
2025/09/16 22:01:25 : Epoch: 332, Train_Loss: 0.00971995
2025/09/16 22:01:26 : Epoch: 333, Train_Loss: 0.00901316
2025/09/16 22:01:26 : Epoch: 334, Train_Loss: 0.01128776
2025/09/16 22:01:26 : Epoch: 334, Eval_Loss: 0.00507411
2025/09/16 22:01:26 : Epoch: 335, Train_Loss: 0.00868765
2025/09/16 22:01:27 : Epoch: 336, Train_Loss: 0.00783851
2025/09/16 22:01:27 : Epoch: 337, Train_Loss: 0.00693307
2025/09/16 22:01:27 : Epoch: 338, Train_Loss: 0.00727808
2025/09/16 22:01:27 : Epoch: 339, Train_Loss: 0.00809879
2025/09/16 22:01:27 : Epoch: 339, Eval_Loss: 0.00844785
2025/09/16 22:01:28 : Epoch: 340, Train_Loss: 0.00587952
2025/09/16 22:01:28 : Epoch: 341, Train_Loss: 0.00537874
2025/09/16 22:01:28 : Epoch: 342, Train_Loss: 0.00574447
2025/09/16 22:01:28 : Epoch: 343, Train_Loss: 0.00912975
2025/09/16 22:01:29 : Epoch: 344, Train_Loss: 0.01102417
2025/09/16 22:01:29 : Epoch: 344, Eval_Loss: 0.00674459
2025/09/16 22:01:29 : Epoch: 345, Train_Loss: 0.00696090
2025/09/16 22:01:29 : Epoch: 346, Train_Loss: 0.01046338
2025/09/16 22:01:29 : Epoch: 347, Train_Loss: 0.00746370
2025/09/16 22:01:30 : Epoch: 348, Train_Loss: 0.00855662
2025/09/16 22:01:30 : Epoch: 349, Train_Loss: 0.00780829
2025/09/16 22:01:30 : Epoch: 349, Eval_Loss: 0.00497349
2025/09/16 22:01:30 : Epoch: 350, Train_Loss: 0.01313792
2025/09/16 22:01:31 : Epoch: 351, Train_Loss: 0.01265076
2025/09/16 22:01:31 : Epoch: 352, Train_Loss: 0.00984793
2025/09/16 22:01:31 : Epoch: 353, Train_Loss: 0.00845885
2025/09/16 22:01:31 : Epoch: 354, Train_Loss: 0.00786465
2025/09/16 22:01:31 : Epoch: 354, Eval_Loss: 0.00489133
2025/09/16 22:01:32 : Epoch: 355, Train_Loss: 0.00725619
2025/09/16 22:01:32 : Epoch: 356, Train_Loss: 0.00862752
2025/09/16 22:01:32 : Epoch: 357, Train_Loss: 0.00714930
2025/09/16 22:01:32 : Epoch: 358, Train_Loss: 0.00730311
2025/09/16 22:01:33 : Epoch: 359, Train_Loss: 0.00903307
2025/09/16 22:01:33 : Epoch: 359, Eval_Loss: 0.00461130
2025/09/16 22:01:33 : Epoch: 360, Train_Loss: 0.01119686
2025/09/16 22:01:33 : Epoch: 361, Train_Loss: 0.00745439
2025/09/16 22:01:33 : Epoch: 362, Train_Loss: 0.00620294
2025/09/16 22:01:34 : Epoch: 363, Train_Loss: 0.00573739
2025/09/16 22:01:34 : Epoch: 364, Train_Loss: 0.00568662
2025/09/16 22:01:34 : Epoch: 364, Eval_Loss: 0.00490585
2025/09/16 22:01:34 : Epoch: 365, Train_Loss: 0.00800231
2025/09/16 22:01:34 : Epoch: 366, Train_Loss: 0.00598987
2025/09/16 22:01:35 : Epoch: 367, Train_Loss: 0.00835158
2025/09/16 22:01:35 : Epoch: 368, Train_Loss: 0.00595240
2025/09/16 22:01:35 : Epoch: 369, Train_Loss: 0.00897901
2025/09/16 22:01:35 : Epoch: 369, Eval_Loss: 0.00527110
2025/09/16 22:01:36 : Epoch: 370, Train_Loss: 0.00726581
2025/09/16 22:01:36 : Epoch: 371, Train_Loss: 0.00641501
2025/09/16 22:01:36 : Epoch: 372, Train_Loss: 0.00959799
2025/09/16 22:01:36 : Epoch: 373, Train_Loss: 0.00878927
2025/09/16 22:01:37 : Epoch: 374, Train_Loss: 0.00626128
2025/09/16 22:01:37 : Epoch: 374, Eval_Loss: 0.00513424
2025/09/16 22:01:37 : Epoch: 375, Train_Loss: 0.00928783
2025/09/16 22:01:37 : Epoch: 376, Train_Loss: 0.01088571
2025/09/16 22:01:37 : Epoch: 377, Train_Loss: 0.00880880
2025/09/16 22:01:38 : Epoch: 378, Train_Loss: 0.00865042
2025/09/16 22:01:38 : Epoch: 379, Train_Loss: 0.00874115
2025/09/16 22:01:38 : Epoch: 379, Eval_Loss: 0.00504639
2025/09/16 22:01:38 : Epoch: 380, Train_Loss: 0.00988662
2025/09/16 22:01:38 : Epoch: 381, Train_Loss: 0.00822415
2025/09/16 22:01:39 : Epoch: 382, Train_Loss: 0.00724077
2025/09/16 22:01:39 : Epoch: 383, Train_Loss: 0.00853272
2025/09/16 22:01:39 : Epoch: 384, Train_Loss: 0.01194842
2025/09/16 22:01:39 : Epoch: 384, Eval_Loss: 0.00497781
2025/09/16 22:01:40 : Epoch: 385, Train_Loss: 0.00860420
2025/09/16 22:01:40 : Epoch: 386, Train_Loss: 0.00768949
2025/09/16 22:01:40 : Epoch: 387, Train_Loss: 0.00795567
2025/09/16 22:01:40 : Epoch: 388, Train_Loss: 0.00691214
2025/09/16 22:01:40 : Epoch: 389, Train_Loss: 0.00803983
2025/09/16 22:01:41 : Epoch: 389, Eval_Loss: 0.00480568
2025/09/16 22:01:41 : Epoch: 390, Train_Loss: 0.00759332
2025/09/16 22:01:41 : Epoch: 391, Train_Loss: 0.00697311
2025/09/16 22:01:41 : Epoch: 392, Train_Loss: 0.00762729
2025/09/16 22:01:42 : Epoch: 393, Train_Loss: 0.00806163
2025/09/16 22:01:42 : Epoch: 394, Train_Loss: 0.00840704
2025/09/16 22:01:42 : Epoch: 394, Eval_Loss: 0.00476173
2025/09/16 22:01:42 : Epoch: 395, Train_Loss: 0.00785273
2025/09/16 22:01:42 : Epoch: 396, Train_Loss: 0.00994249
2025/09/16 22:01:43 : Epoch: 397, Train_Loss: 0.00665125
2025/09/16 22:01:43 : Epoch: 398, Train_Loss: 0.00747667
2025/09/16 22:01:43 : Epoch: 399, Train_Loss: 0.00528446
2025/09/16 22:01:43 : Epoch: 399, Eval_Loss: 0.00488277
2025/09/16 22:01:43 : 
Epoch: 399, save response figures

2025/09/16 22:01:56 : Epoch: 400, Train_Loss: 0.00587501
2025/09/16 22:01:56 : Epoch: 401, Train_Loss: 0.00642010
2025/09/16 22:01:56 : Epoch: 402, Train_Loss: 0.00682283
2025/09/16 22:01:56 : Epoch: 403, Train_Loss: 0.00565614
2025/09/16 22:01:57 : Epoch: 404, Train_Loss: 0.00562010
2025/09/16 22:01:57 : Epoch: 404, Eval_Loss: 0.00543134
2025/09/16 22:01:57 : Epoch: 405, Train_Loss: 0.00858091
2025/09/16 22:01:57 : Epoch: 406, Train_Loss: 0.01013084
2025/09/16 22:01:57 : Epoch: 407, Train_Loss: 0.00948451
2025/09/16 22:01:58 : Epoch: 408, Train_Loss: 0.00923645
2025/09/16 22:01:58 : Epoch: 409, Train_Loss: 0.00739994
2025/09/16 22:01:58 : Epoch: 409, Eval_Loss: 0.00478182
2025/09/16 22:01:58 : Epoch: 410, Train_Loss: 0.00633129
2025/09/16 22:01:59 : Epoch: 411, Train_Loss: 0.01027576
2025/09/16 22:01:59 : Epoch: 412, Train_Loss: 0.00771249
2025/09/16 22:01:59 : Epoch: 413, Train_Loss: 0.00718078
2025/09/16 22:01:59 : Epoch: 414, Train_Loss: 0.00646936
2025/09/16 22:01:59 : Epoch: 414, Eval_Loss: 0.00512411
2025/09/16 22:02:00 : Epoch: 415, Train_Loss: 0.00695525
2025/09/16 22:02:00 : Epoch: 416, Train_Loss: 0.00852066
2025/09/16 22:02:00 : Epoch: 417, Train_Loss: 0.00610694
2025/09/16 22:02:00 : Epoch: 418, Train_Loss: 0.00972997
2025/09/16 22:02:01 : Epoch: 419, Train_Loss: 0.00580642
2025/09/16 22:02:01 : Epoch: 419, Eval_Loss: 0.00447571
2025/09/16 22:02:01 : Epoch: 420, Train_Loss: 0.00584830
2025/09/16 22:02:01 : Epoch: 421, Train_Loss: 0.00619525
2025/09/16 22:02:01 : Epoch: 422, Train_Loss: 0.00655809
2025/09/16 22:02:02 : Epoch: 423, Train_Loss: 0.00735040
2025/09/16 22:02:02 : Epoch: 424, Train_Loss: 0.00615865
2025/09/16 22:02:02 : Epoch: 424, Eval_Loss: 0.00449567
2025/09/16 22:02:02 : Epoch: 425, Train_Loss: 0.00622513
2025/09/16 22:02:02 : Epoch: 426, Train_Loss: 0.00628717
2025/09/16 22:02:03 : Epoch: 427, Train_Loss: 0.00752623
2025/09/16 22:02:03 : Epoch: 428, Train_Loss: 0.00527191
2025/09/16 22:02:03 : Epoch: 429, Train_Loss: 0.00748864
2025/09/16 22:02:03 : Epoch: 429, Eval_Loss: 0.00442222
2025/09/16 22:02:04 : Epoch: 430, Train_Loss: 0.00806812
2025/09/16 22:02:04 : Epoch: 431, Train_Loss: 0.00603271
2025/09/16 22:02:04 : Epoch: 432, Train_Loss: 0.00765954
2025/09/16 22:02:04 : Epoch: 433, Train_Loss: 0.00605130
2025/09/16 22:02:05 : Epoch: 434, Train_Loss: 0.00663175
2025/09/16 22:02:05 : Epoch: 434, Eval_Loss: 0.00439919
2025/09/16 22:02:05 : Epoch: 434, Save the best checkpoint
2025/09/16 22:02:05 : Epoch: 435, Train_Loss: 0.00655798
2025/09/16 22:02:05 : Epoch: 436, Train_Loss: 0.00716183
2025/09/16 22:02:05 : Epoch: 437, Train_Loss: 0.00793667
2025/09/16 22:02:06 : Epoch: 438, Train_Loss: 0.00824613
2025/09/16 22:02:06 : Epoch: 439, Train_Loss: 0.00626897
2025/09/16 22:02:06 : Epoch: 439, Eval_Loss: 0.00528591
2025/09/16 22:02:06 : Epoch: 440, Train_Loss: 0.00670185
2025/09/16 22:02:06 : Epoch: 441, Train_Loss: 0.00564053
2025/09/16 22:02:07 : Epoch: 442, Train_Loss: 0.00732875
2025/09/16 22:02:07 : Epoch: 443, Train_Loss: 0.00587598
2025/09/16 22:02:07 : Epoch: 444, Train_Loss: 0.00560573
2025/09/16 22:02:07 : Epoch: 444, Eval_Loss: 0.00521776
2025/09/16 22:02:07 : Epoch: 445, Train_Loss: 0.00544897
2025/09/16 22:02:08 : Epoch: 446, Train_Loss: 0.00552231
2025/09/16 22:02:08 : Epoch: 447, Train_Loss: 0.00593317
2025/09/16 22:02:08 : Epoch: 448, Train_Loss: 0.00591257
2025/09/16 22:02:08 : Epoch: 449, Train_Loss: 0.00541796
2025/09/16 22:02:09 : Epoch: 449, Eval_Loss: 0.00432923
2025/09/16 22:02:09 : Epoch: 449, Save the best checkpoint
2025/09/16 22:02:09 : Epoch: 450, Train_Loss: 0.00645110
2025/09/16 22:02:09 : Epoch: 451, Train_Loss: 0.00593842
2025/09/16 22:02:09 : Epoch: 452, Train_Loss: 0.00526433
2025/09/16 22:02:09 : Epoch: 453, Train_Loss: 0.00456845
2025/09/16 22:02:10 : Epoch: 454, Train_Loss: 0.00762472
2025/09/16 22:02:10 : Epoch: 454, Eval_Loss: 0.00418470
2025/09/16 22:02:10 : Epoch: 454, Save the best checkpoint
2025/09/16 22:02:10 : Epoch: 455, Train_Loss: 0.00890674
2025/09/16 22:02:10 : Epoch: 456, Train_Loss: 0.00491675
2025/09/16 22:02:11 : Epoch: 457, Train_Loss: 0.00611097
2025/09/16 22:02:11 : Epoch: 458, Train_Loss: 0.00824491
2025/09/16 22:02:11 : Epoch: 459, Train_Loss: 0.00733420
2025/09/16 22:02:11 : Epoch: 459, Eval_Loss: 0.00485406
2025/09/16 22:02:11 : Epoch: 460, Train_Loss: 0.00657488
2025/09/16 22:02:12 : Epoch: 461, Train_Loss: 0.00714034
2025/09/16 22:02:12 : Epoch: 462, Train_Loss: 0.00597871
2025/09/16 22:02:12 : Epoch: 463, Train_Loss: 0.00556520
2025/09/16 22:02:12 : Epoch: 464, Train_Loss: 0.00787434
2025/09/16 22:02:12 : Epoch: 464, Eval_Loss: 0.00525278
2025/09/16 22:02:13 : Epoch: 465, Train_Loss: 0.00452722
2025/09/16 22:02:13 : Epoch: 466, Train_Loss: 0.00816349
2025/09/16 22:02:13 : Epoch: 467, Train_Loss: 0.00791101
2025/09/16 22:02:13 : Epoch: 468, Train_Loss: 0.00887417
2025/09/16 22:02:14 : Epoch: 469, Train_Loss: 0.00473898
2025/09/16 22:02:14 : Epoch: 469, Eval_Loss: 0.00479705
2025/09/16 22:02:14 : Epoch: 470, Train_Loss: 0.00741042
2025/09/16 22:02:14 : Epoch: 471, Train_Loss: 0.00871574
2025/09/16 22:02:14 : Epoch: 472, Train_Loss: 0.00614214
2025/09/16 22:02:15 : Epoch: 473, Train_Loss: 0.00813172
2025/09/16 22:02:15 : Epoch: 474, Train_Loss: 0.00487733
2025/09/16 22:02:15 : Epoch: 474, Eval_Loss: 0.00430261
2025/09/16 22:02:15 : Epoch: 475, Train_Loss: 0.00530181
2025/09/16 22:02:16 : Epoch: 476, Train_Loss: 0.00633200
2025/09/16 22:02:16 : Epoch: 477, Train_Loss: 0.00559290
2025/09/16 22:02:16 : Epoch: 478, Train_Loss: 0.00559738
2025/09/16 22:02:16 : Epoch: 479, Train_Loss: 0.00541886
2025/09/16 22:02:16 : Epoch: 479, Eval_Loss: 0.00397176
2025/09/16 22:02:16 : Epoch: 479, Save the best checkpoint
2025/09/16 22:02:17 : Epoch: 480, Train_Loss: 0.00968159
2025/09/16 22:02:17 : Epoch: 481, Train_Loss: 0.00796709
2025/09/16 22:02:17 : Epoch: 482, Train_Loss: 0.00703373
2025/09/16 22:02:17 : Epoch: 483, Train_Loss: 0.00794704
2025/09/16 22:02:18 : Epoch: 484, Train_Loss: 0.00501547
2025/09/16 22:02:18 : Epoch: 484, Eval_Loss: 0.00468043
2025/09/16 22:02:18 : Epoch: 485, Train_Loss: 0.00936111
2025/09/16 22:02:18 : Epoch: 486, Train_Loss: 0.00511504
2025/09/16 22:02:18 : Epoch: 487, Train_Loss: 0.00861375
2025/09/16 22:02:19 : Epoch: 488, Train_Loss: 0.00878505
2025/09/16 22:02:19 : Epoch: 489, Train_Loss: 0.00458161
2025/09/16 22:02:19 : Epoch: 489, Eval_Loss: 0.00488384
2025/09/16 22:02:19 : Epoch: 490, Train_Loss: 0.00498221
2025/09/16 22:02:19 : Epoch: 491, Train_Loss: 0.00773550
2025/09/16 22:02:20 : Epoch: 492, Train_Loss: 0.00594034
2025/09/16 22:02:20 : Epoch: 493, Train_Loss: 0.00569503
2025/09/16 22:02:20 : Epoch: 494, Train_Loss: 0.00545379
2025/09/16 22:02:20 : Epoch: 494, Eval_Loss: 0.00420727
2025/09/16 22:02:21 : Epoch: 495, Train_Loss: 0.00477201
2025/09/16 22:02:21 : Epoch: 496, Train_Loss: 0.00524720
2025/09/16 22:02:21 : Epoch: 497, Train_Loss: 0.00419906
2025/09/16 22:02:21 : Epoch: 498, Train_Loss: 0.00430479
2025/09/16 22:02:22 : Epoch: 499, Train_Loss: 0.00485772
2025/09/16 22:02:22 : Epoch: 499, Eval_Loss: 0.00447020
2025/09/16 22:02:22 : Epoch: 500, Train_Loss: 0.00467797
2025/09/16 22:02:22 : Epoch: 501, Train_Loss: 0.00587806
2025/09/16 22:02:22 : Epoch: 502, Train_Loss: 0.00651086
2025/09/16 22:02:23 : Epoch: 503, Train_Loss: 0.00744743
2025/09/16 22:02:23 : Epoch: 504, Train_Loss: 0.00657195
2025/09/16 22:02:23 : Epoch: 504, Eval_Loss: 0.00507422
2025/09/16 22:02:23 : Epoch: 505, Train_Loss: 0.00862887
2025/09/16 22:02:23 : Epoch: 506, Train_Loss: 0.00710087
2025/09/16 22:02:24 : Epoch: 507, Train_Loss: 0.00495851
2025/09/16 22:02:24 : Epoch: 508, Train_Loss: 0.00775062
2025/09/16 22:02:24 : Epoch: 509, Train_Loss: 0.00681485
2025/09/16 22:02:24 : Epoch: 509, Eval_Loss: 0.00602860
2025/09/16 22:02:24 : Epoch: 510, Train_Loss: 0.00662994
2025/09/16 22:02:25 : Epoch: 511, Train_Loss: 0.00455005
2025/09/16 22:02:25 : Epoch: 512, Train_Loss: 0.00712685
2025/09/16 22:02:25 : Epoch: 513, Train_Loss: 0.00559450
2025/09/16 22:02:25 : Epoch: 514, Train_Loss: 0.00556563
2025/09/16 22:02:26 : Epoch: 514, Eval_Loss: 0.00482281
2025/09/16 22:02:26 : Epoch: 515, Train_Loss: 0.00778012
2025/09/16 22:02:26 : Epoch: 516, Train_Loss: 0.00419892
2025/09/16 22:02:26 : Epoch: 517, Train_Loss: 0.00365243
2025/09/16 22:02:27 : Epoch: 518, Train_Loss: 0.00594937
2025/09/16 22:02:27 : Epoch: 519, Train_Loss: 0.00620572
2025/09/16 22:02:27 : Epoch: 519, Eval_Loss: 0.00699900
2025/09/16 22:02:27 : Epoch: 520, Train_Loss: 0.00985489
2025/09/16 22:02:27 : Epoch: 521, Train_Loss: 0.00655824
2025/09/16 22:02:28 : Epoch: 522, Train_Loss: 0.00641288
2025/09/16 22:02:28 : Epoch: 523, Train_Loss: 0.00876553
2025/09/16 22:02:28 : Epoch: 524, Train_Loss: 0.00629072
2025/09/16 22:02:28 : Epoch: 524, Eval_Loss: 0.00432607
2025/09/16 22:02:28 : Epoch: 525, Train_Loss: 0.00718342
2025/09/16 22:02:29 : Epoch: 526, Train_Loss: 0.00602911
2025/09/16 22:02:29 : Epoch: 527, Train_Loss: 0.00552284
2025/09/16 22:02:29 : Epoch: 528, Train_Loss: 0.00597695
2025/09/16 22:02:29 : Epoch: 529, Train_Loss: 0.00562580
2025/09/16 22:02:29 : Epoch: 529, Eval_Loss: 0.00435291
2025/09/16 22:02:30 : Epoch: 530, Train_Loss: 0.00903958
2025/09/16 22:02:30 : Epoch: 531, Train_Loss: 0.00617414
2025/09/16 22:02:30 : Epoch: 532, Train_Loss: 0.00800078
2025/09/16 22:02:30 : Epoch: 533, Train_Loss: 0.00575995
2025/09/16 22:02:31 : Epoch: 534, Train_Loss: 0.00618670
2025/09/16 22:02:31 : Epoch: 534, Eval_Loss: 0.00608521
2025/09/16 22:02:31 : Epoch: 535, Train_Loss: 0.00550845
2025/09/16 22:02:31 : Epoch: 536, Train_Loss: 0.00439319
2025/09/16 22:02:32 : Epoch: 537, Train_Loss: 0.00396315
2025/09/16 22:02:32 : Epoch: 538, Train_Loss: 0.00534790
2025/09/16 22:02:32 : Epoch: 539, Train_Loss: 0.00566922
2025/09/16 22:02:32 : Epoch: 539, Eval_Loss: 0.00656795
2025/09/16 22:02:32 : Epoch: 540, Train_Loss: 0.00565513
2025/09/16 22:02:33 : Epoch: 541, Train_Loss: 0.00777299
2025/09/16 22:02:33 : Epoch: 542, Train_Loss: 0.00714344
2025/09/16 22:02:33 : Epoch: 543, Train_Loss: 0.00798576
2025/09/16 22:02:33 : Epoch: 544, Train_Loss: 0.00938023
2025/09/16 22:02:33 : Epoch: 544, Eval_Loss: 0.00518774
2025/09/16 22:02:34 : Epoch: 545, Train_Loss: 0.00974601
2025/09/16 22:02:34 : Epoch: 546, Train_Loss: 0.00861748
2025/09/16 22:02:34 : Epoch: 547, Train_Loss: 0.00664696
2025/09/16 22:02:34 : Epoch: 548, Train_Loss: 0.00912156
2025/09/16 22:02:35 : Epoch: 549, Train_Loss: 0.00790602
2025/09/16 22:02:35 : Epoch: 549, Eval_Loss: 0.01976615
2025/09/16 22:02:35 : Epoch: 550, Train_Loss: 0.00784566
2025/09/16 22:02:35 : Epoch: 551, Train_Loss: 0.00740247
2025/09/16 22:02:36 : Epoch: 552, Train_Loss: 0.00539175
2025/09/16 22:02:36 : Epoch: 553, Train_Loss: 0.00628802
2025/09/16 22:02:36 : Epoch: 554, Train_Loss: 0.00545024
2025/09/16 22:02:36 : Epoch: 554, Eval_Loss: 0.01396454
2025/09/16 22:02:36 : Epoch: 555, Train_Loss: 0.00484279
2025/09/16 22:02:37 : Epoch: 556, Train_Loss: 0.00776156
2025/09/16 22:02:37 : Epoch: 557, Train_Loss: 0.00682198
2025/09/16 22:02:37 : Epoch: 558, Train_Loss: 0.00622870
2025/09/16 22:02:37 : Epoch: 559, Train_Loss: 0.00478120
2025/09/16 22:02:37 : Epoch: 559, Eval_Loss: 0.00713027
2025/09/16 22:02:38 : Epoch: 560, Train_Loss: 0.00543383
2025/09/16 22:02:38 : Epoch: 561, Train_Loss: 0.00695999
2025/09/16 22:02:38 : Epoch: 562, Train_Loss: 0.00642527
2025/09/16 22:02:38 : Epoch: 563, Train_Loss: 0.00569695
2025/09/16 22:02:39 : Epoch: 564, Train_Loss: 0.00673224
2025/09/16 22:02:39 : Epoch: 564, Eval_Loss: 0.00901076
2025/09/16 22:02:39 : Epoch: 565, Train_Loss: 0.00555949
2025/09/16 22:02:39 : Epoch: 566, Train_Loss: 0.00765349
2025/09/16 22:02:39 : Epoch: 567, Train_Loss: 0.00734664
2025/09/16 22:02:40 : Epoch: 568, Train_Loss: 0.00663090
2025/09/16 22:02:40 : Epoch: 569, Train_Loss: 0.00556417
2025/09/16 22:02:40 : Epoch: 569, Eval_Loss: 0.00691641
2025/09/16 22:02:40 : Epoch: 570, Train_Loss: 0.00711434
2025/09/16 22:02:41 : Epoch: 571, Train_Loss: 0.00861676
2025/09/16 22:02:41 : Epoch: 572, Train_Loss: 0.00562624
2025/09/16 22:02:41 : Epoch: 573, Train_Loss: 0.00622034
2025/09/16 22:02:41 : Epoch: 574, Train_Loss: 0.00591935
2025/09/16 22:02:41 : Epoch: 574, Eval_Loss: 0.01009530
2025/09/16 22:02:42 : Epoch: 575, Train_Loss: 0.00746385
2025/09/16 22:02:42 : Epoch: 576, Train_Loss: 0.00852871
2025/09/16 22:02:42 : Epoch: 577, Train_Loss: 0.00795797
2025/09/16 22:02:42 : Epoch: 578, Train_Loss: 0.00647713
2025/09/16 22:02:43 : Epoch: 579, Train_Loss: 0.00557173
2025/09/16 22:02:43 : Epoch: 579, Eval_Loss: 0.01115684
2025/09/16 22:02:43 : Epoch: 580, Train_Loss: 0.00583975
2025/09/16 22:02:43 : Epoch: 581, Train_Loss: 0.00543514
2025/09/16 22:02:43 : Epoch: 582, Train_Loss: 0.00581329
2025/09/16 22:02:44 : Epoch: 583, Train_Loss: 0.00510307
2025/09/16 22:02:44 : Epoch: 584, Train_Loss: 0.00464014
2025/09/16 22:02:44 : Epoch: 584, Eval_Loss: 0.00958453
2025/09/16 22:02:44 : Epoch: 585, Train_Loss: 0.00493119
2025/09/16 22:02:44 : Epoch: 586, Train_Loss: 0.00421715
2025/09/16 22:02:45 : Epoch: 587, Train_Loss: 0.00517306
2025/09/16 22:02:45 : Epoch: 588, Train_Loss: 0.00417083
2025/09/16 22:02:45 : Epoch: 589, Train_Loss: 0.00526336
2025/09/16 22:02:45 : Epoch: 589, Eval_Loss: 0.00676293
2025/09/16 22:02:46 : Epoch: 590, Train_Loss: 0.00561727
2025/09/16 22:02:46 : Epoch: 591, Train_Loss: 0.00538183
2025/09/16 22:02:46 : Epoch: 592, Train_Loss: 0.00516009
2025/09/16 22:02:46 : Epoch: 593, Train_Loss: 0.00507783
2025/09/16 22:02:47 : Epoch: 594, Train_Loss: 0.00541796
2025/09/16 22:02:47 : Epoch: 594, Eval_Loss: 0.00843816
2025/09/16 22:02:47 : Epoch: 595, Train_Loss: 0.00527712
2025/09/16 22:02:47 : Epoch: 596, Train_Loss: 0.00447266
2025/09/16 22:02:47 : Epoch: 597, Train_Loss: 0.00462693
2025/09/16 22:02:48 : Epoch: 598, Train_Loss: 0.00388421
2025/09/16 22:02:48 : Epoch: 599, Train_Loss: 0.00556894
2025/09/16 22:02:48 : Epoch: 599, Eval_Loss: 0.00727111
2025/09/16 22:02:48 : Epoch: 600, Train_Loss: 0.00462559
2025/09/16 22:02:48 : Epoch: 601, Train_Loss: 0.00393246
2025/09/16 22:02:49 : Epoch: 602, Train_Loss: 0.00598828
2025/09/16 22:02:49 : Epoch: 603, Train_Loss: 0.00583150
2025/09/16 22:02:49 : Epoch: 604, Train_Loss: 0.00706522
2025/09/16 22:02:49 : Epoch: 604, Eval_Loss: 0.00758393
2025/09/16 22:02:50 : Epoch: 605, Train_Loss: 0.00832974
2025/09/16 22:02:50 : Epoch: 606, Train_Loss: 0.00647409
2025/09/16 22:02:50 : Epoch: 607, Train_Loss: 0.00715483
2025/09/16 22:02:50 : Epoch: 608, Train_Loss: 0.00709470
2025/09/16 22:02:51 : Epoch: 609, Train_Loss: 0.00662792
2025/09/16 22:02:51 : Epoch: 609, Eval_Loss: 0.01063298
2025/09/16 22:02:51 : Epoch: 610, Train_Loss: 0.00729097
2025/09/16 22:02:51 : Epoch: 611, Train_Loss: 0.00735531
2025/09/16 22:02:51 : Epoch: 612, Train_Loss: 0.00491486
2025/09/16 22:02:52 : Epoch: 613, Train_Loss: 0.00645102
2025/09/16 22:02:52 : Epoch: 614, Train_Loss: 0.00668657
2025/09/16 22:02:52 : Epoch: 614, Eval_Loss: 0.00658028
2025/09/16 22:02:52 : Epoch: 615, Train_Loss: 0.00555110
2025/09/16 22:02:52 : Epoch: 616, Train_Loss: 0.00584560
2025/09/16 22:02:53 : Epoch: 617, Train_Loss: 0.00429376
2025/09/16 22:02:53 : Epoch: 618, Train_Loss: 0.00484963
2025/09/16 22:02:53 : Epoch: 619, Train_Loss: 0.00518855
2025/09/16 22:02:53 : Epoch: 619, Eval_Loss: 0.00611189
2025/09/16 22:02:53 : Epoch: 620, Train_Loss: 0.00402265
2025/09/16 22:02:54 : Epoch: 621, Train_Loss: 0.00536733
2025/09/16 22:02:54 : Epoch: 622, Train_Loss: 0.00375935
2025/09/16 22:02:54 : Epoch: 623, Train_Loss: 0.00322658
2025/09/16 22:02:54 : Epoch: 624, Train_Loss: 0.00403166
2025/09/16 22:02:54 : Epoch: 624, Eval_Loss: 0.00760097
2025/09/16 22:02:55 : Epoch: 625, Train_Loss: 0.00529263
2025/09/16 22:02:55 : Epoch: 626, Train_Loss: 0.00786461
2025/09/16 22:02:55 : Epoch: 627, Train_Loss: 0.00818834
2025/09/16 22:02:55 : Epoch: 628, Train_Loss: 0.00692196
2025/09/16 22:02:56 : Epoch: 629, Train_Loss: 0.00539273
2025/09/16 22:02:56 : Epoch: 629, Eval_Loss: 0.00809336
2025/09/16 22:02:56 : Epoch: 630, Train_Loss: 0.00842489
2025/09/16 22:02:56 : Epoch: 631, Train_Loss: 0.00560964
2025/09/16 22:02:57 : Epoch: 632, Train_Loss: 0.00808105
2025/09/16 22:02:57 : Epoch: 633, Train_Loss: 0.00643945
2025/09/16 22:02:57 : Epoch: 634, Train_Loss: 0.00564714
2025/09/16 22:02:57 : Epoch: 634, Eval_Loss: 0.00731681
2025/09/16 22:02:57 : Epoch: 635, Train_Loss: 0.00892706
2025/09/16 22:02:58 : Epoch: 636, Train_Loss: 0.00729188
2025/09/16 22:02:58 : Epoch: 637, Train_Loss: 0.00469758
2025/09/16 22:02:58 : Epoch: 638, Train_Loss: 0.00841308
2025/09/16 22:02:58 : Epoch: 639, Train_Loss: 0.00630373
2025/09/16 22:02:58 : Epoch: 639, Eval_Loss: 0.00947862
2025/09/16 22:02:59 : Epoch: 640, Train_Loss: 0.00523916
2025/09/16 22:02:59 : Epoch: 641, Train_Loss: 0.00724357
2025/09/16 22:02:59 : Epoch: 642, Train_Loss: 0.00549320
2025/09/16 22:02:59 : Epoch: 643, Train_Loss: 0.00637091
2025/09/16 22:03:00 : Epoch: 644, Train_Loss: 0.00583670
2025/09/16 22:03:00 : Epoch: 644, Eval_Loss: 0.00704228
2025/09/16 22:03:00 : Epoch: 645, Train_Loss: 0.00598534
2025/09/16 22:03:00 : Epoch: 646, Train_Loss: 0.00447936
2025/09/16 22:03:00 : Epoch: 647, Train_Loss: 0.00529157
2025/09/16 22:03:01 : Epoch: 648, Train_Loss: 0.00597996
2025/09/16 22:03:01 : Epoch: 649, Train_Loss: 0.00471299
2025/09/16 22:03:01 : Epoch: 649, Eval_Loss: 0.00850396
2025/09/16 22:03:01 : Epoch: 650, Train_Loss: 0.00439953
2025/09/16 22:03:01 : Epoch: 651, Train_Loss: 0.00537713
2025/09/16 22:03:02 : Epoch: 652, Train_Loss: 0.00610392
2025/09/16 22:03:02 : Epoch: 653, Train_Loss: 0.00552926
2025/09/16 22:03:02 : Epoch: 654, Train_Loss: 0.00685137
2025/09/16 22:03:02 : Epoch: 654, Eval_Loss: 0.00936161
2025/09/16 22:03:02 : Epoch: 655, Train_Loss: 0.00548056
2025/09/16 22:03:03 : Epoch: 656, Train_Loss: 0.00727408
2025/09/16 22:03:03 : Epoch: 657, Train_Loss: 0.00649461
2025/09/16 22:03:03 : Epoch: 658, Train_Loss: 0.00788831
2025/09/16 22:03:03 : Epoch: 659, Train_Loss: 0.00670789
2025/09/16 22:03:04 : Epoch: 659, Eval_Loss: 0.01497772
2025/09/16 22:03:04 : Epoch: 660, Train_Loss: 0.00475960
2025/09/16 22:03:04 : Epoch: 661, Train_Loss: 0.00608155
2025/09/16 22:03:04 : Epoch: 662, Train_Loss: 0.00538087
2025/09/16 22:03:05 : Epoch: 663, Train_Loss: 0.00450949
2025/09/16 22:03:05 : Epoch: 664, Train_Loss: 0.00362564
2025/09/16 22:03:05 : Epoch: 664, Eval_Loss: 0.00741253
2025/09/16 22:03:05 : Epoch: 665, Train_Loss: 0.00646180
2025/09/16 22:03:05 : Epoch: 666, Train_Loss: 0.00499080
2025/09/16 22:03:06 : Epoch: 667, Train_Loss: 0.00877797
2025/09/16 22:03:06 : Epoch: 668, Train_Loss: 0.00712582
2025/09/16 22:03:06 : Epoch: 669, Train_Loss: 0.00749280
2025/09/16 22:03:06 : Epoch: 669, Eval_Loss: 0.00823228
2025/09/16 22:03:06 : Epoch: 670, Train_Loss: 0.00450701
2025/09/16 22:03:07 : Epoch: 671, Train_Loss: 0.00499235
2025/09/16 22:03:07 : Epoch: 672, Train_Loss: 0.00545939
2025/09/16 22:03:07 : Epoch: 673, Train_Loss: 0.00417639
2025/09/16 22:03:07 : Epoch: 674, Train_Loss: 0.00635785
2025/09/16 22:03:07 : Epoch: 674, Eval_Loss: 0.00506408
2025/09/16 22:03:08 : Epoch: 675, Train_Loss: 0.00454794
2025/09/16 22:03:08 : Epoch: 676, Train_Loss: 0.00472312
2025/09/16 22:03:08 : Epoch: 677, Train_Loss: 0.00397964
2025/09/16 22:03:08 : Epoch: 678, Train_Loss: 0.00317562
2025/09/16 22:03:09 : Epoch: 679, Train_Loss: 0.00359866
2025/09/16 22:03:09 : Epoch: 679, Eval_Loss: 0.00579032
2025/09/16 22:03:09 : Epoch: 680, Train_Loss: 0.00386038
2025/09/16 22:03:09 : Epoch: 681, Train_Loss: 0.00378433
2025/09/16 22:03:09 : Epoch: 682, Train_Loss: 0.00421587
2025/09/16 22:03:10 : Epoch: 683, Train_Loss: 0.00501109
2025/09/16 22:03:10 : Epoch: 684, Train_Loss: 0.00503504
2025/09/16 22:03:10 : Epoch: 684, Eval_Loss: 0.00825242
2025/09/16 22:03:10 : Epoch: 685, Train_Loss: 0.00570431
2025/09/16 22:03:11 : Epoch: 686, Train_Loss: 0.00497087
2025/09/16 22:03:11 : Epoch: 687, Train_Loss: 0.00302311
2025/09/16 22:03:11 : Epoch: 688, Train_Loss: 0.00489696
2025/09/16 22:03:11 : Epoch: 689, Train_Loss: 0.00444371
2025/09/16 22:03:11 : Epoch: 689, Eval_Loss: 0.01174902
2025/09/16 22:03:12 : Epoch: 690, Train_Loss: 0.00430240
2025/09/16 22:03:12 : Epoch: 691, Train_Loss: 0.00383410
2025/09/16 22:03:12 : Epoch: 692, Train_Loss: 0.00640988
2025/09/16 22:03:12 : Epoch: 693, Train_Loss: 0.00513490
2025/09/16 22:03:13 : Epoch: 694, Train_Loss: 0.00337953
2025/09/16 22:03:13 : Epoch: 694, Eval_Loss: 0.01176721
2025/09/16 22:03:13 : Epoch: 695, Train_Loss: 0.00478041
2025/09/16 22:03:13 : Epoch: 696, Train_Loss: 0.00396929
2025/09/16 22:03:13 : Epoch: 697, Train_Loss: 0.00530582
2025/09/16 22:03:14 : Epoch: 698, Train_Loss: 0.00512626
2025/09/16 22:03:14 : Epoch: 699, Train_Loss: 0.00404186
2025/09/16 22:03:14 : Epoch: 699, Eval_Loss: 0.01186463
2025/09/16 22:03:14 : Epoch: 700, Train_Loss: 0.00424766
2025/09/16 22:03:14 : Epoch: 701, Train_Loss: 0.00506940
2025/09/16 22:03:15 : Epoch: 702, Train_Loss: 0.00396229
2025/09/16 22:03:15 : Epoch: 703, Train_Loss: 0.00383196
2025/09/16 22:03:15 : Epoch: 704, Train_Loss: 0.00289851
2025/09/16 22:03:15 : Epoch: 704, Eval_Loss: 0.00843811
2025/09/16 22:03:16 : Epoch: 705, Train_Loss: 0.00357009
2025/09/16 22:03:16 : Epoch: 706, Train_Loss: 0.00322317
2025/09/16 22:03:16 : Epoch: 707, Train_Loss: 0.00540802
2025/09/16 22:03:16 : Epoch: 708, Train_Loss: 0.00379466
2025/09/16 22:03:16 : Epoch: 709, Train_Loss: 0.00326778
2025/09/16 22:03:17 : Epoch: 709, Eval_Loss: 0.00913912
2025/09/16 22:03:17 : Epoch: 710, Train_Loss: 0.00470997
2025/09/16 22:03:17 : Epoch: 711, Train_Loss: 0.00422065
2025/09/16 22:03:17 : Epoch: 712, Train_Loss: 0.00292617
2025/09/16 22:03:18 : Epoch: 713, Train_Loss: 0.00302355
2025/09/16 22:03:18 : Epoch: 714, Train_Loss: 0.00363397
2025/09/16 22:03:18 : Epoch: 714, Eval_Loss: 0.00976891
2025/09/16 22:03:18 : Epoch: 715, Train_Loss: 0.00302621
2025/09/16 22:03:18 : Epoch: 716, Train_Loss: 0.00312184
2025/09/16 22:03:19 : Epoch: 717, Train_Loss: 0.00280052
2025/09/16 22:03:19 : Epoch: 718, Train_Loss: 0.00451967
2025/09/16 22:03:19 : Epoch: 719, Train_Loss: 0.00328112
2025/09/16 22:03:19 : Epoch: 719, Eval_Loss: 0.01066041
2025/09/16 22:03:19 : Epoch: 720, Train_Loss: 0.00388652
2025/09/16 22:03:20 : Epoch: 721, Train_Loss: 0.00356023
2025/09/16 22:03:20 : Epoch: 722, Train_Loss: 0.00497887
2025/09/16 22:03:20 : Epoch: 723, Train_Loss: 0.00397329
2025/09/16 22:03:20 : Epoch: 724, Train_Loss: 0.00306568
2025/09/16 22:03:21 : Epoch: 724, Eval_Loss: 0.00963308
2025/09/16 22:03:21 : Epoch: 725, Train_Loss: 0.00335318
2025/09/16 22:03:21 : Epoch: 726, Train_Loss: 0.00439882
2025/09/16 22:03:21 : Epoch: 727, Train_Loss: 0.00330611
2025/09/16 22:03:22 : Epoch: 728, Train_Loss: 0.00389711
2025/09/16 22:03:22 : Epoch: 729, Train_Loss: 0.00418631
2025/09/16 22:03:22 : Epoch: 729, Eval_Loss: 0.00887897
2025/09/16 22:03:22 : Epoch: 730, Train_Loss: 0.00577860
2025/09/16 22:03:22 : Epoch: 731, Train_Loss: 0.00411179
2025/09/16 22:03:23 : Epoch: 732, Train_Loss: 0.00475681
2025/09/16 22:03:23 : Epoch: 733, Train_Loss: 0.00434024
2025/09/16 22:03:23 : Epoch: 734, Train_Loss: 0.00367314
2025/09/16 22:03:23 : Epoch: 734, Eval_Loss: 0.01330995
2025/09/16 22:03:23 : Epoch: 735, Train_Loss: 0.00549088
2025/09/16 22:03:24 : Epoch: 736, Train_Loss: 0.00331989
2025/09/16 22:03:24 : Epoch: 737, Train_Loss: 0.00415320
2025/09/16 22:03:24 : Epoch: 738, Train_Loss: 0.00395046
2025/09/16 22:03:24 : Epoch: 739, Train_Loss: 0.00274180
2025/09/16 22:03:24 : Epoch: 739, Eval_Loss: 0.01156404
2025/09/16 22:03:25 : Epoch: 740, Train_Loss: 0.00420615
2025/09/16 22:03:25 : Epoch: 741, Train_Loss: 0.00374447
2025/09/16 22:03:25 : Epoch: 742, Train_Loss: 0.00457945
2025/09/16 22:03:25 : Epoch: 743, Train_Loss: 0.00386155
2025/09/16 22:03:26 : Epoch: 744, Train_Loss: 0.00322995
2025/09/16 22:03:26 : Epoch: 744, Eval_Loss: 0.01155453
2025/09/16 22:03:26 : Epoch: 745, Train_Loss: 0.00370469
2025/09/16 22:03:26 : Epoch: 746, Train_Loss: 0.00299329
2025/09/16 22:03:26 : Epoch: 747, Train_Loss: 0.00321028
2025/09/16 22:03:27 : Epoch: 748, Train_Loss: 0.00245295
2025/09/16 22:03:27 : Epoch: 749, Train_Loss: 0.00289158
2025/09/16 22:03:27 : Epoch: 749, Eval_Loss: 0.00884409
2025/09/16 22:03:27 : Epoch: 750, Train_Loss: 0.00366577
2025/09/16 22:03:27 : Epoch: 751, Train_Loss: 0.00225329
2025/09/16 22:03:28 : Epoch: 752, Train_Loss: 0.00510068
2025/09/16 22:03:28 : Epoch: 753, Train_Loss: 0.00500647
2025/09/16 22:03:28 : Epoch: 754, Train_Loss: 0.00560165
2025/09/16 22:03:28 : Epoch: 754, Eval_Loss: 0.00891955
2025/09/16 22:03:29 : Epoch: 755, Train_Loss: 0.00333382
2025/09/16 22:03:29 : Epoch: 756, Train_Loss: 0.00401236
2025/09/16 22:03:29 : Epoch: 757, Train_Loss: 0.00432540
2025/09/16 22:03:29 : Epoch: 758, Train_Loss: 0.00372491
2025/09/16 22:03:30 : Epoch: 759, Train_Loss: 0.00386135
2025/09/16 22:03:30 : Epoch: 759, Eval_Loss: 0.00862072
2025/09/16 22:03:30 : Epoch: 760, Train_Loss: 0.00335197
2025/09/16 22:03:30 : Epoch: 761, Train_Loss: 0.00339045
2025/09/16 22:03:30 : Epoch: 762, Train_Loss: 0.00332946
2025/09/16 22:03:31 : Epoch: 763, Train_Loss: 0.00294052
2025/09/16 22:03:31 : Epoch: 764, Train_Loss: 0.00371029
2025/09/16 22:03:31 : Epoch: 764, Eval_Loss: 0.00919253
2025/09/16 22:03:31 : Epoch: 765, Train_Loss: 0.00430547
2025/09/16 22:03:31 : Epoch: 766, Train_Loss: 0.00448924
2025/09/16 22:03:32 : Epoch: 767, Train_Loss: 0.00546472
2025/09/16 22:03:32 : Epoch: 768, Train_Loss: 0.00798816
2025/09/16 22:03:32 : Epoch: 769, Train_Loss: 0.00413692
2025/09/16 22:03:32 : Epoch: 769, Eval_Loss: 0.00753164
2025/09/16 22:03:33 : Epoch: 770, Train_Loss: 0.00694811
2025/09/16 22:03:33 : Epoch: 771, Train_Loss: 0.00461190
2025/09/16 22:03:33 : Epoch: 772, Train_Loss: 0.00545928
2025/09/16 22:03:33 : Epoch: 773, Train_Loss: 0.00424084
2025/09/16 22:03:34 : Epoch: 774, Train_Loss: 0.00648712
2025/09/16 22:03:34 : Epoch: 774, Eval_Loss: 0.00814324
2025/09/16 22:03:34 : Epoch: 775, Train_Loss: 0.00555181
2025/09/16 22:03:34 : Epoch: 776, Train_Loss: 0.00324711
2025/09/16 22:03:34 : Epoch: 777, Train_Loss: 0.00373996
2025/09/16 22:03:35 : Epoch: 778, Train_Loss: 0.00639596
2025/09/16 22:03:35 : Epoch: 779, Train_Loss: 0.00351922
2025/09/16 22:03:35 : Epoch: 779, Eval_Loss: 0.00643157
2025/09/16 22:03:35 : Epoch: 780, Train_Loss: 0.00470173
2025/09/16 22:03:35 : Epoch: 781, Train_Loss: 0.00527719
2025/09/16 22:03:36 : Epoch: 782, Train_Loss: 0.00366616
2025/09/16 22:03:36 : Epoch: 783, Train_Loss: 0.00355040
2025/09/16 22:03:36 : Epoch: 784, Train_Loss: 0.00396999
2025/09/16 22:03:36 : Epoch: 784, Eval_Loss: 0.00862965
2025/09/16 22:03:36 : Epoch: 785, Train_Loss: 0.00415893
2025/09/16 22:03:37 : Epoch: 786, Train_Loss: 0.00384351
2025/09/16 22:03:37 : Epoch: 787, Train_Loss: 0.00406540
2025/09/16 22:03:37 : Epoch: 788, Train_Loss: 0.00399138
2025/09/16 22:03:37 : Epoch: 789, Train_Loss: 0.00347380
2025/09/16 22:03:38 : Epoch: 789, Eval_Loss: 0.00786116
2025/09/16 22:03:38 : Epoch: 790, Train_Loss: 0.00344140
2025/09/16 22:03:38 : Epoch: 791, Train_Loss: 0.00295605
2025/09/16 22:03:38 : Epoch: 792, Train_Loss: 0.00569447
2025/09/16 22:03:39 : Epoch: 793, Train_Loss: 0.00264276
2025/09/16 22:03:39 : Epoch: 794, Train_Loss: 0.00405419
2025/09/16 22:03:39 : Epoch: 794, Eval_Loss: 0.01063364
2025/09/16 22:03:39 : Epoch: 795, Train_Loss: 0.00303432
2025/09/16 22:03:39 : Epoch: 796, Train_Loss: 0.00545839
2025/09/16 22:03:40 : Epoch: 797, Train_Loss: 0.00397284
2025/09/16 22:03:40 : Epoch: 798, Train_Loss: 0.00333423
2025/09/16 22:03:40 : Epoch: 799, Train_Loss: 0.00254241
2025/09/16 22:03:40 : Epoch: 799, Eval_Loss: 0.01077681
2025/09/16 22:03:40 : 
Epoch: 799, save response figures

2025/09/16 22:03:53 : Epoch: 800, Train_Loss: 0.00311186
2025/09/16 22:03:53 : Epoch: 801, Train_Loss: 0.00287878
2025/09/16 22:03:53 : Epoch: 802, Train_Loss: 0.00281468
2025/09/16 22:03:53 : Epoch: 803, Train_Loss: 0.00292667
2025/09/16 22:03:54 : Epoch: 804, Train_Loss: 0.00301847
2025/09/16 22:03:54 : Epoch: 804, Eval_Loss: 0.01064250
2025/09/16 22:03:54 : Epoch: 805, Train_Loss: 0.00319338
2025/09/16 22:03:54 : Epoch: 806, Train_Loss: 0.00290422
2025/09/16 22:03:55 : Epoch: 807, Train_Loss: 0.00369146
2025/09/16 22:03:55 : Epoch: 808, Train_Loss: 0.00258137
2025/09/16 22:03:55 : Epoch: 809, Train_Loss: 0.00222834
2025/09/16 22:03:55 : Epoch: 809, Eval_Loss: 0.01117813
2025/09/16 22:03:55 : Epoch: 810, Train_Loss: 0.00417827
2025/09/16 22:03:56 : Epoch: 811, Train_Loss: 0.00322637
2025/09/16 22:03:56 : Epoch: 812, Train_Loss: 0.00354014
2025/09/16 22:03:56 : Epoch: 813, Train_Loss: 0.00205940
2025/09/16 22:03:56 : Epoch: 814, Train_Loss: 0.00259862
2025/09/16 22:03:56 : Epoch: 814, Eval_Loss: 0.01078689
2025/09/16 22:03:57 : Epoch: 815, Train_Loss: 0.00237724
2025/09/16 22:03:57 : Epoch: 816, Train_Loss: 0.00387176
2025/09/16 22:03:57 : Epoch: 817, Train_Loss: 0.00255288
2025/09/16 22:03:57 : Epoch: 818, Train_Loss: 0.00248060
2025/09/16 22:03:58 : Epoch: 819, Train_Loss: 0.00236574
2025/09/16 22:03:58 : Epoch: 819, Eval_Loss: 0.01021079
2025/09/16 22:03:58 : Epoch: 820, Train_Loss: 0.00282209
2025/09/16 22:03:58 : Epoch: 821, Train_Loss: 0.00215817
2025/09/16 22:03:58 : Epoch: 822, Train_Loss: 0.00307678
2025/09/16 22:03:59 : Epoch: 823, Train_Loss: 0.00452468
2025/09/16 22:03:59 : Epoch: 824, Train_Loss: 0.00332105
2025/09/16 22:03:59 : Epoch: 824, Eval_Loss: 0.01252185
2025/09/16 22:03:59 : Epoch: 825, Train_Loss: 0.00264486
2025/09/16 22:04:00 : Epoch: 826, Train_Loss: 0.00287660
2025/09/16 22:04:00 : Epoch: 827, Train_Loss: 0.00357483
2025/09/16 22:04:00 : Epoch: 828, Train_Loss: 0.00271404
2025/09/16 22:04:00 : Epoch: 829, Train_Loss: 0.00231812
2025/09/16 22:04:00 : Epoch: 829, Eval_Loss: 0.01547432
2025/09/16 22:04:01 : Epoch: 830, Train_Loss: 0.00239030
2025/09/16 22:04:01 : Epoch: 831, Train_Loss: 0.00232618
2025/09/16 22:04:01 : Epoch: 832, Train_Loss: 0.00302546
2025/09/16 22:04:01 : Epoch: 833, Train_Loss: 0.00253800
2025/09/16 22:04:02 : Epoch: 834, Train_Loss: 0.00280498
2025/09/16 22:04:02 : Epoch: 834, Eval_Loss: 0.01659897
2025/09/16 22:04:02 : Epoch: 835, Train_Loss: 0.00340031
2025/09/16 22:04:02 : Epoch: 836, Train_Loss: 0.00412756
2025/09/16 22:04:02 : Epoch: 837, Train_Loss: 0.00401056
2025/09/16 22:04:03 : Epoch: 838, Train_Loss: 0.00309212
2025/09/16 22:04:03 : Epoch: 839, Train_Loss: 0.00397517
2025/09/16 22:04:03 : Epoch: 839, Eval_Loss: 0.01645068
2025/09/16 22:04:03 : Epoch: 840, Train_Loss: 0.00388802
2025/09/16 22:04:03 : Epoch: 841, Train_Loss: 0.00345008
2025/09/16 22:04:04 : Epoch: 842, Train_Loss: 0.00258448
2025/09/16 22:04:04 : Epoch: 843, Train_Loss: 0.00263626
2025/09/16 22:04:04 : Epoch: 844, Train_Loss: 0.00435799
2025/09/16 22:04:04 : Epoch: 844, Eval_Loss: 0.01238470
2025/09/16 22:04:05 : Epoch: 845, Train_Loss: 0.00327770
2025/09/16 22:04:05 : Epoch: 846, Train_Loss: 0.00383879
2025/09/16 22:04:05 : Epoch: 847, Train_Loss: 0.00286417
2025/09/16 22:04:05 : Epoch: 848, Train_Loss: 0.00257678
2025/09/16 22:04:05 : Epoch: 849, Train_Loss: 0.00299087
2025/09/16 22:04:06 : Epoch: 849, Eval_Loss: 0.01144091
2025/09/16 22:04:06 : Epoch: 850, Train_Loss: 0.00345246
2025/09/16 22:04:06 : Epoch: 851, Train_Loss: 0.00283877
2025/09/16 22:04:06 : Epoch: 852, Train_Loss: 0.00283985
2025/09/16 22:04:07 : Epoch: 853, Train_Loss: 0.00472248
2025/09/16 22:04:07 : Epoch: 854, Train_Loss: 0.00277444
2025/09/16 22:04:07 : Epoch: 854, Eval_Loss: 0.00699896
2025/09/16 22:04:07 : Epoch: 855, Train_Loss: 0.00360965
2025/09/16 22:04:07 : Epoch: 856, Train_Loss: 0.00437646
2025/09/16 22:04:08 : Epoch: 857, Train_Loss: 0.00363253
2025/09/16 22:04:08 : Epoch: 858, Train_Loss: 0.00375819
2025/09/16 22:04:08 : Epoch: 859, Train_Loss: 0.00458142
2025/09/16 22:04:08 : Epoch: 859, Eval_Loss: 0.00882562
2025/09/16 22:04:08 : Epoch: 860, Train_Loss: 0.00435091
2025/09/16 22:04:09 : Epoch: 861, Train_Loss: 0.00288624
2025/09/16 22:04:09 : Epoch: 862, Train_Loss: 0.00415062
2025/09/16 22:04:09 : Epoch: 863, Train_Loss: 0.00259464
2025/09/16 22:04:09 : Epoch: 864, Train_Loss: 0.00264265
2025/09/16 22:04:10 : Epoch: 864, Eval_Loss: 0.00637115
2025/09/16 22:04:10 : Epoch: 865, Train_Loss: 0.00395064
2025/09/16 22:04:10 : Epoch: 866, Train_Loss: 0.00281039
2025/09/16 22:04:10 : Epoch: 867, Train_Loss: 0.00248201
2025/09/16 22:04:11 : Epoch: 868, Train_Loss: 0.00485292
2025/09/16 22:04:11 : Epoch: 869, Train_Loss: 0.00362541
2025/09/16 22:04:11 : Epoch: 869, Eval_Loss: 0.00648997
2025/09/16 22:04:11 : Epoch: 870, Train_Loss: 0.00300684
2025/09/16 22:04:11 : Epoch: 871, Train_Loss: 0.00317580
2025/09/16 22:04:12 : Epoch: 872, Train_Loss: 0.00459938
2025/09/16 22:04:12 : Epoch: 873, Train_Loss: 0.00368921
2025/09/16 22:04:12 : Epoch: 874, Train_Loss: 0.00329683
2025/09/16 22:04:12 : Epoch: 874, Eval_Loss: 0.00624021
2025/09/16 22:04:12 : Epoch: 875, Train_Loss: 0.00231005
2025/09/16 22:04:13 : Epoch: 876, Train_Loss: 0.00329636
2025/09/16 22:04:13 : Epoch: 877, Train_Loss: 0.00285201
2025/09/16 22:04:13 : Epoch: 878, Train_Loss: 0.00395773
2025/09/16 22:04:13 : Epoch: 879, Train_Loss: 0.00270615
2025/09/16 22:04:13 : Epoch: 879, Eval_Loss: 0.00733493
2025/09/16 22:04:14 : Epoch: 880, Train_Loss: 0.00541888
2025/09/16 22:04:14 : Epoch: 881, Train_Loss: 0.00341278
2025/09/16 22:04:14 : Epoch: 882, Train_Loss: 0.00454215
2025/09/16 22:04:14 : Epoch: 883, Train_Loss: 0.00284322
2025/09/16 22:04:15 : Epoch: 884, Train_Loss: 0.00279730
2025/09/16 22:04:15 : Epoch: 884, Eval_Loss: 0.00838678
2025/09/16 22:04:15 : Epoch: 885, Train_Loss: 0.00286727
2025/09/16 22:04:15 : Epoch: 886, Train_Loss: 0.00297805
2025/09/16 22:04:15 : Epoch: 887, Train_Loss: 0.00310600
2025/09/16 22:04:16 : Epoch: 888, Train_Loss: 0.00358068
2025/09/16 22:04:16 : Epoch: 889, Train_Loss: 0.00310608
2025/09/16 22:04:16 : Epoch: 889, Eval_Loss: 0.00828411
2025/09/16 22:04:16 : Epoch: 890, Train_Loss: 0.00218317
2025/09/16 22:04:16 : Epoch: 891, Train_Loss: 0.00241240
2025/09/16 22:04:17 : Epoch: 892, Train_Loss: 0.00362710
2025/09/16 22:04:17 : Epoch: 893, Train_Loss: 0.00211768
2025/09/16 22:04:17 : Epoch: 894, Train_Loss: 0.00267280
2025/09/16 22:04:17 : Epoch: 894, Eval_Loss: 0.00752160
2025/09/16 22:04:18 : Epoch: 895, Train_Loss: 0.00197526
2025/09/16 22:04:18 : Epoch: 896, Train_Loss: 0.00296206
2025/09/16 22:04:18 : Epoch: 897, Train_Loss: 0.00283980
2025/09/16 22:04:18 : Epoch: 898, Train_Loss: 0.00197847
2025/09/16 22:04:19 : Epoch: 899, Train_Loss: 0.00350476
2025/09/16 22:04:19 : Epoch: 899, Eval_Loss: 0.00893571
2025/09/16 22:04:19 : Epoch: 900, Train_Loss: 0.00314810
2025/09/16 22:04:19 : Epoch: 901, Train_Loss: 0.00388528
2025/09/16 22:04:19 : Epoch: 902, Train_Loss: 0.00241430
2025/09/16 22:04:20 : Epoch: 903, Train_Loss: 0.00177152
2025/09/16 22:04:20 : Epoch: 904, Train_Loss: 0.00188805
2025/09/16 22:04:20 : Epoch: 904, Eval_Loss: 0.00834288
2025/09/16 22:04:20 : Epoch: 905, Train_Loss: 0.00323142
2025/09/16 22:04:20 : Epoch: 906, Train_Loss: 0.00171525
2025/09/16 22:04:21 : Epoch: 907, Train_Loss: 0.00206884
2025/09/16 22:04:21 : Epoch: 908, Train_Loss: 0.00193965
2025/09/16 22:04:21 : Epoch: 909, Train_Loss: 0.00207258
2025/09/16 22:04:21 : Epoch: 909, Eval_Loss: 0.00884679
2025/09/16 22:04:21 : Epoch: 910, Train_Loss: 0.00173483
2025/09/16 22:04:22 : Epoch: 911, Train_Loss: 0.00314674
2025/09/16 22:04:22 : Epoch: 912, Train_Loss: 0.00316222
2025/09/16 22:04:22 : Epoch: 913, Train_Loss: 0.00345062
2025/09/16 22:04:22 : Epoch: 914, Train_Loss: 0.00794841
2025/09/16 22:04:23 : Epoch: 914, Eval_Loss: 0.00822699
2025/09/16 22:04:23 : Epoch: 915, Train_Loss: 0.00344928
2025/09/16 22:04:23 : Epoch: 916, Train_Loss: 0.00518173
2025/09/16 22:04:23 : Epoch: 917, Train_Loss: 0.00338035
2025/09/16 22:04:24 : Epoch: 918, Train_Loss: 0.00478127
2025/09/16 22:04:24 : Epoch: 919, Train_Loss: 0.00378712
2025/09/16 22:04:24 : Epoch: 919, Eval_Loss: 0.00652647
2025/09/16 22:04:24 : Epoch: 920, Train_Loss: 0.00435461
2025/09/16 22:04:24 : Epoch: 921, Train_Loss: 0.00355434
2025/09/16 22:04:25 : Epoch: 922, Train_Loss: 0.00499428
2025/09/16 22:04:25 : Epoch: 923, Train_Loss: 0.00315684
2025/09/16 22:04:25 : Epoch: 924, Train_Loss: 0.00287458
2025/09/16 22:04:25 : Epoch: 924, Eval_Loss: 0.00548827
2025/09/16 22:04:25 : Epoch: 925, Train_Loss: 0.00455183
2025/09/16 22:04:26 : Epoch: 926, Train_Loss: 0.00386747
2025/09/16 22:04:26 : Epoch: 927, Train_Loss: 0.00298431
2025/09/16 22:04:26 : Epoch: 928, Train_Loss: 0.00279127
2025/09/16 22:04:26 : Epoch: 929, Train_Loss: 0.00505948
2025/09/16 22:04:26 : Epoch: 929, Eval_Loss: 0.00599572
2025/09/16 22:04:27 : Epoch: 930, Train_Loss: 0.00260834
2025/09/16 22:04:27 : Epoch: 931, Train_Loss: 0.00251054
2025/09/16 22:04:27 : Epoch: 932, Train_Loss: 0.00343330
2025/09/16 22:04:27 : Epoch: 933, Train_Loss: 0.00445205
2025/09/16 22:04:28 : Epoch: 934, Train_Loss: 0.00531573
2025/09/16 22:04:28 : Epoch: 934, Eval_Loss: 0.00830261
2025/09/16 22:04:28 : Epoch: 935, Train_Loss: 0.00493427
2025/09/16 22:04:28 : Epoch: 936, Train_Loss: 0.00320035
2025/09/16 22:04:29 : Epoch: 937, Train_Loss: 0.00382726
2025/09/16 22:04:29 : Epoch: 938, Train_Loss: 0.00277320
2025/09/16 22:04:29 : Epoch: 939, Train_Loss: 0.00407045
2025/09/16 22:04:29 : Epoch: 939, Eval_Loss: 0.01002184
2025/09/16 22:04:29 : Epoch: 940, Train_Loss: 0.00419926
2025/09/16 22:04:30 : Epoch: 941, Train_Loss: 0.00393222
2025/09/16 22:04:30 : Epoch: 942, Train_Loss: 0.00264077
2025/09/16 22:04:30 : Epoch: 943, Train_Loss: 0.00235115
2025/09/16 22:04:30 : Epoch: 944, Train_Loss: 0.00206400
2025/09/16 22:04:30 : Epoch: 944, Eval_Loss: 0.00524813
2025/09/16 22:04:31 : Epoch: 945, Train_Loss: 0.00243051
2025/09/16 22:04:31 : Epoch: 946, Train_Loss: 0.00235684
2025/09/16 22:04:31 : Epoch: 947, Train_Loss: 0.00420400
2025/09/16 22:04:31 : Epoch: 948, Train_Loss: 0.00274244
2025/09/16 22:04:32 : Epoch: 949, Train_Loss: 0.00237811
2025/09/16 22:04:32 : Epoch: 949, Eval_Loss: 0.00671782
2025/09/16 22:04:32 : Epoch: 950, Train_Loss: 0.00242639
2025/09/16 22:04:32 : Epoch: 951, Train_Loss: 0.00226089
2025/09/16 22:04:32 : Epoch: 952, Train_Loss: 0.00312677
2025/09/16 22:04:33 : Epoch: 953, Train_Loss: 0.00346595
2025/09/16 22:04:33 : Epoch: 954, Train_Loss: 0.00192537
2025/09/16 22:04:33 : Epoch: 954, Eval_Loss: 0.00710266
2025/09/16 22:04:33 : Epoch: 955, Train_Loss: 0.00242859
2025/09/16 22:04:33 : Epoch: 956, Train_Loss: 0.00293686
2025/09/16 22:04:34 : Epoch: 957, Train_Loss: 0.00396967
2025/09/16 22:04:34 : Epoch: 958, Train_Loss: 0.00253251
2025/09/16 22:04:34 : Epoch: 959, Train_Loss: 0.00445485
2025/09/16 22:04:34 : Epoch: 959, Eval_Loss: 0.00667537
2025/09/16 22:04:35 : Epoch: 960, Train_Loss: 0.00397057
2025/09/16 22:04:35 : Epoch: 961, Train_Loss: 0.00248928
2025/09/16 22:04:35 : Epoch: 962, Train_Loss: 0.00218499
2025/09/16 22:04:35 : Epoch: 963, Train_Loss: 0.00224651
2025/09/16 22:04:36 : Epoch: 964, Train_Loss: 0.00271258
2025/09/16 22:04:36 : Epoch: 964, Eval_Loss: 0.00625583
2025/09/16 22:04:36 : Epoch: 965, Train_Loss: 0.00212534
2025/09/16 22:04:36 : Epoch: 966, Train_Loss: 0.00219087
2025/09/16 22:04:36 : Epoch: 967, Train_Loss: 0.00231423
2025/09/16 22:04:37 : Epoch: 968, Train_Loss: 0.00260987
2025/09/16 22:04:37 : Epoch: 969, Train_Loss: 0.00300228
2025/09/16 22:04:37 : Epoch: 969, Eval_Loss: 0.00653503
2025/09/16 22:04:37 : Epoch: 970, Train_Loss: 0.00504058
2025/09/16 22:04:37 : Epoch: 971, Train_Loss: 0.00294849
2025/09/16 22:04:38 : Epoch: 972, Train_Loss: 0.00253702
2025/09/16 22:04:38 : Epoch: 973, Train_Loss: 0.00400078
2025/09/16 22:04:38 : Epoch: 974, Train_Loss: 0.00222463
2025/09/16 22:04:38 : Epoch: 974, Eval_Loss: 0.00758333
2025/09/16 22:04:39 : Epoch: 975, Train_Loss: 0.00409165
2025/09/16 22:04:39 : Epoch: 976, Train_Loss: 0.00216124
2025/09/16 22:04:39 : Epoch: 977, Train_Loss: 0.00311632
2025/09/16 22:04:39 : Epoch: 978, Train_Loss: 0.00447820
2025/09/16 22:04:40 : Epoch: 979, Train_Loss: 0.00427799
2025/09/16 22:04:40 : Epoch: 979, Eval_Loss: 0.00666996
2025/09/16 22:04:40 : Epoch: 980, Train_Loss: 0.00390340
2025/09/16 22:04:40 : Epoch: 981, Train_Loss: 0.00418221
2025/09/16 22:04:40 : Epoch: 982, Train_Loss: 0.00381049
2025/09/16 22:04:41 : Epoch: 983, Train_Loss: 0.00321400
2025/09/16 22:04:41 : Epoch: 984, Train_Loss: 0.00314668
2025/09/16 22:04:41 : Epoch: 984, Eval_Loss: 0.00701429
2025/09/16 22:04:41 : Epoch: 985, Train_Loss: 0.00314057
2025/09/16 22:04:41 : Epoch: 986, Train_Loss: 0.00488462
2025/09/16 22:04:42 : Epoch: 987, Train_Loss: 0.00411069
2025/09/16 22:04:42 : Epoch: 988, Train_Loss: 0.00352656
2025/09/16 22:04:42 : Epoch: 989, Train_Loss: 0.00281474
2025/09/16 22:04:42 : Epoch: 989, Eval_Loss: 0.00614383
2025/09/16 22:04:42 : Epoch: 990, Train_Loss: 0.00273050
2025/09/16 22:04:43 : Epoch: 991, Train_Loss: 0.00362348
2025/09/16 22:04:43 : Epoch: 992, Train_Loss: 0.00231197
2025/09/16 22:04:43 : Epoch: 993, Train_Loss: 0.00213527
2025/09/16 22:04:43 : Epoch: 994, Train_Loss: 0.00234279
2025/09/16 22:04:44 : Epoch: 994, Eval_Loss: 0.00765133
2025/09/16 22:04:44 : Epoch: 995, Train_Loss: 0.00172047
2025/09/16 22:04:44 : Epoch: 996, Train_Loss: 0.00317281
2025/09/16 22:04:44 : Epoch: 997, Train_Loss: 0.00205490
2025/09/16 22:04:45 : Epoch: 998, Train_Loss: 0.00261178
2025/09/16 22:04:45 : Epoch: 999, Train_Loss: 0.00259548
2025/09/16 22:04:45 : Epoch: 999, Eval_Loss: 0.00783468
2025/09/16 22:04:45 : Epoch: 1000, Train_Loss: 0.00203166
2025/09/16 22:04:45 : Epoch: 1001, Train_Loss: 0.00169569
2025/09/16 22:04:46 : Epoch: 1002, Train_Loss: 0.00179753
2025/09/16 22:04:46 : Epoch: 1003, Train_Loss: 0.00151799
2025/09/16 22:04:46 : Epoch: 1004, Train_Loss: 0.00165513
2025/09/16 22:04:46 : Epoch: 1004, Eval_Loss: 0.00824428
2025/09/16 22:04:46 : Epoch: 1005, Train_Loss: 0.00207596
2025/09/16 22:04:47 : Epoch: 1006, Train_Loss: 0.00196644
2025/09/16 22:04:47 : Epoch: 1007, Train_Loss: 0.00133038
2025/09/16 22:04:47 : Epoch: 1008, Train_Loss: 0.00155808
2025/09/16 22:04:47 : Epoch: 1009, Train_Loss: 0.00209995
2025/09/16 22:04:47 : Epoch: 1009, Eval_Loss: 0.00750498
2025/09/16 22:04:48 : Epoch: 1010, Train_Loss: 0.00221891
2025/09/16 22:04:48 : Epoch: 1011, Train_Loss: 0.00180186
2025/09/16 22:04:48 : Epoch: 1012, Train_Loss: 0.00161610
2025/09/16 22:04:48 : Epoch: 1013, Train_Loss: 0.00196204
2025/09/16 22:04:49 : Epoch: 1014, Train_Loss: 0.00216094
2025/09/16 22:04:49 : Epoch: 1014, Eval_Loss: 0.00857072
2025/09/16 22:04:49 : Epoch: 1015, Train_Loss: 0.00264487
2025/09/16 22:04:49 : Epoch: 1016, Train_Loss: 0.00160407
2025/09/16 22:04:50 : Epoch: 1017, Train_Loss: 0.00226681
2025/09/16 22:04:50 : Epoch: 1018, Train_Loss: 0.00319716
2025/09/16 22:04:50 : Epoch: 1019, Train_Loss: 0.00153025
2025/09/16 22:04:50 : Epoch: 1019, Eval_Loss: 0.00906448
2025/09/16 22:04:50 : Epoch: 1020, Train_Loss: 0.00152435
2025/09/16 22:04:51 : Epoch: 1021, Train_Loss: 0.00164682
2025/09/16 22:04:51 : Epoch: 1022, Train_Loss: 0.00170753
2025/09/16 22:04:51 : Epoch: 1023, Train_Loss: 0.00145783
2025/09/16 22:04:51 : Epoch: 1024, Train_Loss: 0.00190337
2025/09/16 22:04:51 : Epoch: 1024, Eval_Loss: 0.00951923
2025/09/16 22:04:52 : Epoch: 1025, Train_Loss: 0.00186223
2025/09/16 22:04:52 : Epoch: 1026, Train_Loss: 0.00168135
2025/09/16 22:04:52 : Epoch: 1027, Train_Loss: 0.00287238
2025/09/16 22:04:52 : Epoch: 1028, Train_Loss: 0.00166727
2025/09/16 22:04:53 : Epoch: 1029, Train_Loss: 0.00177189
2025/09/16 22:04:53 : Epoch: 1029, Eval_Loss: 0.00844788
2025/09/16 22:04:53 : Epoch: 1030, Train_Loss: 0.00137726
2025/09/16 22:04:53 : Epoch: 1031, Train_Loss: 0.00178186
2025/09/16 22:04:53 : Epoch: 1032, Train_Loss: 0.00255277
2025/09/16 22:04:54 : Epoch: 1033, Train_Loss: 0.00123249
2025/09/16 22:04:54 : Epoch: 1034, Train_Loss: 0.00173758
2025/09/16 22:04:54 : Epoch: 1034, Eval_Loss: 0.00945232
2025/09/16 22:04:54 : Epoch: 1035, Train_Loss: 0.00146746
2025/09/16 22:04:55 : Epoch: 1036, Train_Loss: 0.00136342
2025/09/16 22:04:55 : Epoch: 1037, Train_Loss: 0.00279360
2025/09/16 22:04:55 : Epoch: 1038, Train_Loss: 0.00134065
2025/09/16 22:04:55 : Epoch: 1039, Train_Loss: 0.00176413
2025/09/16 22:04:55 : Epoch: 1039, Eval_Loss: 0.00921153
2025/09/16 22:04:56 : Epoch: 1040, Train_Loss: 0.00162214
2025/09/16 22:04:56 : Epoch: 1041, Train_Loss: 0.00289024
2025/09/16 22:04:56 : Epoch: 1042, Train_Loss: 0.00255260
2025/09/16 22:04:56 : Epoch: 1043, Train_Loss: 0.00314465
2025/09/16 22:04:57 : Epoch: 1044, Train_Loss: 0.00229013
2025/09/16 22:04:57 : Epoch: 1044, Eval_Loss: 0.00851656
2025/09/16 22:04:57 : Epoch: 1045, Train_Loss: 0.00362615
2025/09/16 22:04:57 : Epoch: 1046, Train_Loss: 0.00276809
2025/09/16 22:04:57 : Epoch: 1047, Train_Loss: 0.00324840
2025/09/16 22:04:58 : Epoch: 1048, Train_Loss: 0.00284918
2025/09/16 22:04:58 : Epoch: 1049, Train_Loss: 0.00286865
2025/09/16 22:04:58 : Epoch: 1049, Eval_Loss: 0.00839051
2025/09/16 22:04:58 : Epoch: 1050, Train_Loss: 0.00247995
2025/09/16 22:04:59 : Epoch: 1051, Train_Loss: 0.00363543
2025/09/16 22:04:59 : Epoch: 1052, Train_Loss: 0.00339267
2025/09/16 22:04:59 : Epoch: 1053, Train_Loss: 0.00325345
2025/09/16 22:04:59 : Epoch: 1054, Train_Loss: 0.00229384
2025/09/16 22:04:59 : Epoch: 1054, Eval_Loss: 0.00762781
2025/09/16 22:05:00 : Epoch: 1055, Train_Loss: 0.00343610
2025/09/16 22:05:00 : Epoch: 1056, Train_Loss: 0.00282776
2025/09/16 22:05:00 : Epoch: 1057, Train_Loss: 0.00278540
2025/09/16 22:05:00 : Epoch: 1058, Train_Loss: 0.00229679
2025/09/16 22:05:01 : Epoch: 1059, Train_Loss: 0.00231543
2025/09/16 22:05:01 : Epoch: 1059, Eval_Loss: 0.01037103
2025/09/16 22:05:01 : Epoch: 1060, Train_Loss: 0.00239505
2025/09/16 22:05:01 : Epoch: 1061, Train_Loss: 0.00173599
2025/09/16 22:05:01 : Epoch: 1062, Train_Loss: 0.00315288
2025/09/16 22:05:02 : Epoch: 1063, Train_Loss: 0.00212713
2025/09/16 22:05:02 : Epoch: 1064, Train_Loss: 0.00177396
2025/09/16 22:05:02 : Epoch: 1064, Eval_Loss: 0.00868192
2025/09/16 22:05:02 : Epoch: 1065, Train_Loss: 0.00293609
2025/09/16 22:05:02 : Epoch: 1066, Train_Loss: 0.00167221
2025/09/16 22:05:03 : Epoch: 1067, Train_Loss: 0.00195020
2025/09/16 22:05:03 : Epoch: 1068, Train_Loss: 0.00328002
2025/09/16 22:05:03 : Epoch: 1069, Train_Loss: 0.00161660
2025/09/16 22:05:03 : Epoch: 1069, Eval_Loss: 0.01008578
2025/09/16 22:05:04 : Epoch: 1070, Train_Loss: 0.00221968
2025/09/16 22:05:04 : Epoch: 1071, Train_Loss: 0.00230239
2025/09/16 22:05:04 : Epoch: 1072, Train_Loss: 0.00201722
2025/09/16 22:05:04 : Epoch: 1073, Train_Loss: 0.00257841
2025/09/16 22:05:05 : Epoch: 1074, Train_Loss: 0.00142896
2025/09/16 22:05:05 : Epoch: 1074, Eval_Loss: 0.00801646
2025/09/16 22:05:05 : Epoch: 1075, Train_Loss: 0.00241756
2025/09/16 22:05:05 : Epoch: 1076, Train_Loss: 0.00311206
2025/09/16 22:05:05 : Epoch: 1077, Train_Loss: 0.00172260
2025/09/16 22:05:06 : Epoch: 1078, Train_Loss: 0.00192416
2025/09/16 22:05:06 : Epoch: 1079, Train_Loss: 0.00218367
2025/09/16 22:05:06 : Epoch: 1079, Eval_Loss: 0.00892567
2025/09/16 22:05:06 : Epoch: 1080, Train_Loss: 0.00230807
2025/09/16 22:05:06 : Epoch: 1081, Train_Loss: 0.00223415
2025/09/16 22:05:07 : Epoch: 1082, Train_Loss: 0.00136571
2025/09/16 22:05:07 : Epoch: 1083, Train_Loss: 0.00296423
2025/09/16 22:05:07 : Epoch: 1084, Train_Loss: 0.00143356
2025/09/16 22:05:07 : Epoch: 1084, Eval_Loss: 0.00737691
2025/09/16 22:05:08 : Epoch: 1085, Train_Loss: 0.00258962
2025/09/16 22:05:08 : Epoch: 1086, Train_Loss: 0.00167052
2025/09/16 22:05:08 : Epoch: 1087, Train_Loss: 0.00142564
2025/09/16 22:05:08 : Epoch: 1088, Train_Loss: 0.00125928
2025/09/16 22:05:09 : Epoch: 1089, Train_Loss: 0.00135354
2025/09/16 22:05:09 : Epoch: 1089, Eval_Loss: 0.00936318
2025/09/16 22:05:09 : Epoch: 1090, Train_Loss: 0.00135323
2025/09/16 22:05:09 : Epoch: 1091, Train_Loss: 0.00200931
2025/09/16 22:05:09 : Epoch: 1092, Train_Loss: 0.00124479
2025/09/16 22:05:10 : Epoch: 1093, Train_Loss: 0.00106372
2025/09/16 22:05:10 : Epoch: 1094, Train_Loss: 0.00126881
2025/09/16 22:05:10 : Epoch: 1094, Eval_Loss: 0.01078890
2025/09/16 22:05:10 : Epoch: 1095, Train_Loss: 0.00237178
2025/09/16 22:05:10 : Epoch: 1096, Train_Loss: 0.00161650
2025/09/16 22:05:11 : Epoch: 1097, Train_Loss: 0.00234384
2025/09/16 22:05:11 : Epoch: 1098, Train_Loss: 0.00249655
2025/09/16 22:05:11 : Epoch: 1099, Train_Loss: 0.00278265
2025/09/16 22:05:11 : Epoch: 1099, Eval_Loss: 0.01028306
2025/09/16 22:05:11 : Epoch: 1100, Train_Loss: 0.00254821
2025/09/16 22:05:12 : Epoch: 1101, Train_Loss: 0.00247438
2025/09/16 22:05:12 : Epoch: 1102, Train_Loss: 0.00196233
2025/09/16 22:05:12 : Epoch: 1103, Train_Loss: 0.00226518
2025/09/16 22:05:12 : Epoch: 1104, Train_Loss: 0.00315173
2025/09/16 22:05:13 : Epoch: 1104, Eval_Loss: 0.00621343
2025/09/16 22:05:13 : Epoch: 1105, Train_Loss: 0.00261275
2025/09/16 22:05:13 : Epoch: 1106, Train_Loss: 0.00421997
2025/09/16 22:05:13 : Epoch: 1107, Train_Loss: 0.00467021
2025/09/16 22:05:14 : Epoch: 1108, Train_Loss: 0.00187268
2025/09/16 22:05:14 : Epoch: 1109, Train_Loss: 0.00315478
2025/09/16 22:05:14 : Epoch: 1109, Eval_Loss: 0.00988888
2025/09/16 22:05:14 : Epoch: 1110, Train_Loss: 0.00253375
2025/09/16 22:05:14 : Epoch: 1111, Train_Loss: 0.00241779
2025/09/16 22:05:15 : Epoch: 1112, Train_Loss: 0.00317563
2025/09/16 22:05:15 : Epoch: 1113, Train_Loss: 0.00323552
2025/09/16 22:05:15 : Epoch: 1114, Train_Loss: 0.00326687
2025/09/16 22:05:15 : Epoch: 1114, Eval_Loss: 0.00788944
2025/09/16 22:05:15 : Epoch: 1115, Train_Loss: 0.00242681
2025/09/16 22:05:16 : Epoch: 1116, Train_Loss: 0.00176717
2025/09/16 22:05:16 : Epoch: 1117, Train_Loss: 0.00256213
2025/09/16 22:05:16 : Epoch: 1118, Train_Loss: 0.00141350
2025/09/16 22:05:16 : Epoch: 1119, Train_Loss: 0.00165909
2025/09/16 22:05:16 : Epoch: 1119, Eval_Loss: 0.00696791
2025/09/16 22:05:17 : Epoch: 1120, Train_Loss: 0.00194699
2025/09/16 22:05:17 : Epoch: 1121, Train_Loss: 0.00177644
2025/09/16 22:05:17 : Epoch: 1122, Train_Loss: 0.00152435
2025/09/16 22:05:17 : Epoch: 1123, Train_Loss: 0.00199990
2025/09/16 22:05:18 : Epoch: 1124, Train_Loss: 0.00150108
2025/09/16 22:05:18 : Epoch: 1124, Eval_Loss: 0.00749664
2025/09/16 22:05:18 : Epoch: 1125, Train_Loss: 0.00145644
2025/09/16 22:05:18 : Epoch: 1126, Train_Loss: 0.00187757
2025/09/16 22:05:19 : Epoch: 1127, Train_Loss: 0.00136566
2025/09/16 22:05:19 : Epoch: 1128, Train_Loss: 0.00123430
2025/09/16 22:05:19 : Epoch: 1129, Train_Loss: 0.00153752
2025/09/16 22:05:19 : Epoch: 1129, Eval_Loss: 0.00737321
2025/09/16 22:05:19 : Epoch: 1130, Train_Loss: 0.00115912
2025/09/16 22:05:20 : Epoch: 1131, Train_Loss: 0.00237350
2025/09/16 22:05:20 : Epoch: 1132, Train_Loss: 0.00131908
2025/09/16 22:05:20 : Epoch: 1133, Train_Loss: 0.00124770
2025/09/16 22:05:20 : Epoch: 1134, Train_Loss: 0.00103382
2025/09/16 22:05:20 : Epoch: 1134, Eval_Loss: 0.00830346
2025/09/16 22:05:21 : Epoch: 1135, Train_Loss: 0.00102483
2025/09/16 22:05:21 : Epoch: 1136, Train_Loss: 0.00139821
2025/09/16 22:05:21 : Epoch: 1137, Train_Loss: 0.00099978
2025/09/16 22:05:21 : Epoch: 1138, Train_Loss: 0.00097473
2025/09/16 22:05:22 : Epoch: 1139, Train_Loss: 0.00140849
2025/09/16 22:05:22 : Epoch: 1139, Eval_Loss: 0.00754176
2025/09/16 22:05:22 : Epoch: 1140, Train_Loss: 0.00202593
2025/09/16 22:05:22 : Epoch: 1141, Train_Loss: 0.00112892
2025/09/16 22:05:23 : Epoch: 1142, Train_Loss: 0.00174844
2025/09/16 22:05:23 : Epoch: 1143, Train_Loss: 0.00122411
2025/09/16 22:05:23 : Epoch: 1144, Train_Loss: 0.00171501
2025/09/16 22:05:23 : Epoch: 1144, Eval_Loss: 0.00967416
2025/09/16 22:05:23 : Epoch: 1145, Train_Loss: 0.00185350
2025/09/16 22:05:24 : Epoch: 1146, Train_Loss: 0.00156907
2025/09/16 22:05:24 : Epoch: 1147, Train_Loss: 0.00148021
2025/09/16 22:05:24 : Epoch: 1148, Train_Loss: 0.00160523
2025/09/16 22:05:24 : Epoch: 1149, Train_Loss: 0.00289177
2025/09/16 22:05:24 : Epoch: 1149, Eval_Loss: 0.00642368
2025/09/16 22:05:25 : Epoch: 1150, Train_Loss: 0.00115352
2025/09/16 22:05:25 : Epoch: 1151, Train_Loss: 0.00123024
2025/09/16 22:05:25 : Epoch: 1152, Train_Loss: 0.00150004
2025/09/16 22:05:25 : Epoch: 1153, Train_Loss: 0.00290589
2025/09/16 22:05:26 : Epoch: 1154, Train_Loss: 0.00147941
2025/09/16 22:05:26 : Epoch: 1154, Eval_Loss: 0.00939038
2025/09/16 22:05:26 : Epoch: 1155, Train_Loss: 0.00183870
2025/09/16 22:05:26 : Epoch: 1156, Train_Loss: 0.00169823
2025/09/16 22:05:26 : Epoch: 1157, Train_Loss: 0.00189816
2025/09/16 22:05:27 : Epoch: 1158, Train_Loss: 0.00253332
2025/09/16 22:05:27 : Epoch: 1159, Train_Loss: 0.00174765
2025/09/16 22:05:27 : Epoch: 1159, Eval_Loss: 0.00500500
2025/09/16 22:05:27 : Epoch: 1160, Train_Loss: 0.00399305
2025/09/16 22:05:28 : Epoch: 1161, Train_Loss: 0.00222609
2025/09/16 22:05:28 : Epoch: 1162, Train_Loss: 0.00133252
2025/09/16 22:05:28 : Epoch: 1163, Train_Loss: 0.00279523
2025/09/16 22:05:28 : Epoch: 1164, Train_Loss: 0.00311293
2025/09/16 22:05:28 : Epoch: 1164, Eval_Loss: 0.00776833
2025/09/16 22:05:29 : Epoch: 1165, Train_Loss: 0.00232726
2025/09/16 22:05:29 : Epoch: 1166, Train_Loss: 0.00194644
2025/09/16 22:05:29 : Epoch: 1167, Train_Loss: 0.00226899
2025/09/16 22:05:29 : Epoch: 1168, Train_Loss: 0.00129207
2025/09/16 22:05:29 : Epoch: 1169, Train_Loss: 0.00224475
2025/09/16 22:05:30 : Epoch: 1169, Eval_Loss: 0.01056433
2025/09/16 22:05:30 : Epoch: 1170, Train_Loss: 0.00186978
2025/09/16 22:05:30 : Epoch: 1171, Train_Loss: 0.00285012
2025/09/16 22:05:30 : Epoch: 1172, Train_Loss: 0.00175203
2025/09/16 22:05:31 : Epoch: 1173, Train_Loss: 0.00185377
2025/09/16 22:05:31 : Epoch: 1174, Train_Loss: 0.00148137
2025/09/16 22:05:31 : Epoch: 1174, Eval_Loss: 0.00919445
2025/09/16 22:05:31 : Epoch: 1175, Train_Loss: 0.00161506
2025/09/16 22:05:31 : Epoch: 1176, Train_Loss: 0.00182048
2025/09/16 22:05:32 : Epoch: 1177, Train_Loss: 0.00223675
2025/09/16 22:05:32 : Epoch: 1178, Train_Loss: 0.00291210
2025/09/16 22:05:32 : Epoch: 1179, Train_Loss: 0.00186618
2025/09/16 22:05:32 : Epoch: 1179, Eval_Loss: 0.00875334
2025/09/16 22:05:32 : Epoch: 1180, Train_Loss: 0.00187076
2025/09/16 22:05:33 : Epoch: 1181, Train_Loss: 0.00165671
2025/09/16 22:05:33 : Epoch: 1182, Train_Loss: 0.00180641
2025/09/16 22:05:33 : Epoch: 1183, Train_Loss: 0.00139064
2025/09/16 22:05:33 : Epoch: 1184, Train_Loss: 0.00247931
2025/09/16 22:05:34 : Epoch: 1184, Eval_Loss: 0.00791493
2025/09/16 22:05:34 : Epoch: 1185, Train_Loss: 0.00190232
2025/09/16 22:05:34 : Epoch: 1186, Train_Loss: 0.00133822
2025/09/16 22:05:34 : Epoch: 1187, Train_Loss: 0.00129665
2025/09/16 22:05:34 : Epoch: 1188, Train_Loss: 0.00119544
2025/09/16 22:05:35 : Epoch: 1189, Train_Loss: 0.00103968
2025/09/16 22:05:35 : Epoch: 1189, Eval_Loss: 0.00694480
2025/09/16 22:05:35 : Epoch: 1190, Train_Loss: 0.00103869
2025/09/16 22:05:35 : Epoch: 1191, Train_Loss: 0.00110642
2025/09/16 22:05:36 : Epoch: 1192, Train_Loss: 0.00114534
2025/09/16 22:05:36 : Epoch: 1193, Train_Loss: 0.00132889
2025/09/16 22:05:36 : Epoch: 1194, Train_Loss: 0.00084354
2025/09/16 22:05:36 : Epoch: 1194, Eval_Loss: 0.00797955
2025/09/16 22:05:36 : Epoch: 1195, Train_Loss: 0.00150008
2025/09/16 22:05:37 : Epoch: 1196, Train_Loss: 0.00087114
2025/09/16 22:05:37 : Epoch: 1197, Train_Loss: 0.00088682
2025/09/16 22:05:37 : Epoch: 1198, Train_Loss: 0.00078060
2025/09/16 22:05:37 : Epoch: 1199, Train_Loss: 0.00108224
2025/09/16 22:05:37 : Epoch: 1199, Eval_Loss: 0.00684436
2025/09/16 22:05:37 : 
Epoch: 1199, save response figures

2025/09/16 22:05:50 : Epoch: 1200, Train_Loss: 0.00101548
2025/09/16 22:05:50 : Epoch: 1201, Train_Loss: 0.00175516
2025/09/16 22:05:50 : Epoch: 1202, Train_Loss: 0.00099869
2025/09/16 22:05:51 : Epoch: 1203, Train_Loss: 0.00184992
2025/09/16 22:05:51 : Epoch: 1204, Train_Loss: 0.00216768
2025/09/16 22:05:51 : Epoch: 1204, Eval_Loss: 0.00850350
2025/09/16 22:05:51 : Epoch: 1205, Train_Loss: 0.00179270
2025/09/16 22:05:51 : Epoch: 1206, Train_Loss: 0.00176969
2025/09/16 22:05:52 : Epoch: 1207, Train_Loss: 0.00218062
2025/09/16 22:05:52 : Epoch: 1208, Train_Loss: 0.00186061
2025/09/16 22:05:52 : Epoch: 1209, Train_Loss: 0.00266308
2025/09/16 22:05:52 : Epoch: 1209, Eval_Loss: 0.00613234
2025/09/16 22:05:53 : Epoch: 1210, Train_Loss: 0.00169879
2025/09/16 22:05:53 : Epoch: 1211, Train_Loss: 0.00139824
2025/09/16 22:05:53 : Epoch: 1212, Train_Loss: 0.00184537
2025/09/16 22:05:53 : Epoch: 1213, Train_Loss: 0.00099011
2025/09/16 22:05:53 : Epoch: 1214, Train_Loss: 0.00117883
2025/09/16 22:05:54 : Epoch: 1214, Eval_Loss: 0.00645489
2025/09/16 22:05:54 : Epoch: 1215, Train_Loss: 0.00107040
2025/09/16 22:05:54 : Epoch: 1216, Train_Loss: 0.00148164
2025/09/16 22:05:54 : Epoch: 1217, Train_Loss: 0.00325721
2025/09/16 22:05:55 : Epoch: 1218, Train_Loss: 0.00180807
2025/09/16 22:05:55 : Epoch: 1219, Train_Loss: 0.00202267
2025/09/16 22:05:55 : Epoch: 1219, Eval_Loss: 0.00868403
2025/09/16 22:05:55 : Epoch: 1220, Train_Loss: 0.00118950
2025/09/16 22:05:55 : Epoch: 1221, Train_Loss: 0.00197560
2025/09/16 22:05:56 : Epoch: 1222, Train_Loss: 0.00143662
2025/09/16 22:05:56 : Epoch: 1223, Train_Loss: 0.00138197
2025/09/16 22:05:56 : Epoch: 1224, Train_Loss: 0.00119159
2025/09/16 22:05:56 : Epoch: 1224, Eval_Loss: 0.00749615
2025/09/16 22:05:56 : Epoch: 1225, Train_Loss: 0.00111560
2025/09/16 22:05:57 : Epoch: 1226, Train_Loss: 0.00173176
2025/09/16 22:05:57 : Epoch: 1227, Train_Loss: 0.00155690
2025/09/16 22:05:57 : Epoch: 1228, Train_Loss: 0.00167067
2025/09/16 22:05:57 : Epoch: 1229, Train_Loss: 0.00159837
2025/09/16 22:05:58 : Epoch: 1229, Eval_Loss: 0.00779655
2025/09/16 22:05:58 : Epoch: 1230, Train_Loss: 0.00113767
2025/09/16 22:05:58 : Epoch: 1231, Train_Loss: 0.00120254
2025/09/16 22:05:58 : Epoch: 1232, Train_Loss: 0.00106655
2025/09/16 22:05:59 : Epoch: 1233, Train_Loss: 0.00089229
2025/09/16 22:05:59 : Epoch: 1234, Train_Loss: 0.00141765
2025/09/16 22:05:59 : Epoch: 1234, Eval_Loss: 0.00737742
2025/09/16 22:05:59 : Epoch: 1235, Train_Loss: 0.00108586
2025/09/16 22:05:59 : Epoch: 1236, Train_Loss: 0.00092981
2025/09/16 22:06:00 : Epoch: 1237, Train_Loss: 0.00111824
2025/09/16 22:06:00 : Epoch: 1238, Train_Loss: 0.00128724
2025/09/16 22:06:00 : Epoch: 1239, Train_Loss: 0.00067951
2025/09/16 22:06:00 : Epoch: 1239, Eval_Loss: 0.00773213
2025/09/16 22:06:00 : Epoch: 1240, Train_Loss: 0.00072052
2025/09/16 22:06:01 : Epoch: 1241, Train_Loss: 0.00114408
2025/09/16 22:06:01 : Epoch: 1242, Train_Loss: 0.00072993
2025/09/16 22:06:01 : Epoch: 1243, Train_Loss: 0.00083540
2025/09/16 22:06:01 : Epoch: 1244, Train_Loss: 0.00095640
2025/09/16 22:06:01 : Epoch: 1244, Eval_Loss: 0.00810731
2025/09/16 22:06:02 : Epoch: 1245, Train_Loss: 0.00094115
2025/09/16 22:06:02 : Epoch: 1246, Train_Loss: 0.00071363
2025/09/16 22:06:02 : Epoch: 1247, Train_Loss: 0.00108334
2025/09/16 22:06:02 : Epoch: 1248, Train_Loss: 0.00097129
2025/09/16 22:06:03 : Epoch: 1249, Train_Loss: 0.00126126
2025/09/16 22:06:03 : Epoch: 1249, Eval_Loss: 0.00758527
2025/09/16 22:06:03 : Epoch: 1250, Train_Loss: 0.00170907
2025/09/16 22:06:03 : Epoch: 1251, Train_Loss: 0.00128729
2025/09/16 22:06:03 : Epoch: 1252, Train_Loss: 0.00299067
2025/09/16 22:06:04 : Epoch: 1253, Train_Loss: 0.00156561
2025/09/16 22:06:04 : Epoch: 1254, Train_Loss: 0.00162110
2025/09/16 22:06:04 : Epoch: 1254, Eval_Loss: 0.00974263
2025/09/16 22:06:04 : Epoch: 1255, Train_Loss: 0.00165963
2025/09/16 22:06:05 : Epoch: 1256, Train_Loss: 0.00113662
2025/09/16 22:06:05 : Epoch: 1257, Train_Loss: 0.00139585
2025/09/16 22:06:05 : Epoch: 1258, Train_Loss: 0.00124815
2025/09/16 22:06:05 : Epoch: 1259, Train_Loss: 0.00088425
2025/09/16 22:06:05 : Epoch: 1259, Eval_Loss: 0.00788481
2025/09/16 22:06:06 : Epoch: 1260, Train_Loss: 0.00155706
2025/09/16 22:06:06 : Epoch: 1261, Train_Loss: 0.00082467
2025/09/16 22:06:06 : Epoch: 1262, Train_Loss: 0.00117379
2025/09/16 22:06:06 : Epoch: 1263, Train_Loss: 0.00076533
2025/09/16 22:06:07 : Epoch: 1264, Train_Loss: 0.00098440
2025/09/16 22:06:07 : Epoch: 1264, Eval_Loss: 0.00922165
2025/09/16 22:06:07 : Epoch: 1265, Train_Loss: 0.00097008
2025/09/16 22:06:07 : Epoch: 1266, Train_Loss: 0.00076604
2025/09/16 22:06:07 : Epoch: 1267, Train_Loss: 0.00128872
2025/09/16 22:06:08 : Epoch: 1268, Train_Loss: 0.00121043
2025/09/16 22:06:08 : Epoch: 1269, Train_Loss: 0.00079902
2025/09/16 22:06:08 : Epoch: 1269, Eval_Loss: 0.00747856
2025/09/16 22:06:08 : Epoch: 1270, Train_Loss: 0.00114448
2025/09/16 22:06:08 : Epoch: 1271, Train_Loss: 0.00079296
2025/09/16 22:06:09 : Epoch: 1272, Train_Loss: 0.00086172
2025/09/16 22:06:09 : Epoch: 1273, Train_Loss: 0.00110962
2025/09/16 22:06:09 : Epoch: 1274, Train_Loss: 0.00086475
2025/09/16 22:06:09 : Epoch: 1274, Eval_Loss: 0.00877621
2025/09/16 22:06:09 : Epoch: 1275, Train_Loss: 0.00103986
2025/09/16 22:06:10 : Epoch: 1276, Train_Loss: 0.00171447
2025/09/16 22:06:10 : Epoch: 1277, Train_Loss: 0.00146712
2025/09/16 22:06:10 : Epoch: 1278, Train_Loss: 0.00122603
2025/09/16 22:06:10 : Epoch: 1279, Train_Loss: 0.00131279
2025/09/16 22:06:11 : Epoch: 1279, Eval_Loss: 0.00837877
2025/09/16 22:06:11 : Epoch: 1280, Train_Loss: 0.00114505
2025/09/16 22:06:11 : Epoch: 1281, Train_Loss: 0.00111872
2025/09/16 22:06:11 : Epoch: 1282, Train_Loss: 0.00109840
2025/09/16 22:06:12 : Epoch: 1283, Train_Loss: 0.00108497
2025/09/16 22:06:12 : Epoch: 1284, Train_Loss: 0.00134205
2025/09/16 22:06:12 : Epoch: 1284, Eval_Loss: 0.00808543
2025/09/16 22:06:12 : Epoch: 1285, Train_Loss: 0.00074653
2025/09/16 22:06:12 : Epoch: 1286, Train_Loss: 0.00084511
2025/09/16 22:06:13 : Epoch: 1287, Train_Loss: 0.00089406
2025/09/16 22:06:13 : Epoch: 1288, Train_Loss: 0.00115767
2025/09/16 22:06:13 : Epoch: 1289, Train_Loss: 0.00100998
2025/09/16 22:06:13 : Epoch: 1289, Eval_Loss: 0.00808168
2025/09/16 22:06:13 : Epoch: 1290, Train_Loss: 0.00139065
2025/09/16 22:06:14 : Epoch: 1291, Train_Loss: 0.00080168
2025/09/16 22:06:14 : Epoch: 1292, Train_Loss: 0.00105008
2025/09/16 22:06:14 : Epoch: 1293, Train_Loss: 0.00105968
2025/09/16 22:06:14 : Epoch: 1294, Train_Loss: 0.00120414
2025/09/16 22:06:14 : Epoch: 1294, Eval_Loss: 0.00906937
2025/09/16 22:06:15 : Epoch: 1295, Train_Loss: 0.00077167
2025/09/16 22:06:15 : Epoch: 1296, Train_Loss: 0.00078899
2025/09/16 22:06:15 : Epoch: 1297, Train_Loss: 0.00105906
2025/09/16 22:06:15 : Epoch: 1298, Train_Loss: 0.00078084
2025/09/16 22:06:16 : Epoch: 1299, Train_Loss: 0.00153938
2025/09/16 22:06:16 : Epoch: 1299, Eval_Loss: 0.00933667
2025/09/16 22:06:16 : Epoch: 1300, Train_Loss: 0.00067875
2025/09/16 22:06:16 : Epoch: 1301, Train_Loss: 0.00140570
2025/09/16 22:06:16 : Epoch: 1302, Train_Loss: 0.00073409
2025/09/16 22:06:17 : Epoch: 1303, Train_Loss: 0.00103230
2025/09/16 22:06:17 : Epoch: 1304, Train_Loss: 0.00060706
2025/09/16 22:06:17 : Epoch: 1304, Eval_Loss: 0.00848948
2025/09/16 22:06:17 : Epoch: 1305, Train_Loss: 0.00102240
2025/09/16 22:06:18 : Epoch: 1306, Train_Loss: 0.00101454
2025/09/16 22:06:18 : Epoch: 1307, Train_Loss: 0.00075787
2025/09/16 22:06:18 : Epoch: 1308, Train_Loss: 0.00083464
2025/09/16 22:06:18 : Epoch: 1309, Train_Loss: 0.00057713
2025/09/16 22:06:18 : Epoch: 1309, Eval_Loss: 0.00797225
2025/09/16 22:06:19 : Epoch: 1310, Train_Loss: 0.00071217
2025/09/16 22:06:19 : Epoch: 1311, Train_Loss: 0.00075461
2025/09/16 22:06:19 : Epoch: 1312, Train_Loss: 0.00059071
2025/09/16 22:06:19 : Epoch: 1313, Train_Loss: 0.00055761
2025/09/16 22:06:20 : Epoch: 1314, Train_Loss: 0.00076690
2025/09/16 22:06:20 : Epoch: 1314, Eval_Loss: 0.00871986
2025/09/16 22:06:20 : Epoch: 1315, Train_Loss: 0.00071751
2025/09/16 22:06:20 : Epoch: 1316, Train_Loss: 0.00123665
2025/09/16 22:06:20 : Epoch: 1317, Train_Loss: 0.00059489
2025/09/16 22:06:21 : Epoch: 1318, Train_Loss: 0.00095788
2025/09/16 22:06:21 : Epoch: 1319, Train_Loss: 0.00070502
2025/09/16 22:06:21 : Epoch: 1319, Eval_Loss: 0.00802212
2025/09/16 22:06:21 : Epoch: 1320, Train_Loss: 0.00100133
2025/09/16 22:06:21 : Epoch: 1321, Train_Loss: 0.00094948
2025/09/16 22:06:22 : Epoch: 1322, Train_Loss: 0.00119777
2025/09/16 22:06:22 : Epoch: 1323, Train_Loss: 0.00086708
2025/09/16 22:06:22 : Epoch: 1324, Train_Loss: 0.00098236
2025/09/16 22:06:22 : Epoch: 1324, Eval_Loss: 0.00752421
2025/09/16 22:06:23 : Epoch: 1325, Train_Loss: 0.00060619
2025/09/16 22:06:23 : Epoch: 1326, Train_Loss: 0.00053388
2025/09/16 22:06:23 : Epoch: 1327, Train_Loss: 0.00131372
2025/09/16 22:06:23 : Epoch: 1328, Train_Loss: 0.00067467
2025/09/16 22:06:24 : Epoch: 1329, Train_Loss: 0.00057086
2025/09/16 22:06:24 : Epoch: 1329, Eval_Loss: 0.00795114
2025/09/16 22:06:24 : Epoch: 1330, Train_Loss: 0.00078732
2025/09/16 22:06:24 : Epoch: 1331, Train_Loss: 0.00104746
2025/09/16 22:06:24 : Epoch: 1332, Train_Loss: 0.00084114
2025/09/16 22:06:25 : Epoch: 1333, Train_Loss: 0.00076610
2025/09/16 22:06:25 : Epoch: 1334, Train_Loss: 0.00098150
2025/09/16 22:06:25 : Epoch: 1334, Eval_Loss: 0.00747994
2025/09/16 22:06:25 : Epoch: 1335, Train_Loss: 0.00073590
2025/09/16 22:06:25 : Epoch: 1336, Train_Loss: 0.00092355
2025/09/16 22:06:26 : Epoch: 1337, Train_Loss: 0.00083495
2025/09/16 22:06:26 : Epoch: 1338, Train_Loss: 0.00057029
2025/09/16 22:06:26 : Epoch: 1339, Train_Loss: 0.00095242
2025/09/16 22:06:26 : Epoch: 1339, Eval_Loss: 0.00885591
2025/09/16 22:06:27 : Epoch: 1340, Train_Loss: 0.00075275
2025/09/16 22:06:27 : Epoch: 1341, Train_Loss: 0.00057165
2025/09/16 22:06:27 : Epoch: 1342, Train_Loss: 0.00053487
2025/09/16 22:06:27 : Epoch: 1343, Train_Loss: 0.00088711
2025/09/16 22:06:27 : Epoch: 1344, Train_Loss: 0.00102917
2025/09/16 22:06:28 : Epoch: 1344, Eval_Loss: 0.00900742
2025/09/16 22:06:28 : Epoch: 1345, Train_Loss: 0.00086673
2025/09/16 22:06:28 : Epoch: 1346, Train_Loss: 0.00053691
2025/09/16 22:06:28 : Epoch: 1347, Train_Loss: 0.00071136
2025/09/16 22:06:29 : Epoch: 1348, Train_Loss: 0.00092212
2025/09/16 22:06:29 : Epoch: 1349, Train_Loss: 0.00053279
2025/09/16 22:06:29 : Epoch: 1349, Eval_Loss: 0.00897477
2025/09/16 22:06:29 : Epoch: 1350, Train_Loss: 0.00105198
2025/09/16 22:06:29 : Epoch: 1351, Train_Loss: 0.00055885
2025/09/16 22:06:30 : Epoch: 1352, Train_Loss: 0.00086910
2025/09/16 22:06:30 : Epoch: 1353, Train_Loss: 0.00054595
2025/09/16 22:06:30 : Epoch: 1354, Train_Loss: 0.00067041
2025/09/16 22:06:30 : Epoch: 1354, Eval_Loss: 0.00889248
2025/09/16 22:06:30 : Epoch: 1355, Train_Loss: 0.00087921
2025/09/16 22:06:31 : Epoch: 1356, Train_Loss: 0.00072640
2025/09/16 22:06:31 : Epoch: 1357, Train_Loss: 0.00086163
2025/09/16 22:06:31 : Epoch: 1358, Train_Loss: 0.00081643
2025/09/16 22:06:31 : Epoch: 1359, Train_Loss: 0.00071645
2025/09/16 22:06:32 : Epoch: 1359, Eval_Loss: 0.00887311
2025/09/16 22:06:32 : Epoch: 1360, Train_Loss: 0.00050236
2025/09/16 22:06:32 : Epoch: 1361, Train_Loss: 0.00101917
2025/09/16 22:06:32 : Epoch: 1362, Train_Loss: 0.00104405
2025/09/16 22:06:33 : Epoch: 1363, Train_Loss: 0.00089520
2025/09/16 22:06:33 : Epoch: 1364, Train_Loss: 0.00048989
2025/09/16 22:06:33 : Epoch: 1364, Eval_Loss: 0.00889300
2025/09/16 22:06:33 : Epoch: 1365, Train_Loss: 0.00100133
2025/09/16 22:06:33 : Epoch: 1366, Train_Loss: 0.00085876
2025/09/16 22:06:34 : Epoch: 1367, Train_Loss: 0.00103633
2025/09/16 22:06:34 : Epoch: 1368, Train_Loss: 0.00087865
2025/09/16 22:06:34 : Epoch: 1369, Train_Loss: 0.00067522
2025/09/16 22:06:34 : Epoch: 1369, Eval_Loss: 0.00912809
2025/09/16 22:06:34 : Epoch: 1370, Train_Loss: 0.00050896
2025/09/16 22:06:35 : Epoch: 1371, Train_Loss: 0.00054142
2025/09/16 22:06:35 : Epoch: 1372, Train_Loss: 0.00051556
2025/09/16 22:06:35 : Epoch: 1373, Train_Loss: 0.00069313
2025/09/16 22:06:35 : Epoch: 1374, Train_Loss: 0.00068419
2025/09/16 22:06:36 : Epoch: 1374, Eval_Loss: 0.00904344
2025/09/16 22:06:36 : Epoch: 1375, Train_Loss: 0.00069348
2025/09/16 22:06:36 : Epoch: 1376, Train_Loss: 0.00069327
2025/09/16 22:06:36 : Epoch: 1377, Train_Loss: 0.00047979
2025/09/16 22:06:37 : Epoch: 1378, Train_Loss: 0.00051417
2025/09/16 22:06:37 : Epoch: 1379, Train_Loss: 0.00070360
2025/09/16 22:06:37 : Epoch: 1379, Eval_Loss: 0.00905932
2025/09/16 22:06:37 : Epoch: 1380, Train_Loss: 0.00063139
2025/09/16 22:06:37 : Epoch: 1381, Train_Loss: 0.00068962
2025/09/16 22:06:38 : Epoch: 1382, Train_Loss: 0.00090958
2025/09/16 22:06:38 : Epoch: 1383, Train_Loss: 0.00054090
2025/09/16 22:06:38 : Epoch: 1384, Train_Loss: 0.00055330
2025/09/16 22:06:38 : Epoch: 1384, Eval_Loss: 0.00915228
2025/09/16 22:06:38 : Epoch: 1385, Train_Loss: 0.00056164
2025/09/16 22:06:39 : Epoch: 1386, Train_Loss: 0.00079659
2025/09/16 22:06:39 : Epoch: 1387, Train_Loss: 0.00084628
2025/09/16 22:06:39 : Epoch: 1388, Train_Loss: 0.00066941
2025/09/16 22:06:39 : Epoch: 1389, Train_Loss: 0.00124259
2025/09/16 22:06:39 : Epoch: 1389, Eval_Loss: 0.00831774
2025/09/16 22:06:40 : Epoch: 1390, Train_Loss: 0.00062604
2025/09/16 22:06:40 : Epoch: 1391, Train_Loss: 0.00059716
2025/09/16 22:06:40 : Epoch: 1392, Train_Loss: 0.00086579
2025/09/16 22:06:40 : Epoch: 1393, Train_Loss: 0.00094280
2025/09/16 22:06:41 : Epoch: 1394, Train_Loss: 0.00070637
2025/09/16 22:06:41 : Epoch: 1394, Eval_Loss: 0.00941066
2025/09/16 22:06:41 : Epoch: 1395, Train_Loss: 0.00059898
2025/09/16 22:06:41 : Epoch: 1396, Train_Loss: 0.00068589
2025/09/16 22:06:41 : Epoch: 1397, Train_Loss: 0.00103137
2025/09/16 22:06:42 : Epoch: 1398, Train_Loss: 0.00130305
2025/09/16 22:06:42 : Epoch: 1399, Train_Loss: 0.00148745
2025/09/16 22:06:42 : Epoch: 1399, Eval_Loss: 0.00831792
2025/09/16 22:06:42 : Epoch: 1400, Train_Loss: 0.00127048
2025/09/16 22:06:43 : Epoch: 1401, Train_Loss: 0.00145703
2025/09/16 22:06:43 : Epoch: 1402, Train_Loss: 0.00199048
2025/09/16 22:06:43 : Epoch: 1403, Train_Loss: 0.00085800
2025/09/16 22:06:43 : Epoch: 1404, Train_Loss: 0.00126376
2025/09/16 22:06:43 : Epoch: 1404, Eval_Loss: 0.00801436
2025/09/16 22:06:44 : Epoch: 1405, Train_Loss: 0.00095892
2025/09/16 22:06:44 : Epoch: 1406, Train_Loss: 0.00136241
2025/09/16 22:06:44 : Epoch: 1407, Train_Loss: 0.00122668
2025/09/16 22:06:44 : Epoch: 1408, Train_Loss: 0.00109311
2025/09/16 22:06:45 : Epoch: 1409, Train_Loss: 0.00061126
2025/09/16 22:06:45 : Epoch: 1409, Eval_Loss: 0.00808833
2025/09/16 22:06:45 : Epoch: 1410, Train_Loss: 0.00076504
2025/09/16 22:06:45 : Epoch: 1411, Train_Loss: 0.00083181
2025/09/16 22:06:45 : Epoch: 1412, Train_Loss: 0.00069038
2025/09/16 22:06:46 : Epoch: 1413, Train_Loss: 0.00078798
2025/09/16 22:06:46 : Epoch: 1414, Train_Loss: 0.00094566
2025/09/16 22:06:46 : Epoch: 1414, Eval_Loss: 0.00790668
2025/09/16 22:06:46 : Epoch: 1415, Train_Loss: 0.00099897
2025/09/16 22:06:47 : Epoch: 1416, Train_Loss: 0.00087716
2025/09/16 22:06:47 : Epoch: 1417, Train_Loss: 0.00057777
2025/09/16 22:06:47 : Epoch: 1418, Train_Loss: 0.00058408
2025/09/16 22:06:47 : Epoch: 1419, Train_Loss: 0.00101132
2025/09/16 22:06:47 : Epoch: 1419, Eval_Loss: 0.00812418
2025/09/16 22:06:48 : Epoch: 1420, Train_Loss: 0.00096081
2025/09/16 22:06:48 : Epoch: 1421, Train_Loss: 0.00061184
2025/09/16 22:06:48 : Epoch: 1422, Train_Loss: 0.00056794
2025/09/16 22:06:48 : Epoch: 1423, Train_Loss: 0.00073566
2025/09/16 22:06:49 : Epoch: 1424, Train_Loss: 0.00071118
2025/09/16 22:06:49 : Epoch: 1424, Eval_Loss: 0.00993963
2025/09/16 22:06:49 : Epoch: 1425, Train_Loss: 0.00090948
2025/09/16 22:06:49 : Epoch: 1426, Train_Loss: 0.00113813
2025/09/16 22:06:49 : Epoch: 1427, Train_Loss: 0.00077620
2025/09/16 22:06:50 : Epoch: 1428, Train_Loss: 0.00113629
2025/09/16 22:06:50 : Epoch: 1429, Train_Loss: 0.00078827
2025/09/16 22:06:50 : Epoch: 1429, Eval_Loss: 0.00799353
2025/09/16 22:06:50 : Epoch: 1430, Train_Loss: 0.00130605
2025/09/16 22:06:50 : Epoch: 1431, Train_Loss: 0.00106952
2025/09/16 22:06:51 : Epoch: 1432, Train_Loss: 0.00106074
2025/09/16 22:06:51 : Epoch: 1433, Train_Loss: 0.00074357
2025/09/16 22:06:51 : Epoch: 1434, Train_Loss: 0.00109782
2025/09/16 22:06:51 : Epoch: 1434, Eval_Loss: 0.00954374
2025/09/16 22:06:52 : Epoch: 1435, Train_Loss: 0.00063163
2025/09/16 22:06:52 : Epoch: 1436, Train_Loss: 0.00071874
2025/09/16 22:06:52 : Epoch: 1437, Train_Loss: 0.00075129
2025/09/16 22:06:52 : Epoch: 1438, Train_Loss: 0.00069896
2025/09/16 22:06:52 : Epoch: 1439, Train_Loss: 0.00095637
2025/09/16 22:06:53 : Epoch: 1439, Eval_Loss: 0.00753486
2025/09/16 22:06:53 : Epoch: 1440, Train_Loss: 0.00085423
2025/09/16 22:06:53 : Epoch: 1441, Train_Loss: 0.00109450
2025/09/16 22:06:53 : Epoch: 1442, Train_Loss: 0.00106560
2025/09/16 22:06:54 : Epoch: 1443, Train_Loss: 0.00127849
2025/09/16 22:06:54 : Epoch: 1444, Train_Loss: 0.00076849
2025/09/16 22:06:54 : Epoch: 1444, Eval_Loss: 0.00770861
2025/09/16 22:06:54 : Epoch: 1445, Train_Loss: 0.00064229
2025/09/16 22:06:54 : Epoch: 1446, Train_Loss: 0.00078075
2025/09/16 22:06:55 : Epoch: 1447, Train_Loss: 0.00077819
2025/09/16 22:06:55 : Epoch: 1448, Train_Loss: 0.00075132
2025/09/16 22:06:55 : Epoch: 1449, Train_Loss: 0.00071117
2025/09/16 22:06:55 : Epoch: 1449, Eval_Loss: 0.00810051
2025/09/16 22:06:55 : Epoch: 1450, Train_Loss: 0.00062608
2025/09/16 22:06:56 : Epoch: 1451, Train_Loss: 0.00053357
2025/09/16 22:06:56 : Epoch: 1452, Train_Loss: 0.00055165
2025/09/16 22:06:56 : Epoch: 1453, Train_Loss: 0.00074544
2025/09/16 22:06:56 : Epoch: 1454, Train_Loss: 0.00067870
2025/09/16 22:06:56 : Epoch: 1454, Eval_Loss: 0.00761743
2025/09/16 22:06:57 : Epoch: 1455, Train_Loss: 0.00084928
2025/09/16 22:06:57 : Epoch: 1456, Train_Loss: 0.00048622
2025/09/16 22:06:57 : Epoch: 1457, Train_Loss: 0.00048692
2025/09/16 22:06:57 : Epoch: 1458, Train_Loss: 0.00055144
2025/09/16 22:06:58 : Epoch: 1459, Train_Loss: 0.00103987
2025/09/16 22:06:58 : Epoch: 1459, Eval_Loss: 0.00804345
2025/09/16 22:06:58 : Epoch: 1460, Train_Loss: 0.00051752
2025/09/16 22:06:58 : Epoch: 1461, Train_Loss: 0.00106133
2025/09/16 22:06:59 : Epoch: 1462, Train_Loss: 0.00051020
2025/09/16 22:06:59 : Epoch: 1463, Train_Loss: 0.00054290
2025/09/16 22:06:59 : Epoch: 1464, Train_Loss: 0.00064766
2025/09/16 22:06:59 : Epoch: 1464, Eval_Loss: 0.00828183
2025/09/16 22:06:59 : Epoch: 1465, Train_Loss: 0.00070088
2025/09/16 22:07:00 : Epoch: 1466, Train_Loss: 0.00059046
2025/09/16 22:07:00 : Epoch: 1467, Train_Loss: 0.00047781
2025/09/16 22:07:00 : Epoch: 1468, Train_Loss: 0.00078115
2025/09/16 22:07:00 : Epoch: 1469, Train_Loss: 0.00045500
2025/09/16 22:07:00 : Epoch: 1469, Eval_Loss: 0.00790483
2025/09/16 22:07:01 : Epoch: 1470, Train_Loss: 0.00066853
2025/09/16 22:07:01 : Epoch: 1471, Train_Loss: 0.00074185
2025/09/16 22:07:01 : Epoch: 1472, Train_Loss: 0.00051440
2025/09/16 22:07:01 : Epoch: 1473, Train_Loss: 0.00050367
2025/09/16 22:07:02 : Epoch: 1474, Train_Loss: 0.00064145
2025/09/16 22:07:02 : Epoch: 1474, Eval_Loss: 0.00784723
2025/09/16 22:07:02 : Epoch: 1475, Train_Loss: 0.00075015
2025/09/16 22:07:02 : Epoch: 1476, Train_Loss: 0.00064024
2025/09/16 22:07:02 : Epoch: 1477, Train_Loss: 0.00093529
2025/09/16 22:07:03 : Epoch: 1478, Train_Loss: 0.00085435
2025/09/16 22:07:03 : Epoch: 1479, Train_Loss: 0.00079531
2025/09/16 22:07:03 : Epoch: 1479, Eval_Loss: 0.00852220
2025/09/16 22:07:03 : Epoch: 1480, Train_Loss: 0.00069832
2025/09/16 22:07:03 : Epoch: 1481, Train_Loss: 0.00094101
2025/09/16 22:07:04 : Epoch: 1482, Train_Loss: 0.00077237
2025/09/16 22:07:04 : Epoch: 1483, Train_Loss: 0.00095847
2025/09/16 22:07:04 : Epoch: 1484, Train_Loss: 0.00060104
2025/09/16 22:07:04 : Epoch: 1484, Eval_Loss: 0.00835264
2025/09/16 22:07:04 : Epoch: 1485, Train_Loss: 0.00085973
2025/09/16 22:07:05 : Epoch: 1486, Train_Loss: 0.00065078
2025/09/16 22:07:05 : Epoch: 1487, Train_Loss: 0.00065865
2025/09/16 22:07:05 : Epoch: 1488, Train_Loss: 0.00100446
2025/09/16 22:07:05 : Epoch: 1489, Train_Loss: 0.00072362
2025/09/16 22:07:06 : Epoch: 1489, Eval_Loss: 0.00925365
2025/09/16 22:07:06 : Epoch: 1490, Train_Loss: 0.00071251
2025/09/16 22:07:06 : Epoch: 1491, Train_Loss: 0.00093781
2025/09/16 22:07:06 : Epoch: 1492, Train_Loss: 0.00050249
2025/09/16 22:07:07 : Epoch: 1493, Train_Loss: 0.00049556
2025/09/16 22:07:07 : Epoch: 1494, Train_Loss: 0.00098620
2025/09/16 22:07:07 : Epoch: 1494, Eval_Loss: 0.00846242
2025/09/16 22:07:07 : Epoch: 1495, Train_Loss: 0.00079979
2025/09/16 22:07:07 : Epoch: 1496, Train_Loss: 0.00070436
2025/09/16 22:07:08 : Epoch: 1497, Train_Loss: 0.00053090
2025/09/16 22:07:08 : Epoch: 1498, Train_Loss: 0.00052897
2025/09/16 22:07:08 : Epoch: 1499, Train_Loss: 0.00088761
2025/09/16 22:07:08 : Epoch: 1499, Eval_Loss: 0.00869759
2025/09/16 22:07:08 : Epoch: 1500, Train_Loss: 0.00064225
2025/09/16 22:07:09 : Epoch: 1501, Train_Loss: 0.00051082
2025/09/16 22:07:09 : Epoch: 1502, Train_Loss: 0.00047216
2025/09/16 22:07:09 : Epoch: 1503, Train_Loss: 0.00062251
2025/09/16 22:07:09 : Epoch: 1504, Train_Loss: 0.00110737
2025/09/16 22:07:09 : Epoch: 1504, Eval_Loss: 0.00875962
2025/09/16 22:07:10 : Epoch: 1505, Train_Loss: 0.00048304
2025/09/16 22:07:10 : Epoch: 1506, Train_Loss: 0.00094493
2025/09/16 22:07:10 : Epoch: 1507, Train_Loss: 0.00060238
2025/09/16 22:07:10 : Epoch: 1508, Train_Loss: 0.00067018
2025/09/16 22:07:11 : Epoch: 1509, Train_Loss: 0.00059524
2025/09/16 22:07:11 : Epoch: 1509, Eval_Loss: 0.00760564
2025/09/16 22:07:11 : Epoch: 1510, Train_Loss: 0.00082391
2025/09/16 22:07:11 : Epoch: 1511, Train_Loss: 0.00049032
2025/09/16 22:07:11 : Epoch: 1512, Train_Loss: 0.00062418
2025/09/16 22:07:12 : Epoch: 1513, Train_Loss: 0.00058150
2025/09/16 22:07:12 : Epoch: 1514, Train_Loss: 0.00068494
2025/09/16 22:07:12 : Epoch: 1514, Eval_Loss: 0.00787921
2025/09/16 22:07:12 : Epoch: 1515, Train_Loss: 0.00080655
2025/09/16 22:07:13 : Epoch: 1516, Train_Loss: 0.00088699
2025/09/16 22:07:13 : Epoch: 1517, Train_Loss: 0.00066071
2025/09/16 22:07:13 : Epoch: 1518, Train_Loss: 0.00094627
2025/09/16 22:07:13 : Epoch: 1519, Train_Loss: 0.00084845
2025/09/16 22:07:13 : Epoch: 1519, Eval_Loss: 0.00792534
2025/09/16 22:07:14 : Epoch: 1520, Train_Loss: 0.00045520
2025/09/16 22:07:14 : Epoch: 1521, Train_Loss: 0.00058084
2025/09/16 22:07:14 : Epoch: 1522, Train_Loss: 0.00064396
2025/09/16 22:07:14 : Epoch: 1523, Train_Loss: 0.00076295
2025/09/16 22:07:15 : Epoch: 1524, Train_Loss: 0.00062386
2025/09/16 22:07:15 : Epoch: 1524, Eval_Loss: 0.00857122
2025/09/16 22:07:15 : Epoch: 1525, Train_Loss: 0.00053443
2025/09/16 22:07:15 : Epoch: 1526, Train_Loss: 0.00048466
2025/09/16 22:07:15 : Epoch: 1527, Train_Loss: 0.00059938
2025/09/16 22:07:16 : Epoch: 1528, Train_Loss: 0.00065979
2025/09/16 22:07:16 : Epoch: 1529, Train_Loss: 0.00057981
2025/09/16 22:07:16 : Epoch: 1529, Eval_Loss: 0.00872808
2025/09/16 22:07:16 : Epoch: 1530, Train_Loss: 0.00097967
2025/09/16 22:07:16 : Epoch: 1531, Train_Loss: 0.00078884
2025/09/16 22:07:17 : Epoch: 1532, Train_Loss: 0.00082130
2025/09/16 22:07:17 : Epoch: 1533, Train_Loss: 0.00067300
2025/09/16 22:07:17 : Epoch: 1534, Train_Loss: 0.00061390
2025/09/16 22:07:17 : Epoch: 1534, Eval_Loss: 0.00763991
2025/09/16 22:07:18 : Epoch: 1535, Train_Loss: 0.00075135
2025/09/16 22:07:18 : Epoch: 1536, Train_Loss: 0.00065139
2025/09/16 22:07:18 : Epoch: 1537, Train_Loss: 0.00043164
2025/09/16 22:07:18 : Epoch: 1538, Train_Loss: 0.00077147
2025/09/16 22:07:19 : Epoch: 1539, Train_Loss: 0.00060003
2025/09/16 22:07:19 : Epoch: 1539, Eval_Loss: 0.00762053
2025/09/16 22:07:19 : Epoch: 1540, Train_Loss: 0.00049980
2025/09/16 22:07:19 : Epoch: 1541, Train_Loss: 0.00081157
2025/09/16 22:07:19 : Epoch: 1542, Train_Loss: 0.00095530
2025/09/16 22:07:20 : Epoch: 1543, Train_Loss: 0.00044512
2025/09/16 22:07:20 : Epoch: 1544, Train_Loss: 0.00095473
2025/09/16 22:07:20 : Epoch: 1544, Eval_Loss: 0.00766037
2025/09/16 22:07:20 : Epoch: 1545, Train_Loss: 0.00042769
2025/09/16 22:07:20 : Epoch: 1546, Train_Loss: 0.00091727
2025/09/16 22:07:21 : Epoch: 1547, Train_Loss: 0.00042752
2025/09/16 22:07:21 : Epoch: 1548, Train_Loss: 0.00060940
2025/09/16 22:07:21 : Epoch: 1549, Train_Loss: 0.00060410
2025/09/16 22:07:21 : Epoch: 1549, Eval_Loss: 0.00785612
2025/09/16 22:07:21 : Epoch: 1550, Train_Loss: 0.00044221
2025/09/16 22:07:22 : Epoch: 1551, Train_Loss: 0.00091834
2025/09/16 22:07:22 : Epoch: 1552, Train_Loss: 0.00060355
2025/09/16 22:07:22 : Epoch: 1553, Train_Loss: 0.00056206
2025/09/16 22:07:22 : Epoch: 1554, Train_Loss: 0.00046695
2025/09/16 22:07:23 : Epoch: 1554, Eval_Loss: 0.00800014
2025/09/16 22:07:23 : Epoch: 1555, Train_Loss: 0.00058621
2025/09/16 22:07:23 : Epoch: 1556, Train_Loss: 0.00056326
2025/09/16 22:07:23 : Epoch: 1557, Train_Loss: 0.00043342
2025/09/16 22:07:23 : Epoch: 1558, Train_Loss: 0.00047424
2025/09/16 22:07:24 : Epoch: 1559, Train_Loss: 0.00043792
2025/09/16 22:07:24 : Epoch: 1559, Eval_Loss: 0.00878268
2025/09/16 22:07:24 : Epoch: 1560, Train_Loss: 0.00054598
2025/09/16 22:07:24 : Epoch: 1561, Train_Loss: 0.00059340
2025/09/16 22:07:25 : Epoch: 1562, Train_Loss: 0.00057015
2025/09/16 22:07:25 : Epoch: 1563, Train_Loss: 0.00105553
2025/09/16 22:07:25 : Epoch: 1564, Train_Loss: 0.00054040
2025/09/16 22:07:25 : Epoch: 1564, Eval_Loss: 0.00770746
2025/09/16 22:07:25 : Epoch: 1565, Train_Loss: 0.00080219
2025/09/16 22:07:26 : Epoch: 1566, Train_Loss: 0.00057763
2025/09/16 22:07:26 : Epoch: 1567, Train_Loss: 0.00048380
2025/09/16 22:07:26 : Epoch: 1568, Train_Loss: 0.00090884
2025/09/16 22:07:26 : Epoch: 1569, Train_Loss: 0.00053165
2025/09/16 22:07:26 : Epoch: 1569, Eval_Loss: 0.00770558
2025/09/16 22:07:27 : Epoch: 1570, Train_Loss: 0.00041894
2025/09/16 22:07:27 : Epoch: 1571, Train_Loss: 0.00054781
2025/09/16 22:07:27 : Epoch: 1572, Train_Loss: 0.00062630
2025/09/16 22:07:27 : Epoch: 1573, Train_Loss: 0.00060263
2025/09/16 22:07:28 : Epoch: 1574, Train_Loss: 0.00062908
2025/09/16 22:07:28 : Epoch: 1574, Eval_Loss: 0.00801519
2025/09/16 22:07:28 : Epoch: 1575, Train_Loss: 0.00057681
2025/09/16 22:07:28 : Epoch: 1576, Train_Loss: 0.00054439
2025/09/16 22:07:28 : Epoch: 1577, Train_Loss: 0.00053726
2025/09/16 22:07:29 : Epoch: 1578, Train_Loss: 0.00062148
2025/09/16 22:07:29 : Epoch: 1579, Train_Loss: 0.00041959
2025/09/16 22:07:29 : Epoch: 1579, Eval_Loss: 0.00777095
2025/09/16 22:07:29 : Epoch: 1580, Train_Loss: 0.00040233
2025/09/16 22:07:30 : Epoch: 1581, Train_Loss: 0.00043539
2025/09/16 22:07:30 : Epoch: 1582, Train_Loss: 0.00052539
2025/09/16 22:07:30 : Epoch: 1583, Train_Loss: 0.00046671
2025/09/16 22:07:30 : Epoch: 1584, Train_Loss: 0.00042585
2025/09/16 22:07:30 : Epoch: 1584, Eval_Loss: 0.00899168
2025/09/16 22:07:31 : Epoch: 1585, Train_Loss: 0.00095738
2025/09/16 22:07:31 : Epoch: 1586, Train_Loss: 0.00072139
2025/09/16 22:07:31 : Epoch: 1587, Train_Loss: 0.00095769
2025/09/16 22:07:31 : Epoch: 1588, Train_Loss: 0.00042442
2025/09/16 22:07:32 : Epoch: 1589, Train_Loss: 0.00072945
2025/09/16 22:07:32 : Epoch: 1589, Eval_Loss: 0.00795304
2025/09/16 22:07:32 : Epoch: 1590, Train_Loss: 0.00048641
2025/09/16 22:07:32 : Epoch: 1591, Train_Loss: 0.00040637
2025/09/16 22:07:32 : Epoch: 1592, Train_Loss: 0.00071624
2025/09/16 22:07:33 : Epoch: 1593, Train_Loss: 0.00066286
2025/09/16 22:07:33 : Epoch: 1594, Train_Loss: 0.00042922
2025/09/16 22:07:33 : Epoch: 1594, Eval_Loss: 0.00899630
2025/09/16 22:07:33 : Epoch: 1595, Train_Loss: 0.00049929
2025/09/16 22:07:33 : Epoch: 1596, Train_Loss: 0.00049315
2025/09/16 22:07:34 : Epoch: 1597, Train_Loss: 0.00069982
2025/09/16 22:07:34 : Epoch: 1598, Train_Loss: 0.00062978
2025/09/16 22:07:34 : Epoch: 1599, Train_Loss: 0.00051420
2025/09/16 22:07:34 : Epoch: 1599, Eval_Loss: 0.00849914
2025/09/16 22:07:34 : 
Epoch: 1599, save response figures

2025/09/16 22:07:47 : Epoch: 1600, Train_Loss: 0.00081451
2025/09/16 22:07:47 : Epoch: 1601, Train_Loss: 0.00093479
2025/09/16 22:07:47 : Epoch: 1602, Train_Loss: 0.00043645
2025/09/16 22:07:48 : Epoch: 1603, Train_Loss: 0.00046120
2025/09/16 22:07:48 : Epoch: 1604, Train_Loss: 0.00089999
2025/09/16 22:07:48 : Epoch: 1604, Eval_Loss: 0.00842319
2025/09/16 22:07:48 : Epoch: 1605, Train_Loss: 0.00049000
2025/09/16 22:07:49 : Epoch: 1606, Train_Loss: 0.00041009
2025/09/16 22:07:49 : Epoch: 1607, Train_Loss: 0.00042074
2025/09/16 22:07:49 : Epoch: 1608, Train_Loss: 0.00056238
2025/09/16 22:07:49 : Epoch: 1609, Train_Loss: 0.00080468
2025/09/16 22:07:49 : Epoch: 1609, Eval_Loss: 0.00830343
2025/09/16 22:07:50 : Epoch: 1610, Train_Loss: 0.00045116
2025/09/16 22:07:50 : Epoch: 1611, Train_Loss: 0.00052401
2025/09/16 22:07:50 : Epoch: 1612, Train_Loss: 0.00056833
2025/09/16 22:07:50 : Epoch: 1613, Train_Loss: 0.00067920
2025/09/16 22:07:51 : Epoch: 1614, Train_Loss: 0.00101518
2025/09/16 22:07:51 : Epoch: 1614, Eval_Loss: 0.00889672
2025/09/16 22:07:51 : Epoch: 1615, Train_Loss: 0.00059850
2025/09/16 22:07:51 : Epoch: 1616, Train_Loss: 0.00045083
2025/09/16 22:07:51 : Epoch: 1617, Train_Loss: 0.00043929
2025/09/16 22:07:52 : Epoch: 1618, Train_Loss: 0.00047121
2025/09/16 22:07:52 : Epoch: 1619, Train_Loss: 0.00040318
2025/09/16 22:07:52 : Epoch: 1619, Eval_Loss: 0.00974728
2025/09/16 22:07:52 : Epoch: 1620, Train_Loss: 0.00060991
2025/09/16 22:07:52 : Epoch: 1621, Train_Loss: 0.00052987
2025/09/16 22:07:53 : Epoch: 1622, Train_Loss: 0.00047834
2025/09/16 22:07:53 : Epoch: 1623, Train_Loss: 0.00047185
2025/09/16 22:07:53 : Epoch: 1624, Train_Loss: 0.00084552
2025/09/16 22:07:53 : Epoch: 1624, Eval_Loss: 0.00944881
2025/09/16 22:07:54 : Epoch: 1625, Train_Loss: 0.00094593
2025/09/16 22:07:54 : Epoch: 1626, Train_Loss: 0.00062622
2025/09/16 22:07:54 : Epoch: 1627, Train_Loss: 0.00041763
2025/09/16 22:07:54 : Epoch: 1628, Train_Loss: 0.00061384
2025/09/16 22:07:54 : Epoch: 1629, Train_Loss: 0.00045374
2025/09/16 22:07:55 : Epoch: 1629, Eval_Loss: 0.00971481
2025/09/16 22:07:55 : Epoch: 1630, Train_Loss: 0.00055684
2025/09/16 22:07:55 : Epoch: 1631, Train_Loss: 0.00047653
2025/09/16 22:07:55 : Epoch: 1632, Train_Loss: 0.00098159
2025/09/16 22:07:56 : Epoch: 1633, Train_Loss: 0.00045129
2025/09/16 22:07:56 : Epoch: 1634, Train_Loss: 0.00045789
2025/09/16 22:07:56 : Epoch: 1634, Eval_Loss: 0.00988273
2025/09/16 22:07:56 : Epoch: 1635, Train_Loss: 0.00044082
2025/09/16 22:07:56 : Epoch: 1636, Train_Loss: 0.00042230
2025/09/16 22:07:57 : Epoch: 1637, Train_Loss: 0.00055903
2025/09/16 22:07:57 : Epoch: 1638, Train_Loss: 0.00060526
2025/09/16 22:07:57 : Epoch: 1639, Train_Loss: 0.00073599
2025/09/16 22:07:57 : Epoch: 1639, Eval_Loss: 0.00964593
2025/09/16 22:07:57 : Epoch: 1640, Train_Loss: 0.00045877
2025/09/16 22:07:58 : Epoch: 1641, Train_Loss: 0.00061905
2025/09/16 22:07:58 : Epoch: 1642, Train_Loss: 0.00082489
2025/09/16 22:07:58 : Epoch: 1643, Train_Loss: 0.00042969
2025/09/16 22:07:58 : Epoch: 1644, Train_Loss: 0.00043718
2025/09/16 22:07:59 : Epoch: 1644, Eval_Loss: 0.00953870
2025/09/16 22:07:59 : Epoch: 1645, Train_Loss: 0.00079261
2025/09/16 22:07:59 : Epoch: 1646, Train_Loss: 0.00081047
2025/09/16 22:07:59 : Epoch: 1647, Train_Loss: 0.00041861
2025/09/16 22:08:00 : Epoch: 1648, Train_Loss: 0.00043838
2025/09/16 22:08:00 : Epoch: 1649, Train_Loss: 0.00079029
2025/09/16 22:08:00 : Epoch: 1649, Eval_Loss: 0.00970837
2025/09/16 22:08:00 : Epoch: 1650, Train_Loss: 0.00048766
2025/09/16 22:08:00 : Epoch: 1651, Train_Loss: 0.00066238
2025/09/16 22:08:01 : Epoch: 1652, Train_Loss: 0.00054857
2025/09/16 22:08:01 : Epoch: 1653, Train_Loss: 0.00061996
2025/09/16 22:08:01 : Epoch: 1654, Train_Loss: 0.00057846
2025/09/16 22:08:01 : Epoch: 1654, Eval_Loss: 0.00967867
2025/09/16 22:08:01 : Epoch: 1655, Train_Loss: 0.00040408
2025/09/16 22:08:02 : Epoch: 1656, Train_Loss: 0.00072838
2025/09/16 22:08:02 : Epoch: 1657, Train_Loss: 0.00040329
2025/09/16 22:08:02 : Epoch: 1658, Train_Loss: 0.00082341
2025/09/16 22:08:02 : Epoch: 1659, Train_Loss: 0.00051810
2025/09/16 22:08:03 : Epoch: 1659, Eval_Loss: 0.00960923
2025/09/16 22:08:03 : Epoch: 1660, Train_Loss: 0.00078911
2025/09/16 22:08:03 : Epoch: 1661, Train_Loss: 0.00053603
2025/09/16 22:08:03 : Epoch: 1662, Train_Loss: 0.00066071
2025/09/16 22:08:04 : Epoch: 1663, Train_Loss: 0.00058306
2025/09/16 22:08:04 : Epoch: 1664, Train_Loss: 0.00089725
2025/09/16 22:08:04 : Epoch: 1664, Eval_Loss: 0.00951984
2025/09/16 22:08:04 : Epoch: 1665, Train_Loss: 0.00068203
2025/09/16 22:08:04 : Epoch: 1666, Train_Loss: 0.00102963
2025/09/16 22:08:05 : Epoch: 1667, Train_Loss: 0.00075829
2025/09/16 22:08:05 : Epoch: 1668, Train_Loss: 0.00051375
2025/09/16 22:08:05 : Epoch: 1669, Train_Loss: 0.00060652
2025/09/16 22:08:05 : Epoch: 1669, Eval_Loss: 0.00941644
2025/09/16 22:08:05 : Epoch: 1670, Train_Loss: 0.00074706
2025/09/16 22:08:06 : Epoch: 1671, Train_Loss: 0.00063612
2025/09/16 22:08:06 : Epoch: 1672, Train_Loss: 0.00123718
2025/09/16 22:08:06 : Epoch: 1673, Train_Loss: 0.00102750
2025/09/16 22:08:06 : Epoch: 1674, Train_Loss: 0.00083537
2025/09/16 22:08:06 : Epoch: 1674, Eval_Loss: 0.00945068
2025/09/16 22:08:07 : Epoch: 1675, Train_Loss: 0.00065043
2025/09/16 22:08:07 : Epoch: 1676, Train_Loss: 0.00050335
2025/09/16 22:08:07 : Epoch: 1677, Train_Loss: 0.00103632
2025/09/16 22:08:07 : Epoch: 1678, Train_Loss: 0.00073157
2025/09/16 22:08:08 : Epoch: 1679, Train_Loss: 0.00057754
2025/09/16 22:08:08 : Epoch: 1679, Eval_Loss: 0.00978463
2025/09/16 22:08:08 : Epoch: 1680, Train_Loss: 0.00062333
2025/09/16 22:08:08 : Epoch: 1681, Train_Loss: 0.00072658
2025/09/16 22:08:09 : Epoch: 1682, Train_Loss: 0.00082576
2025/09/16 22:08:09 : Epoch: 1683, Train_Loss: 0.00059740
2025/09/16 22:08:09 : Epoch: 1684, Train_Loss: 0.00046085
2025/09/16 22:08:09 : Epoch: 1684, Eval_Loss: 0.00819042
2025/09/16 22:08:09 : Epoch: 1685, Train_Loss: 0.00052985
2025/09/16 22:08:10 : Epoch: 1686, Train_Loss: 0.00061706
2025/09/16 22:08:10 : Epoch: 1687, Train_Loss: 0.00081950
2025/09/16 22:08:10 : Epoch: 1688, Train_Loss: 0.00053373
2025/09/16 22:08:10 : Epoch: 1689, Train_Loss: 0.00047190
2025/09/16 22:08:10 : Epoch: 1689, Eval_Loss: 0.01011649
2025/09/16 22:08:11 : Epoch: 1690, Train_Loss: 0.00047866
2025/09/16 22:08:11 : Epoch: 1691, Train_Loss: 0.00058296
2025/09/16 22:08:11 : Epoch: 1692, Train_Loss: 0.00046572
2025/09/16 22:08:11 : Epoch: 1693, Train_Loss: 0.00054469
2025/09/16 22:08:12 : Epoch: 1694, Train_Loss: 0.00043821
2025/09/16 22:08:12 : Epoch: 1694, Eval_Loss: 0.00875248
2025/09/16 22:08:12 : Epoch: 1695, Train_Loss: 0.00062802
2025/09/16 22:08:12 : Epoch: 1696, Train_Loss: 0.00060083
2025/09/16 22:08:12 : Epoch: 1697, Train_Loss: 0.00059393
2025/09/16 22:08:13 : Epoch: 1698, Train_Loss: 0.00067975
2025/09/16 22:08:13 : Epoch: 1699, Train_Loss: 0.00083179
2025/09/16 22:08:13 : Epoch: 1699, Eval_Loss: 0.00926074
2025/09/16 22:08:13 : Epoch: 1700, Train_Loss: 0.00062640
2025/09/16 22:08:14 : Epoch: 1701, Train_Loss: 0.00067604
2025/09/16 22:08:14 : Epoch: 1702, Train_Loss: 0.00063976
2025/09/16 22:08:14 : Epoch: 1703, Train_Loss: 0.00054312
2025/09/16 22:08:14 : Epoch: 1704, Train_Loss: 0.00081365
2025/09/16 22:08:14 : Epoch: 1704, Eval_Loss: 0.00912401
2025/09/16 22:08:15 : Epoch: 1705, Train_Loss: 0.00089896
2025/09/16 22:08:15 : Epoch: 1706, Train_Loss: 0.00046353
2025/09/16 22:08:15 : Epoch: 1707, Train_Loss: 0.00054742
2025/09/16 22:08:15 : Epoch: 1708, Train_Loss: 0.00048001
2025/09/16 22:08:16 : Epoch: 1709, Train_Loss: 0.00057220
2025/09/16 22:08:16 : Epoch: 1709, Eval_Loss: 0.00938137
2025/09/16 22:08:16 : Epoch: 1710, Train_Loss: 0.00042095
2025/09/16 22:08:16 : Epoch: 1711, Train_Loss: 0.00086684
2025/09/16 22:08:16 : Epoch: 1712, Train_Loss: 0.00043510
2025/09/16 22:08:17 : Epoch: 1713, Train_Loss: 0.00050368
2025/09/16 22:08:17 : Epoch: 1714, Train_Loss: 0.00076454
2025/09/16 22:08:17 : Epoch: 1714, Eval_Loss: 0.00914913
2025/09/16 22:08:17 : Epoch: 1715, Train_Loss: 0.00085013
2025/09/16 22:08:17 : Epoch: 1716, Train_Loss: 0.00076006
2025/09/16 22:08:18 : Epoch: 1717, Train_Loss: 0.00109541
2025/09/16 22:08:18 : Epoch: 1718, Train_Loss: 0.00094942
2025/09/16 22:08:18 : Epoch: 1719, Train_Loss: 0.00049893
2025/09/16 22:08:18 : Epoch: 1719, Eval_Loss: 0.00935500
2025/09/16 22:08:18 : Epoch: 1720, Train_Loss: 0.00048936
2025/09/16 22:08:19 : Epoch: 1721, Train_Loss: 0.00041487
2025/09/16 22:08:19 : Epoch: 1722, Train_Loss: 0.00073935
2025/09/16 22:08:19 : Epoch: 1723, Train_Loss: 0.00045674
2025/09/16 22:08:19 : Epoch: 1724, Train_Loss: 0.00048742
2025/09/16 22:08:20 : Epoch: 1724, Eval_Loss: 0.00906301
2025/09/16 22:08:20 : Epoch: 1725, Train_Loss: 0.00076779
2025/09/16 22:08:20 : Epoch: 1726, Train_Loss: 0.00039622
2025/09/16 22:08:20 : Epoch: 1727, Train_Loss: 0.00051178
2025/09/16 22:08:20 : Epoch: 1728, Train_Loss: 0.00107693
2025/09/16 22:08:21 : Epoch: 1729, Train_Loss: 0.00091580
2025/09/16 22:08:21 : Epoch: 1729, Eval_Loss: 0.00924743
2025/09/16 22:08:21 : Epoch: 1730, Train_Loss: 0.00075709
2025/09/16 22:08:21 : Epoch: 1731, Train_Loss: 0.00085804
2025/09/16 22:08:22 : Epoch: 1732, Train_Loss: 0.00073933
2025/09/16 22:08:22 : Epoch: 1733, Train_Loss: 0.00082789
2025/09/16 22:08:22 : Epoch: 1734, Train_Loss: 0.00042675
2025/09/16 22:08:22 : Epoch: 1734, Eval_Loss: 0.00931943
2025/09/16 22:08:22 : Epoch: 1735, Train_Loss: 0.00039239
2025/09/16 22:08:23 : Epoch: 1736, Train_Loss: 0.00047348
2025/09/16 22:08:23 : Epoch: 1737, Train_Loss: 0.00077439
2025/09/16 22:08:23 : Epoch: 1738, Train_Loss: 0.00047117
2025/09/16 22:08:23 : Epoch: 1739, Train_Loss: 0.00076336
2025/09/16 22:08:24 : Epoch: 1739, Eval_Loss: 0.00934083
2025/09/16 22:08:24 : Epoch: 1740, Train_Loss: 0.00038586
2025/09/16 22:08:24 : Epoch: 1741, Train_Loss: 0.00041120
2025/09/16 22:08:24 : Epoch: 1742, Train_Loss: 0.00054714
2025/09/16 22:08:24 : Epoch: 1743, Train_Loss: 0.00044703
2025/09/16 22:08:25 : Epoch: 1744, Train_Loss: 0.00055211
2025/09/16 22:08:25 : Epoch: 1744, Eval_Loss: 0.00886387
2025/09/16 22:08:25 : Epoch: 1745, Train_Loss: 0.00042514
2025/09/16 22:08:25 : Epoch: 1746, Train_Loss: 0.00043190
2025/09/16 22:08:25 : Epoch: 1747, Train_Loss: 0.00080192
2025/09/16 22:08:26 : Epoch: 1748, Train_Loss: 0.00046937
2025/09/16 22:08:26 : Epoch: 1749, Train_Loss: 0.00079221
2025/09/16 22:08:26 : Epoch: 1749, Eval_Loss: 0.00930404
2025/09/16 22:08:26 : Epoch: 1750, Train_Loss: 0.00046020
2025/09/16 22:08:27 : Epoch: 1751, Train_Loss: 0.00046011
2025/09/16 22:08:27 : Epoch: 1752, Train_Loss: 0.00043214
2025/09/16 22:08:27 : Epoch: 1753, Train_Loss: 0.00042201
2025/09/16 22:08:27 : Epoch: 1754, Train_Loss: 0.00042003
2025/09/16 22:08:27 : Epoch: 1754, Eval_Loss: 0.00900967
2025/09/16 22:08:28 : Epoch: 1755, Train_Loss: 0.00040847
2025/09/16 22:08:28 : Epoch: 1756, Train_Loss: 0.00039163
2025/09/16 22:08:28 : Epoch: 1757, Train_Loss: 0.00055491
2025/09/16 22:08:28 : Epoch: 1758, Train_Loss: 0.00075055
2025/09/16 22:08:29 : Epoch: 1759, Train_Loss: 0.00046734
2025/09/16 22:08:29 : Epoch: 1759, Eval_Loss: 0.00926886
2025/09/16 22:08:29 : Epoch: 1760, Train_Loss: 0.00080799
2025/09/16 22:08:29 : Epoch: 1761, Train_Loss: 0.00045580
2025/09/16 22:08:29 : Epoch: 1762, Train_Loss: 0.00090347
2025/09/16 22:08:30 : Epoch: 1763, Train_Loss: 0.00053027
2025/09/16 22:08:30 : Epoch: 1764, Train_Loss: 0.00066257
2025/09/16 22:08:30 : Epoch: 1764, Eval_Loss: 0.00921623
2025/09/16 22:08:30 : Epoch: 1765, Train_Loss: 0.00043144
2025/09/16 22:08:30 : Epoch: 1766, Train_Loss: 0.00048864
2025/09/16 22:08:31 : Epoch: 1767, Train_Loss: 0.00077043
2025/09/16 22:08:31 : Epoch: 1768, Train_Loss: 0.00041171
2025/09/16 22:08:31 : Epoch: 1769, Train_Loss: 0.00076529
2025/09/16 22:08:31 : Epoch: 1769, Eval_Loss: 0.00909512
2025/09/16 22:08:32 : Epoch: 1770, Train_Loss: 0.00044525
2025/09/16 22:08:32 : Epoch: 1771, Train_Loss: 0.00075360
2025/09/16 22:08:32 : Epoch: 1772, Train_Loss: 0.00060168
2025/09/16 22:08:32 : Epoch: 1773, Train_Loss: 0.00041433
2025/09/16 22:08:33 : Epoch: 1774, Train_Loss: 0.00042891
2025/09/16 22:08:33 : Epoch: 1774, Eval_Loss: 0.00904566
2025/09/16 22:08:33 : Epoch: 1775, Train_Loss: 0.00078134
2025/09/16 22:08:33 : Epoch: 1776, Train_Loss: 0.00047021
2025/09/16 22:08:33 : Epoch: 1777, Train_Loss: 0.00059480
2025/09/16 22:08:34 : Epoch: 1778, Train_Loss: 0.00085148
2025/09/16 22:08:34 : Epoch: 1779, Train_Loss: 0.00081531
2025/09/16 22:08:34 : Epoch: 1779, Eval_Loss: 0.00895699
2025/09/16 22:08:34 : Epoch: 1780, Train_Loss: 0.00036980
2025/09/16 22:08:34 : Epoch: 1781, Train_Loss: 0.00042051
2025/09/16 22:08:35 : Epoch: 1782, Train_Loss: 0.00055805
2025/09/16 22:08:35 : Epoch: 1783, Train_Loss: 0.00041513
2025/09/16 22:08:35 : Epoch: 1784, Train_Loss: 0.00043075
2025/09/16 22:08:35 : Epoch: 1784, Eval_Loss: 0.00898512
2025/09/16 22:08:36 : Epoch: 1785, Train_Loss: 0.00042087
2025/09/16 22:08:36 : Epoch: 1786, Train_Loss: 0.00054143
2025/09/16 22:08:36 : Epoch: 1787, Train_Loss: 0.00053354
2025/09/16 22:08:36 : Epoch: 1788, Train_Loss: 0.00049789
2025/09/16 22:08:37 : Epoch: 1789, Train_Loss: 0.00038708
2025/09/16 22:08:37 : Epoch: 1789, Eval_Loss: 0.00900098
2025/09/16 22:08:37 : Epoch: 1790, Train_Loss: 0.00086386
2025/09/16 22:08:37 : Epoch: 1791, Train_Loss: 0.00036927
2025/09/16 22:08:37 : Epoch: 1792, Train_Loss: 0.00051293
2025/09/16 22:08:38 : Epoch: 1793, Train_Loss: 0.00054990
2025/09/16 22:08:38 : Epoch: 1794, Train_Loss: 0.00041937
2025/09/16 22:08:38 : Epoch: 1794, Eval_Loss: 0.00874112
2025/09/16 22:08:38 : Epoch: 1795, Train_Loss: 0.00079357
2025/09/16 22:08:38 : Epoch: 1796, Train_Loss: 0.00047993
2025/09/16 22:08:39 : Epoch: 1797, Train_Loss: 0.00092677
2025/09/16 22:08:39 : Epoch: 1798, Train_Loss: 0.00039504
2025/09/16 22:08:39 : Epoch: 1799, Train_Loss: 0.00055569
2025/09/16 22:08:39 : Epoch: 1799, Eval_Loss: 0.00784562
2025/09/16 22:08:39 : Epoch: 1800, Train_Loss: 0.00037272
2025/09/16 22:08:40 : Epoch: 1801, Train_Loss: 0.00056652
2025/09/16 22:08:40 : Epoch: 1802, Train_Loss: 0.00036849
2025/09/16 22:08:40 : Epoch: 1803, Train_Loss: 0.00043292
2025/09/16 22:08:40 : Epoch: 1804, Train_Loss: 0.00044430
2025/09/16 22:08:40 : Epoch: 1804, Eval_Loss: 0.00641959
2025/09/16 22:08:41 : Epoch: 1805, Train_Loss: 0.00052418
2025/09/16 22:08:41 : Epoch: 1806, Train_Loss: 0.00053987
2025/09/16 22:08:41 : Epoch: 1807, Train_Loss: 0.00044524
2025/09/16 22:08:41 : Epoch: 1808, Train_Loss: 0.00036733
2025/09/16 22:08:42 : Epoch: 1809, Train_Loss: 0.00042397
2025/09/16 22:08:42 : Epoch: 1809, Eval_Loss: 0.00873258
2025/09/16 22:08:42 : Epoch: 1810, Train_Loss: 0.00054673
2025/09/16 22:08:42 : Epoch: 1811, Train_Loss: 0.00045884
2025/09/16 22:08:43 : Epoch: 1812, Train_Loss: 0.00037539
2025/09/16 22:08:43 : Epoch: 1813, Train_Loss: 0.00073635
2025/09/16 22:08:43 : Epoch: 1814, Train_Loss: 0.00078031
2025/09/16 22:08:43 : Epoch: 1814, Eval_Loss: 0.00778232
2025/09/16 22:08:43 : Epoch: 1815, Train_Loss: 0.00084769
2025/09/16 22:08:44 : Epoch: 1816, Train_Loss: 0.00036568
2025/09/16 22:08:44 : Epoch: 1817, Train_Loss: 0.00072846
2025/09/16 22:08:44 : Epoch: 1818, Train_Loss: 0.00036830
2025/09/16 22:08:44 : Epoch: 1819, Train_Loss: 0.00072363
2025/09/16 22:08:44 : Epoch: 1819, Eval_Loss: 0.00887963
2025/09/16 22:08:45 : Epoch: 1820, Train_Loss: 0.00038640
2025/09/16 22:08:45 : Epoch: 1821, Train_Loss: 0.00039221
2025/09/16 22:08:45 : Epoch: 1822, Train_Loss: 0.00052895
2025/09/16 22:08:45 : Epoch: 1823, Train_Loss: 0.00041341
2025/09/16 22:08:46 : Epoch: 1824, Train_Loss: 0.00041545
2025/09/16 22:08:46 : Epoch: 1824, Eval_Loss: 0.00663273
2025/09/16 22:08:46 : Epoch: 1825, Train_Loss: 0.00059738
2025/09/16 22:08:46 : Epoch: 1826, Train_Loss: 0.00042764
2025/09/16 22:08:46 : Epoch: 1827, Train_Loss: 0.00081013
2025/09/16 22:08:47 : Epoch: 1828, Train_Loss: 0.00045873
2025/09/16 22:08:47 : Epoch: 1829, Train_Loss: 0.00042711
2025/09/16 22:08:47 : Epoch: 1829, Eval_Loss: 0.00893489
2025/09/16 22:08:47 : Epoch: 1830, Train_Loss: 0.00088940
2025/09/16 22:08:48 : Epoch: 1831, Train_Loss: 0.00047058
2025/09/16 22:08:48 : Epoch: 1832, Train_Loss: 0.00059500
2025/09/16 22:08:48 : Epoch: 1833, Train_Loss: 0.00060407
2025/09/16 22:08:48 : Epoch: 1834, Train_Loss: 0.00063074
2025/09/16 22:08:48 : Epoch: 1834, Eval_Loss: 0.00731494
2025/09/16 22:08:49 : Epoch: 1835, Train_Loss: 0.00063640
2025/09/16 22:08:49 : Epoch: 1836, Train_Loss: 0.00056366
2025/09/16 22:08:49 : Epoch: 1837, Train_Loss: 0.00049510
2025/09/16 22:08:49 : Epoch: 1838, Train_Loss: 0.00040518
2025/09/16 22:08:50 : Epoch: 1839, Train_Loss: 0.00077746
2025/09/16 22:08:50 : Epoch: 1839, Eval_Loss: 0.00760789
2025/09/16 22:08:50 : Epoch: 1840, Train_Loss: 0.00040439
2025/09/16 22:08:50 : Epoch: 1841, Train_Loss: 0.00052453
2025/09/16 22:08:50 : Epoch: 1842, Train_Loss: 0.00082905
2025/09/16 22:08:51 : Epoch: 1843, Train_Loss: 0.00038684
2025/09/16 22:08:51 : Epoch: 1844, Train_Loss: 0.00040055
2025/09/16 22:08:51 : Epoch: 1844, Eval_Loss: 0.00773885
2025/09/16 22:08:51 : Epoch: 1845, Train_Loss: 0.00078947
2025/09/16 22:08:52 : Epoch: 1846, Train_Loss: 0.00046561
2025/09/16 22:08:52 : Epoch: 1847, Train_Loss: 0.00064206
2025/09/16 22:08:52 : Epoch: 1848, Train_Loss: 0.00076734
2025/09/16 22:08:52 : Epoch: 1849, Train_Loss: 0.00062039
2025/09/16 22:08:52 : Epoch: 1849, Eval_Loss: 0.00766017
2025/09/16 22:08:53 : Epoch: 1850, Train_Loss: 0.00046614
2025/09/16 22:08:53 : Epoch: 1851, Train_Loss: 0.00080096
2025/09/16 22:08:53 : Epoch: 1852, Train_Loss: 0.00061747
2025/09/16 22:08:53 : Epoch: 1853, Train_Loss: 0.00054084
2025/09/16 22:08:54 : Epoch: 1854, Train_Loss: 0.00075396
2025/09/16 22:08:54 : Epoch: 1854, Eval_Loss: 0.00683996
2025/09/16 22:08:54 : Epoch: 1855, Train_Loss: 0.00080307
2025/09/16 22:08:54 : Epoch: 1856, Train_Loss: 0.00046034
2025/09/16 22:08:54 : Epoch: 1857, Train_Loss: 0.00078057
2025/09/16 22:08:55 : Epoch: 1858, Train_Loss: 0.00081677
2025/09/16 22:08:55 : Epoch: 1859, Train_Loss: 0.00040095
2025/09/16 22:08:55 : Epoch: 1859, Eval_Loss: 0.00659347
2025/09/16 22:08:55 : Epoch: 1860, Train_Loss: 0.00043612
2025/09/16 22:08:56 : Epoch: 1861, Train_Loss: 0.00093240
2025/09/16 22:08:56 : Epoch: 1862, Train_Loss: 0.00038935
2025/09/16 22:08:56 : Epoch: 1863, Train_Loss: 0.00056709
2025/09/16 22:08:56 : Epoch: 1864, Train_Loss: 0.00057839
2025/09/16 22:08:56 : Epoch: 1864, Eval_Loss: 0.00883508
2025/09/16 22:08:57 : Epoch: 1865, Train_Loss: 0.00058378
2025/09/16 22:08:57 : Epoch: 1866, Train_Loss: 0.00047332
2025/09/16 22:08:57 : Epoch: 1867, Train_Loss: 0.00050711
2025/09/16 22:08:57 : Epoch: 1868, Train_Loss: 0.00045526
2025/09/16 22:08:58 : Epoch: 1869, Train_Loss: 0.00071568
2025/09/16 22:08:58 : Epoch: 1869, Eval_Loss: 0.00667250
2025/09/16 22:08:58 : Epoch: 1870, Train_Loss: 0.00070768
2025/09/16 22:08:58 : Epoch: 1871, Train_Loss: 0.00034981
2025/09/16 22:08:58 : Epoch: 1872, Train_Loss: 0.00053896
2025/09/16 22:08:59 : Epoch: 1873, Train_Loss: 0.00084592
2025/09/16 22:08:59 : Epoch: 1874, Train_Loss: 0.00039439
2025/09/16 22:08:59 : Epoch: 1874, Eval_Loss: 0.00803284
2025/09/16 22:08:59 : Epoch: 1875, Train_Loss: 0.00038639
2025/09/16 22:08:59 : Epoch: 1876, Train_Loss: 0.00085184
2025/09/16 22:09:00 : Epoch: 1877, Train_Loss: 0.00039250
2025/09/16 22:09:00 : Epoch: 1878, Train_Loss: 0.00046440
2025/09/16 22:09:00 : Epoch: 1879, Train_Loss: 0.00049636
2025/09/16 22:09:00 : Epoch: 1879, Eval_Loss: 0.00666518
2025/09/16 22:09:01 : Epoch: 1880, Train_Loss: 0.00054618
2025/09/16 22:09:01 : Epoch: 1881, Train_Loss: 0.00040307
2025/09/16 22:09:01 : Epoch: 1882, Train_Loss: 0.00054651
2025/09/16 22:09:01 : Epoch: 1883, Train_Loss: 0.00039584
2025/09/16 22:09:02 : Epoch: 1884, Train_Loss: 0.00050229
2025/09/16 22:09:02 : Epoch: 1884, Eval_Loss: 0.00808397
2025/09/16 22:09:02 : Epoch: 1885, Train_Loss: 0.00046809
2025/09/16 22:09:02 : Epoch: 1886, Train_Loss: 0.00082608
2025/09/16 22:09:02 : Epoch: 1887, Train_Loss: 0.00076177
2025/09/16 22:09:03 : Epoch: 1888, Train_Loss: 0.00044789
2025/09/16 22:09:03 : Epoch: 1889, Train_Loss: 0.00040078
2025/09/16 22:09:03 : Epoch: 1889, Eval_Loss: 0.00814327
2025/09/16 22:09:03 : Epoch: 1890, Train_Loss: 0.00038947
2025/09/16 22:09:03 : Epoch: 1891, Train_Loss: 0.00037566
2025/09/16 22:09:04 : Epoch: 1892, Train_Loss: 0.00057640
2025/09/16 22:09:04 : Epoch: 1893, Train_Loss: 0.00043418
2025/09/16 22:09:04 : Epoch: 1894, Train_Loss: 0.00062598
2025/09/16 22:09:04 : Epoch: 1894, Eval_Loss: 0.00667332
2025/09/16 22:09:04 : Epoch: 1895, Train_Loss: 0.00093477
2025/09/16 22:09:05 : Epoch: 1896, Train_Loss: 0.00051134
2025/09/16 22:09:05 : Epoch: 1897, Train_Loss: 0.00063332
2025/09/16 22:09:05 : Epoch: 1898, Train_Loss: 0.00048750
2025/09/16 22:09:05 : Epoch: 1899, Train_Loss: 0.00092292
2025/09/16 22:09:06 : Epoch: 1899, Eval_Loss: 0.00789270
2025/09/16 22:09:06 : Epoch: 1900, Train_Loss: 0.00077139
2025/09/16 22:09:06 : Epoch: 1901, Train_Loss: 0.00082350
2025/09/16 22:09:06 : Epoch: 1902, Train_Loss: 0.00058102
2025/09/16 22:09:07 : Epoch: 1903, Train_Loss: 0.00051755
2025/09/16 22:09:07 : Epoch: 1904, Train_Loss: 0.00056111
2025/09/16 22:09:07 : Epoch: 1904, Eval_Loss: 0.00813276
2025/09/16 22:09:07 : Epoch: 1905, Train_Loss: 0.00067360
2025/09/16 22:09:07 : Epoch: 1906, Train_Loss: 0.00068410
2025/09/16 22:09:08 : Epoch: 1907, Train_Loss: 0.00069448
2025/09/16 22:09:08 : Epoch: 1908, Train_Loss: 0.00051249
2025/09/16 22:09:08 : Epoch: 1909, Train_Loss: 0.00046270
2025/09/16 22:09:08 : Epoch: 1909, Eval_Loss: 0.00795020
2025/09/16 22:09:08 : Epoch: 1910, Train_Loss: 0.00079172
2025/09/16 22:09:09 : Epoch: 1911, Train_Loss: 0.00040477
2025/09/16 22:09:09 : Epoch: 1912, Train_Loss: 0.00046413
2025/09/16 22:09:09 : Epoch: 1913, Train_Loss: 0.00039790
2025/09/16 22:09:09 : Epoch: 1914, Train_Loss: 0.00042644
2025/09/16 22:09:09 : Epoch: 1914, Eval_Loss: 0.00770204
2025/09/16 22:09:10 : Epoch: 1915, Train_Loss: 0.00046321
2025/09/16 22:09:10 : Epoch: 1916, Train_Loss: 0.00052333
2025/09/16 22:09:10 : Epoch: 1917, Train_Loss: 0.00058533
2025/09/16 22:09:10 : Epoch: 1918, Train_Loss: 0.00042486
2025/09/16 22:09:11 : Epoch: 1919, Train_Loss: 0.00044092
2025/09/16 22:09:11 : Epoch: 1919, Eval_Loss: 0.00801683
2025/09/16 22:09:11 : Epoch: 1920, Train_Loss: 0.00048201
2025/09/16 22:09:11 : Epoch: 1921, Train_Loss: 0.00054276
2025/09/16 22:09:12 : Epoch: 1922, Train_Loss: 0.00038481
2025/09/16 22:09:12 : Epoch: 1923, Train_Loss: 0.00041924
2025/09/16 22:09:12 : Epoch: 1924, Train_Loss: 0.00039652
2025/09/16 22:09:12 : Epoch: 1924, Eval_Loss: 0.00783361
2025/09/16 22:09:12 : Epoch: 1925, Train_Loss: 0.00047729
2025/09/16 22:09:13 : Epoch: 1926, Train_Loss: 0.00046745
2025/09/16 22:09:13 : Epoch: 1927, Train_Loss: 0.00061202
2025/09/16 22:09:13 : Epoch: 1928, Train_Loss: 0.00088396
2025/09/16 22:09:13 : Epoch: 1929, Train_Loss: 0.00068575
2025/09/16 22:09:13 : Epoch: 1929, Eval_Loss: 0.00466980
2025/09/16 22:09:14 : Epoch: 1930, Train_Loss: 0.00107244
2025/09/16 22:09:14 : Epoch: 1931, Train_Loss: 0.00138306
2025/09/16 22:09:14 : Epoch: 1932, Train_Loss: 0.00098516
2025/09/16 22:09:14 : Epoch: 1933, Train_Loss: 0.00099033
2025/09/16 22:09:15 : Epoch: 1934, Train_Loss: 0.00163841
2025/09/16 22:09:15 : Epoch: 1934, Eval_Loss: 0.01142942
2025/09/16 22:09:15 : Epoch: 1935, Train_Loss: 0.00080697
2025/09/16 22:09:15 : Epoch: 1936, Train_Loss: 0.00086976
2025/09/16 22:09:15 : Epoch: 1937, Train_Loss: 0.00105055
2025/09/16 22:09:16 : Epoch: 1938, Train_Loss: 0.00111882
2025/09/16 22:09:16 : Epoch: 1939, Train_Loss: 0.00147662
2025/09/16 22:09:16 : Epoch: 1939, Eval_Loss: 0.00786107
2025/09/16 22:09:16 : Epoch: 1940, Train_Loss: 0.00162902
2025/09/16 22:09:16 : Epoch: 1941, Train_Loss: 0.00140910
2025/09/16 22:09:17 : Epoch: 1942, Train_Loss: 0.00118608
2025/09/16 22:09:17 : Epoch: 1943, Train_Loss: 0.00113447
2025/09/16 22:09:17 : Epoch: 1944, Train_Loss: 0.00108200
2025/09/16 22:09:17 : Epoch: 1944, Eval_Loss: 0.00541622
2025/09/16 22:09:18 : Epoch: 1945, Train_Loss: 0.00159083
2025/09/16 22:09:18 : Epoch: 1946, Train_Loss: 0.00224057
2025/09/16 22:09:18 : Epoch: 1947, Train_Loss: 0.00210226
2025/09/16 22:09:18 : Epoch: 1948, Train_Loss: 0.00136555
2025/09/16 22:09:19 : Epoch: 1949, Train_Loss: 0.00156099
2025/09/16 22:09:19 : Epoch: 1949, Eval_Loss: 0.00537458
2025/09/16 22:09:19 : Epoch: 1950, Train_Loss: 0.00156943
2025/09/16 22:09:19 : Epoch: 1951, Train_Loss: 0.00159199
2025/09/16 22:09:19 : Epoch: 1952, Train_Loss: 0.00089431
2025/09/16 22:09:20 : Epoch: 1953, Train_Loss: 0.00115128
2025/09/16 22:09:20 : Epoch: 1954, Train_Loss: 0.00088018
2025/09/16 22:09:20 : Epoch: 1954, Eval_Loss: 0.00513851
2025/09/16 22:09:20 : Epoch: 1955, Train_Loss: 0.00152399
2025/09/16 22:09:20 : Epoch: 1956, Train_Loss: 0.00144926
2025/09/16 22:09:21 : Epoch: 1957, Train_Loss: 0.00146595
2025/09/16 22:09:21 : Epoch: 1958, Train_Loss: 0.00084184
2025/09/16 22:09:21 : Epoch: 1959, Train_Loss: 0.00082593
2025/09/16 22:09:21 : Epoch: 1959, Eval_Loss: 0.00836836
2025/09/16 22:09:21 : Epoch: 1960, Train_Loss: 0.00105448
2025/09/16 22:09:22 : Epoch: 1961, Train_Loss: 0.00079897
2025/09/16 22:09:22 : Epoch: 1962, Train_Loss: 0.00104048
2025/09/16 22:09:22 : Epoch: 1963, Train_Loss: 0.00137890
2025/09/16 22:09:22 : Epoch: 1964, Train_Loss: 0.00072935
2025/09/16 22:09:23 : Epoch: 1964, Eval_Loss: 0.00871027
2025/09/16 22:09:23 : Epoch: 1965, Train_Loss: 0.00187954
2025/09/16 22:09:23 : Epoch: 1966, Train_Loss: 0.00074293
2025/09/16 22:09:23 : Epoch: 1967, Train_Loss: 0.00071619
2025/09/16 22:09:24 : Epoch: 1968, Train_Loss: 0.00075330
2025/09/16 22:09:24 : Epoch: 1969, Train_Loss: 0.00072752
2025/09/16 22:09:24 : Epoch: 1969, Eval_Loss: 0.00822428
2025/09/16 22:09:24 : Epoch: 1970, Train_Loss: 0.00124218
2025/09/16 22:09:24 : Epoch: 1971, Train_Loss: 0.00108676
2025/09/16 22:09:25 : Epoch: 1972, Train_Loss: 0.00091906
2025/09/16 22:09:25 : Epoch: 1973, Train_Loss: 0.00137526
2025/09/16 22:09:25 : Epoch: 1974, Train_Loss: 0.00096158
2025/09/16 22:09:25 : Epoch: 1974, Eval_Loss: 0.00905023
2025/09/16 22:09:25 : Epoch: 1975, Train_Loss: 0.00062084
2025/09/16 22:09:26 : Epoch: 1976, Train_Loss: 0.00136572
2025/09/16 22:09:26 : Epoch: 1977, Train_Loss: 0.00066771
2025/09/16 22:09:26 : Epoch: 1978, Train_Loss: 0.00082572
2025/09/16 22:09:26 : Epoch: 1979, Train_Loss: 0.00074913
2025/09/16 22:09:26 : Epoch: 1979, Eval_Loss: 0.00952519
2025/09/16 22:09:27 : Epoch: 1980, Train_Loss: 0.00057125
2025/09/16 22:09:27 : Epoch: 1981, Train_Loss: 0.00085711
2025/09/16 22:09:27 : Epoch: 1982, Train_Loss: 0.00073402
2025/09/16 22:09:27 : Epoch: 1983, Train_Loss: 0.00084823
2025/09/16 22:09:28 : Epoch: 1984, Train_Loss: 0.00108571
2025/09/16 22:09:28 : Epoch: 1984, Eval_Loss: 0.00916997
2025/09/16 22:09:28 : Epoch: 1985, Train_Loss: 0.00119323
2025/09/16 22:09:28 : Epoch: 1986, Train_Loss: 0.00079271
2025/09/16 22:09:29 : Epoch: 1987, Train_Loss: 0.00063564
2025/09/16 22:09:29 : Epoch: 1988, Train_Loss: 0.00096837
2025/09/16 22:09:29 : Epoch: 1989, Train_Loss: 0.00058693
2025/09/16 22:09:29 : Epoch: 1989, Eval_Loss: 0.00866620
2025/09/16 22:09:29 : Epoch: 1990, Train_Loss: 0.00109012
2025/09/16 22:09:30 : Epoch: 1991, Train_Loss: 0.00105522
2025/09/16 22:09:30 : Epoch: 1992, Train_Loss: 0.00076857
2025/09/16 22:09:30 : Epoch: 1993, Train_Loss: 0.00057684
2025/09/16 22:09:30 : Epoch: 1994, Train_Loss: 0.00103102
2025/09/16 22:09:30 : Epoch: 1994, Eval_Loss: 0.00839520
2025/09/16 22:09:31 : Epoch: 1995, Train_Loss: 0.00105377
2025/09/16 22:09:31 : Epoch: 1996, Train_Loss: 0.00070435
2025/09/16 22:09:31 : Epoch: 1997, Train_Loss: 0.00125042
2025/09/16 22:09:31 : Epoch: 1998, Train_Loss: 0.00053193
2025/09/16 22:09:32 : Epoch: 1999, Train_Loss: 0.00070035
2025/09/16 22:09:32 : Epoch: 1999, Eval_Loss: 0.00911758
2025/09/16 22:09:32 : 
Epoch: 1999, save response figures

