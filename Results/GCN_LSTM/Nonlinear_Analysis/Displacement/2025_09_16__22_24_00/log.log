2025/09/16 22:24:00 : 

** GPU Info **
2025/09/16 22:24:00 : ====================================================================================================
2025/09/16 22:24:00 : My GPU is NVIDIA L40
2025/09/16 22:24:00 : ====================================================================================================
2025/09/16 22:24:20 : 

** Load Data **
2025/09/16 22:24:20 : ====================================================================================================
2025/09/16 22:24:20 : Response Type: Displacement
2025/09/16 22:24:20 : Train dataset: ['./Data/Nonlinear_Analysis/train/ChiChi_DBE', './Data/Nonlinear_Analysis/train/NGAWest2_DBE', './Data/Nonlinear_Analysis/train/ChiChi_MCE', './Data/Nonlinear_Analysis/train/NGAWest2_MCE']
2025/09/16 22:24:20 : Eval dataset: ['./Data/Nonlinear_Analysis/eval/ChiChi_DBE', './Data/Nonlinear_Analysis/eval/NGAWest2_DBE', './Data/Nonlinear_Analysis/eval/ChiChi_MCE', './Data/Nonlinear_Analysis/eval/NGAWest2_MCE']
2025/09/16 22:24:20 : # of effective train data: 20
2025/09/16 22:24:20 : # of effective eval data: 20
2025/09/16 22:24:20 : ====================================================================================================
2025/09/16 22:24:25 : 

** Get Normalization Dictionary **
2025/09/16 22:24:25 : ====================================================================================================
2025/09/16 22:24:25 : 
normalization dictionary: 
{'x': {'XYZ_gridline_num': tensor(8.), 'XYZ_grid_index': tensor(7.), 'period': tensor(1.3262), 'DOF': tensor(1.), 'mass': tensor(0.0255), 'XYZ_inertia': tensor(255288.), 'XYZ_mode_shape': tensor(1.8960)}, 'ground_motion': tensor(10479.9434), 'y': tensor(241.7000), 'edge_attr': {'S_y': tensor(3687090.), 'S_z': tensor(3687090.), 'area': tensor(30774.), 'element_length': tensor(8000.)}, 'response_type': 'Displacement'}
2025/09/16 22:24:25 : ====================================================================================================
2025/09/16 22:24:25 : 

** Model Info **
2025/09/16 22:24:25 : ====================================================================================================
2025/09/16 22:24:25 : GCN_LSTM(
  (GCN_Encoder): GCN_Encoder(
    (relu): ReLU()
    (dropout): Dropout(p=0.2, inplace=False)
    (conv1): GCNConv(15, 512)
    (conv2): GCNConv(512, 1024)
    (conv3): GCNConv(1024, 512)
  )
  (LSTM): LSTM(
    (lstm): LSTM(522, 512, num_layers=2, batch_first=True, dropout=0.2)
    (fc_out): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=8, bias=True)
    )
  )
)
2025/09/16 22:24:25 : ====================================================================================================
2025/09/16 22:24:25 : 

** Train **
2025/09/16 22:24:25 : ====================================================================================================
2025/09/16 22:24:25 :   Packed Mode = True
2025/09/16 22:24:25 :   Compression Rate of Ground Motion = 10
2025/09/16 22:24:25 :   Compression Rate of Response Sequence  = 1
2025/09/16 22:24:25 :   Compressed Seqence Length  = 2000
2025/09/16 22:24:25 :   Num Epochs = 2000
2025/09/16 22:24:25 :   Num Train Examples = 20
2025/09/16 22:24:25 :   Num Eval Examples = 20
2025/09/16 22:24:25 :   Batch Size = 16
2025/09/16 22:24:25 :   Evaluation Interval = 5
2025/09/16 22:24:25 :   Plot Interval = 400
2025/09/16 22:24:25 : ====================================================================================================
2025/09/16 22:24:25 : Epoch: 000, Train_Loss: 0.00985057
2025/09/16 22:24:25 : Epoch: 001, Train_Loss: 0.00952908
2025/09/16 22:24:26 : Epoch: 002, Train_Loss: 0.01265387
2025/09/16 22:24:26 : Epoch: 003, Train_Loss: 0.00936715
2025/09/16 22:24:26 : Epoch: 004, Train_Loss: 0.00776229
2025/09/16 22:24:26 : Epoch: 004, Eval_Loss: 0.00524700
2025/09/16 22:24:26 : Epoch: 004, Save the best checkpoint
2025/09/16 22:24:27 : Epoch: 005, Train_Loss: 0.00856245
2025/09/16 22:24:27 : Epoch: 006, Train_Loss: 0.00876309
2025/09/16 22:24:27 : Epoch: 007, Train_Loss: 0.01112336
2025/09/16 22:24:27 : Epoch: 008, Train_Loss: 0.01028516
2025/09/16 22:24:28 : Epoch: 009, Train_Loss: 0.00976623
2025/09/16 22:24:28 : Epoch: 009, Eval_Loss: 0.00514226
2025/09/16 22:24:28 : Epoch: 009, Save the best checkpoint
2025/09/16 22:24:28 : Epoch: 010, Train_Loss: 0.01006167
2025/09/16 22:24:28 : Epoch: 011, Train_Loss: 0.00783357
2025/09/16 22:24:28 : Epoch: 012, Train_Loss: 0.01515867
2025/09/16 22:24:29 : Epoch: 013, Train_Loss: 0.00765997
2025/09/16 22:24:29 : Epoch: 014, Train_Loss: 0.00985412
2025/09/16 22:24:29 : Epoch: 014, Eval_Loss: 0.00515624
2025/09/16 22:24:29 : Epoch: 015, Train_Loss: 0.00744774
2025/09/16 22:24:29 : Epoch: 016, Train_Loss: 0.01532569
2025/09/16 22:24:30 : Epoch: 017, Train_Loss: 0.00834238
2025/09/16 22:24:30 : Epoch: 018, Train_Loss: 0.00938145
2025/09/16 22:24:30 : Epoch: 019, Train_Loss: 0.00856413
2025/09/16 22:24:30 : Epoch: 019, Eval_Loss: 0.00497391
2025/09/16 22:24:30 : Epoch: 019, Save the best checkpoint
2025/09/16 22:24:30 : Epoch: 020, Train_Loss: 0.01218530
2025/09/16 22:24:31 : Epoch: 021, Train_Loss: 0.01165837
2025/09/16 22:24:31 : Epoch: 022, Train_Loss: 0.00961616
2025/09/16 22:24:31 : Epoch: 023, Train_Loss: 0.00838158
2025/09/16 22:24:31 : Epoch: 024, Train_Loss: 0.00938956
2025/09/16 22:24:32 : Epoch: 024, Eval_Loss: 0.00499193
2025/09/16 22:24:32 : Epoch: 025, Train_Loss: 0.00927260
2025/09/16 22:24:32 : Epoch: 026, Train_Loss: 0.00785058
2025/09/16 22:24:32 : Epoch: 027, Train_Loss: 0.00917642
2025/09/16 22:24:33 : Epoch: 028, Train_Loss: 0.00870221
2025/09/16 22:24:33 : Epoch: 029, Train_Loss: 0.00732021
2025/09/16 22:24:33 : Epoch: 029, Eval_Loss: 0.00479758
2025/09/16 22:24:33 : Epoch: 029, Save the best checkpoint
2025/09/16 22:24:33 : Epoch: 030, Train_Loss: 0.00795781
2025/09/16 22:24:33 : Epoch: 031, Train_Loss: 0.00849201
2025/09/16 22:24:34 : Epoch: 032, Train_Loss: 0.00878207
2025/09/16 22:24:34 : Epoch: 033, Train_Loss: 0.00784551
2025/09/16 22:24:34 : Epoch: 034, Train_Loss: 0.00787747
2025/09/16 22:24:34 : Epoch: 034, Eval_Loss: 0.00477730
2025/09/16 22:24:34 : Epoch: 034, Save the best checkpoint
2025/09/16 22:24:34 : Epoch: 035, Train_Loss: 0.00719296
2025/09/16 22:24:35 : Epoch: 036, Train_Loss: 0.00812719
2025/09/16 22:24:35 : Epoch: 037, Train_Loss: 0.01215618
2025/09/16 22:24:35 : Epoch: 038, Train_Loss: 0.00985249
2025/09/16 22:24:35 : Epoch: 039, Train_Loss: 0.00767435
2025/09/16 22:24:35 : Epoch: 039, Eval_Loss: 0.00491941
2025/09/16 22:24:36 : Epoch: 040, Train_Loss: 0.01235854
2025/09/16 22:24:36 : Epoch: 041, Train_Loss: 0.01236700
2025/09/16 22:24:36 : Epoch: 042, Train_Loss: 0.00745055
2025/09/16 22:24:36 : Epoch: 043, Train_Loss: 0.00967004
2025/09/16 22:24:37 : Epoch: 044, Train_Loss: 0.00851129
2025/09/16 22:24:37 : Epoch: 044, Eval_Loss: 0.00499319
2025/09/16 22:24:37 : Epoch: 045, Train_Loss: 0.00897310
2025/09/16 22:24:37 : Epoch: 046, Train_Loss: 0.00761724
2025/09/16 22:24:38 : Epoch: 047, Train_Loss: 0.00806173
2025/09/16 22:24:38 : Epoch: 048, Train_Loss: 0.00976933
2025/09/16 22:24:38 : Epoch: 049, Train_Loss: 0.01328070
2025/09/16 22:24:38 : Epoch: 049, Eval_Loss: 0.00503333
2025/09/16 22:24:38 : Epoch: 050, Train_Loss: 0.00925508
2025/09/16 22:24:39 : Epoch: 051, Train_Loss: 0.00810635
2025/09/16 22:24:39 : Epoch: 052, Train_Loss: 0.01036921
2025/09/16 22:24:39 : Epoch: 053, Train_Loss: 0.00965186
2025/09/16 22:24:39 : Epoch: 054, Train_Loss: 0.00993239
2025/09/16 22:24:39 : Epoch: 054, Eval_Loss: 0.00530664
2025/09/16 22:24:40 : Epoch: 055, Train_Loss: 0.01018743
2025/09/16 22:24:40 : Epoch: 056, Train_Loss: 0.01298128
2025/09/16 22:24:40 : Epoch: 057, Train_Loss: 0.01029815
2025/09/16 22:24:40 : Epoch: 058, Train_Loss: 0.01185622
2025/09/16 22:24:41 : Epoch: 059, Train_Loss: 0.01020719
2025/09/16 22:24:41 : Epoch: 059, Eval_Loss: 0.00518307
2025/09/16 22:24:41 : Epoch: 060, Train_Loss: 0.00849219
2025/09/16 22:24:41 : Epoch: 061, Train_Loss: 0.00794402
2025/09/16 22:24:41 : Epoch: 062, Train_Loss: 0.00964163
2025/09/16 22:24:42 : Epoch: 063, Train_Loss: 0.00805814
2025/09/16 22:24:42 : Epoch: 064, Train_Loss: 0.00861291
2025/09/16 22:24:42 : Epoch: 064, Eval_Loss: 0.00503118
2025/09/16 22:24:42 : Epoch: 065, Train_Loss: 0.01346060
2025/09/16 22:24:42 : Epoch: 066, Train_Loss: 0.00849026
2025/09/16 22:24:43 : Epoch: 067, Train_Loss: 0.01005482
2025/09/16 22:24:43 : Epoch: 068, Train_Loss: 0.01062610
2025/09/16 22:24:43 : Epoch: 069, Train_Loss: 0.00776684
2025/09/16 22:24:43 : Epoch: 069, Eval_Loss: 0.00520199
2025/09/16 22:24:44 : Epoch: 070, Train_Loss: 0.01381997
2025/09/16 22:24:44 : Epoch: 071, Train_Loss: 0.00727096
2025/09/16 22:24:44 : Epoch: 072, Train_Loss: 0.00828460
2025/09/16 22:24:44 : Epoch: 073, Train_Loss: 0.00843213
2025/09/16 22:24:45 : Epoch: 074, Train_Loss: 0.00780781
2025/09/16 22:24:45 : Epoch: 074, Eval_Loss: 0.00506399
2025/09/16 22:24:45 : Epoch: 075, Train_Loss: 0.00743035
2025/09/16 22:24:45 : Epoch: 076, Train_Loss: 0.00875833
2025/09/16 22:24:45 : Epoch: 077, Train_Loss: 0.01208174
2025/09/16 22:24:46 : Epoch: 078, Train_Loss: 0.01081896
2025/09/16 22:24:46 : Epoch: 079, Train_Loss: 0.01064526
2025/09/16 22:24:46 : Epoch: 079, Eval_Loss: 0.00536885
2025/09/16 22:24:46 : Epoch: 080, Train_Loss: 0.01056035
2025/09/16 22:24:46 : Epoch: 081, Train_Loss: 0.00947678
2025/09/16 22:24:47 : Epoch: 082, Train_Loss: 0.01188021
2025/09/16 22:24:47 : Epoch: 083, Train_Loss: 0.00926147
2025/09/16 22:24:47 : Epoch: 084, Train_Loss: 0.01076178
2025/09/16 22:24:47 : Epoch: 084, Eval_Loss: 0.00505168
2025/09/16 22:24:48 : Epoch: 085, Train_Loss: 0.00965971
2025/09/16 22:24:48 : Epoch: 086, Train_Loss: 0.00748962
2025/09/16 22:24:48 : Epoch: 087, Train_Loss: 0.01066211
2025/09/16 22:24:48 : Epoch: 088, Train_Loss: 0.00835336
2025/09/16 22:24:48 : Epoch: 089, Train_Loss: 0.00686670
2025/09/16 22:24:49 : Epoch: 089, Eval_Loss: 0.00496266
2025/09/16 22:24:49 : Epoch: 090, Train_Loss: 0.01150271
2025/09/16 22:24:49 : Epoch: 091, Train_Loss: 0.00633245
2025/09/16 22:24:49 : Epoch: 092, Train_Loss: 0.01069098
2025/09/16 22:24:50 : Epoch: 093, Train_Loss: 0.00804747
2025/09/16 22:24:50 : Epoch: 094, Train_Loss: 0.00825904
2025/09/16 22:24:50 : Epoch: 094, Eval_Loss: 0.00481835
2025/09/16 22:24:50 : Epoch: 095, Train_Loss: 0.00769998
2025/09/16 22:24:50 : Epoch: 096, Train_Loss: 0.00768480
2025/09/16 22:24:51 : Epoch: 097, Train_Loss: 0.00889358
2025/09/16 22:24:51 : Epoch: 098, Train_Loss: 0.00935372
2025/09/16 22:24:51 : Epoch: 099, Train_Loss: 0.01127462
2025/09/16 22:24:51 : Epoch: 099, Eval_Loss: 0.00481019
2025/09/16 22:24:51 : Epoch: 100, Train_Loss: 0.00896861
2025/09/16 22:24:52 : Epoch: 101, Train_Loss: 0.01012050
2025/09/16 22:24:52 : Epoch: 102, Train_Loss: 0.01263886
2025/09/16 22:24:52 : Epoch: 103, Train_Loss: 0.00991142
2025/09/16 22:24:52 : Epoch: 104, Train_Loss: 0.00958256
2025/09/16 22:24:52 : Epoch: 104, Eval_Loss: 0.00480808
2025/09/16 22:24:53 : Epoch: 105, Train_Loss: 0.00827428
2025/09/16 22:24:53 : Epoch: 106, Train_Loss: 0.00960031
2025/09/16 22:24:53 : Epoch: 107, Train_Loss: 0.00948417
2025/09/16 22:24:53 : Epoch: 108, Train_Loss: 0.01198625
2025/09/16 22:24:54 : Epoch: 109, Train_Loss: 0.00858297
2025/09/16 22:24:54 : Epoch: 109, Eval_Loss: 0.00507313
2025/09/16 22:24:54 : Epoch: 110, Train_Loss: 0.01040340
2025/09/16 22:24:54 : Epoch: 111, Train_Loss: 0.00965783
2025/09/16 22:24:55 : Epoch: 112, Train_Loss: 0.01446558
2025/09/16 22:24:55 : Epoch: 113, Train_Loss: 0.00742776
2025/09/16 22:24:55 : Epoch: 114, Train_Loss: 0.00891217
2025/09/16 22:24:55 : Epoch: 114, Eval_Loss: 0.00525645
2025/09/16 22:24:55 : Epoch: 115, Train_Loss: 0.00649913
2025/09/16 22:24:56 : Epoch: 116, Train_Loss: 0.00763634
2025/09/16 22:24:56 : Epoch: 117, Train_Loss: 0.00707418
2025/09/16 22:24:56 : Epoch: 118, Train_Loss: 0.01023073
2025/09/16 22:24:56 : Epoch: 119, Train_Loss: 0.00767784
2025/09/16 22:24:56 : Epoch: 119, Eval_Loss: 0.00502249
2025/09/16 22:24:57 : Epoch: 120, Train_Loss: 0.00985171
2025/09/16 22:24:57 : Epoch: 121, Train_Loss: 0.00960949
2025/09/16 22:24:57 : Epoch: 122, Train_Loss: 0.00853478
2025/09/16 22:24:57 : Epoch: 123, Train_Loss: 0.00961191
2025/09/16 22:24:58 : Epoch: 124, Train_Loss: 0.01163314
2025/09/16 22:24:58 : Epoch: 124, Eval_Loss: 0.00518459
2025/09/16 22:24:58 : Epoch: 125, Train_Loss: 0.01176785
2025/09/16 22:24:58 : Epoch: 126, Train_Loss: 0.01070065
2025/09/16 22:24:58 : Epoch: 127, Train_Loss: 0.01128634
2025/09/16 22:24:59 : Epoch: 128, Train_Loss: 0.00881966
2025/09/16 22:24:59 : Epoch: 129, Train_Loss: 0.01269926
2025/09/16 22:24:59 : Epoch: 129, Eval_Loss: 0.00513452
2025/09/16 22:24:59 : Epoch: 130, Train_Loss: 0.01147938
2025/09/16 22:25:00 : Epoch: 131, Train_Loss: 0.00756732
2025/09/16 22:25:00 : Epoch: 132, Train_Loss: 0.00923755
2025/09/16 22:25:00 : Epoch: 133, Train_Loss: 0.01412474
2025/09/16 22:25:00 : Epoch: 134, Train_Loss: 0.00692420
2025/09/16 22:25:00 : Epoch: 134, Eval_Loss: 0.00521637
2025/09/16 22:25:01 : Epoch: 135, Train_Loss: 0.00851862
2025/09/16 22:25:01 : Epoch: 136, Train_Loss: 0.00997889
2025/09/16 22:25:01 : Epoch: 137, Train_Loss: 0.01387481
2025/09/16 22:25:01 : Epoch: 138, Train_Loss: 0.00899234
2025/09/16 22:25:02 : Epoch: 139, Train_Loss: 0.00898241
2025/09/16 22:25:02 : Epoch: 139, Eval_Loss: 0.00538848
2025/09/16 22:25:02 : Epoch: 140, Train_Loss: 0.00994560
2025/09/16 22:25:02 : Epoch: 141, Train_Loss: 0.01099633
2025/09/16 22:25:02 : Epoch: 142, Train_Loss: 0.01293715
2025/09/16 22:25:03 : Epoch: 143, Train_Loss: 0.01115275
2025/09/16 22:25:03 : Epoch: 144, Train_Loss: 0.01017782
2025/09/16 22:25:03 : Epoch: 144, Eval_Loss: 0.00531384
2025/09/16 22:25:03 : Epoch: 145, Train_Loss: 0.01478190
2025/09/16 22:25:03 : Epoch: 146, Train_Loss: 0.01241958
2025/09/16 22:25:04 : Epoch: 147, Train_Loss: 0.00733909
2025/09/16 22:25:04 : Epoch: 148, Train_Loss: 0.00988014
2025/09/16 22:25:04 : Epoch: 149, Train_Loss: 0.00722296
2025/09/16 22:25:04 : Epoch: 149, Eval_Loss: 0.00526767
2025/09/16 22:25:04 : Epoch: 150, Train_Loss: 0.00835143
2025/09/16 22:25:05 : Epoch: 151, Train_Loss: 0.00737681
2025/09/16 22:25:05 : Epoch: 152, Train_Loss: 0.00839113
2025/09/16 22:25:05 : Epoch: 153, Train_Loss: 0.01015523
2025/09/16 22:25:05 : Epoch: 154, Train_Loss: 0.01215081
2025/09/16 22:25:06 : Epoch: 154, Eval_Loss: 0.00523989
2025/09/16 22:25:06 : Epoch: 155, Train_Loss: 0.00866112
2025/09/16 22:25:06 : Epoch: 156, Train_Loss: 0.01099232
2025/09/16 22:25:06 : Epoch: 157, Train_Loss: 0.00907475
2025/09/16 22:25:07 : Epoch: 158, Train_Loss: 0.00864062
2025/09/16 22:25:07 : Epoch: 159, Train_Loss: 0.01434609
2025/09/16 22:25:07 : Epoch: 159, Eval_Loss: 0.00524008
2025/09/16 22:25:07 : Epoch: 160, Train_Loss: 0.01028135
2025/09/16 22:25:07 : Epoch: 161, Train_Loss: 0.01072977
2025/09/16 22:25:08 : Epoch: 162, Train_Loss: 0.00895628
2025/09/16 22:25:08 : Epoch: 163, Train_Loss: 0.01096351
2025/09/16 22:25:08 : Epoch: 164, Train_Loss: 0.00795375
2025/09/16 22:25:08 : Epoch: 164, Eval_Loss: 0.00524144
2025/09/16 22:25:08 : Epoch: 165, Train_Loss: 0.01209719
2025/09/16 22:25:09 : Epoch: 166, Train_Loss: 0.00924083
2025/09/16 22:25:09 : Epoch: 167, Train_Loss: 0.01126647
2025/09/16 22:25:09 : Epoch: 168, Train_Loss: 0.00794365
2025/09/16 22:25:09 : Epoch: 169, Train_Loss: 0.00831041
2025/09/16 22:25:09 : Epoch: 169, Eval_Loss: 0.00523817
2025/09/16 22:25:10 : Epoch: 170, Train_Loss: 0.00839685
2025/09/16 22:25:10 : Epoch: 171, Train_Loss: 0.01191942
2025/09/16 22:25:10 : Epoch: 172, Train_Loss: 0.00912152
2025/09/16 22:25:10 : Epoch: 173, Train_Loss: 0.00869607
2025/09/16 22:25:11 : Epoch: 174, Train_Loss: 0.01251054
2025/09/16 22:25:11 : Epoch: 174, Eval_Loss: 0.00525060
2025/09/16 22:25:11 : Epoch: 175, Train_Loss: 0.00897584
2025/09/16 22:25:11 : Epoch: 176, Train_Loss: 0.01106770
2025/09/16 22:25:12 : Epoch: 177, Train_Loss: 0.00666443
2025/09/16 22:25:12 : Epoch: 178, Train_Loss: 0.00902303
2025/09/16 22:25:12 : Epoch: 179, Train_Loss: 0.00916113
2025/09/16 22:25:12 : Epoch: 179, Eval_Loss: 0.00525575
2025/09/16 22:25:12 : Epoch: 180, Train_Loss: 0.01058269
2025/09/16 22:25:13 : Epoch: 181, Train_Loss: 0.00831949
2025/09/16 22:25:13 : Epoch: 182, Train_Loss: 0.00792140
2025/09/16 22:25:13 : Epoch: 183, Train_Loss: 0.01223279
2025/09/16 22:25:13 : Epoch: 184, Train_Loss: 0.00935417
2025/09/16 22:25:13 : Epoch: 184, Eval_Loss: 0.00523718
2025/09/16 22:25:14 : Epoch: 185, Train_Loss: 0.00773607
2025/09/16 22:25:14 : Epoch: 186, Train_Loss: 0.00809280
2025/09/16 22:25:14 : Epoch: 187, Train_Loss: 0.01279475
2025/09/16 22:25:14 : Epoch: 188, Train_Loss: 0.00839190
2025/09/16 22:25:15 : Epoch: 189, Train_Loss: 0.00763519
2025/09/16 22:25:15 : Epoch: 189, Eval_Loss: 0.00523645
2025/09/16 22:25:15 : Epoch: 190, Train_Loss: 0.00713422
2025/09/16 22:25:15 : Epoch: 191, Train_Loss: 0.00758960
2025/09/16 22:25:15 : Epoch: 192, Train_Loss: 0.00781141
2025/09/16 22:25:16 : Epoch: 193, Train_Loss: 0.00856163
2025/09/16 22:25:16 : Epoch: 194, Train_Loss: 0.01102863
2025/09/16 22:25:16 : Epoch: 194, Eval_Loss: 0.00523510
2025/09/16 22:25:16 : Epoch: 195, Train_Loss: 0.01000417
2025/09/16 22:25:16 : Epoch: 196, Train_Loss: 0.00977013
2025/09/16 22:25:17 : Epoch: 197, Train_Loss: 0.01507575
2025/09/16 22:25:17 : Epoch: 198, Train_Loss: 0.01347380
2025/09/16 22:25:17 : Epoch: 199, Train_Loss: 0.00797571
2025/09/16 22:25:17 : Epoch: 199, Eval_Loss: 0.00524280
2025/09/16 22:25:18 : Epoch: 200, Train_Loss: 0.00942241
2025/09/16 22:25:18 : Epoch: 201, Train_Loss: 0.00888772
2025/09/16 22:25:18 : Epoch: 202, Train_Loss: 0.01175267
2025/09/16 22:25:18 : Epoch: 203, Train_Loss: 0.00931430
2025/09/16 22:25:19 : Epoch: 204, Train_Loss: 0.00811102
2025/09/16 22:25:19 : Epoch: 204, Eval_Loss: 0.00524724
2025/09/16 22:25:19 : Epoch: 205, Train_Loss: 0.00890967
2025/09/16 22:25:19 : Epoch: 206, Train_Loss: 0.00929396
2025/09/16 22:25:19 : Epoch: 207, Train_Loss: 0.01026067
2025/09/16 22:25:20 : Epoch: 208, Train_Loss: 0.00798761
2025/09/16 22:25:20 : Epoch: 209, Train_Loss: 0.00951580
2025/09/16 22:25:20 : Epoch: 209, Eval_Loss: 0.00523747
2025/09/16 22:25:20 : Epoch: 210, Train_Loss: 0.01020819
2025/09/16 22:25:20 : Epoch: 211, Train_Loss: 0.01293769
2025/09/16 22:25:21 : Epoch: 212, Train_Loss: 0.00701284
2025/09/16 22:25:21 : Epoch: 213, Train_Loss: 0.00977898
2025/09/16 22:25:21 : Epoch: 214, Train_Loss: 0.00928893
2025/09/16 22:25:21 : Epoch: 214, Eval_Loss: 0.00524627
2025/09/16 22:25:21 : Epoch: 215, Train_Loss: 0.00907798
2025/09/16 22:25:22 : Epoch: 216, Train_Loss: 0.00785056
2025/09/16 22:25:22 : Epoch: 217, Train_Loss: 0.00884869
2025/09/16 22:25:22 : Epoch: 218, Train_Loss: 0.01021062
2025/09/16 22:25:22 : Epoch: 219, Train_Loss: 0.00875845
2025/09/16 22:25:22 : Epoch: 219, Eval_Loss: 0.00523648
2025/09/16 22:25:23 : Epoch: 220, Train_Loss: 0.00912877
2025/09/16 22:25:23 : Epoch: 221, Train_Loss: 0.01128279
2025/09/16 22:25:23 : Epoch: 222, Train_Loss: 0.00902853
2025/09/16 22:25:23 : Epoch: 223, Train_Loss: 0.00805381
2025/09/16 22:25:24 : Epoch: 224, Train_Loss: 0.01179389
2025/09/16 22:25:24 : Epoch: 224, Eval_Loss: 0.00523199
2025/09/16 22:25:24 : Epoch: 225, Train_Loss: 0.00712050
2025/09/16 22:25:24 : Epoch: 226, Train_Loss: 0.00810128
2025/09/16 22:25:24 : Epoch: 227, Train_Loss: 0.00671018
2025/09/16 22:25:25 : Epoch: 228, Train_Loss: 0.00923692
2025/09/16 22:25:25 : Epoch: 229, Train_Loss: 0.01011708
2025/09/16 22:25:25 : Epoch: 229, Eval_Loss: 0.00523530
2025/09/16 22:25:25 : Epoch: 230, Train_Loss: 0.00888843
2025/09/16 22:25:26 : Epoch: 231, Train_Loss: 0.01382574
2025/09/16 22:25:26 : Epoch: 232, Train_Loss: 0.00738712
2025/09/16 22:25:26 : Epoch: 233, Train_Loss: 0.00871122
2025/09/16 22:25:26 : Epoch: 234, Train_Loss: 0.00828404
2025/09/16 22:25:26 : Epoch: 234, Eval_Loss: 0.00523627
2025/09/16 22:25:27 : Epoch: 235, Train_Loss: 0.00971894
2025/09/16 22:25:27 : Epoch: 236, Train_Loss: 0.00958175
2025/09/16 22:25:27 : Epoch: 237, Train_Loss: 0.00850995
2025/09/16 22:25:27 : Epoch: 238, Train_Loss: 0.00980645
2025/09/16 22:25:28 : Epoch: 239, Train_Loss: 0.01012217
2025/09/16 22:25:28 : Epoch: 239, Eval_Loss: 0.00523459
2025/09/16 22:25:28 : Epoch: 240, Train_Loss: 0.01016358
2025/09/16 22:25:28 : Epoch: 241, Train_Loss: 0.01074607
2025/09/16 22:25:28 : Epoch: 242, Train_Loss: 0.01010796
2025/09/16 22:25:29 : Epoch: 243, Train_Loss: 0.00889788
2025/09/16 22:25:29 : Epoch: 244, Train_Loss: 0.01229596
2025/09/16 22:25:29 : Epoch: 244, Eval_Loss: 0.00523444
2025/09/16 22:25:29 : Epoch: 245, Train_Loss: 0.01336429
2025/09/16 22:25:29 : Epoch: 246, Train_Loss: 0.00843382
2025/09/16 22:25:30 : Epoch: 247, Train_Loss: 0.00836463
2025/09/16 22:25:30 : Epoch: 248, Train_Loss: 0.00833757
2025/09/16 22:25:30 : Epoch: 249, Train_Loss: 0.01171702
2025/09/16 22:25:30 : Epoch: 249, Eval_Loss: 0.00523518
2025/09/16 22:25:31 : Epoch: 250, Train_Loss: 0.00748168
2025/09/16 22:25:31 : Epoch: 251, Train_Loss: 0.01028878
2025/09/16 22:25:31 : Epoch: 252, Train_Loss: 0.01012805
2025/09/16 22:25:31 : Epoch: 253, Train_Loss: 0.00795684
2025/09/16 22:25:32 : Epoch: 254, Train_Loss: 0.00876138
2025/09/16 22:25:32 : Epoch: 254, Eval_Loss: 0.00523422
2025/09/16 22:25:32 : Epoch: 255, Train_Loss: 0.00943654
2025/09/16 22:25:32 : Epoch: 256, Train_Loss: 0.01108608
2025/09/16 22:25:32 : Epoch: 257, Train_Loss: 0.00995868
2025/09/16 22:25:33 : Epoch: 258, Train_Loss: 0.00884907
2025/09/16 22:25:33 : Epoch: 259, Train_Loss: 0.01103992
2025/09/16 22:25:33 : Epoch: 259, Eval_Loss: 0.00523551
2025/09/16 22:25:33 : Epoch: 260, Train_Loss: 0.01171275
2025/09/16 22:25:33 : Epoch: 261, Train_Loss: 0.00812513
2025/09/16 22:25:34 : Epoch: 262, Train_Loss: 0.01122119
2025/09/16 22:25:34 : Epoch: 263, Train_Loss: 0.01083669
2025/09/16 22:25:34 : Epoch: 264, Train_Loss: 0.00766866
2025/09/16 22:25:34 : Epoch: 264, Eval_Loss: 0.00523679
2025/09/16 22:25:34 : Epoch: 265, Train_Loss: 0.00808631
2025/09/16 22:25:35 : Epoch: 266, Train_Loss: 0.00657489
2025/09/16 22:25:35 : Epoch: 267, Train_Loss: 0.00791130
2025/09/16 22:25:35 : Epoch: 268, Train_Loss: 0.01455757
2025/09/16 22:25:35 : Epoch: 269, Train_Loss: 0.01218805
2025/09/16 22:25:35 : Epoch: 269, Eval_Loss: 0.00525930
2025/09/16 22:25:36 : Epoch: 270, Train_Loss: 0.00967159
2025/09/16 22:25:36 : Epoch: 271, Train_Loss: 0.01035785
2025/09/16 22:25:36 : Epoch: 272, Train_Loss: 0.00725432
2025/09/16 22:25:36 : Epoch: 273, Train_Loss: 0.01064458
2025/09/16 22:25:37 : Epoch: 274, Train_Loss: 0.00727343
2025/09/16 22:25:37 : Epoch: 274, Eval_Loss: 0.00528949
2025/09/16 22:25:37 : Epoch: 275, Train_Loss: 0.00888244
2025/09/16 22:25:37 : Epoch: 276, Train_Loss: 0.00823418
2025/09/16 22:25:37 : Epoch: 277, Train_Loss: 0.01338292
2025/09/16 22:25:38 : Epoch: 278, Train_Loss: 0.00866162
2025/09/16 22:25:38 : Epoch: 279, Train_Loss: 0.01366430
2025/09/16 22:25:38 : Epoch: 279, Eval_Loss: 0.00527741
2025/09/16 22:25:38 : Epoch: 280, Train_Loss: 0.00991587
2025/09/16 22:25:38 : Epoch: 281, Train_Loss: 0.00823031
2025/09/16 22:25:39 : Epoch: 282, Train_Loss: 0.00967930
2025/09/16 22:25:39 : Epoch: 283, Train_Loss: 0.01069634
2025/09/16 22:25:39 : Epoch: 284, Train_Loss: 0.00890859
2025/09/16 22:25:39 : Epoch: 284, Eval_Loss: 0.00530062
2025/09/16 22:25:40 : Epoch: 285, Train_Loss: 0.00771367
2025/09/16 22:25:40 : Epoch: 286, Train_Loss: 0.00710078
2025/09/16 22:25:40 : Epoch: 287, Train_Loss: 0.00770965
2025/09/16 22:25:40 : Epoch: 288, Train_Loss: 0.00947086
2025/09/16 22:25:40 : Epoch: 289, Train_Loss: 0.00974948
2025/09/16 22:25:41 : Epoch: 289, Eval_Loss: 0.00524556
2025/09/16 22:25:41 : Epoch: 290, Train_Loss: 0.00785624
2025/09/16 22:25:41 : Epoch: 291, Train_Loss: 0.00815489
2025/09/16 22:25:41 : Epoch: 292, Train_Loss: 0.00679518
2025/09/16 22:25:41 : Epoch: 293, Train_Loss: 0.00692654
2025/09/16 22:25:42 : Epoch: 294, Train_Loss: 0.00888579
2025/09/16 22:25:42 : Epoch: 294, Eval_Loss: 0.00523830
2025/09/16 22:25:42 : Epoch: 295, Train_Loss: 0.01324705
2025/09/16 22:25:42 : Epoch: 296, Train_Loss: 0.00870455
2025/09/16 22:25:43 : Epoch: 297, Train_Loss: 0.01028673
2025/09/16 22:25:43 : Epoch: 298, Train_Loss: 0.01285676
2025/09/16 22:25:43 : Epoch: 299, Train_Loss: 0.00821793
2025/09/16 22:25:43 : Epoch: 299, Eval_Loss: 0.00528407
2025/09/16 22:25:43 : Epoch: 300, Train_Loss: 0.00823311
2025/09/16 22:25:44 : Epoch: 301, Train_Loss: 0.01229928
2025/09/16 22:25:44 : Epoch: 302, Train_Loss: 0.01308671
2025/09/16 22:25:44 : Epoch: 303, Train_Loss: 0.00919365
2025/09/16 22:25:44 : Epoch: 304, Train_Loss: 0.00801499
2025/09/16 22:25:44 : Epoch: 304, Eval_Loss: 0.00526989
2025/09/16 22:25:45 : Epoch: 305, Train_Loss: 0.00963564
2025/09/16 22:25:45 : Epoch: 306, Train_Loss: 0.00730092
2025/09/16 22:25:45 : Epoch: 307, Train_Loss: 0.00812654
2025/09/16 22:25:45 : Epoch: 308, Train_Loss: 0.00719373
2025/09/16 22:25:46 : Epoch: 309, Train_Loss: 0.01105159
2025/09/16 22:25:46 : Epoch: 309, Eval_Loss: 0.00524824
2025/09/16 22:25:46 : Epoch: 310, Train_Loss: 0.01335462
2025/09/16 22:25:46 : Epoch: 311, Train_Loss: 0.01120903
2025/09/16 22:25:46 : Epoch: 312, Train_Loss: 0.00878881
2025/09/16 22:25:47 : Epoch: 313, Train_Loss: 0.01080729
2025/09/16 22:25:47 : Epoch: 314, Train_Loss: 0.00809543
2025/09/16 22:25:47 : Epoch: 314, Eval_Loss: 0.00524872
2025/09/16 22:25:47 : Epoch: 315, Train_Loss: 0.01106227
2025/09/16 22:25:48 : Epoch: 316, Train_Loss: 0.00761222
2025/09/16 22:25:48 : Epoch: 317, Train_Loss: 0.01033289
2025/09/16 22:25:48 : Epoch: 318, Train_Loss: 0.00835434
2025/09/16 22:25:48 : Epoch: 319, Train_Loss: 0.00925297
2025/09/16 22:25:48 : Epoch: 319, Eval_Loss: 0.00524285
2025/09/16 22:25:49 : Epoch: 320, Train_Loss: 0.01369041
2025/09/16 22:25:49 : Epoch: 321, Train_Loss: 0.00966020
2025/09/16 22:25:49 : Epoch: 322, Train_Loss: 0.00869331
2025/09/16 22:25:49 : Epoch: 323, Train_Loss: 0.00773127
2025/09/16 22:25:50 : Epoch: 324, Train_Loss: 0.00758772
2025/09/16 22:25:50 : Epoch: 324, Eval_Loss: 0.00524105
2025/09/16 22:25:50 : Epoch: 325, Train_Loss: 0.00983101
2025/09/16 22:25:50 : Epoch: 326, Train_Loss: 0.00932529
2025/09/16 22:25:50 : Epoch: 327, Train_Loss: 0.01452548
2025/09/16 22:25:51 : Epoch: 328, Train_Loss: 0.00889451
2025/09/16 22:25:51 : Epoch: 329, Train_Loss: 0.01154344
2025/09/16 22:25:51 : Epoch: 329, Eval_Loss: 0.00523987
2025/09/16 22:25:51 : Epoch: 330, Train_Loss: 0.00768142
2025/09/16 22:25:51 : Epoch: 331, Train_Loss: 0.00671565
2025/09/16 22:25:52 : Epoch: 332, Train_Loss: 0.01047749
2025/09/16 22:25:52 : Epoch: 333, Train_Loss: 0.01052010
2025/09/16 22:25:52 : Epoch: 334, Train_Loss: 0.01356450
2025/09/16 22:25:52 : Epoch: 334, Eval_Loss: 0.00523962
2025/09/16 22:25:52 : Epoch: 335, Train_Loss: 0.01041058
2025/09/16 22:25:53 : Epoch: 336, Train_Loss: 0.00906875
2025/09/16 22:25:53 : Epoch: 337, Train_Loss: 0.00886357
2025/09/16 22:25:53 : Epoch: 338, Train_Loss: 0.01080425
2025/09/16 22:25:53 : Epoch: 339, Train_Loss: 0.01162361
2025/09/16 22:25:54 : Epoch: 339, Eval_Loss: 0.00524414
2025/09/16 22:25:54 : Epoch: 340, Train_Loss: 0.00871233
2025/09/16 22:25:54 : Epoch: 341, Train_Loss: 0.00804711
2025/09/16 22:25:54 : Epoch: 342, Train_Loss: 0.00841649
2025/09/16 22:25:55 : Epoch: 343, Train_Loss: 0.01027216
2025/09/16 22:25:55 : Epoch: 344, Train_Loss: 0.01407037
2025/09/16 22:25:55 : Epoch: 344, Eval_Loss: 0.00525865
2025/09/16 22:25:55 : Epoch: 345, Train_Loss: 0.00855424
2025/09/16 22:25:55 : Epoch: 346, Train_Loss: 0.00937405
2025/09/16 22:25:56 : Epoch: 347, Train_Loss: 0.00875336
2025/09/16 22:25:56 : Epoch: 348, Train_Loss: 0.01016334
2025/09/16 22:25:56 : Epoch: 349, Train_Loss: 0.00868993
2025/09/16 22:25:56 : Epoch: 349, Eval_Loss: 0.00525422
2025/09/16 22:25:56 : Epoch: 350, Train_Loss: 0.01450782
2025/09/16 22:25:57 : Epoch: 351, Train_Loss: 0.01447484
2025/09/16 22:25:57 : Epoch: 352, Train_Loss: 0.01143259
2025/09/16 22:25:57 : Epoch: 353, Train_Loss: 0.01058561
2025/09/16 22:25:57 : Epoch: 354, Train_Loss: 0.01137736
2025/09/16 22:25:57 : Epoch: 354, Eval_Loss: 0.00529166
2025/09/16 22:25:58 : Epoch: 355, Train_Loss: 0.00893395
2025/09/16 22:25:58 : Epoch: 356, Train_Loss: 0.01137167
2025/09/16 22:25:58 : Epoch: 357, Train_Loss: 0.00952284
2025/09/16 22:25:58 : Epoch: 358, Train_Loss: 0.00897811
2025/09/16 22:25:59 : Epoch: 359, Train_Loss: 0.01122045
2025/09/16 22:25:59 : Epoch: 359, Eval_Loss: 0.00524250
2025/09/16 22:25:59 : Epoch: 360, Train_Loss: 0.01367923
2025/09/16 22:25:59 : Epoch: 361, Train_Loss: 0.00881502
2025/09/16 22:26:00 : Epoch: 362, Train_Loss: 0.00800660
2025/09/16 22:26:00 : Epoch: 363, Train_Loss: 0.00766836
2025/09/16 22:26:00 : Epoch: 364, Train_Loss: 0.00840754
2025/09/16 22:26:00 : Epoch: 364, Eval_Loss: 0.00524280
2025/09/16 22:26:00 : Epoch: 365, Train_Loss: 0.01099235
2025/09/16 22:26:01 : Epoch: 366, Train_Loss: 0.00833076
2025/09/16 22:26:01 : Epoch: 367, Train_Loss: 0.01137698
2025/09/16 22:26:01 : Epoch: 368, Train_Loss: 0.00863235
2025/09/16 22:26:01 : Epoch: 369, Train_Loss: 0.01122930
2025/09/16 22:26:01 : Epoch: 369, Eval_Loss: 0.00523584
2025/09/16 22:26:02 : Epoch: 370, Train_Loss: 0.00931291
2025/09/16 22:26:02 : Epoch: 371, Train_Loss: 0.00759595
2025/09/16 22:26:02 : Epoch: 372, Train_Loss: 0.01126875
2025/09/16 22:26:02 : Epoch: 373, Train_Loss: 0.00946687
2025/09/16 22:26:03 : Epoch: 374, Train_Loss: 0.00674984
2025/09/16 22:26:03 : Epoch: 374, Eval_Loss: 0.00523849
2025/09/16 22:26:03 : Epoch: 375, Train_Loss: 0.00999848
2025/09/16 22:26:03 : Epoch: 376, Train_Loss: 0.01175449
2025/09/16 22:26:03 : Epoch: 377, Train_Loss: 0.00935583
2025/09/16 22:26:04 : Epoch: 378, Train_Loss: 0.00949224
2025/09/16 22:26:04 : Epoch: 379, Train_Loss: 0.00964707
2025/09/16 22:26:04 : Epoch: 379, Eval_Loss: 0.00523687
2025/09/16 22:26:04 : Epoch: 380, Train_Loss: 0.01163029
2025/09/16 22:26:04 : Epoch: 381, Train_Loss: 0.01007931
2025/09/16 22:26:05 : Epoch: 382, Train_Loss: 0.00802280
2025/09/16 22:26:05 : Epoch: 383, Train_Loss: 0.01035066
2025/09/16 22:26:05 : Epoch: 384, Train_Loss: 0.01391101
2025/09/16 22:26:05 : Epoch: 384, Eval_Loss: 0.00525280
2025/09/16 22:26:06 : Epoch: 385, Train_Loss: 0.01022452
2025/09/16 22:26:06 : Epoch: 386, Train_Loss: 0.00869096
2025/09/16 22:26:06 : Epoch: 387, Train_Loss: 0.01013966
2025/09/16 22:26:06 : Epoch: 388, Train_Loss: 0.00839837
2025/09/16 22:26:07 : Epoch: 389, Train_Loss: 0.00935556
2025/09/16 22:26:07 : Epoch: 389, Eval_Loss: 0.00524060
2025/09/16 22:26:07 : Epoch: 390, Train_Loss: 0.00934028
2025/09/16 22:26:07 : Epoch: 391, Train_Loss: 0.00880366
2025/09/16 22:26:07 : Epoch: 392, Train_Loss: 0.01039132
2025/09/16 22:26:08 : Epoch: 393, Train_Loss: 0.01001738
2025/09/16 22:26:08 : Epoch: 394, Train_Loss: 0.01094659
2025/09/16 22:26:08 : Epoch: 394, Eval_Loss: 0.00523784
2025/09/16 22:26:08 : Epoch: 395, Train_Loss: 0.01059843
2025/09/16 22:26:08 : Epoch: 396, Train_Loss: 0.01239174
2025/09/16 22:26:09 : Epoch: 397, Train_Loss: 0.00875718
2025/09/16 22:26:09 : Epoch: 398, Train_Loss: 0.01010846
2025/09/16 22:26:09 : Epoch: 399, Train_Loss: 0.00715179
2025/09/16 22:26:09 : Epoch: 399, Eval_Loss: 0.00523692
2025/09/16 22:26:09 : 
Epoch: 399, save response figures

2025/09/16 22:26:21 : Epoch: 400, Train_Loss: 0.00869478
2025/09/16 22:26:22 : Epoch: 401, Train_Loss: 0.00969393
2025/09/16 22:26:22 : Epoch: 402, Train_Loss: 0.00958581
2025/09/16 22:26:22 : Epoch: 403, Train_Loss: 0.00822848
2025/09/16 22:26:22 : Epoch: 404, Train_Loss: 0.00865388
2025/09/16 22:26:22 : Epoch: 404, Eval_Loss: 0.00523653
2025/09/16 22:26:23 : Epoch: 405, Train_Loss: 0.00922627
2025/09/16 22:26:23 : Epoch: 406, Train_Loss: 0.01113368
2025/09/16 22:26:23 : Epoch: 407, Train_Loss: 0.01200742
2025/09/16 22:26:23 : Epoch: 408, Train_Loss: 0.01129258
2025/09/16 22:26:24 : Epoch: 409, Train_Loss: 0.00874225
2025/09/16 22:26:24 : Epoch: 409, Eval_Loss: 0.00524470
2025/09/16 22:26:24 : Epoch: 410, Train_Loss: 0.00715753
2025/09/16 22:26:24 : Epoch: 411, Train_Loss: 0.01201130
2025/09/16 22:26:24 : Epoch: 412, Train_Loss: 0.00910804
2025/09/16 22:26:25 : Epoch: 413, Train_Loss: 0.00844791
2025/09/16 22:26:25 : Epoch: 414, Train_Loss: 0.00785633
2025/09/16 22:26:25 : Epoch: 414, Eval_Loss: 0.00524666
2025/09/16 22:26:25 : Epoch: 415, Train_Loss: 0.00868331
2025/09/16 22:26:26 : Epoch: 416, Train_Loss: 0.01083641
2025/09/16 22:26:26 : Epoch: 417, Train_Loss: 0.00766320
2025/09/16 22:26:26 : Epoch: 418, Train_Loss: 0.01211460
2025/09/16 22:26:26 : Epoch: 419, Train_Loss: 0.00763918
2025/09/16 22:26:26 : Epoch: 419, Eval_Loss: 0.00525211
2025/09/16 22:26:27 : Epoch: 420, Train_Loss: 0.00770840
2025/09/16 22:26:27 : Epoch: 421, Train_Loss: 0.00840800
2025/09/16 22:26:27 : Epoch: 422, Train_Loss: 0.00987833
2025/09/16 22:26:27 : Epoch: 423, Train_Loss: 0.01012019
2025/09/16 22:26:28 : Epoch: 424, Train_Loss: 0.00797564
2025/09/16 22:26:28 : Epoch: 424, Eval_Loss: 0.00524508
2025/09/16 22:26:28 : Epoch: 425, Train_Loss: 0.00966346
2025/09/16 22:26:28 : Epoch: 426, Train_Loss: 0.00896532
2025/09/16 22:26:28 : Epoch: 427, Train_Loss: 0.01221326
2025/09/16 22:26:29 : Epoch: 428, Train_Loss: 0.00718579
2025/09/16 22:26:29 : Epoch: 429, Train_Loss: 0.01077293
2025/09/16 22:26:29 : Epoch: 429, Eval_Loss: 0.00523720
2025/09/16 22:26:29 : Epoch: 430, Train_Loss: 0.01175346
2025/09/16 22:26:29 : Epoch: 431, Train_Loss: 0.00834545
2025/09/16 22:26:30 : Epoch: 432, Train_Loss: 0.01175806
2025/09/16 22:26:30 : Epoch: 433, Train_Loss: 0.01103713
2025/09/16 22:26:30 : Epoch: 434, Train_Loss: 0.00942854
2025/09/16 22:26:30 : Epoch: 434, Eval_Loss: 0.00526752
2025/09/16 22:26:31 : Epoch: 435, Train_Loss: 0.00843436
2025/09/16 22:26:31 : Epoch: 436, Train_Loss: 0.00929069
2025/09/16 22:26:31 : Epoch: 437, Train_Loss: 0.01046700
2025/09/16 22:26:31 : Epoch: 438, Train_Loss: 0.01153507
2025/09/16 22:26:31 : Epoch: 439, Train_Loss: 0.00757124
2025/09/16 22:26:32 : Epoch: 439, Eval_Loss: 0.00523608
2025/09/16 22:26:32 : Epoch: 440, Train_Loss: 0.00908539
2025/09/16 22:26:32 : Epoch: 441, Train_Loss: 0.00809603
2025/09/16 22:26:32 : Epoch: 442, Train_Loss: 0.01024663
2025/09/16 22:26:33 : Epoch: 443, Train_Loss: 0.00907695
2025/09/16 22:26:33 : Epoch: 444, Train_Loss: 0.00870535
2025/09/16 22:26:33 : Epoch: 444, Eval_Loss: 0.00523854
2025/09/16 22:26:33 : Epoch: 445, Train_Loss: 0.00808846
2025/09/16 22:26:33 : Epoch: 446, Train_Loss: 0.00863644
2025/09/16 22:26:34 : Epoch: 447, Train_Loss: 0.00839907
2025/09/16 22:26:34 : Epoch: 448, Train_Loss: 0.00871561
2025/09/16 22:26:34 : Epoch: 449, Train_Loss: 0.00864765
2025/09/16 22:26:34 : Epoch: 449, Eval_Loss: 0.00523519
2025/09/16 22:26:34 : Epoch: 450, Train_Loss: 0.01112890
2025/09/16 22:26:35 : Epoch: 451, Train_Loss: 0.00933975
2025/09/16 22:26:35 : Epoch: 452, Train_Loss: 0.00843980
2025/09/16 22:26:35 : Epoch: 453, Train_Loss: 0.00708485
2025/09/16 22:26:35 : Epoch: 454, Train_Loss: 0.01050738
2025/09/16 22:26:35 : Epoch: 454, Eval_Loss: 0.00523656
2025/09/16 22:26:36 : Epoch: 455, Train_Loss: 0.01406040
2025/09/16 22:26:36 : Epoch: 456, Train_Loss: 0.00900399
2025/09/16 22:26:36 : Epoch: 457, Train_Loss: 0.00891245
2025/09/16 22:26:36 : Epoch: 458, Train_Loss: 0.01198438
2025/09/16 22:26:37 : Epoch: 459, Train_Loss: 0.00933295
2025/09/16 22:26:37 : Epoch: 459, Eval_Loss: 0.00524793
2025/09/16 22:26:37 : Epoch: 460, Train_Loss: 0.00863242
2025/09/16 22:26:37 : Epoch: 461, Train_Loss: 0.00958852
2025/09/16 22:26:37 : Epoch: 462, Train_Loss: 0.00942269
2025/09/16 22:26:38 : Epoch: 463, Train_Loss: 0.00905118
2025/09/16 22:26:38 : Epoch: 464, Train_Loss: 0.01221335
2025/09/16 22:26:38 : Epoch: 464, Eval_Loss: 0.00525603
2025/09/16 22:26:38 : Epoch: 465, Train_Loss: 0.00768289
2025/09/16 22:26:39 : Epoch: 466, Train_Loss: 0.01133116
2025/09/16 22:26:39 : Epoch: 467, Train_Loss: 0.01058352
2025/09/16 22:26:39 : Epoch: 468, Train_Loss: 0.01168403
2025/09/16 22:26:39 : Epoch: 469, Train_Loss: 0.00664136
2025/09/16 22:26:39 : Epoch: 469, Eval_Loss: 0.00524503
2025/09/16 22:26:40 : Epoch: 470, Train_Loss: 0.01070783
2025/09/16 22:26:40 : Epoch: 471, Train_Loss: 0.01410059
2025/09/16 22:26:40 : Epoch: 472, Train_Loss: 0.00876216
2025/09/16 22:26:40 : Epoch: 473, Train_Loss: 0.01144824
2025/09/16 22:26:41 : Epoch: 474, Train_Loss: 0.00802781
2025/09/16 22:26:41 : Epoch: 474, Eval_Loss: 0.00525586
2025/09/16 22:26:41 : Epoch: 475, Train_Loss: 0.00758871
2025/09/16 22:26:41 : Epoch: 476, Train_Loss: 0.00959165
2025/09/16 22:26:41 : Epoch: 477, Train_Loss: 0.00832200
2025/09/16 22:26:42 : Epoch: 478, Train_Loss: 0.00857309
2025/09/16 22:26:42 : Epoch: 479, Train_Loss: 0.00766035
2025/09/16 22:26:42 : Epoch: 479, Eval_Loss: 0.00527489
2025/09/16 22:26:42 : Epoch: 480, Train_Loss: 0.01239750
2025/09/16 22:26:42 : Epoch: 481, Train_Loss: 0.01104675
2025/09/16 22:26:43 : Epoch: 482, Train_Loss: 0.00909578
2025/09/16 22:26:43 : Epoch: 483, Train_Loss: 0.01169864
2025/09/16 22:26:43 : Epoch: 484, Train_Loss: 0.00728611
2025/09/16 22:26:43 : Epoch: 484, Eval_Loss: 0.00528557
2025/09/16 22:26:43 : Epoch: 485, Train_Loss: 0.01146109
2025/09/16 22:26:44 : Epoch: 486, Train_Loss: 0.00769969
2025/09/16 22:26:44 : Epoch: 487, Train_Loss: 0.01110041
2025/09/16 22:26:44 : Epoch: 488, Train_Loss: 0.01214703
2025/09/16 22:26:44 : Epoch: 489, Train_Loss: 0.00720067
2025/09/16 22:26:45 : Epoch: 489, Eval_Loss: 0.00526462
2025/09/16 22:26:45 : Epoch: 490, Train_Loss: 0.00727479
2025/09/16 22:26:45 : Epoch: 491, Train_Loss: 0.01234260
2025/09/16 22:26:45 : Epoch: 492, Train_Loss: 0.00912460
2025/09/16 22:26:46 : Epoch: 493, Train_Loss: 0.01049471
2025/09/16 22:26:46 : Epoch: 494, Train_Loss: 0.01040936
2025/09/16 22:26:46 : Epoch: 494, Eval_Loss: 0.00534735
2025/09/16 22:26:46 : Epoch: 495, Train_Loss: 0.00860240
2025/09/16 22:26:46 : Epoch: 496, Train_Loss: 0.00977156
2025/09/16 22:26:47 : Epoch: 497, Train_Loss: 0.00815942
2025/09/16 22:26:47 : Epoch: 498, Train_Loss: 0.00870614
2025/09/16 22:26:47 : Epoch: 499, Train_Loss: 0.00914170
2025/09/16 22:26:47 : Epoch: 499, Eval_Loss: 0.00524323
2025/09/16 22:26:47 : Epoch: 500, Train_Loss: 0.00913946
2025/09/16 22:26:48 : Epoch: 501, Train_Loss: 0.01058127
2025/09/16 22:26:48 : Epoch: 502, Train_Loss: 0.00859689
2025/09/16 22:26:48 : Epoch: 503, Train_Loss: 0.01008117
2025/09/16 22:26:48 : Epoch: 504, Train_Loss: 0.00813531
2025/09/16 22:26:49 : Epoch: 504, Eval_Loss: 0.00525562
2025/09/16 22:26:49 : Epoch: 505, Train_Loss: 0.01098585
2025/09/16 22:26:49 : Epoch: 506, Train_Loss: 0.00947313
2025/09/16 22:26:49 : Epoch: 507, Train_Loss: 0.00722255
2025/09/16 22:26:50 : Epoch: 508, Train_Loss: 0.01213288
2025/09/16 22:26:50 : Epoch: 509, Train_Loss: 0.01086168
2025/09/16 22:26:50 : Epoch: 509, Eval_Loss: 0.00572230
2025/09/16 22:26:50 : Epoch: 510, Train_Loss: 0.01043069
2025/09/16 22:26:50 : Epoch: 511, Train_Loss: 0.00741364
2025/09/16 22:26:51 : Epoch: 512, Train_Loss: 0.01187895
2025/09/16 22:26:51 : Epoch: 513, Train_Loss: 0.01063243
2025/09/16 22:26:51 : Epoch: 514, Train_Loss: 0.00918779
2025/09/16 22:26:51 : Epoch: 514, Eval_Loss: 0.00524654
2025/09/16 22:26:51 : Epoch: 515, Train_Loss: 0.01269446
2025/09/16 22:26:52 : Epoch: 516, Train_Loss: 0.00776378
2025/09/16 22:26:52 : Epoch: 517, Train_Loss: 0.00701076
2025/09/16 22:26:52 : Epoch: 518, Train_Loss: 0.01229319
2025/09/16 22:26:52 : Epoch: 519, Train_Loss: 0.01091315
2025/09/16 22:26:52 : Epoch: 519, Eval_Loss: 0.00532879
2025/09/16 22:26:53 : Epoch: 520, Train_Loss: 0.01157269
2025/09/16 22:26:53 : Epoch: 521, Train_Loss: 0.00915378
2025/09/16 22:26:53 : Epoch: 522, Train_Loss: 0.00790110
2025/09/16 22:26:53 : Epoch: 523, Train_Loss: 0.01175235
2025/09/16 22:26:54 : Epoch: 524, Train_Loss: 0.00769497
2025/09/16 22:26:54 : Epoch: 524, Eval_Loss: 0.00523574
2025/09/16 22:26:54 : Epoch: 525, Train_Loss: 0.00886345
2025/09/16 22:26:54 : Epoch: 526, Train_Loss: 0.00789376
2025/09/16 22:26:54 : Epoch: 527, Train_Loss: 0.00707641
2025/09/16 22:26:55 : Epoch: 528, Train_Loss: 0.00828801
2025/09/16 22:26:55 : Epoch: 529, Train_Loss: 0.00764579
2025/09/16 22:26:55 : Epoch: 529, Eval_Loss: 0.00523449
2025/09/16 22:26:55 : Epoch: 530, Train_Loss: 0.01242940
2025/09/16 22:26:56 : Epoch: 531, Train_Loss: 0.00846827
2025/09/16 22:26:56 : Epoch: 532, Train_Loss: 0.01170867
2025/09/16 22:26:56 : Epoch: 533, Train_Loss: 0.00846661
2025/09/16 22:26:56 : Epoch: 534, Train_Loss: 0.01055369
2025/09/16 22:26:56 : Epoch: 534, Eval_Loss: 0.00526781
2025/09/16 22:26:57 : Epoch: 535, Train_Loss: 0.00975386
2025/09/16 22:26:57 : Epoch: 536, Train_Loss: 0.00801607
2025/09/16 22:26:57 : Epoch: 537, Train_Loss: 0.00756644
2025/09/16 22:26:57 : Epoch: 538, Train_Loss: 0.00982579
2025/09/16 22:26:58 : Epoch: 539, Train_Loss: 0.01203173
2025/09/16 22:26:58 : Epoch: 539, Eval_Loss: 0.00524855
2025/09/16 22:26:58 : Epoch: 540, Train_Loss: 0.01294198
2025/09/16 22:26:58 : Epoch: 541, Train_Loss: 0.01555212
2025/09/16 22:26:58 : Epoch: 542, Train_Loss: 0.00949562
2025/09/16 22:26:59 : Epoch: 543, Train_Loss: 0.00985672
2025/09/16 22:26:59 : Epoch: 544, Train_Loss: 0.01098101
2025/09/16 22:26:59 : Epoch: 544, Eval_Loss: 0.00527083
2025/09/16 22:26:59 : Epoch: 545, Train_Loss: 0.01150204
2025/09/16 22:27:00 : Epoch: 546, Train_Loss: 0.01044026
2025/09/16 22:27:00 : Epoch: 547, Train_Loss: 0.00820115
2025/09/16 22:27:00 : Epoch: 548, Train_Loss: 0.01180762
2025/09/16 22:27:00 : Epoch: 549, Train_Loss: 0.01071195
2025/09/16 22:27:00 : Epoch: 549, Eval_Loss: 0.00523640
2025/09/16 22:27:01 : Epoch: 550, Train_Loss: 0.01295994
2025/09/16 22:27:01 : Epoch: 551, Train_Loss: 0.01068364
2025/09/16 22:27:01 : Epoch: 552, Train_Loss: 0.00754515
2025/09/16 22:27:01 : Epoch: 553, Train_Loss: 0.01047477
2025/09/16 22:27:02 : Epoch: 554, Train_Loss: 0.00875299
2025/09/16 22:27:02 : Epoch: 554, Eval_Loss: 0.00523700
2025/09/16 22:27:02 : Epoch: 555, Train_Loss: 0.00770875
2025/09/16 22:27:02 : Epoch: 556, Train_Loss: 0.01274451
2025/09/16 22:27:02 : Epoch: 557, Train_Loss: 0.01273517
2025/09/16 22:27:03 : Epoch: 558, Train_Loss: 0.01006508
2025/09/16 22:27:03 : Epoch: 559, Train_Loss: 0.00821945
2025/09/16 22:27:03 : Epoch: 559, Eval_Loss: 0.00523826
2025/09/16 22:27:03 : Epoch: 560, Train_Loss: 0.00968656
2025/09/16 22:27:03 : Epoch: 561, Train_Loss: 0.01175165
2025/09/16 22:27:04 : Epoch: 562, Train_Loss: 0.01082985
2025/09/16 22:27:04 : Epoch: 563, Train_Loss: 0.01012034
2025/09/16 22:27:04 : Epoch: 564, Train_Loss: 0.01314161
2025/09/16 22:27:04 : Epoch: 564, Eval_Loss: 0.00523617
2025/09/16 22:27:05 : Epoch: 565, Train_Loss: 0.00775882
2025/09/16 22:27:05 : Epoch: 566, Train_Loss: 0.01149665
2025/09/16 22:27:05 : Epoch: 567, Train_Loss: 0.01124228
2025/09/16 22:27:05 : Epoch: 568, Train_Loss: 0.01049893
2025/09/16 22:27:06 : Epoch: 569, Train_Loss: 0.00853014
2025/09/16 22:27:06 : Epoch: 569, Eval_Loss: 0.00526451
2025/09/16 22:27:06 : Epoch: 570, Train_Loss: 0.01332533
2025/09/16 22:27:06 : Epoch: 571, Train_Loss: 0.01429475
2025/09/16 22:27:06 : Epoch: 572, Train_Loss: 0.00958656
2025/09/16 22:27:07 : Epoch: 573, Train_Loss: 0.00856022
2025/09/16 22:27:07 : Epoch: 574, Train_Loss: 0.00779270
2025/09/16 22:27:07 : Epoch: 574, Eval_Loss: 0.00526690
2025/09/16 22:27:07 : Epoch: 575, Train_Loss: 0.01176763
2025/09/16 22:27:07 : Epoch: 576, Train_Loss: 0.01106313
2025/09/16 22:27:08 : Epoch: 577, Train_Loss: 0.01362165
2025/09/16 22:27:08 : Epoch: 578, Train_Loss: 0.01095060
2025/09/16 22:27:08 : Epoch: 579, Train_Loss: 0.00842913
2025/09/16 22:27:08 : Epoch: 579, Eval_Loss: 0.00527242
2025/09/16 22:27:09 : Epoch: 580, Train_Loss: 0.00842704
2025/09/16 22:27:09 : Epoch: 581, Train_Loss: 0.00794385
2025/09/16 22:27:09 : Epoch: 582, Train_Loss: 0.00865432
2025/09/16 22:27:09 : Epoch: 583, Train_Loss: 0.00793524
2025/09/16 22:27:09 : Epoch: 584, Train_Loss: 0.00757459
2025/09/16 22:27:10 : Epoch: 584, Eval_Loss: 0.00525880
2025/09/16 22:27:10 : Epoch: 585, Train_Loss: 0.00884496
2025/09/16 22:27:10 : Epoch: 586, Train_Loss: 0.00766338
2025/09/16 22:27:10 : Epoch: 587, Train_Loss: 0.01074239
2025/09/16 22:27:11 : Epoch: 588, Train_Loss: 0.00933154
2025/09/16 22:27:11 : Epoch: 589, Train_Loss: 0.01133958
2025/09/16 22:27:11 : Epoch: 589, Eval_Loss: 0.00525224
2025/09/16 22:27:11 : Epoch: 590, Train_Loss: 0.01270305
2025/09/16 22:27:11 : Epoch: 591, Train_Loss: 0.01107803
2025/09/16 22:27:12 : Epoch: 592, Train_Loss: 0.01234655
2025/09/16 22:27:12 : Epoch: 593, Train_Loss: 0.00994085
2025/09/16 22:27:12 : Epoch: 594, Train_Loss: 0.01133837
2025/09/16 22:27:12 : Epoch: 594, Eval_Loss: 0.00526511
2025/09/16 22:27:12 : Epoch: 595, Train_Loss: 0.01099384
2025/09/16 22:27:13 : Epoch: 596, Train_Loss: 0.01007759
2025/09/16 22:27:13 : Epoch: 597, Train_Loss: 0.00755697
2025/09/16 22:27:13 : Epoch: 598, Train_Loss: 0.00790976
2025/09/16 22:27:13 : Epoch: 599, Train_Loss: 0.01084193
2025/09/16 22:27:14 : Epoch: 599, Eval_Loss: 0.00524824
2025/09/16 22:27:14 : Epoch: 600, Train_Loss: 0.00849255
2025/09/16 22:27:14 : Epoch: 601, Train_Loss: 0.00933717
2025/09/16 22:27:14 : Epoch: 602, Train_Loss: 0.00867660
2025/09/16 22:27:14 : Epoch: 603, Train_Loss: 0.01043046
2025/09/16 22:27:15 : Epoch: 604, Train_Loss: 0.00939593
2025/09/16 22:27:15 : Epoch: 604, Eval_Loss: 0.00525704
2025/09/16 22:27:15 : Epoch: 605, Train_Loss: 0.01317535
2025/09/16 22:27:15 : Epoch: 606, Train_Loss: 0.00885224
2025/09/16 22:27:16 : Epoch: 607, Train_Loss: 0.01115015
2025/09/16 22:27:16 : Epoch: 608, Train_Loss: 0.01206014
2025/09/16 22:27:16 : Epoch: 609, Train_Loss: 0.00998456
2025/09/16 22:27:16 : Epoch: 609, Eval_Loss: 0.00523736
2025/09/16 22:27:16 : Epoch: 610, Train_Loss: 0.01105867
2025/09/16 22:27:17 : Epoch: 611, Train_Loss: 0.01091724
2025/09/16 22:27:17 : Epoch: 612, Train_Loss: 0.00754295
2025/09/16 22:27:17 : Epoch: 613, Train_Loss: 0.01136200
2025/09/16 22:27:17 : Epoch: 614, Train_Loss: 0.01067569
2025/09/16 22:27:17 : Epoch: 614, Eval_Loss: 0.00523676
2025/09/16 22:27:18 : Epoch: 615, Train_Loss: 0.00957333
2025/09/16 22:27:18 : Epoch: 616, Train_Loss: 0.01042479
2025/09/16 22:27:18 : Epoch: 617, Train_Loss: 0.00741745
2025/09/16 22:27:18 : Epoch: 618, Train_Loss: 0.00896083
2025/09/16 22:27:19 : Epoch: 619, Train_Loss: 0.01029611
2025/09/16 22:27:19 : Epoch: 619, Eval_Loss: 0.00523367
2025/09/16 22:27:19 : Epoch: 620, Train_Loss: 0.00845350
2025/09/16 22:27:19 : Epoch: 621, Train_Loss: 0.01122668
2025/09/16 22:27:20 : Epoch: 622, Train_Loss: 0.00810628
2025/09/16 22:27:20 : Epoch: 623, Train_Loss: 0.00669047
2025/09/16 22:27:20 : Epoch: 624, Train_Loss: 0.00994079
2025/09/16 22:27:20 : Epoch: 624, Eval_Loss: 0.00523764
2025/09/16 22:27:20 : Epoch: 625, Train_Loss: 0.01093350
2025/09/16 22:27:21 : Epoch: 626, Train_Loss: 0.00981648
2025/09/16 22:27:21 : Epoch: 627, Train_Loss: 0.00966086
2025/09/16 22:27:21 : Epoch: 628, Train_Loss: 0.00923582
2025/09/16 22:27:21 : Epoch: 629, Train_Loss: 0.00701052
2025/09/16 22:27:21 : Epoch: 629, Eval_Loss: 0.00523603
2025/09/16 22:27:22 : Epoch: 630, Train_Loss: 0.01322760
2025/09/16 22:27:22 : Epoch: 631, Train_Loss: 0.00718893
2025/09/16 22:27:22 : Epoch: 632, Train_Loss: 0.00985666
2025/09/16 22:27:22 : Epoch: 633, Train_Loss: 0.00839340
2025/09/16 22:27:23 : Epoch: 634, Train_Loss: 0.00768660
2025/09/16 22:27:23 : Epoch: 634, Eval_Loss: 0.00523742
2025/09/16 22:27:23 : Epoch: 635, Train_Loss: 0.01368227
2025/09/16 22:27:23 : Epoch: 636, Train_Loss: 0.00982269
2025/09/16 22:27:23 : Epoch: 637, Train_Loss: 0.00664652
2025/09/16 22:27:24 : Epoch: 638, Train_Loss: 0.01358446
2025/09/16 22:27:24 : Epoch: 639, Train_Loss: 0.00960149
2025/09/16 22:27:24 : Epoch: 639, Eval_Loss: 0.00524430
2025/09/16 22:27:24 : Epoch: 640, Train_Loss: 0.00842946
2025/09/16 22:27:24 : Epoch: 641, Train_Loss: 0.01253225
2025/09/16 22:27:25 : Epoch: 642, Train_Loss: 0.00932370
2025/09/16 22:27:25 : Epoch: 643, Train_Loss: 0.01015360
2025/09/16 22:27:25 : Epoch: 644, Train_Loss: 0.00967562
2025/09/16 22:27:25 : Epoch: 644, Eval_Loss: 0.00524230
2025/09/16 22:27:25 : Epoch: 645, Train_Loss: 0.01023257
2025/09/16 22:27:26 : Epoch: 646, Train_Loss: 0.00753550
2025/09/16 22:27:26 : Epoch: 647, Train_Loss: 0.00886621
2025/09/16 22:27:26 : Epoch: 648, Train_Loss: 0.01107057
2025/09/16 22:27:26 : Epoch: 649, Train_Loss: 0.00914405
2025/09/16 22:27:27 : Epoch: 649, Eval_Loss: 0.00523485
2025/09/16 22:27:27 : Epoch: 650, Train_Loss: 0.00833479
2025/09/16 22:27:27 : Epoch: 651, Train_Loss: 0.00823364
2025/09/16 22:27:27 : Epoch: 652, Train_Loss: 0.00877105
2025/09/16 22:27:27 : Epoch: 653, Train_Loss: 0.00809714
2025/09/16 22:27:28 : Epoch: 654, Train_Loss: 0.01198315
2025/09/16 22:27:28 : Epoch: 654, Eval_Loss: 0.00523435
2025/09/16 22:27:28 : Epoch: 655, Train_Loss: 0.00824219
2025/09/16 22:27:28 : Epoch: 656, Train_Loss: 0.01218432
2025/09/16 22:27:29 : Epoch: 657, Train_Loss: 0.00962954
2025/09/16 22:27:29 : Epoch: 658, Train_Loss: 0.01202636
2025/09/16 22:27:29 : Epoch: 659, Train_Loss: 0.01102380
2025/09/16 22:27:29 : Epoch: 659, Eval_Loss: 0.00524124
2025/09/16 22:27:29 : Epoch: 660, Train_Loss: 0.00776421
2025/09/16 22:27:30 : Epoch: 661, Train_Loss: 0.00939210
2025/09/16 22:27:30 : Epoch: 662, Train_Loss: 0.00838720
2025/09/16 22:27:30 : Epoch: 663, Train_Loss: 0.00780567
2025/09/16 22:27:30 : Epoch: 664, Train_Loss: 0.00670056
2025/09/16 22:27:30 : Epoch: 664, Eval_Loss: 0.00523793
2025/09/16 22:27:31 : Epoch: 665, Train_Loss: 0.01243557
2025/09/16 22:27:31 : Epoch: 666, Train_Loss: 0.00924148
2025/09/16 22:27:31 : Epoch: 667, Train_Loss: 0.01591037
2025/09/16 22:27:31 : Epoch: 668, Train_Loss: 0.01407210
2025/09/16 22:27:32 : Epoch: 669, Train_Loss: 0.01424254
2025/09/16 22:27:32 : Epoch: 669, Eval_Loss: 0.00523810
2025/09/16 22:27:32 : Epoch: 670, Train_Loss: 0.00810219
2025/09/16 22:27:32 : Epoch: 671, Train_Loss: 0.00980142
2025/09/16 22:27:32 : Epoch: 672, Train_Loss: 0.00973535
2025/09/16 22:27:33 : Epoch: 673, Train_Loss: 0.00835972
2025/09/16 22:27:33 : Epoch: 674, Train_Loss: 0.01433099
2025/09/16 22:27:33 : Epoch: 674, Eval_Loss: 0.00524405
2025/09/16 22:27:33 : Epoch: 675, Train_Loss: 0.01017199
2025/09/16 22:27:34 : Epoch: 676, Train_Loss: 0.01139253
2025/09/16 22:27:34 : Epoch: 677, Train_Loss: 0.00773622
2025/09/16 22:27:34 : Epoch: 678, Train_Loss: 0.00792525
2025/09/16 22:27:34 : Epoch: 679, Train_Loss: 0.00936555
2025/09/16 22:27:34 : Epoch: 679, Eval_Loss: 0.00524514
2025/09/16 22:27:35 : Epoch: 680, Train_Loss: 0.00893094
2025/09/16 22:27:35 : Epoch: 681, Train_Loss: 0.00970439
2025/09/16 22:27:35 : Epoch: 682, Train_Loss: 0.00849610
2025/09/16 22:27:35 : Epoch: 683, Train_Loss: 0.01172123
2025/09/16 22:27:36 : Epoch: 684, Train_Loss: 0.01129868
2025/09/16 22:27:36 : Epoch: 684, Eval_Loss: 0.00523888
2025/09/16 22:27:36 : Epoch: 685, Train_Loss: 0.01407117
2025/09/16 22:27:36 : Epoch: 686, Train_Loss: 0.01024980
2025/09/16 22:27:36 : Epoch: 687, Train_Loss: 0.00677098
2025/09/16 22:27:37 : Epoch: 688, Train_Loss: 0.00935568
2025/09/16 22:27:37 : Epoch: 689, Train_Loss: 0.00882145
2025/09/16 22:27:37 : Epoch: 689, Eval_Loss: 0.00523807
2025/09/16 22:27:37 : Epoch: 690, Train_Loss: 0.00840808
2025/09/16 22:27:37 : Epoch: 691, Train_Loss: 0.00985139
2025/09/16 22:27:38 : Epoch: 692, Train_Loss: 0.01414157
2025/09/16 22:27:38 : Epoch: 693, Train_Loss: 0.01029340
2025/09/16 22:27:38 : Epoch: 694, Train_Loss: 0.00888017
2025/09/16 22:27:38 : Epoch: 694, Eval_Loss: 0.00523976
2025/09/16 22:27:38 : Epoch: 695, Train_Loss: 0.01024962
2025/09/16 22:27:39 : Epoch: 696, Train_Loss: 0.00962915
2025/09/16 22:27:39 : Epoch: 697, Train_Loss: 0.01243342
2025/09/16 22:27:39 : Epoch: 698, Train_Loss: 0.01000990
2025/09/16 22:27:39 : Epoch: 699, Train_Loss: 0.00946537
2025/09/16 22:27:40 : Epoch: 699, Eval_Loss: 0.00525210
2025/09/16 22:27:40 : Epoch: 700, Train_Loss: 0.00912090
2025/09/16 22:27:40 : Epoch: 701, Train_Loss: 0.01180379
2025/09/16 22:27:40 : Epoch: 702, Train_Loss: 0.01081849
2025/09/16 22:27:41 : Epoch: 703, Train_Loss: 0.00941719
2025/09/16 22:27:41 : Epoch: 704, Train_Loss: 0.00724169
2025/09/16 22:27:41 : Epoch: 704, Eval_Loss: 0.00525874
2025/09/16 22:27:41 : Epoch: 705, Train_Loss: 0.01090954
2025/09/16 22:27:41 : Epoch: 706, Train_Loss: 0.00931318
2025/09/16 22:27:42 : Epoch: 707, Train_Loss: 0.01405327
2025/09/16 22:27:42 : Epoch: 708, Train_Loss: 0.00969759
2025/09/16 22:27:42 : Epoch: 709, Train_Loss: 0.00922894
2025/09/16 22:27:42 : Epoch: 709, Eval_Loss: 0.00524645
2025/09/16 22:27:42 : Epoch: 710, Train_Loss: 0.01259393
2025/09/16 22:27:43 : Epoch: 711, Train_Loss: 0.01324906
2025/09/16 22:27:43 : Epoch: 712, Train_Loss: 0.00884186
2025/09/16 22:27:43 : Epoch: 713, Train_Loss: 0.00815398
2025/09/16 22:27:43 : Epoch: 714, Train_Loss: 0.00944179
2025/09/16 22:27:44 : Epoch: 714, Eval_Loss: 0.00525789
2025/09/16 22:27:44 : Epoch: 715, Train_Loss: 0.00770179
2025/09/16 22:27:44 : Epoch: 716, Train_Loss: 0.00859592
2025/09/16 22:27:44 : Epoch: 717, Train_Loss: 0.00824234
2025/09/16 22:27:44 : Epoch: 718, Train_Loss: 0.01241374
2025/09/16 22:27:45 : Epoch: 719, Train_Loss: 0.00948820
2025/09/16 22:27:45 : Epoch: 719, Eval_Loss: 0.00524524
2025/09/16 22:27:45 : Epoch: 720, Train_Loss: 0.00931187
2025/09/16 22:27:45 : Epoch: 721, Train_Loss: 0.00871215
2025/09/16 22:27:46 : Epoch: 722, Train_Loss: 0.01207510
2025/09/16 22:27:46 : Epoch: 723, Train_Loss: 0.00923773
2025/09/16 22:27:46 : Epoch: 724, Train_Loss: 0.00792227
2025/09/16 22:27:46 : Epoch: 724, Eval_Loss: 0.00523642
2025/09/16 22:27:46 : Epoch: 725, Train_Loss: 0.00852437
2025/09/16 22:27:47 : Epoch: 726, Train_Loss: 0.01191352
2025/09/16 22:27:47 : Epoch: 727, Train_Loss: 0.00875735
2025/09/16 22:27:47 : Epoch: 728, Train_Loss: 0.00984539
2025/09/16 22:27:47 : Epoch: 729, Train_Loss: 0.00784580
2025/09/16 22:27:47 : Epoch: 729, Eval_Loss: 0.00523614
2025/09/16 22:27:48 : Epoch: 730, Train_Loss: 0.01180296
2025/09/16 22:27:48 : Epoch: 731, Train_Loss: 0.00859229
2025/09/16 22:27:48 : Epoch: 732, Train_Loss: 0.00970524
2025/09/16 22:27:48 : Epoch: 733, Train_Loss: 0.01178524
2025/09/16 22:27:49 : Epoch: 734, Train_Loss: 0.01094224
2025/09/16 22:27:49 : Epoch: 734, Eval_Loss: 0.00523578
2025/09/16 22:27:49 : Epoch: 735, Train_Loss: 0.01366223
2025/09/16 22:27:49 : Epoch: 736, Train_Loss: 0.00967734
2025/09/16 22:27:50 : Epoch: 737, Train_Loss: 0.01264970
2025/09/16 22:27:50 : Epoch: 738, Train_Loss: 0.01162001
2025/09/16 22:27:50 : Epoch: 739, Train_Loss: 0.00676550
2025/09/16 22:27:50 : Epoch: 739, Eval_Loss: 0.00524422
2025/09/16 22:27:50 : Epoch: 740, Train_Loss: 0.00861972
2025/09/16 22:27:51 : Epoch: 741, Train_Loss: 0.00915421
2025/09/16 22:27:51 : Epoch: 742, Train_Loss: 0.01075621
2025/09/16 22:27:51 : Epoch: 743, Train_Loss: 0.01195985
2025/09/16 22:27:51 : Epoch: 744, Train_Loss: 0.00818366
2025/09/16 22:27:51 : Epoch: 744, Eval_Loss: 0.00523928
2025/09/16 22:27:52 : Epoch: 745, Train_Loss: 0.01082669
2025/09/16 22:27:52 : Epoch: 746, Train_Loss: 0.00991831
2025/09/16 22:27:52 : Epoch: 747, Train_Loss: 0.00847565
2025/09/16 22:27:52 : Epoch: 748, Train_Loss: 0.00788974
2025/09/16 22:27:53 : Epoch: 749, Train_Loss: 0.00917167
2025/09/16 22:27:53 : Epoch: 749, Eval_Loss: 0.00523502
2025/09/16 22:27:53 : Epoch: 750, Train_Loss: 0.01103214
2025/09/16 22:27:53 : Epoch: 751, Train_Loss: 0.00715150
2025/09/16 22:27:53 : Epoch: 752, Train_Loss: 0.01323629
2025/09/16 22:27:54 : Epoch: 753, Train_Loss: 0.01095871
2025/09/16 22:27:54 : Epoch: 754, Train_Loss: 0.01216176
2025/09/16 22:27:54 : Epoch: 754, Eval_Loss: 0.00524540
2025/09/16 22:27:54 : Epoch: 755, Train_Loss: 0.00755615
2025/09/16 22:27:54 : Epoch: 756, Train_Loss: 0.00757630
2025/09/16 22:27:55 : Epoch: 757, Train_Loss: 0.00893630
2025/09/16 22:27:55 : Epoch: 758, Train_Loss: 0.00820850
2025/09/16 22:27:55 : Epoch: 759, Train_Loss: 0.00887458
2025/09/16 22:27:55 : Epoch: 759, Eval_Loss: 0.00525448
2025/09/16 22:27:55 : Epoch: 760, Train_Loss: 0.00769485
2025/09/16 22:27:56 : Epoch: 761, Train_Loss: 0.00806766
2025/09/16 22:27:56 : Epoch: 762, Train_Loss: 0.00913214
2025/09/16 22:27:56 : Epoch: 763, Train_Loss: 0.01011346
2025/09/16 22:27:56 : Epoch: 764, Train_Loss: 0.01096546
2025/09/16 22:27:57 : Epoch: 764, Eval_Loss: 0.00524131
2025/09/16 22:27:57 : Epoch: 765, Train_Loss: 0.00824690
2025/09/16 22:27:57 : Epoch: 766, Train_Loss: 0.00810721
2025/09/16 22:27:57 : Epoch: 767, Train_Loss: 0.00907186
2025/09/16 22:27:58 : Epoch: 768, Train_Loss: 0.01359414
2025/09/16 22:27:58 : Epoch: 769, Train_Loss: 0.00701502
2025/09/16 22:27:58 : Epoch: 769, Eval_Loss: 0.00524364
2025/09/16 22:27:58 : Epoch: 770, Train_Loss: 0.01364674
2025/09/16 22:27:58 : Epoch: 771, Train_Loss: 0.00873056
2025/09/16 22:27:59 : Epoch: 772, Train_Loss: 0.01010995
2025/09/16 22:27:59 : Epoch: 773, Train_Loss: 0.00917683
2025/09/16 22:27:59 : Epoch: 774, Train_Loss: 0.01352305
2025/09/16 22:27:59 : Epoch: 774, Eval_Loss: 0.00525238
2025/09/16 22:27:59 : Epoch: 775, Train_Loss: 0.01161514
2025/09/16 22:28:00 : Epoch: 776, Train_Loss: 0.00656540
2025/09/16 22:28:00 : Epoch: 777, Train_Loss: 0.00782255
2025/09/16 22:28:00 : Epoch: 778, Train_Loss: 0.01413183
2025/09/16 22:28:00 : Epoch: 779, Train_Loss: 0.00781100
2025/09/16 22:28:00 : Epoch: 779, Eval_Loss: 0.00526831
2025/09/16 22:28:01 : Epoch: 780, Train_Loss: 0.01202626
2025/09/16 22:28:01 : Epoch: 781, Train_Loss: 0.01350914
2025/09/16 22:28:01 : Epoch: 782, Train_Loss: 0.00814780
2025/09/16 22:28:01 : Epoch: 783, Train_Loss: 0.00983437
2025/09/16 22:28:02 : Epoch: 784, Train_Loss: 0.00854777
2025/09/16 22:28:02 : Epoch: 784, Eval_Loss: 0.00527744
2025/09/16 22:28:02 : Epoch: 785, Train_Loss: 0.01060487
2025/09/16 22:28:02 : Epoch: 786, Train_Loss: 0.01030321
2025/09/16 22:28:03 : Epoch: 787, Train_Loss: 0.00986155
2025/09/16 22:28:03 : Epoch: 788, Train_Loss: 0.01024407
2025/09/16 22:28:03 : Epoch: 789, Train_Loss: 0.00889132
2025/09/16 22:28:03 : Epoch: 789, Eval_Loss: 0.00524879
2025/09/16 22:28:03 : Epoch: 790, Train_Loss: 0.00873232
2025/09/16 22:28:04 : Epoch: 791, Train_Loss: 0.00932867
2025/09/16 22:28:04 : Epoch: 792, Train_Loss: 0.01455368
2025/09/16 22:28:04 : Epoch: 793, Train_Loss: 0.00891007
2025/09/16 22:28:04 : Epoch: 794, Train_Loss: 0.01185929
2025/09/16 22:28:04 : Epoch: 794, Eval_Loss: 0.00524342
2025/09/16 22:28:05 : Epoch: 795, Train_Loss: 0.00940723
2025/09/16 22:28:05 : Epoch: 796, Train_Loss: 0.01349510
2025/09/16 22:28:05 : Epoch: 797, Train_Loss: 0.01021577
2025/09/16 22:28:05 : Epoch: 798, Train_Loss: 0.00930966
2025/09/16 22:28:06 : Epoch: 799, Train_Loss: 0.00716845
2025/09/16 22:28:06 : Epoch: 799, Eval_Loss: 0.00524460
2025/09/16 22:28:06 : 
Epoch: 799, save response figures

2025/09/16 22:28:18 : Epoch: 800, Train_Loss: 0.00917043
2025/09/16 22:28:18 : Epoch: 801, Train_Loss: 0.00869384
2025/09/16 22:28:18 : Epoch: 802, Train_Loss: 0.00949768
2025/09/16 22:28:19 : Epoch: 803, Train_Loss: 0.00904251
2025/09/16 22:28:19 : Epoch: 804, Train_Loss: 0.00811694
2025/09/16 22:28:19 : Epoch: 804, Eval_Loss: 0.00524125
2025/09/16 22:28:19 : Epoch: 805, Train_Loss: 0.00816594
2025/09/16 22:28:19 : Epoch: 806, Train_Loss: 0.00749865
2025/09/16 22:28:20 : Epoch: 807, Train_Loss: 0.01036424
2025/09/16 22:28:20 : Epoch: 808, Train_Loss: 0.00726292
2025/09/16 22:28:20 : Epoch: 809, Train_Loss: 0.00716951
2025/09/16 22:28:20 : Epoch: 809, Eval_Loss: 0.00523484
2025/09/16 22:28:21 : Epoch: 810, Train_Loss: 0.01247353
2025/09/16 22:28:21 : Epoch: 811, Train_Loss: 0.01064941
2025/09/16 22:28:21 : Epoch: 812, Train_Loss: 0.01106242
2025/09/16 22:28:21 : Epoch: 813, Train_Loss: 0.00765731
2025/09/16 22:28:22 : Epoch: 814, Train_Loss: 0.00836790
2025/09/16 22:28:22 : Epoch: 814, Eval_Loss: 0.00523610
2025/09/16 22:28:22 : Epoch: 815, Train_Loss: 0.00851716
2025/09/16 22:28:22 : Epoch: 816, Train_Loss: 0.01407982
2025/09/16 22:28:22 : Epoch: 817, Train_Loss: 0.00972231
2025/09/16 22:28:23 : Epoch: 818, Train_Loss: 0.00943707
2025/09/16 22:28:23 : Epoch: 819, Train_Loss: 0.00860327
2025/09/16 22:28:23 : Epoch: 819, Eval_Loss: 0.00523772
2025/09/16 22:28:23 : Epoch: 820, Train_Loss: 0.00990207
2025/09/16 22:28:23 : Epoch: 821, Train_Loss: 0.00788677
2025/09/16 22:28:24 : Epoch: 822, Train_Loss: 0.00864083
2025/09/16 22:28:24 : Epoch: 823, Train_Loss: 0.01417232
2025/09/16 22:28:24 : Epoch: 824, Train_Loss: 0.01072056
2025/09/16 22:28:24 : Epoch: 824, Eval_Loss: 0.00523688
2025/09/16 22:28:24 : Epoch: 825, Train_Loss: 0.00865021
2025/09/16 22:28:25 : Epoch: 826, Train_Loss: 0.00843279
2025/09/16 22:28:25 : Epoch: 827, Train_Loss: 0.01061612
2025/09/16 22:28:25 : Epoch: 828, Train_Loss: 0.00773137
2025/09/16 22:28:25 : Epoch: 829, Train_Loss: 0.00839423
2025/09/16 22:28:26 : Epoch: 829, Eval_Loss: 0.00523784
2025/09/16 22:28:26 : Epoch: 830, Train_Loss: 0.00853823
2025/09/16 22:28:26 : Epoch: 831, Train_Loss: 0.00825578
2025/09/16 22:28:26 : Epoch: 832, Train_Loss: 0.00984959
2025/09/16 22:28:27 : Epoch: 833, Train_Loss: 0.00994101
2025/09/16 22:28:27 : Epoch: 834, Train_Loss: 0.00970119
2025/09/16 22:28:27 : Epoch: 834, Eval_Loss: 0.00523655
2025/09/16 22:28:27 : Epoch: 835, Train_Loss: 0.00816041
2025/09/16 22:28:27 : Epoch: 836, Train_Loss: 0.01001308
2025/09/16 22:28:28 : Epoch: 837, Train_Loss: 0.01122260
2025/09/16 22:28:28 : Epoch: 838, Train_Loss: 0.00932418
2025/09/16 22:28:28 : Epoch: 839, Train_Loss: 0.01358682
2025/09/16 22:28:28 : Epoch: 839, Eval_Loss: 0.00523640
2025/09/16 22:28:28 : Epoch: 840, Train_Loss: 0.01253829
2025/09/16 22:28:29 : Epoch: 841, Train_Loss: 0.01018629
2025/09/16 22:28:29 : Epoch: 842, Train_Loss: 0.00933443
2025/09/16 22:28:29 : Epoch: 843, Train_Loss: 0.00859235
2025/09/16 22:28:29 : Epoch: 844, Train_Loss: 0.00912059
2025/09/16 22:28:30 : Epoch: 844, Eval_Loss: 0.00523929
2025/09/16 22:28:30 : Epoch: 845, Train_Loss: 0.00872560
2025/09/16 22:28:30 : Epoch: 846, Train_Loss: 0.00923574
2025/09/16 22:28:30 : Epoch: 847, Train_Loss: 0.00767094
2025/09/16 22:28:30 : Epoch: 848, Train_Loss: 0.00754938
2025/09/16 22:28:31 : Epoch: 849, Train_Loss: 0.00832798
2025/09/16 22:28:31 : Epoch: 849, Eval_Loss: 0.00523774
2025/09/16 22:28:31 : Epoch: 850, Train_Loss: 0.01152074
2025/09/16 22:28:31 : Epoch: 851, Train_Loss: 0.00777695
2025/09/16 22:28:32 : Epoch: 852, Train_Loss: 0.00969986
2025/09/16 22:28:32 : Epoch: 853, Train_Loss: 0.01526037
2025/09/16 22:28:32 : Epoch: 854, Train_Loss: 0.00758141
2025/09/16 22:28:32 : Epoch: 854, Eval_Loss: 0.00523826
2025/09/16 22:28:32 : Epoch: 855, Train_Loss: 0.01027144
2025/09/16 22:28:33 : Epoch: 856, Train_Loss: 0.00876124
2025/09/16 22:28:33 : Epoch: 857, Train_Loss: 0.01016183
2025/09/16 22:28:33 : Epoch: 858, Train_Loss: 0.00850356
2025/09/16 22:28:33 : Epoch: 859, Train_Loss: 0.01240012
2025/09/16 22:28:33 : Epoch: 859, Eval_Loss: 0.00524011
2025/09/16 22:28:34 : Epoch: 860, Train_Loss: 0.00939172
2025/09/16 22:28:34 : Epoch: 861, Train_Loss: 0.00908315
2025/09/16 22:28:34 : Epoch: 862, Train_Loss: 0.01129006
2025/09/16 22:28:34 : Epoch: 863, Train_Loss: 0.00858896
2025/09/16 22:28:35 : Epoch: 864, Train_Loss: 0.00951985
2025/09/16 22:28:35 : Epoch: 864, Eval_Loss: 0.00523967
2025/09/16 22:28:35 : Epoch: 865, Train_Loss: 0.01190580
2025/09/16 22:28:35 : Epoch: 866, Train_Loss: 0.00954796
2025/09/16 22:28:35 : Epoch: 867, Train_Loss: 0.00849772
2025/09/16 22:28:36 : Epoch: 868, Train_Loss: 0.01189629
2025/09/16 22:28:36 : Epoch: 869, Train_Loss: 0.00816204
2025/09/16 22:28:36 : Epoch: 869, Eval_Loss: 0.00525099
2025/09/16 22:28:36 : Epoch: 870, Train_Loss: 0.00950205
2025/09/16 22:28:36 : Epoch: 871, Train_Loss: 0.00864026
2025/09/16 22:28:37 : Epoch: 872, Train_Loss: 0.00949842
2025/09/16 22:28:37 : Epoch: 873, Train_Loss: 0.00884947
2025/09/16 22:28:37 : Epoch: 874, Train_Loss: 0.00992863
2025/09/16 22:28:37 : Epoch: 874, Eval_Loss: 0.00525214
2025/09/16 22:28:38 : Epoch: 875, Train_Loss: 0.00676350
2025/09/16 22:28:38 : Epoch: 876, Train_Loss: 0.00890788
2025/09/16 22:28:38 : Epoch: 877, Train_Loss: 0.00868931
2025/09/16 22:28:38 : Epoch: 878, Train_Loss: 0.01098748
2025/09/16 22:28:38 : Epoch: 879, Train_Loss: 0.00737477
2025/09/16 22:28:39 : Epoch: 879, Eval_Loss: 0.00524115
2025/09/16 22:28:39 : Epoch: 880, Train_Loss: 0.01212277
2025/09/16 22:28:39 : Epoch: 881, Train_Loss: 0.00833018
2025/09/16 22:28:39 : Epoch: 882, Train_Loss: 0.00986226
2025/09/16 22:28:40 : Epoch: 883, Train_Loss: 0.00728374
2025/09/16 22:28:40 : Epoch: 884, Train_Loss: 0.00705555
2025/09/16 22:28:40 : Epoch: 884, Eval_Loss: 0.00523879
2025/09/16 22:28:40 : Epoch: 885, Train_Loss: 0.00823861
2025/09/16 22:28:40 : Epoch: 886, Train_Loss: 0.00972275
2025/09/16 22:28:41 : Epoch: 887, Train_Loss: 0.00806979
2025/09/16 22:28:41 : Epoch: 888, Train_Loss: 0.01169483
2025/09/16 22:28:41 : Epoch: 889, Train_Loss: 0.00985403
2025/09/16 22:28:41 : Epoch: 889, Eval_Loss: 0.00523790
2025/09/16 22:28:41 : Epoch: 890, Train_Loss: 0.00834891
2025/09/16 22:28:42 : Epoch: 891, Train_Loss: 0.00795147
2025/09/16 22:28:42 : Epoch: 892, Train_Loss: 0.01275033
2025/09/16 22:28:42 : Epoch: 893, Train_Loss: 0.00941447
2025/09/16 22:28:42 : Epoch: 894, Train_Loss: 0.00976068
2025/09/16 22:28:42 : Epoch: 894, Eval_Loss: 0.00523551
2025/09/16 22:28:43 : Epoch: 895, Train_Loss: 0.00725494
2025/09/16 22:28:43 : Epoch: 896, Train_Loss: 0.01135202
2025/09/16 22:28:43 : Epoch: 897, Train_Loss: 0.01172957
2025/09/16 22:28:43 : Epoch: 898, Train_Loss: 0.00868804
2025/09/16 22:28:44 : Epoch: 899, Train_Loss: 0.01327621
2025/09/16 22:28:44 : Epoch: 899, Eval_Loss: 0.00523419
2025/09/16 22:28:44 : Epoch: 900, Train_Loss: 0.01338709
2025/09/16 22:28:44 : Epoch: 901, Train_Loss: 0.01458496
2025/09/16 22:28:45 : Epoch: 902, Train_Loss: 0.01122821
2025/09/16 22:28:45 : Epoch: 903, Train_Loss: 0.00844868
2025/09/16 22:28:45 : Epoch: 904, Train_Loss: 0.01018823
2025/09/16 22:28:45 : Epoch: 904, Eval_Loss: 0.00524262
2025/09/16 22:28:45 : Epoch: 905, Train_Loss: 0.01148457
2025/09/16 22:28:46 : Epoch: 906, Train_Loss: 0.00866663
2025/09/16 22:28:46 : Epoch: 907, Train_Loss: 0.00976989
2025/09/16 22:28:46 : Epoch: 908, Train_Loss: 0.00838200
2025/09/16 22:28:46 : Epoch: 909, Train_Loss: 0.00910796
2025/09/16 22:28:46 : Epoch: 909, Eval_Loss: 0.00524760
2025/09/16 22:28:47 : Epoch: 910, Train_Loss: 0.00942342
2025/09/16 22:28:47 : Epoch: 911, Train_Loss: 0.01054408
2025/09/16 22:28:47 : Epoch: 912, Train_Loss: 0.00914389
2025/09/16 22:28:47 : Epoch: 913, Train_Loss: 0.00839295
2025/09/16 22:28:48 : Epoch: 914, Train_Loss: 0.01448823
2025/09/16 22:28:48 : Epoch: 914, Eval_Loss: 0.00524698
2025/09/16 22:28:48 : Epoch: 915, Train_Loss: 0.01006979
2025/09/16 22:28:48 : Epoch: 916, Train_Loss: 0.01067558
2025/09/16 22:28:48 : Epoch: 917, Train_Loss: 0.00784991
2025/09/16 22:28:49 : Epoch: 918, Train_Loss: 0.01026781
2025/09/16 22:28:49 : Epoch: 919, Train_Loss: 0.00932946
2025/09/16 22:28:49 : Epoch: 919, Eval_Loss: 0.00524106
2025/09/16 22:28:49 : Epoch: 920, Train_Loss: 0.01031772
2025/09/16 22:28:49 : Epoch: 921, Train_Loss: 0.00833016
2025/09/16 22:28:50 : Epoch: 922, Train_Loss: 0.01296053
2025/09/16 22:28:50 : Epoch: 923, Train_Loss: 0.00982895
2025/09/16 22:28:50 : Epoch: 924, Train_Loss: 0.00910571
2025/09/16 22:28:50 : Epoch: 924, Eval_Loss: 0.00523927
2025/09/16 22:28:51 : Epoch: 925, Train_Loss: 0.01281479
2025/09/16 22:28:51 : Epoch: 926, Train_Loss: 0.01103435
2025/09/16 22:28:51 : Epoch: 927, Train_Loss: 0.00983331
2025/09/16 22:28:51 : Epoch: 928, Train_Loss: 0.00882215
2025/09/16 22:28:52 : Epoch: 929, Train_Loss: 0.01508129
2025/09/16 22:28:52 : Epoch: 929, Eval_Loss: 0.00523782
2025/09/16 22:28:52 : Epoch: 930, Train_Loss: 0.01074801
2025/09/16 22:28:52 : Epoch: 931, Train_Loss: 0.00986316
2025/09/16 22:28:52 : Epoch: 932, Train_Loss: 0.00759026
2025/09/16 22:28:53 : Epoch: 933, Train_Loss: 0.00921299
2025/09/16 22:28:53 : Epoch: 934, Train_Loss: 0.01207740
2025/09/16 22:28:53 : Epoch: 934, Eval_Loss: 0.00523607
2025/09/16 22:28:53 : Epoch: 935, Train_Loss: 0.01150119
2025/09/16 22:28:53 : Epoch: 936, Train_Loss: 0.00766232
2025/09/16 22:28:54 : Epoch: 937, Train_Loss: 0.01228484
2025/09/16 22:28:54 : Epoch: 938, Train_Loss: 0.00949576
2025/09/16 22:28:54 : Epoch: 939, Train_Loss: 0.01061292
2025/09/16 22:28:54 : Epoch: 939, Eval_Loss: 0.00524259
2025/09/16 22:28:54 : Epoch: 940, Train_Loss: 0.01343001
2025/09/16 22:28:55 : Epoch: 941, Train_Loss: 0.01170721
2025/09/16 22:28:55 : Epoch: 942, Train_Loss: 0.00971281
2025/09/16 22:28:55 : Epoch: 943, Train_Loss: 0.00840025
2025/09/16 22:28:55 : Epoch: 944, Train_Loss: 0.00651999
2025/09/16 22:28:56 : Epoch: 944, Eval_Loss: 0.00525443
2025/09/16 22:28:56 : Epoch: 945, Train_Loss: 0.01008949
2025/09/16 22:28:56 : Epoch: 946, Train_Loss: 0.00935419
2025/09/16 22:28:56 : Epoch: 947, Train_Loss: 0.01352813
2025/09/16 22:28:56 : Epoch: 948, Train_Loss: 0.00979734
2025/09/16 22:28:57 : Epoch: 949, Train_Loss: 0.00741266
2025/09/16 22:28:57 : Epoch: 949, Eval_Loss: 0.00525161
2025/09/16 22:28:57 : Epoch: 950, Train_Loss: 0.00841793
2025/09/16 22:28:57 : Epoch: 951, Train_Loss: 0.00718173
2025/09/16 22:28:58 : Epoch: 952, Train_Loss: 0.01167499
2025/09/16 22:28:58 : Epoch: 953, Train_Loss: 0.01252311
2025/09/16 22:28:58 : Epoch: 954, Train_Loss: 0.00784118
2025/09/16 22:28:58 : Epoch: 954, Eval_Loss: 0.00524078
2025/09/16 22:28:58 : Epoch: 955, Train_Loss: 0.00724372
2025/09/16 22:28:59 : Epoch: 956, Train_Loss: 0.00928534
2025/09/16 22:28:59 : Epoch: 957, Train_Loss: 0.01262094
2025/09/16 22:28:59 : Epoch: 958, Train_Loss: 0.00904657
2025/09/16 22:28:59 : Epoch: 959, Train_Loss: 0.01292368
2025/09/16 22:28:59 : Epoch: 959, Eval_Loss: 0.00523940
2025/09/16 22:29:00 : Epoch: 960, Train_Loss: 0.01273170
2025/09/16 22:29:00 : Epoch: 961, Train_Loss: 0.00824408
2025/09/16 22:29:00 : Epoch: 962, Train_Loss: 0.00920697
2025/09/16 22:29:00 : Epoch: 963, Train_Loss: 0.00839034
2025/09/16 22:29:01 : Epoch: 964, Train_Loss: 0.00975441
2025/09/16 22:29:01 : Epoch: 964, Eval_Loss: 0.00526171
2025/09/16 22:29:01 : Epoch: 965, Train_Loss: 0.00912709
2025/09/16 22:29:01 : Epoch: 966, Train_Loss: 0.01007415
2025/09/16 22:29:01 : Epoch: 967, Train_Loss: 0.01024315
2025/09/16 22:29:02 : Epoch: 968, Train_Loss: 0.01119982
2025/09/16 22:29:02 : Epoch: 969, Train_Loss: 0.00989219
2025/09/16 22:29:02 : Epoch: 969, Eval_Loss: 0.00524550
2025/09/16 22:29:02 : Epoch: 970, Train_Loss: 0.01403574
2025/09/16 22:29:03 : Epoch: 971, Train_Loss: 0.00821857
2025/09/16 22:29:03 : Epoch: 972, Train_Loss: 0.00850420
2025/09/16 22:29:03 : Epoch: 973, Train_Loss: 0.01307593
2025/09/16 22:29:03 : Epoch: 974, Train_Loss: 0.00917344
2025/09/16 22:29:03 : Epoch: 974, Eval_Loss: 0.00524237
2025/09/16 22:29:04 : Epoch: 975, Train_Loss: 0.01433676
2025/09/16 22:29:04 : Epoch: 976, Train_Loss: 0.00893266
2025/09/16 22:29:04 : Epoch: 977, Train_Loss: 0.00997525
2025/09/16 22:29:04 : Epoch: 978, Train_Loss: 0.01115944
2025/09/16 22:29:05 : Epoch: 979, Train_Loss: 0.00991318
2025/09/16 22:29:05 : Epoch: 979, Eval_Loss: 0.00524486
2025/09/16 22:29:05 : Epoch: 980, Train_Loss: 0.01015915
2025/09/16 22:29:05 : Epoch: 981, Train_Loss: 0.00956938
2025/09/16 22:29:05 : Epoch: 982, Train_Loss: 0.00911951
2025/09/16 22:29:06 : Epoch: 983, Train_Loss: 0.00916856
2025/09/16 22:29:06 : Epoch: 984, Train_Loss: 0.00814624
2025/09/16 22:29:06 : Epoch: 984, Eval_Loss: 0.00523939
2025/09/16 22:29:06 : Epoch: 985, Train_Loss: 0.00900741
2025/09/16 22:29:06 : Epoch: 986, Train_Loss: 0.01350590
2025/09/16 22:29:07 : Epoch: 987, Train_Loss: 0.01289667
2025/09/16 22:29:07 : Epoch: 988, Train_Loss: 0.01059892
2025/09/16 22:29:07 : Epoch: 989, Train_Loss: 0.01014806
2025/09/16 22:29:07 : Epoch: 989, Eval_Loss: 0.00524014
2025/09/16 22:29:07 : Epoch: 990, Train_Loss: 0.01206202
2025/09/16 22:29:08 : Epoch: 991, Train_Loss: 0.01308936
2025/09/16 22:29:08 : Epoch: 992, Train_Loss: 0.01015374
2025/09/16 22:29:08 : Epoch: 993, Train_Loss: 0.01039100
2025/09/16 22:29:09 : Epoch: 994, Train_Loss: 0.00909860
2025/09/16 22:29:09 : Epoch: 994, Eval_Loss: 0.00525160
2025/09/16 22:29:09 : Epoch: 995, Train_Loss: 0.00765902
2025/09/16 22:29:09 : Epoch: 996, Train_Loss: 0.01101242
2025/09/16 22:29:09 : Epoch: 997, Train_Loss: 0.00891675
2025/09/16 22:29:10 : Epoch: 998, Train_Loss: 0.01119780
2025/09/16 22:29:10 : Epoch: 999, Train_Loss: 0.01017870
2025/09/16 22:29:10 : Epoch: 999, Eval_Loss: 0.00524931
2025/09/16 22:29:10 : Epoch: 1000, Train_Loss: 0.00899297
2025/09/16 22:29:10 : Epoch: 1001, Train_Loss: 0.00758886
2025/09/16 22:29:11 : Epoch: 1002, Train_Loss: 0.00797125
2025/09/16 22:29:11 : Epoch: 1003, Train_Loss: 0.00656541
2025/09/16 22:29:11 : Epoch: 1004, Train_Loss: 0.00851901
2025/09/16 22:29:11 : Epoch: 1004, Eval_Loss: 0.00523849
2025/09/16 22:29:11 : Epoch: 1005, Train_Loss: 0.01002326
2025/09/16 22:29:12 : Epoch: 1006, Train_Loss: 0.00841032
2025/09/16 22:29:12 : Epoch: 1007, Train_Loss: 0.00675644
2025/09/16 22:29:12 : Epoch: 1008, Train_Loss: 0.00867085
2025/09/16 22:29:12 : Epoch: 1009, Train_Loss: 0.00958964
2025/09/16 22:29:13 : Epoch: 1009, Eval_Loss: 0.00523960
2025/09/16 22:29:13 : Epoch: 1010, Train_Loss: 0.01068064
2025/09/16 22:29:13 : Epoch: 1011, Train_Loss: 0.00808469
2025/09/16 22:29:13 : Epoch: 1012, Train_Loss: 0.00751643
2025/09/16 22:29:13 : Epoch: 1013, Train_Loss: 0.01026949
2025/09/16 22:29:14 : Epoch: 1014, Train_Loss: 0.01148030
2025/09/16 22:29:14 : Epoch: 1014, Eval_Loss: 0.00524019
2025/09/16 22:29:14 : Epoch: 1015, Train_Loss: 0.01049379
2025/09/16 22:29:14 : Epoch: 1016, Train_Loss: 0.00847531
2025/09/16 22:29:15 : Epoch: 1017, Train_Loss: 0.00996475
2025/09/16 22:29:15 : Epoch: 1018, Train_Loss: 0.01291236
2025/09/16 22:29:15 : Epoch: 1019, Train_Loss: 0.00760933
2025/09/16 22:29:15 : Epoch: 1019, Eval_Loss: 0.00524438
2025/09/16 22:29:15 : Epoch: 1020, Train_Loss: 0.00758169
2025/09/16 22:29:16 : Epoch: 1021, Train_Loss: 0.00862128
2025/09/16 22:29:16 : Epoch: 1022, Train_Loss: 0.01046824
2025/09/16 22:29:16 : Epoch: 1023, Train_Loss: 0.01008963
2025/09/16 22:29:16 : Epoch: 1024, Train_Loss: 0.01060772
2025/09/16 22:29:16 : Epoch: 1024, Eval_Loss: 0.00523334
2025/09/16 22:29:17 : Epoch: 1025, Train_Loss: 0.01027860
2025/09/16 22:29:17 : Epoch: 1026, Train_Loss: 0.00826277
2025/09/16 22:29:17 : Epoch: 1027, Train_Loss: 0.01361975
2025/09/16 22:29:17 : Epoch: 1028, Train_Loss: 0.00987450
2025/09/16 22:29:18 : Epoch: 1029, Train_Loss: 0.01097096
2025/09/16 22:29:18 : Epoch: 1029, Eval_Loss: 0.00523312
2025/09/16 22:29:18 : Epoch: 1030, Train_Loss: 0.00875038
2025/09/16 22:29:18 : Epoch: 1031, Train_Loss: 0.01239500
2025/09/16 22:29:18 : Epoch: 1032, Train_Loss: 0.01105162
2025/09/16 22:29:19 : Epoch: 1033, Train_Loss: 0.00740788
2025/09/16 22:29:19 : Epoch: 1034, Train_Loss: 0.01047935
2025/09/16 22:29:19 : Epoch: 1034, Eval_Loss: 0.00523523
2025/09/16 22:29:19 : Epoch: 1035, Train_Loss: 0.00991364
2025/09/16 22:29:20 : Epoch: 1036, Train_Loss: 0.00834904
2025/09/16 22:29:20 : Epoch: 1037, Train_Loss: 0.01163566
2025/09/16 22:29:20 : Epoch: 1038, Train_Loss: 0.00869720
2025/09/16 22:29:20 : Epoch: 1039, Train_Loss: 0.01235333
2025/09/16 22:29:20 : Epoch: 1039, Eval_Loss: 0.00523706
2025/09/16 22:29:21 : Epoch: 1040, Train_Loss: 0.00883748
2025/09/16 22:29:21 : Epoch: 1041, Train_Loss: 0.01270675
2025/09/16 22:29:21 : Epoch: 1042, Train_Loss: 0.01116208
2025/09/16 22:29:21 : Epoch: 1043, Train_Loss: 0.01434774
2025/09/16 22:29:22 : Epoch: 1044, Train_Loss: 0.01082945
2025/09/16 22:29:22 : Epoch: 1044, Eval_Loss: 0.00525022
2025/09/16 22:29:22 : Epoch: 1045, Train_Loss: 0.01385940
2025/09/16 22:29:22 : Epoch: 1046, Train_Loss: 0.00818717
2025/09/16 22:29:22 : Epoch: 1047, Train_Loss: 0.00998038
2025/09/16 22:29:23 : Epoch: 1048, Train_Loss: 0.00814246
2025/09/16 22:29:23 : Epoch: 1049, Train_Loss: 0.00770118
2025/09/16 22:29:23 : Epoch: 1049, Eval_Loss: 0.00526205
2025/09/16 22:29:23 : Epoch: 1050, Train_Loss: 0.00895229
2025/09/16 22:29:23 : Epoch: 1051, Train_Loss: 0.01246333
2025/09/16 22:29:24 : Epoch: 1052, Train_Loss: 0.01293265
2025/09/16 22:29:24 : Epoch: 1053, Train_Loss: 0.01156860
2025/09/16 22:29:24 : Epoch: 1054, Train_Loss: 0.01005561
2025/09/16 22:29:24 : Epoch: 1054, Eval_Loss: 0.00525728
2025/09/16 22:29:25 : Epoch: 1055, Train_Loss: 0.01120145
2025/09/16 22:29:25 : Epoch: 1056, Train_Loss: 0.01088855
2025/09/16 22:29:25 : Epoch: 1057, Train_Loss: 0.01058378
2025/09/16 22:29:25 : Epoch: 1058, Train_Loss: 0.01082889
2025/09/16 22:29:26 : Epoch: 1059, Train_Loss: 0.00812780
2025/09/16 22:29:26 : Epoch: 1059, Eval_Loss: 0.00524459
2025/09/16 22:29:26 : Epoch: 1060, Train_Loss: 0.00941951
2025/09/16 22:29:26 : Epoch: 1061, Train_Loss: 0.00878859
2025/09/16 22:29:26 : Epoch: 1062, Train_Loss: 0.01167505
2025/09/16 22:29:27 : Epoch: 1063, Train_Loss: 0.01037530
2025/09/16 22:29:27 : Epoch: 1064, Train_Loss: 0.00849310
2025/09/16 22:29:27 : Epoch: 1064, Eval_Loss: 0.00523761
2025/09/16 22:29:27 : Epoch: 1065, Train_Loss: 0.01354021
2025/09/16 22:29:27 : Epoch: 1066, Train_Loss: 0.00752320
2025/09/16 22:29:28 : Epoch: 1067, Train_Loss: 0.00830785
2025/09/16 22:29:28 : Epoch: 1068, Train_Loss: 0.01261752
2025/09/16 22:29:28 : Epoch: 1069, Train_Loss: 0.00950276
2025/09/16 22:29:28 : Epoch: 1069, Eval_Loss: 0.00523909
2025/09/16 22:29:28 : Epoch: 1070, Train_Loss: 0.00992373
2025/09/16 22:29:29 : Epoch: 1071, Train_Loss: 0.01066847
2025/09/16 22:29:29 : Epoch: 1072, Train_Loss: 0.01065633
2025/09/16 22:29:29 : Epoch: 1073, Train_Loss: 0.01058613
2025/09/16 22:29:29 : Epoch: 1074, Train_Loss: 0.00711942
2025/09/16 22:29:30 : Epoch: 1074, Eval_Loss: 0.00523792
2025/09/16 22:29:30 : Epoch: 1075, Train_Loss: 0.00911958
2025/09/16 22:29:30 : Epoch: 1076, Train_Loss: 0.01204295
2025/09/16 22:29:30 : Epoch: 1077, Train_Loss: 0.00876802
2025/09/16 22:29:30 : Epoch: 1078, Train_Loss: 0.00862103
2025/09/16 22:29:31 : Epoch: 1079, Train_Loss: 0.00996102
2025/09/16 22:29:31 : Epoch: 1079, Eval_Loss: 0.00524077
2025/09/16 22:29:31 : Epoch: 1080, Train_Loss: 0.01015544
2025/09/16 22:29:31 : Epoch: 1081, Train_Loss: 0.00982373
2025/09/16 22:29:32 : Epoch: 1082, Train_Loss: 0.00666833
2025/09/16 22:29:32 : Epoch: 1083, Train_Loss: 0.01379691
2025/09/16 22:29:32 : Epoch: 1084, Train_Loss: 0.00780674
2025/09/16 22:29:32 : Epoch: 1084, Eval_Loss: 0.00524268
2025/09/16 22:29:32 : Epoch: 1085, Train_Loss: 0.01229484
2025/09/16 22:29:33 : Epoch: 1086, Train_Loss: 0.01037737
2025/09/16 22:29:33 : Epoch: 1087, Train_Loss: 0.00827121
2025/09/16 22:29:33 : Epoch: 1088, Train_Loss: 0.00737080
2025/09/16 22:29:33 : Epoch: 1089, Train_Loss: 0.00943107
2025/09/16 22:29:33 : Epoch: 1089, Eval_Loss: 0.00523461
2025/09/16 22:29:34 : Epoch: 1090, Train_Loss: 0.00947583
2025/09/16 22:29:34 : Epoch: 1091, Train_Loss: 0.01105297
2025/09/16 22:29:34 : Epoch: 1092, Train_Loss: 0.00976761
2025/09/16 22:29:34 : Epoch: 1093, Train_Loss: 0.00764926
2025/09/16 22:29:35 : Epoch: 1094, Train_Loss: 0.00917153
2025/09/16 22:29:35 : Epoch: 1094, Eval_Loss: 0.00523425
2025/09/16 22:29:35 : Epoch: 1095, Train_Loss: 0.01187618
2025/09/16 22:29:35 : Epoch: 1096, Train_Loss: 0.00876235
2025/09/16 22:29:35 : Epoch: 1097, Train_Loss: 0.01113240
2025/09/16 22:29:36 : Epoch: 1098, Train_Loss: 0.00884753
2025/09/16 22:29:36 : Epoch: 1099, Train_Loss: 0.00949506
2025/09/16 22:29:36 : Epoch: 1099, Eval_Loss: 0.00523256
2025/09/16 22:29:36 : Epoch: 1100, Train_Loss: 0.00892692
2025/09/16 22:29:36 : Epoch: 1101, Train_Loss: 0.00993402
2025/09/16 22:29:37 : Epoch: 1102, Train_Loss: 0.00796658
2025/09/16 22:29:37 : Epoch: 1103, Train_Loss: 0.01095456
2025/09/16 22:29:37 : Epoch: 1104, Train_Loss: 0.00868212
2025/09/16 22:29:37 : Epoch: 1104, Eval_Loss: 0.00523459
2025/09/16 22:29:38 : Epoch: 1105, Train_Loss: 0.00920880
2025/09/16 22:29:38 : Epoch: 1106, Train_Loss: 0.01277617
2025/09/16 22:29:38 : Epoch: 1107, Train_Loss: 0.01479996
2025/09/16 22:29:38 : Epoch: 1108, Train_Loss: 0.00679570
2025/09/16 22:29:39 : Epoch: 1109, Train_Loss: 0.00901187
2025/09/16 22:29:39 : Epoch: 1109, Eval_Loss: 0.00523290
2025/09/16 22:29:39 : Epoch: 1110, Train_Loss: 0.01083207
2025/09/16 22:29:39 : Epoch: 1111, Train_Loss: 0.00923404
2025/09/16 22:29:39 : Epoch: 1112, Train_Loss: 0.01107065
2025/09/16 22:29:40 : Epoch: 1113, Train_Loss: 0.01186395
2025/09/16 22:29:40 : Epoch: 1114, Train_Loss: 0.01186174
2025/09/16 22:29:40 : Epoch: 1114, Eval_Loss: 0.00523436
2025/09/16 22:29:40 : Epoch: 1115, Train_Loss: 0.00757576
2025/09/16 22:29:40 : Epoch: 1116, Train_Loss: 0.00941803
2025/09/16 22:29:41 : Epoch: 1117, Train_Loss: 0.01096285
2025/09/16 22:29:41 : Epoch: 1118, Train_Loss: 0.00783790
2025/09/16 22:29:41 : Epoch: 1119, Train_Loss: 0.00924701
2025/09/16 22:29:41 : Epoch: 1119, Eval_Loss: 0.00523572
2025/09/16 22:29:41 : Epoch: 1120, Train_Loss: 0.01368136
2025/09/16 22:29:42 : Epoch: 1121, Train_Loss: 0.01065311
2025/09/16 22:29:42 : Epoch: 1122, Train_Loss: 0.01096112
2025/09/16 22:29:42 : Epoch: 1123, Train_Loss: 0.01100734
2025/09/16 22:29:42 : Epoch: 1124, Train_Loss: 0.01063472
2025/09/16 22:29:43 : Epoch: 1124, Eval_Loss: 0.00523809
2025/09/16 22:29:43 : Epoch: 1125, Train_Loss: 0.00889456
2025/09/16 22:29:43 : Epoch: 1126, Train_Loss: 0.01303369
2025/09/16 22:29:43 : Epoch: 1127, Train_Loss: 0.00889341
2025/09/16 22:29:44 : Epoch: 1128, Train_Loss: 0.00791165
2025/09/16 22:29:44 : Epoch: 1129, Train_Loss: 0.00964893
2025/09/16 22:29:44 : Epoch: 1129, Eval_Loss: 0.00523896
2025/09/16 22:29:44 : Epoch: 1130, Train_Loss: 0.01011798
2025/09/16 22:29:44 : Epoch: 1131, Train_Loss: 0.01268983
2025/09/16 22:29:45 : Epoch: 1132, Train_Loss: 0.01033669
2025/09/16 22:29:45 : Epoch: 1133, Train_Loss: 0.00950751
2025/09/16 22:29:45 : Epoch: 1134, Train_Loss: 0.00926455
2025/09/16 22:29:45 : Epoch: 1134, Eval_Loss: 0.00523383
2025/09/16 22:29:45 : Epoch: 1135, Train_Loss: 0.00957250
2025/09/16 22:29:46 : Epoch: 1136, Train_Loss: 0.01028144
2025/09/16 22:29:46 : Epoch: 1137, Train_Loss: 0.00860675
2025/09/16 22:29:46 : Epoch: 1138, Train_Loss: 0.00864390
2025/09/16 22:29:46 : Epoch: 1139, Train_Loss: 0.01078582
2025/09/16 22:29:46 : Epoch: 1139, Eval_Loss: 0.00523286
2025/09/16 22:29:47 : Epoch: 1140, Train_Loss: 0.01246566
2025/09/16 22:29:47 : Epoch: 1141, Train_Loss: 0.00955688
2025/09/16 22:29:47 : Epoch: 1142, Train_Loss: 0.01093626
2025/09/16 22:29:47 : Epoch: 1143, Train_Loss: 0.00846248
2025/09/16 22:29:48 : Epoch: 1144, Train_Loss: 0.01077722
2025/09/16 22:29:48 : Epoch: 1144, Eval_Loss: 0.00523414
2025/09/16 22:29:48 : Epoch: 1145, Train_Loss: 0.00759135
2025/09/16 22:29:48 : Epoch: 1146, Train_Loss: 0.00908820
2025/09/16 22:29:49 : Epoch: 1147, Train_Loss: 0.00884005
2025/09/16 22:29:49 : Epoch: 1148, Train_Loss: 0.00827365
2025/09/16 22:29:49 : Epoch: 1149, Train_Loss: 0.01340958
2025/09/16 22:29:49 : Epoch: 1149, Eval_Loss: 0.00523408
2025/09/16 22:29:49 : Epoch: 1150, Train_Loss: 0.00787433
2025/09/16 22:29:50 : Epoch: 1151, Train_Loss: 0.00965393
2025/09/16 22:29:50 : Epoch: 1152, Train_Loss: 0.01033259
2025/09/16 22:29:50 : Epoch: 1153, Train_Loss: 0.01176180
2025/09/16 22:29:50 : Epoch: 1154, Train_Loss: 0.00773440
2025/09/16 22:29:50 : Epoch: 1154, Eval_Loss: 0.00523740
2025/09/16 22:29:51 : Epoch: 1155, Train_Loss: 0.00888757
2025/09/16 22:29:51 : Epoch: 1156, Train_Loss: 0.00941253
2025/09/16 22:29:51 : Epoch: 1157, Train_Loss: 0.00777390
2025/09/16 22:29:51 : Epoch: 1158, Train_Loss: 0.00867667
2025/09/16 22:29:52 : Epoch: 1159, Train_Loss: 0.00903780
2025/09/16 22:29:52 : Epoch: 1159, Eval_Loss: 0.00523973
2025/09/16 22:29:52 : Epoch: 1160, Train_Loss: 0.01368903
2025/09/16 22:29:52 : Epoch: 1161, Train_Loss: 0.01056981
2025/09/16 22:29:52 : Epoch: 1162, Train_Loss: 0.00691750
2025/09/16 22:29:53 : Epoch: 1163, Train_Loss: 0.01158697
2025/09/16 22:29:53 : Epoch: 1164, Train_Loss: 0.01323636
2025/09/16 22:29:53 : Epoch: 1164, Eval_Loss: 0.00523918
2025/09/16 22:29:53 : Epoch: 1165, Train_Loss: 0.00952082
2025/09/16 22:29:53 : Epoch: 1166, Train_Loss: 0.00963854
2025/09/16 22:29:54 : Epoch: 1167, Train_Loss: 0.01066787
2025/09/16 22:29:54 : Epoch: 1168, Train_Loss: 0.00687549
2025/09/16 22:29:54 : Epoch: 1169, Train_Loss: 0.01130368
2025/09/16 22:29:54 : Epoch: 1169, Eval_Loss: 0.00524310
2025/09/16 22:29:54 : Epoch: 1170, Train_Loss: 0.00825319
2025/09/16 22:29:55 : Epoch: 1171, Train_Loss: 0.01258207
2025/09/16 22:29:55 : Epoch: 1172, Train_Loss: 0.00763456
2025/09/16 22:29:55 : Epoch: 1173, Train_Loss: 0.00752821
2025/09/16 22:29:55 : Epoch: 1174, Train_Loss: 0.01041105
2025/09/16 22:29:55 : Epoch: 1174, Eval_Loss: 0.00524079
2025/09/16 22:29:56 : Epoch: 1175, Train_Loss: 0.01083065
2025/09/16 22:29:56 : Epoch: 1176, Train_Loss: 0.01013644
2025/09/16 22:29:56 : Epoch: 1177, Train_Loss: 0.01070482
2025/09/16 22:29:56 : Epoch: 1178, Train_Loss: 0.01377401
2025/09/16 22:29:57 : Epoch: 1179, Train_Loss: 0.01004532
2025/09/16 22:29:57 : Epoch: 1179, Eval_Loss: 0.00523919
2025/09/16 22:29:57 : Epoch: 1180, Train_Loss: 0.00773510
2025/09/16 22:29:57 : Epoch: 1181, Train_Loss: 0.00963057
2025/09/16 22:29:58 : Epoch: 1182, Train_Loss: 0.01008071
2025/09/16 22:29:58 : Epoch: 1183, Train_Loss: 0.00867583
2025/09/16 22:29:58 : Epoch: 1184, Train_Loss: 0.01314692
2025/09/16 22:29:58 : Epoch: 1184, Eval_Loss: 0.00523858
2025/09/16 22:29:58 : Epoch: 1185, Train_Loss: 0.01073294
2025/09/16 22:29:59 : Epoch: 1186, Train_Loss: 0.00817764
2025/09/16 22:29:59 : Epoch: 1187, Train_Loss: 0.01001682
2025/09/16 22:29:59 : Epoch: 1188, Train_Loss: 0.00909262
2025/09/16 22:29:59 : Epoch: 1189, Train_Loss: 0.00912679
2025/09/16 22:29:59 : Epoch: 1189, Eval_Loss: 0.00524321
2025/09/16 22:30:00 : Epoch: 1190, Train_Loss: 0.00885592
2025/09/16 22:30:00 : Epoch: 1191, Train_Loss: 0.00740292
2025/09/16 22:30:00 : Epoch: 1192, Train_Loss: 0.00874681
2025/09/16 22:30:00 : Epoch: 1193, Train_Loss: 0.01084811
2025/09/16 22:30:01 : Epoch: 1194, Train_Loss: 0.00827998
2025/09/16 22:30:01 : Epoch: 1194, Eval_Loss: 0.00523891
2025/09/16 22:30:01 : Epoch: 1195, Train_Loss: 0.01456636
2025/09/16 22:30:01 : Epoch: 1196, Train_Loss: 0.01016113
2025/09/16 22:30:01 : Epoch: 1197, Train_Loss: 0.00979001
2025/09/16 22:30:02 : Epoch: 1198, Train_Loss: 0.00746037
2025/09/16 22:30:02 : Epoch: 1199, Train_Loss: 0.00880130
2025/09/16 22:30:02 : Epoch: 1199, Eval_Loss: 0.00523862
2025/09/16 22:30:02 : 
Epoch: 1199, save response figures

2025/09/16 22:30:14 : Epoch: 1200, Train_Loss: 0.00858201
2025/09/16 22:30:14 : Epoch: 1201, Train_Loss: 0.01365690
2025/09/16 22:30:15 : Epoch: 1202, Train_Loss: 0.00947167
2025/09/16 22:30:15 : Epoch: 1203, Train_Loss: 0.01505536
2025/09/16 22:30:15 : Epoch: 1204, Train_Loss: 0.01228195
2025/09/16 22:30:15 : Epoch: 1204, Eval_Loss: 0.00523986
2025/09/16 22:30:15 : Epoch: 1205, Train_Loss: 0.00764737
2025/09/16 22:30:16 : Epoch: 1206, Train_Loss: 0.00766789
2025/09/16 22:30:16 : Epoch: 1207, Train_Loss: 0.00927259
2025/09/16 22:30:16 : Epoch: 1208, Train_Loss: 0.00823974
2025/09/16 22:30:16 : Epoch: 1209, Train_Loss: 0.01169903
2025/09/16 22:30:16 : Epoch: 1209, Eval_Loss: 0.00524289
2025/09/16 22:30:17 : Epoch: 1210, Train_Loss: 0.00927520
2025/09/16 22:30:17 : Epoch: 1211, Train_Loss: 0.00754535
2025/09/16 22:30:17 : Epoch: 1212, Train_Loss: 0.01269735
2025/09/16 22:30:17 : Epoch: 1213, Train_Loss: 0.00808523
2025/09/16 22:30:18 : Epoch: 1214, Train_Loss: 0.00804899
2025/09/16 22:30:18 : Epoch: 1214, Eval_Loss: 0.00523780
2025/09/16 22:30:18 : Epoch: 1215, Train_Loss: 0.00708650
2025/09/16 22:30:18 : Epoch: 1216, Train_Loss: 0.00992606
2025/09/16 22:30:18 : Epoch: 1217, Train_Loss: 0.01305345
2025/09/16 22:30:19 : Epoch: 1218, Train_Loss: 0.01074187
2025/09/16 22:30:19 : Epoch: 1219, Train_Loss: 0.00875564
2025/09/16 22:30:19 : Epoch: 1219, Eval_Loss: 0.00523796
2025/09/16 22:30:19 : Epoch: 1220, Train_Loss: 0.00791510
2025/09/16 22:30:20 : Epoch: 1221, Train_Loss: 0.01270414
2025/09/16 22:30:20 : Epoch: 1222, Train_Loss: 0.00869820
2025/09/16 22:30:20 : Epoch: 1223, Train_Loss: 0.00766984
2025/09/16 22:30:20 : Epoch: 1224, Train_Loss: 0.00748123
2025/09/16 22:30:20 : Epoch: 1224, Eval_Loss: 0.00523436
2025/09/16 22:30:21 : Epoch: 1225, Train_Loss: 0.00741601
2025/09/16 22:30:21 : Epoch: 1226, Train_Loss: 0.01380152
2025/09/16 22:30:21 : Epoch: 1227, Train_Loss: 0.00978489
2025/09/16 22:30:21 : Epoch: 1228, Train_Loss: 0.01029977
2025/09/16 22:30:22 : Epoch: 1229, Train_Loss: 0.01192607
2025/09/16 22:30:22 : Epoch: 1229, Eval_Loss: 0.00523346
2025/09/16 22:30:22 : Epoch: 1230, Train_Loss: 0.00938279
2025/09/16 22:30:22 : Epoch: 1231, Train_Loss: 0.00815221
2025/09/16 22:30:22 : Epoch: 1232, Train_Loss: 0.00960314
2025/09/16 22:30:23 : Epoch: 1233, Train_Loss: 0.00704936
2025/09/16 22:30:23 : Epoch: 1234, Train_Loss: 0.01047810
2025/09/16 22:30:23 : Epoch: 1234, Eval_Loss: 0.00523384
2025/09/16 22:30:23 : Epoch: 1235, Train_Loss: 0.00885399
2025/09/16 22:30:23 : Epoch: 1236, Train_Loss: 0.00770994
2025/09/16 22:30:24 : Epoch: 1237, Train_Loss: 0.00942415
2025/09/16 22:30:24 : Epoch: 1238, Train_Loss: 0.01240138
2025/09/16 22:30:24 : Epoch: 1239, Train_Loss: 0.00707903
2025/09/16 22:30:24 : Epoch: 1239, Eval_Loss: 0.00523288
2025/09/16 22:30:24 : Epoch: 1240, Train_Loss: 0.00834671
2025/09/16 22:30:25 : Epoch: 1241, Train_Loss: 0.00969750
2025/09/16 22:30:25 : Epoch: 1242, Train_Loss: 0.00730154
2025/09/16 22:30:25 : Epoch: 1243, Train_Loss: 0.00863458
2025/09/16 22:30:25 : Epoch: 1244, Train_Loss: 0.00885448
2025/09/16 22:30:26 : Epoch: 1244, Eval_Loss: 0.00523388
2025/09/16 22:30:26 : Epoch: 1245, Train_Loss: 0.00932173
2025/09/16 22:30:26 : Epoch: 1246, Train_Loss: 0.00816829
2025/09/16 22:30:26 : Epoch: 1247, Train_Loss: 0.01038614
2025/09/16 22:30:26 : Epoch: 1248, Train_Loss: 0.01017909
2025/09/16 22:30:27 : Epoch: 1249, Train_Loss: 0.01216302
2025/09/16 22:30:27 : Epoch: 1249, Eval_Loss: 0.00523845
2025/09/16 22:30:27 : Epoch: 1250, Train_Loss: 0.01194337
2025/09/16 22:30:27 : Epoch: 1251, Train_Loss: 0.01120725
2025/09/16 22:30:28 : Epoch: 1252, Train_Loss: 0.01205583
2025/09/16 22:30:28 : Epoch: 1253, Train_Loss: 0.01040963
2025/09/16 22:30:28 : Epoch: 1254, Train_Loss: 0.00794022
2025/09/16 22:30:28 : Epoch: 1254, Eval_Loss: 0.00523974
2025/09/16 22:30:28 : Epoch: 1255, Train_Loss: 0.00987654
2025/09/16 22:30:29 : Epoch: 1256, Train_Loss: 0.00910240
2025/09/16 22:30:29 : Epoch: 1257, Train_Loss: 0.01032365
2025/09/16 22:30:29 : Epoch: 1258, Train_Loss: 0.01081125
2025/09/16 22:30:29 : Epoch: 1259, Train_Loss: 0.00830803
2025/09/16 22:30:29 : Epoch: 1259, Eval_Loss: 0.00523852
2025/09/16 22:30:30 : Epoch: 1260, Train_Loss: 0.01315955
2025/09/16 22:30:30 : Epoch: 1261, Train_Loss: 0.00858796
2025/09/16 22:30:30 : Epoch: 1262, Train_Loss: 0.01158032
2025/09/16 22:30:30 : Epoch: 1263, Train_Loss: 0.00762480
2025/09/16 22:30:31 : Epoch: 1264, Train_Loss: 0.00808925
2025/09/16 22:30:31 : Epoch: 1264, Eval_Loss: 0.00523557
2025/09/16 22:30:31 : Epoch: 1265, Train_Loss: 0.00904139
2025/09/16 22:30:31 : Epoch: 1266, Train_Loss: 0.00672115
2025/09/16 22:30:31 : Epoch: 1267, Train_Loss: 0.01274764
2025/09/16 22:30:32 : Epoch: 1268, Train_Loss: 0.01253111
2025/09/16 22:30:32 : Epoch: 1269, Train_Loss: 0.00962928
2025/09/16 22:30:32 : Epoch: 1269, Eval_Loss: 0.00523463
2025/09/16 22:30:32 : Epoch: 1270, Train_Loss: 0.01049809
2025/09/16 22:30:33 : Epoch: 1271, Train_Loss: 0.00781564
2025/09/16 22:30:33 : Epoch: 1272, Train_Loss: 0.00914162
2025/09/16 22:30:33 : Epoch: 1273, Train_Loss: 0.00701493
2025/09/16 22:30:33 : Epoch: 1274, Train_Loss: 0.00825872
2025/09/16 22:30:33 : Epoch: 1274, Eval_Loss: 0.00523914
2025/09/16 22:30:34 : Epoch: 1275, Train_Loss: 0.01000720
2025/09/16 22:30:34 : Epoch: 1276, Train_Loss: 0.01565093
2025/09/16 22:30:34 : Epoch: 1277, Train_Loss: 0.01037211
2025/09/16 22:30:34 : Epoch: 1278, Train_Loss: 0.00909088
2025/09/16 22:30:35 : Epoch: 1279, Train_Loss: 0.01241232
2025/09/16 22:30:35 : Epoch: 1279, Eval_Loss: 0.00523957
2025/09/16 22:30:35 : Epoch: 1280, Train_Loss: 0.00932640
2025/09/16 22:30:35 : Epoch: 1281, Train_Loss: 0.00790782
2025/09/16 22:30:35 : Epoch: 1282, Train_Loss: 0.01014453
2025/09/16 22:30:36 : Epoch: 1283, Train_Loss: 0.00841114
2025/09/16 22:30:36 : Epoch: 1284, Train_Loss: 0.01102827
2025/09/16 22:30:36 : Epoch: 1284, Eval_Loss: 0.00523859
2025/09/16 22:30:36 : Epoch: 1285, Train_Loss: 0.00681915
2025/09/16 22:30:36 : Epoch: 1286, Train_Loss: 0.00746174
2025/09/16 22:30:37 : Epoch: 1287, Train_Loss: 0.00879772
2025/09/16 22:30:37 : Epoch: 1288, Train_Loss: 0.01009052
2025/09/16 22:30:37 : Epoch: 1289, Train_Loss: 0.00842448
2025/09/16 22:30:37 : Epoch: 1289, Eval_Loss: 0.00523834
2025/09/16 22:30:37 : Epoch: 1290, Train_Loss: 0.01170145
2025/09/16 22:30:38 : Epoch: 1291, Train_Loss: 0.00706568
2025/09/16 22:30:38 : Epoch: 1292, Train_Loss: 0.01106733
2025/09/16 22:30:38 : Epoch: 1293, Train_Loss: 0.01102287
2025/09/16 22:30:38 : Epoch: 1294, Train_Loss: 0.01321965
2025/09/16 22:30:39 : Epoch: 1294, Eval_Loss: 0.00524040
2025/09/16 22:30:39 : Epoch: 1295, Train_Loss: 0.00865480
2025/09/16 22:30:39 : Epoch: 1296, Train_Loss: 0.00796549
2025/09/16 22:30:39 : Epoch: 1297, Train_Loss: 0.01093631
2025/09/16 22:30:39 : Epoch: 1298, Train_Loss: 0.00820486
2025/09/16 22:30:40 : Epoch: 1299, Train_Loss: 0.01464148
2025/09/16 22:30:40 : Epoch: 1299, Eval_Loss: 0.00524037
2025/09/16 22:30:40 : Epoch: 1300, Train_Loss: 0.00768664
2025/09/16 22:30:40 : Epoch: 1301, Train_Loss: 0.01223491
2025/09/16 22:30:41 : Epoch: 1302, Train_Loss: 0.00962709
2025/09/16 22:30:41 : Epoch: 1303, Train_Loss: 0.01046772
2025/09/16 22:30:41 : Epoch: 1304, Train_Loss: 0.00823685
2025/09/16 22:30:41 : Epoch: 1304, Eval_Loss: 0.00524202
2025/09/16 22:30:41 : Epoch: 1305, Train_Loss: 0.01166464
2025/09/16 22:30:42 : Epoch: 1306, Train_Loss: 0.01317388
2025/09/16 22:30:42 : Epoch: 1307, Train_Loss: 0.01031054
2025/09/16 22:30:42 : Epoch: 1308, Train_Loss: 0.01207538
2025/09/16 22:30:42 : Epoch: 1309, Train_Loss: 0.00921811
2025/09/16 22:30:42 : Epoch: 1309, Eval_Loss: 0.00524830
2025/09/16 22:30:43 : Epoch: 1310, Train_Loss: 0.00850989
2025/09/16 22:30:43 : Epoch: 1311, Train_Loss: 0.00904529
2025/09/16 22:30:43 : Epoch: 1312, Train_Loss: 0.01026191
2025/09/16 22:30:43 : Epoch: 1313, Train_Loss: 0.00789058
2025/09/16 22:30:44 : Epoch: 1314, Train_Loss: 0.00981152
2025/09/16 22:30:44 : Epoch: 1314, Eval_Loss: 0.00524264
2025/09/16 22:30:44 : Epoch: 1315, Train_Loss: 0.00934246
2025/09/16 22:30:44 : Epoch: 1316, Train_Loss: 0.01425264
2025/09/16 22:30:45 : Epoch: 1317, Train_Loss: 0.00850611
2025/09/16 22:30:45 : Epoch: 1318, Train_Loss: 0.01020803
2025/09/16 22:30:45 : Epoch: 1319, Train_Loss: 0.00836711
2025/09/16 22:30:45 : Epoch: 1319, Eval_Loss: 0.00523923
2025/09/16 22:30:45 : Epoch: 1320, Train_Loss: 0.01205152
2025/09/16 22:30:46 : Epoch: 1321, Train_Loss: 0.01269041
2025/09/16 22:30:46 : Epoch: 1322, Train_Loss: 0.01379820
2025/09/16 22:30:46 : Epoch: 1323, Train_Loss: 0.01118717
2025/09/16 22:30:46 : Epoch: 1324, Train_Loss: 0.01258036
2025/09/16 22:30:46 : Epoch: 1324, Eval_Loss: 0.00524225
2025/09/16 22:30:47 : Epoch: 1325, Train_Loss: 0.00975243
2025/09/16 22:30:47 : Epoch: 1326, Train_Loss: 0.00712164
2025/09/16 22:30:47 : Epoch: 1327, Train_Loss: 0.01430723
2025/09/16 22:30:47 : Epoch: 1328, Train_Loss: 0.00913938
2025/09/16 22:30:48 : Epoch: 1329, Train_Loss: 0.00930904
2025/09/16 22:30:48 : Epoch: 1329, Eval_Loss: 0.00525073
2025/09/16 22:30:48 : Epoch: 1330, Train_Loss: 0.01100014
2025/09/16 22:30:48 : Epoch: 1331, Train_Loss: 0.01220797
2025/09/16 22:30:48 : Epoch: 1332, Train_Loss: 0.01010596
2025/09/16 22:30:49 : Epoch: 1333, Train_Loss: 0.00882778
2025/09/16 22:30:49 : Epoch: 1334, Train_Loss: 0.01103025
2025/09/16 22:30:49 : Epoch: 1334, Eval_Loss: 0.00524724
2025/09/16 22:30:49 : Epoch: 1335, Train_Loss: 0.00916863
2025/09/16 22:30:49 : Epoch: 1336, Train_Loss: 0.01087244
2025/09/16 22:30:50 : Epoch: 1337, Train_Loss: 0.01079834
2025/09/16 22:30:50 : Epoch: 1338, Train_Loss: 0.00787937
2025/09/16 22:30:50 : Epoch: 1339, Train_Loss: 0.01328536
2025/09/16 22:30:50 : Epoch: 1339, Eval_Loss: 0.00524405
2025/09/16 22:30:51 : Epoch: 1340, Train_Loss: 0.00884993
2025/09/16 22:30:51 : Epoch: 1341, Train_Loss: 0.00734321
2025/09/16 22:30:51 : Epoch: 1342, Train_Loss: 0.00927831
2025/09/16 22:30:51 : Epoch: 1343, Train_Loss: 0.01232810
2025/09/16 22:30:52 : Epoch: 1344, Train_Loss: 0.01194322
2025/09/16 22:30:52 : Epoch: 1344, Eval_Loss: 0.00524657
2025/09/16 22:30:52 : Epoch: 1345, Train_Loss: 0.01142423
2025/09/16 22:30:52 : Epoch: 1346, Train_Loss: 0.00851119
2025/09/16 22:30:52 : Epoch: 1347, Train_Loss: 0.00971338
2025/09/16 22:30:53 : Epoch: 1348, Train_Loss: 0.01185750
2025/09/16 22:30:53 : Epoch: 1349, Train_Loss: 0.00957828
2025/09/16 22:30:53 : Epoch: 1349, Eval_Loss: 0.00525099
2025/09/16 22:30:53 : Epoch: 1350, Train_Loss: 0.01326379
2025/09/16 22:30:53 : Epoch: 1351, Train_Loss: 0.01029831
2025/09/16 22:30:54 : Epoch: 1352, Train_Loss: 0.01114594
2025/09/16 22:30:54 : Epoch: 1353, Train_Loss: 0.00757463
2025/09/16 22:30:54 : Epoch: 1354, Train_Loss: 0.01052060
2025/09/16 22:30:54 : Epoch: 1354, Eval_Loss: 0.00525766
2025/09/16 22:30:54 : Epoch: 1355, Train_Loss: 0.01102607
2025/09/16 22:30:55 : Epoch: 1356, Train_Loss: 0.01136892
2025/09/16 22:30:55 : Epoch: 1357, Train_Loss: 0.01100336
2025/09/16 22:30:55 : Epoch: 1358, Train_Loss: 0.00913331
2025/09/16 22:30:55 : Epoch: 1359, Train_Loss: 0.01127049
2025/09/16 22:30:56 : Epoch: 1359, Eval_Loss: 0.00525076
2025/09/16 22:30:56 : Epoch: 1360, Train_Loss: 0.00814891
2025/09/16 22:30:56 : Epoch: 1361, Train_Loss: 0.01173674
2025/09/16 22:30:56 : Epoch: 1362, Train_Loss: 0.01240448
2025/09/16 22:30:57 : Epoch: 1363, Train_Loss: 0.01102766
2025/09/16 22:30:57 : Epoch: 1364, Train_Loss: 0.00838513
2025/09/16 22:30:57 : Epoch: 1364, Eval_Loss: 0.00525410
2025/09/16 22:30:57 : Epoch: 1365, Train_Loss: 0.01183713
2025/09/16 22:30:57 : Epoch: 1366, Train_Loss: 0.01198175
2025/09/16 22:30:58 : Epoch: 1367, Train_Loss: 0.01328635
2025/09/16 22:30:58 : Epoch: 1368, Train_Loss: 0.01145406
2025/09/16 22:30:58 : Epoch: 1369, Train_Loss: 0.01035199
2025/09/16 22:30:58 : Epoch: 1369, Eval_Loss: 0.00529016
2025/09/16 22:30:58 : Epoch: 1370, Train_Loss: 0.00900949
2025/09/16 22:30:59 : Epoch: 1371, Train_Loss: 0.00987464
2025/09/16 22:30:59 : Epoch: 1372, Train_Loss: 0.00994930
2025/09/16 22:30:59 : Epoch: 1373, Train_Loss: 0.01145524
2025/09/16 22:30:59 : Epoch: 1374, Train_Loss: 0.00996863
2025/09/16 22:31:00 : Epoch: 1374, Eval_Loss: 0.00527931
2025/09/16 22:31:00 : Epoch: 1375, Train_Loss: 0.00926563
2025/09/16 22:31:00 : Epoch: 1376, Train_Loss: 0.01088556
2025/09/16 22:31:00 : Epoch: 1377, Train_Loss: 0.00774217
2025/09/16 22:31:01 : Epoch: 1378, Train_Loss: 0.00820531
2025/09/16 22:31:01 : Epoch: 1379, Train_Loss: 0.01255677
2025/09/16 22:31:01 : Epoch: 1379, Eval_Loss: 0.00525175
2025/09/16 22:31:01 : Epoch: 1380, Train_Loss: 0.00770324
2025/09/16 22:31:01 : Epoch: 1381, Train_Loss: 0.00902360
2025/09/16 22:31:02 : Epoch: 1382, Train_Loss: 0.01331234
2025/09/16 22:31:02 : Epoch: 1383, Train_Loss: 0.00816607
2025/09/16 22:31:02 : Epoch: 1384, Train_Loss: 0.00816480
2025/09/16 22:31:02 : Epoch: 1384, Eval_Loss: 0.00524516
2025/09/16 22:31:02 : Epoch: 1385, Train_Loss: 0.00776145
2025/09/16 22:31:03 : Epoch: 1386, Train_Loss: 0.00958863
2025/09/16 22:31:03 : Epoch: 1387, Train_Loss: 0.01010941
2025/09/16 22:31:03 : Epoch: 1388, Train_Loss: 0.00896245
2025/09/16 22:31:03 : Epoch: 1389, Train_Loss: 0.01342369
2025/09/16 22:31:03 : Epoch: 1389, Eval_Loss: 0.00523749
2025/09/16 22:31:04 : Epoch: 1390, Train_Loss: 0.00723038
2025/09/16 22:31:04 : Epoch: 1391, Train_Loss: 0.00784094
2025/09/16 22:31:04 : Epoch: 1392, Train_Loss: 0.00876133
2025/09/16 22:31:04 : Epoch: 1393, Train_Loss: 0.01110171
2025/09/16 22:31:05 : Epoch: 1394, Train_Loss: 0.00847006
2025/09/16 22:31:05 : Epoch: 1394, Eval_Loss: 0.00523861
2025/09/16 22:31:05 : Epoch: 1395, Train_Loss: 0.00754532
2025/09/16 22:31:05 : Epoch: 1396, Train_Loss: 0.01033549
2025/09/16 22:31:05 : Epoch: 1397, Train_Loss: 0.01091248
2025/09/16 22:31:06 : Epoch: 1398, Train_Loss: 0.01173911
2025/09/16 22:31:06 : Epoch: 1399, Train_Loss: 0.00890051
2025/09/16 22:31:06 : Epoch: 1399, Eval_Loss: 0.00523975
2025/09/16 22:31:06 : Epoch: 1400, Train_Loss: 0.01181777
2025/09/16 22:31:07 : Epoch: 1401, Train_Loss: 0.00984231
2025/09/16 22:31:07 : Epoch: 1402, Train_Loss: 0.01053821
2025/09/16 22:31:07 : Epoch: 1403, Train_Loss: 0.00720061
2025/09/16 22:31:07 : Epoch: 1404, Train_Loss: 0.00973503
2025/09/16 22:31:07 : Epoch: 1404, Eval_Loss: 0.00524065
2025/09/16 22:31:08 : Epoch: 1405, Train_Loss: 0.00856654
2025/09/16 22:31:08 : Epoch: 1406, Train_Loss: 0.01020733
2025/09/16 22:31:08 : Epoch: 1407, Train_Loss: 0.01255254
2025/09/16 22:31:08 : Epoch: 1408, Train_Loss: 0.01220584
2025/09/16 22:31:09 : Epoch: 1409, Train_Loss: 0.00756409
2025/09/16 22:31:09 : Epoch: 1409, Eval_Loss: 0.00524127
2025/09/16 22:31:09 : Epoch: 1410, Train_Loss: 0.00754343
2025/09/16 22:31:09 : Epoch: 1411, Train_Loss: 0.00873072
2025/09/16 22:31:09 : Epoch: 1412, Train_Loss: 0.00961405
2025/09/16 22:31:10 : Epoch: 1413, Train_Loss: 0.00953967
2025/09/16 22:31:10 : Epoch: 1414, Train_Loss: 0.00994063
2025/09/16 22:31:10 : Epoch: 1414, Eval_Loss: 0.00524192
2025/09/16 22:31:10 : Epoch: 1415, Train_Loss: 0.01179489
2025/09/16 22:31:11 : Epoch: 1416, Train_Loss: 0.01091902
2025/09/16 22:31:11 : Epoch: 1417, Train_Loss: 0.00763458
2025/09/16 22:31:11 : Epoch: 1418, Train_Loss: 0.00931648
2025/09/16 22:31:11 : Epoch: 1419, Train_Loss: 0.01177492
2025/09/16 22:31:11 : Epoch: 1419, Eval_Loss: 0.00523968
2025/09/16 22:31:12 : Epoch: 1420, Train_Loss: 0.01201575
2025/09/16 22:31:12 : Epoch: 1421, Train_Loss: 0.00897384
2025/09/16 22:31:12 : Epoch: 1422, Train_Loss: 0.00853206
2025/09/16 22:31:12 : Epoch: 1423, Train_Loss: 0.00876434
2025/09/16 22:31:13 : Epoch: 1424, Train_Loss: 0.00943619
2025/09/16 22:31:13 : Epoch: 1424, Eval_Loss: 0.00523708
2025/09/16 22:31:13 : Epoch: 1425, Train_Loss: 0.00930436
2025/09/16 22:31:13 : Epoch: 1426, Train_Loss: 0.01367465
2025/09/16 22:31:13 : Epoch: 1427, Train_Loss: 0.00797662
2025/09/16 22:31:14 : Epoch: 1428, Train_Loss: 0.01050898
2025/09/16 22:31:14 : Epoch: 1429, Train_Loss: 0.00916599
2025/09/16 22:31:14 : Epoch: 1429, Eval_Loss: 0.00523888
2025/09/16 22:31:14 : Epoch: 1430, Train_Loss: 0.01258539
2025/09/16 22:31:15 : Epoch: 1431, Train_Loss: 0.01294228
2025/09/16 22:31:15 : Epoch: 1432, Train_Loss: 0.01325027
2025/09/16 22:31:15 : Epoch: 1433, Train_Loss: 0.00859008
2025/09/16 22:31:15 : Epoch: 1434, Train_Loss: 0.01076414
2025/09/16 22:31:15 : Epoch: 1434, Eval_Loss: 0.00524605
2025/09/16 22:31:16 : Epoch: 1435, Train_Loss: 0.00726245
2025/09/16 22:31:16 : Epoch: 1436, Train_Loss: 0.00853010
2025/09/16 22:31:16 : Epoch: 1437, Train_Loss: 0.00976047
2025/09/16 22:31:16 : Epoch: 1438, Train_Loss: 0.00892327
2025/09/16 22:31:17 : Epoch: 1439, Train_Loss: 0.01025607
2025/09/16 22:31:17 : Epoch: 1439, Eval_Loss: 0.00524157
2025/09/16 22:31:17 : Epoch: 1440, Train_Loss: 0.00826433
2025/09/16 22:31:17 : Epoch: 1441, Train_Loss: 0.01225270
2025/09/16 22:31:17 : Epoch: 1442, Train_Loss: 0.01323060
2025/09/16 22:31:18 : Epoch: 1443, Train_Loss: 0.01281033
2025/09/16 22:31:18 : Epoch: 1444, Train_Loss: 0.00818862
2025/09/16 22:31:18 : Epoch: 1444, Eval_Loss: 0.00523546
2025/09/16 22:31:18 : Epoch: 1445, Train_Loss: 0.00931314
2025/09/16 22:31:18 : Epoch: 1446, Train_Loss: 0.00874885
2025/09/16 22:31:19 : Epoch: 1447, Train_Loss: 0.00746477
2025/09/16 22:31:19 : Epoch: 1448, Train_Loss: 0.00902119
2025/09/16 22:31:19 : Epoch: 1449, Train_Loss: 0.00896086
2025/09/16 22:31:19 : Epoch: 1449, Eval_Loss: 0.00523452
2025/09/16 22:31:19 : Epoch: 1450, Train_Loss: 0.00834413
2025/09/16 22:31:20 : Epoch: 1451, Train_Loss: 0.00898956
2025/09/16 22:31:20 : Epoch: 1452, Train_Loss: 0.00949229
2025/09/16 22:31:20 : Epoch: 1453, Train_Loss: 0.01206754
2025/09/16 22:31:20 : Epoch: 1454, Train_Loss: 0.00854105
2025/09/16 22:31:21 : Epoch: 1454, Eval_Loss: 0.00523349
2025/09/16 22:31:21 : Epoch: 1455, Train_Loss: 0.01185574
2025/09/16 22:31:21 : Epoch: 1456, Train_Loss: 0.00757390
2025/09/16 22:31:21 : Epoch: 1457, Train_Loss: 0.00791693
2025/09/16 22:31:22 : Epoch: 1458, Train_Loss: 0.00932532
2025/09/16 22:31:22 : Epoch: 1459, Train_Loss: 0.01405055
2025/09/16 22:31:22 : Epoch: 1459, Eval_Loss: 0.00523471
2025/09/16 22:31:22 : Epoch: 1460, Train_Loss: 0.00962158
2025/09/16 22:31:22 : Epoch: 1461, Train_Loss: 0.01436991
2025/09/16 22:31:23 : Epoch: 1462, Train_Loss: 0.00784005
2025/09/16 22:31:23 : Epoch: 1463, Train_Loss: 0.01062943
2025/09/16 22:31:23 : Epoch: 1464, Train_Loss: 0.00888226
2025/09/16 22:31:23 : Epoch: 1464, Eval_Loss: 0.00523663
2025/09/16 22:31:23 : Epoch: 1465, Train_Loss: 0.01085231
2025/09/16 22:31:24 : Epoch: 1466, Train_Loss: 0.00756763
2025/09/16 22:31:24 : Epoch: 1467, Train_Loss: 0.00805157
2025/09/16 22:31:24 : Epoch: 1468, Train_Loss: 0.01164487
2025/09/16 22:31:24 : Epoch: 1469, Train_Loss: 0.00726651
2025/09/16 22:31:24 : Epoch: 1469, Eval_Loss: 0.00523799
2025/09/16 22:31:25 : Epoch: 1470, Train_Loss: 0.00962532
2025/09/16 22:31:25 : Epoch: 1471, Train_Loss: 0.00926016
2025/09/16 22:31:25 : Epoch: 1472, Train_Loss: 0.00783513
2025/09/16 22:31:25 : Epoch: 1473, Train_Loss: 0.01107952
2025/09/16 22:31:26 : Epoch: 1474, Train_Loss: 0.01134615
2025/09/16 22:31:26 : Epoch: 1474, Eval_Loss: 0.00523928
2025/09/16 22:31:26 : Epoch: 1475, Train_Loss: 0.00979534
2025/09/16 22:31:26 : Epoch: 1476, Train_Loss: 0.00844656
2025/09/16 22:31:26 : Epoch: 1477, Train_Loss: 0.00985942
2025/09/16 22:31:27 : Epoch: 1478, Train_Loss: 0.01124692
2025/09/16 22:31:27 : Epoch: 1479, Train_Loss: 0.00960135
2025/09/16 22:31:27 : Epoch: 1479, Eval_Loss: 0.00523531
2025/09/16 22:31:27 : Epoch: 1480, Train_Loss: 0.00687912
2025/09/16 22:31:27 : Epoch: 1481, Train_Loss: 0.00853872
2025/09/16 22:31:28 : Epoch: 1482, Train_Loss: 0.00988648
2025/09/16 22:31:28 : Epoch: 1483, Train_Loss: 0.00781160
2025/09/16 22:31:28 : Epoch: 1484, Train_Loss: 0.00677281
2025/09/16 22:31:28 : Epoch: 1484, Eval_Loss: 0.00523362
2025/09/16 22:31:28 : Epoch: 1485, Train_Loss: 0.00771078
2025/09/16 22:31:29 : Epoch: 1486, Train_Loss: 0.00756378
2025/09/16 22:31:29 : Epoch: 1487, Train_Loss: 0.00840698
2025/09/16 22:31:29 : Epoch: 1488, Train_Loss: 0.01226486
2025/09/16 22:31:29 : Epoch: 1489, Train_Loss: 0.00969756
2025/09/16 22:31:30 : Epoch: 1489, Eval_Loss: 0.00523185
2025/09/16 22:31:30 : Epoch: 1490, Train_Loss: 0.00907105
2025/09/16 22:31:30 : Epoch: 1491, Train_Loss: 0.01056772
2025/09/16 22:31:30 : Epoch: 1492, Train_Loss: 0.00708891
2025/09/16 22:31:31 : Epoch: 1493, Train_Loss: 0.00833099
2025/09/16 22:31:31 : Epoch: 1494, Train_Loss: 0.01250964
2025/09/16 22:31:31 : Epoch: 1494, Eval_Loss: 0.00523263
2025/09/16 22:31:31 : Epoch: 1495, Train_Loss: 0.01046368
2025/09/16 22:31:31 : Epoch: 1496, Train_Loss: 0.01049288
2025/09/16 22:31:32 : Epoch: 1497, Train_Loss: 0.00830409
2025/09/16 22:31:32 : Epoch: 1498, Train_Loss: 0.00921595
2025/09/16 22:31:32 : Epoch: 1499, Train_Loss: 0.01320457
2025/09/16 22:31:32 : Epoch: 1499, Eval_Loss: 0.00523472
2025/09/16 22:31:32 : Epoch: 1500, Train_Loss: 0.00969000
2025/09/16 22:31:33 : Epoch: 1501, Train_Loss: 0.00767166
2025/09/16 22:31:33 : Epoch: 1502, Train_Loss: 0.00774930
2025/09/16 22:31:33 : Epoch: 1503, Train_Loss: 0.01039668
2025/09/16 22:31:33 : Epoch: 1504, Train_Loss: 0.01557352
2025/09/16 22:31:33 : Epoch: 1504, Eval_Loss: 0.00523682
2025/09/16 22:31:34 : Epoch: 1505, Train_Loss: 0.00905772
2025/09/16 22:31:34 : Epoch: 1506, Train_Loss: 0.01307554
2025/09/16 22:31:34 : Epoch: 1507, Train_Loss: 0.00896164
2025/09/16 22:31:34 : Epoch: 1508, Train_Loss: 0.01139291
2025/09/16 22:31:35 : Epoch: 1509, Train_Loss: 0.00944687
2025/09/16 22:31:35 : Epoch: 1509, Eval_Loss: 0.00524009
2025/09/16 22:31:35 : Epoch: 1510, Train_Loss: 0.01198015
2025/09/16 22:31:35 : Epoch: 1511, Train_Loss: 0.01089812
2025/09/16 22:31:36 : Epoch: 1512, Train_Loss: 0.00808481
2025/09/16 22:31:36 : Epoch: 1513, Train_Loss: 0.00764343
2025/09/16 22:31:36 : Epoch: 1514, Train_Loss: 0.01312815
2025/09/16 22:31:36 : Epoch: 1514, Eval_Loss: 0.00523560
2025/09/16 22:31:36 : Epoch: 1515, Train_Loss: 0.01058423
2025/09/16 22:31:37 : Epoch: 1516, Train_Loss: 0.01155153
2025/09/16 22:31:37 : Epoch: 1517, Train_Loss: 0.01132999
2025/09/16 22:31:37 : Epoch: 1518, Train_Loss: 0.01144422
2025/09/16 22:31:37 : Epoch: 1519, Train_Loss: 0.01238357
2025/09/16 22:31:37 : Epoch: 1519, Eval_Loss: 0.00523772
2025/09/16 22:31:38 : Epoch: 1520, Train_Loss: 0.00840975
2025/09/16 22:31:38 : Epoch: 1521, Train_Loss: 0.00893153
2025/09/16 22:31:38 : Epoch: 1522, Train_Loss: 0.01002057
2025/09/16 22:31:38 : Epoch: 1523, Train_Loss: 0.00965108
2025/09/16 22:31:39 : Epoch: 1524, Train_Loss: 0.00938848
2025/09/16 22:31:39 : Epoch: 1524, Eval_Loss: 0.00524041
2025/09/16 22:31:39 : Epoch: 1525, Train_Loss: 0.00816337
2025/09/16 22:31:39 : Epoch: 1526, Train_Loss: 0.00720537
2025/09/16 22:31:39 : Epoch: 1527, Train_Loss: 0.00790188
2025/09/16 22:31:40 : Epoch: 1528, Train_Loss: 0.01238106
2025/09/16 22:31:40 : Epoch: 1529, Train_Loss: 0.00747163
2025/09/16 22:31:40 : Epoch: 1529, Eval_Loss: 0.00523696
2025/09/16 22:31:40 : Epoch: 1530, Train_Loss: 0.01366197
2025/09/16 22:31:40 : Epoch: 1531, Train_Loss: 0.01060705
2025/09/16 22:31:41 : Epoch: 1532, Train_Loss: 0.01293955
2025/09/16 22:31:41 : Epoch: 1533, Train_Loss: 0.00929754
2025/09/16 22:31:41 : Epoch: 1534, Train_Loss: 0.01066650
2025/09/16 22:31:41 : Epoch: 1534, Eval_Loss: 0.00524095
2025/09/16 22:31:42 : Epoch: 1535, Train_Loss: 0.01118689
2025/09/16 22:31:42 : Epoch: 1536, Train_Loss: 0.01110384
2025/09/16 22:31:42 : Epoch: 1537, Train_Loss: 0.00702801
2025/09/16 22:31:42 : Epoch: 1538, Train_Loss: 0.01182058
2025/09/16 22:31:43 : Epoch: 1539, Train_Loss: 0.00963304
2025/09/16 22:31:43 : Epoch: 1539, Eval_Loss: 0.00523965
2025/09/16 22:31:43 : Epoch: 1540, Train_Loss: 0.00895740
2025/09/16 22:31:43 : Epoch: 1541, Train_Loss: 0.01367733
2025/09/16 22:31:43 : Epoch: 1542, Train_Loss: 0.01448523
2025/09/16 22:31:44 : Epoch: 1543, Train_Loss: 0.00908115
2025/09/16 22:31:44 : Epoch: 1544, Train_Loss: 0.01445851
2025/09/16 22:31:44 : Epoch: 1544, Eval_Loss: 0.00524034
2025/09/16 22:31:44 : Epoch: 1545, Train_Loss: 0.00870809
2025/09/16 22:31:44 : Epoch: 1546, Train_Loss: 0.01239138
2025/09/16 22:31:45 : Epoch: 1547, Train_Loss: 0.00863267
2025/09/16 22:31:45 : Epoch: 1548, Train_Loss: 0.00868870
2025/09/16 22:31:45 : Epoch: 1549, Train_Loss: 0.01009601
2025/09/16 22:31:45 : Epoch: 1549, Eval_Loss: 0.00525167
2025/09/16 22:31:45 : Epoch: 1550, Train_Loss: 0.00894016
2025/09/16 22:31:46 : Epoch: 1551, Train_Loss: 0.01263411
2025/09/16 22:31:46 : Epoch: 1552, Train_Loss: 0.00900287
2025/09/16 22:31:46 : Epoch: 1553, Train_Loss: 0.00904491
2025/09/16 22:31:46 : Epoch: 1554, Train_Loss: 0.00975598
2025/09/16 22:31:47 : Epoch: 1554, Eval_Loss: 0.00525435
2025/09/16 22:31:47 : Epoch: 1555, Train_Loss: 0.01183596
2025/09/16 22:31:47 : Epoch: 1556, Train_Loss: 0.00883669
2025/09/16 22:31:47 : Epoch: 1557, Train_Loss: 0.00744473
2025/09/16 22:31:47 : Epoch: 1558, Train_Loss: 0.01051766
2025/09/16 22:31:48 : Epoch: 1559, Train_Loss: 0.00793058
2025/09/16 22:31:48 : Epoch: 1559, Eval_Loss: 0.00524450
2025/09/16 22:31:48 : Epoch: 1560, Train_Loss: 0.00923880
2025/09/16 22:31:48 : Epoch: 1561, Train_Loss: 0.00943406
2025/09/16 22:31:49 : Epoch: 1562, Train_Loss: 0.00864579
2025/09/16 22:31:49 : Epoch: 1563, Train_Loss: 0.01371253
2025/09/16 22:31:49 : Epoch: 1564, Train_Loss: 0.00955762
2025/09/16 22:31:49 : Epoch: 1564, Eval_Loss: 0.00523713
2025/09/16 22:31:49 : Epoch: 1565, Train_Loss: 0.01192918
2025/09/16 22:31:50 : Epoch: 1566, Train_Loss: 0.00840127
2025/09/16 22:31:50 : Epoch: 1567, Train_Loss: 0.00835069
2025/09/16 22:31:50 : Epoch: 1568, Train_Loss: 0.01182028
2025/09/16 22:31:50 : Epoch: 1569, Train_Loss: 0.00826766
2025/09/16 22:31:50 : Epoch: 1569, Eval_Loss: 0.00523995
2025/09/16 22:31:51 : Epoch: 1570, Train_Loss: 0.00777083
2025/09/16 22:31:51 : Epoch: 1571, Train_Loss: 0.00810453
2025/09/16 22:31:51 : Epoch: 1572, Train_Loss: 0.01067760
2025/09/16 22:31:51 : Epoch: 1573, Train_Loss: 0.00994652
2025/09/16 22:31:52 : Epoch: 1574, Train_Loss: 0.01011107
2025/09/16 22:31:52 : Epoch: 1574, Eval_Loss: 0.00523997
2025/09/16 22:31:52 : Epoch: 1575, Train_Loss: 0.01052211
2025/09/16 22:31:52 : Epoch: 1576, Train_Loss: 0.01025444
2025/09/16 22:31:52 : Epoch: 1577, Train_Loss: 0.00808028
2025/09/16 22:31:53 : Epoch: 1578, Train_Loss: 0.00901963
2025/09/16 22:31:53 : Epoch: 1579, Train_Loss: 0.00667509
2025/09/16 22:31:53 : Epoch: 1579, Eval_Loss: 0.00523705
2025/09/16 22:31:53 : Epoch: 1580, Train_Loss: 0.00673758
2025/09/16 22:31:53 : Epoch: 1581, Train_Loss: 0.00964498
2025/09/16 22:31:54 : Epoch: 1582, Train_Loss: 0.00908258
2025/09/16 22:31:54 : Epoch: 1583, Train_Loss: 0.00750312
2025/09/16 22:31:54 : Epoch: 1584, Train_Loss: 0.00741754
2025/09/16 22:31:54 : Epoch: 1584, Eval_Loss: 0.00523562
2025/09/16 22:31:55 : Epoch: 1585, Train_Loss: 0.01367288
2025/09/16 22:31:55 : Epoch: 1586, Train_Loss: 0.01082595
2025/09/16 22:31:55 : Epoch: 1587, Train_Loss: 0.01387611
2025/09/16 22:31:55 : Epoch: 1588, Train_Loss: 0.00889924
2025/09/16 22:31:56 : Epoch: 1589, Train_Loss: 0.01053166
2025/09/16 22:31:56 : Epoch: 1589, Eval_Loss: 0.00523826
2025/09/16 22:31:56 : Epoch: 1590, Train_Loss: 0.01000463
2025/09/16 22:31:56 : Epoch: 1591, Train_Loss: 0.00702716
2025/09/16 22:31:56 : Epoch: 1592, Train_Loss: 0.01018085
2025/09/16 22:31:57 : Epoch: 1593, Train_Loss: 0.01028435
2025/09/16 22:31:57 : Epoch: 1594, Train_Loss: 0.00667795
2025/09/16 22:31:57 : Epoch: 1594, Eval_Loss: 0.00523866
2025/09/16 22:31:57 : Epoch: 1595, Train_Loss: 0.00841192
2025/09/16 22:31:57 : Epoch: 1596, Train_Loss: 0.00866291
2025/09/16 22:31:58 : Epoch: 1597, Train_Loss: 0.00979246
2025/09/16 22:31:58 : Epoch: 1598, Train_Loss: 0.01034118
2025/09/16 22:31:58 : Epoch: 1599, Train_Loss: 0.00938705
2025/09/16 22:31:58 : Epoch: 1599, Eval_Loss: 0.00523609
2025/09/16 22:31:58 : 
Epoch: 1599, save response figures

2025/09/16 22:32:11 : Epoch: 1600, Train_Loss: 0.01058278
2025/09/16 22:32:11 : Epoch: 1601, Train_Loss: 0.01340533
2025/09/16 22:32:11 : Epoch: 1602, Train_Loss: 0.00889544
2025/09/16 22:32:11 : Epoch: 1603, Train_Loss: 0.00862793
2025/09/16 22:32:12 : Epoch: 1604, Train_Loss: 0.01198960
2025/09/16 22:32:12 : Epoch: 1604, Eval_Loss: 0.00523838
2025/09/16 22:32:12 : Epoch: 1605, Train_Loss: 0.00968770
2025/09/16 22:32:12 : Epoch: 1606, Train_Loss: 0.00821127
2025/09/16 22:32:12 : Epoch: 1607, Train_Loss: 0.00950015
2025/09/16 22:32:13 : Epoch: 1608, Train_Loss: 0.00856891
2025/09/16 22:32:13 : Epoch: 1609, Train_Loss: 0.01274596
2025/09/16 22:32:13 : Epoch: 1609, Eval_Loss: 0.00524321
2025/09/16 22:32:13 : Epoch: 1610, Train_Loss: 0.00936538
2025/09/16 22:32:13 : Epoch: 1611, Train_Loss: 0.00859473
2025/09/16 22:32:14 : Epoch: 1612, Train_Loss: 0.00970868
2025/09/16 22:32:14 : Epoch: 1613, Train_Loss: 0.00950467
2025/09/16 22:32:14 : Epoch: 1614, Train_Loss: 0.01404327
2025/09/16 22:32:14 : Epoch: 1614, Eval_Loss: 0.00524736
2025/09/16 22:32:14 : Epoch: 1615, Train_Loss: 0.00792732
2025/09/16 22:32:15 : Epoch: 1616, Train_Loss: 0.00949803
2025/09/16 22:32:15 : Epoch: 1617, Train_Loss: 0.00883732
2025/09/16 22:32:15 : Epoch: 1618, Train_Loss: 0.01123511
2025/09/16 22:32:15 : Epoch: 1619, Train_Loss: 0.00758045
2025/09/16 22:32:15 : Epoch: 1619, Eval_Loss: 0.00524800
2025/09/16 22:32:16 : Epoch: 1620, Train_Loss: 0.01037240
2025/09/16 22:32:16 : Epoch: 1621, Train_Loss: 0.01198420
2025/09/16 22:32:16 : Epoch: 1622, Train_Loss: 0.00969045
2025/09/16 22:32:16 : Epoch: 1623, Train_Loss: 0.00927534
2025/09/16 22:32:17 : Epoch: 1624, Train_Loss: 0.01308097
2025/09/16 22:32:17 : Epoch: 1624, Eval_Loss: 0.00524009
2025/09/16 22:32:17 : Epoch: 1625, Train_Loss: 0.01314789
2025/09/16 22:32:17 : Epoch: 1626, Train_Loss: 0.01011260
2025/09/16 22:32:17 : Epoch: 1627, Train_Loss: 0.00776036
2025/09/16 22:32:18 : Epoch: 1628, Train_Loss: 0.00897877
2025/09/16 22:32:18 : Epoch: 1629, Train_Loss: 0.00859080
2025/09/16 22:32:18 : Epoch: 1629, Eval_Loss: 0.00524282
2025/09/16 22:32:18 : Epoch: 1630, Train_Loss: 0.00956930
2025/09/16 22:32:19 : Epoch: 1631, Train_Loss: 0.01072624
2025/09/16 22:32:19 : Epoch: 1632, Train_Loss: 0.01432403
2025/09/16 22:32:19 : Epoch: 1633, Train_Loss: 0.00760672
2025/09/16 22:32:19 : Epoch: 1634, Train_Loss: 0.01010057
2025/09/16 22:32:19 : Epoch: 1634, Eval_Loss: 0.00524368
2025/09/16 22:32:20 : Epoch: 1635, Train_Loss: 0.00926586
2025/09/16 22:32:20 : Epoch: 1636, Train_Loss: 0.00859187
2025/09/16 22:32:20 : Epoch: 1637, Train_Loss: 0.00797480
2025/09/16 22:32:20 : Epoch: 1638, Train_Loss: 0.01100037
2025/09/16 22:32:21 : Epoch: 1639, Train_Loss: 0.01324680
2025/09/16 22:32:21 : Epoch: 1639, Eval_Loss: 0.00524118
2025/09/16 22:32:21 : Epoch: 1640, Train_Loss: 0.00816372
2025/09/16 22:32:21 : Epoch: 1641, Train_Loss: 0.01101911
2025/09/16 22:32:21 : Epoch: 1642, Train_Loss: 0.01268839
2025/09/16 22:32:22 : Epoch: 1643, Train_Loss: 0.00893003
2025/09/16 22:32:22 : Epoch: 1644, Train_Loss: 0.00784871
2025/09/16 22:32:22 : Epoch: 1644, Eval_Loss: 0.00523962
2025/09/16 22:32:22 : Epoch: 1645, Train_Loss: 0.01201838
2025/09/16 22:32:23 : Epoch: 1646, Train_Loss: 0.01230758
2025/09/16 22:32:23 : Epoch: 1647, Train_Loss: 0.00732192
2025/09/16 22:32:23 : Epoch: 1648, Train_Loss: 0.00769866
2025/09/16 22:32:23 : Epoch: 1649, Train_Loss: 0.01306759
2025/09/16 22:32:23 : Epoch: 1649, Eval_Loss: 0.00524482
2025/09/16 22:32:24 : Epoch: 1650, Train_Loss: 0.01049479
2025/09/16 22:32:24 : Epoch: 1651, Train_Loss: 0.01196797
2025/09/16 22:32:24 : Epoch: 1652, Train_Loss: 0.01016691
2025/09/16 22:32:24 : Epoch: 1653, Train_Loss: 0.01186248
2025/09/16 22:32:25 : Epoch: 1654, Train_Loss: 0.01031172
2025/09/16 22:32:25 : Epoch: 1654, Eval_Loss: 0.00524622
2025/09/16 22:32:25 : Epoch: 1655, Train_Loss: 0.00795268
2025/09/16 22:32:25 : Epoch: 1656, Train_Loss: 0.01090102
2025/09/16 22:32:25 : Epoch: 1657, Train_Loss: 0.00905097
2025/09/16 22:32:26 : Epoch: 1658, Train_Loss: 0.01103682
2025/09/16 22:32:26 : Epoch: 1659, Train_Loss: 0.01095944
2025/09/16 22:32:26 : Epoch: 1659, Eval_Loss: 0.00524056
2025/09/16 22:32:26 : Epoch: 1660, Train_Loss: 0.01295081
2025/09/16 22:32:26 : Epoch: 1661, Train_Loss: 0.00891081
2025/09/16 22:32:27 : Epoch: 1662, Train_Loss: 0.01141716
2025/09/16 22:32:27 : Epoch: 1663, Train_Loss: 0.00920197
2025/09/16 22:32:27 : Epoch: 1664, Train_Loss: 0.00821516
2025/09/16 22:32:27 : Epoch: 1664, Eval_Loss: 0.00523966
2025/09/16 22:32:28 : Epoch: 1665, Train_Loss: 0.00790101
2025/09/16 22:32:28 : Epoch: 1666, Train_Loss: 0.01117597
2025/09/16 22:32:28 : Epoch: 1667, Train_Loss: 0.01187573
2025/09/16 22:32:28 : Epoch: 1668, Train_Loss: 0.00824683
2025/09/16 22:32:28 : Epoch: 1669, Train_Loss: 0.01000514
2025/09/16 22:32:29 : Epoch: 1669, Eval_Loss: 0.00523835
2025/09/16 22:32:29 : Epoch: 1670, Train_Loss: 0.00878468
2025/09/16 22:32:29 : Epoch: 1671, Train_Loss: 0.00819156
2025/09/16 22:32:29 : Epoch: 1672, Train_Loss: 0.01366638
2025/09/16 22:32:30 : Epoch: 1673, Train_Loss: 0.01334539
2025/09/16 22:32:30 : Epoch: 1674, Train_Loss: 0.01026841
2025/09/16 22:32:30 : Epoch: 1674, Eval_Loss: 0.00523837
2025/09/16 22:32:30 : Epoch: 1675, Train_Loss: 0.01023837
2025/09/16 22:32:30 : Epoch: 1676, Train_Loss: 0.00983250
2025/09/16 22:32:31 : Epoch: 1677, Train_Loss: 0.01366035
2025/09/16 22:32:31 : Epoch: 1678, Train_Loss: 0.00931351
2025/09/16 22:32:31 : Epoch: 1679, Train_Loss: 0.00981029
2025/09/16 22:32:31 : Epoch: 1679, Eval_Loss: 0.00523877
2025/09/16 22:32:31 : Epoch: 1680, Train_Loss: 0.01015866
2025/09/16 22:32:32 : Epoch: 1681, Train_Loss: 0.00837109
2025/09/16 22:32:32 : Epoch: 1682, Train_Loss: 0.01116182
2025/09/16 22:32:32 : Epoch: 1683, Train_Loss: 0.01032914
2025/09/16 22:32:32 : Epoch: 1684, Train_Loss: 0.00868471
2025/09/16 22:32:33 : Epoch: 1684, Eval_Loss: 0.00523926
2025/09/16 22:32:33 : Epoch: 1685, Train_Loss: 0.00914369
2025/09/16 22:32:33 : Epoch: 1686, Train_Loss: 0.01057072
2025/09/16 22:32:33 : Epoch: 1687, Train_Loss: 0.01087364
2025/09/16 22:32:33 : Epoch: 1688, Train_Loss: 0.00914978
2025/09/16 22:32:34 : Epoch: 1689, Train_Loss: 0.00758462
2025/09/16 22:32:34 : Epoch: 1689, Eval_Loss: 0.00524090
2025/09/16 22:32:34 : Epoch: 1690, Train_Loss: 0.00911111
2025/09/16 22:32:34 : Epoch: 1691, Train_Loss: 0.00834547
2025/09/16 22:32:35 : Epoch: 1692, Train_Loss: 0.00866393
2025/09/16 22:32:35 : Epoch: 1693, Train_Loss: 0.00908909
2025/09/16 22:32:35 : Epoch: 1694, Train_Loss: 0.00774475
2025/09/16 22:32:35 : Epoch: 1694, Eval_Loss: 0.00524021
2025/09/16 22:32:35 : Epoch: 1695, Train_Loss: 0.00786265
2025/09/16 22:32:36 : Epoch: 1696, Train_Loss: 0.00968006
2025/09/16 22:32:36 : Epoch: 1697, Train_Loss: 0.00915357
2025/09/16 22:32:36 : Epoch: 1698, Train_Loss: 0.00948617
2025/09/16 22:32:36 : Epoch: 1699, Train_Loss: 0.01133990
2025/09/16 22:32:36 : Epoch: 1699, Eval_Loss: 0.00523697
2025/09/16 22:32:37 : Epoch: 1700, Train_Loss: 0.00807920
2025/09/16 22:32:37 : Epoch: 1701, Train_Loss: 0.01105847
2025/09/16 22:32:37 : Epoch: 1702, Train_Loss: 0.00826853
2025/09/16 22:32:37 : Epoch: 1703, Train_Loss: 0.00841058
2025/09/16 22:32:38 : Epoch: 1704, Train_Loss: 0.01083540
2025/09/16 22:32:38 : Epoch: 1704, Eval_Loss: 0.00523685
2025/09/16 22:32:38 : Epoch: 1705, Train_Loss: 0.01269066
2025/09/16 22:32:38 : Epoch: 1706, Train_Loss: 0.00704062
2025/09/16 22:32:38 : Epoch: 1707, Train_Loss: 0.00752918
2025/09/16 22:32:39 : Epoch: 1708, Train_Loss: 0.00767347
2025/09/16 22:32:39 : Epoch: 1709, Train_Loss: 0.00792718
2025/09/16 22:32:39 : Epoch: 1709, Eval_Loss: 0.00523738
2025/09/16 22:32:39 : Epoch: 1710, Train_Loss: 0.00800002
2025/09/16 22:32:40 : Epoch: 1711, Train_Loss: 0.01296572
2025/09/16 22:32:40 : Epoch: 1712, Train_Loss: 0.01105297
2025/09/16 22:32:40 : Epoch: 1713, Train_Loss: 0.00951586
2025/09/16 22:32:40 : Epoch: 1714, Train_Loss: 0.01266657
2025/09/16 22:32:40 : Epoch: 1714, Eval_Loss: 0.00523943
2025/09/16 22:32:41 : Epoch: 1715, Train_Loss: 0.01389540
2025/09/16 22:32:41 : Epoch: 1716, Train_Loss: 0.01237021
2025/09/16 22:32:41 : Epoch: 1717, Train_Loss: 0.01514944
2025/09/16 22:32:41 : Epoch: 1718, Train_Loss: 0.01322457
2025/09/16 22:32:42 : Epoch: 1719, Train_Loss: 0.00818709
2025/09/16 22:32:42 : Epoch: 1719, Eval_Loss: 0.00526209
2025/09/16 22:32:42 : Epoch: 1720, Train_Loss: 0.00947083
2025/09/16 22:32:42 : Epoch: 1721, Train_Loss: 0.00838568
2025/09/16 22:32:42 : Epoch: 1722, Train_Loss: 0.01042675
2025/09/16 22:32:43 : Epoch: 1723, Train_Loss: 0.00775011
2025/09/16 22:32:43 : Epoch: 1724, Train_Loss: 0.00853252
2025/09/16 22:32:43 : Epoch: 1724, Eval_Loss: 0.00527389
2025/09/16 22:32:43 : Epoch: 1725, Train_Loss: 0.01158401
2025/09/16 22:32:43 : Epoch: 1726, Train_Loss: 0.00953802
2025/09/16 22:32:44 : Epoch: 1727, Train_Loss: 0.00819519
2025/09/16 22:32:44 : Epoch: 1728, Train_Loss: 0.01523659
2025/09/16 22:32:44 : Epoch: 1729, Train_Loss: 0.01416223
2025/09/16 22:32:44 : Epoch: 1729, Eval_Loss: 0.00527186
2025/09/16 22:32:45 : Epoch: 1730, Train_Loss: 0.01316764
2025/09/16 22:32:45 : Epoch: 1731, Train_Loss: 0.01221361
2025/09/16 22:32:45 : Epoch: 1732, Train_Loss: 0.01133850
2025/09/16 22:32:45 : Epoch: 1733, Train_Loss: 0.01189631
2025/09/16 22:32:46 : Epoch: 1734, Train_Loss: 0.00806401
2025/09/16 22:32:46 : Epoch: 1734, Eval_Loss: 0.00529431
2025/09/16 22:32:46 : Epoch: 1735, Train_Loss: 0.00835587
2025/09/16 22:32:46 : Epoch: 1736, Train_Loss: 0.00807340
2025/09/16 22:32:46 : Epoch: 1737, Train_Loss: 0.01284727
2025/09/16 22:32:47 : Epoch: 1738, Train_Loss: 0.01074021
2025/09/16 22:32:47 : Epoch: 1739, Train_Loss: 0.01344923
2025/09/16 22:32:47 : Epoch: 1739, Eval_Loss: 0.00529277
2025/09/16 22:32:47 : Epoch: 1740, Train_Loss: 0.00761460
2025/09/16 22:32:47 : Epoch: 1741, Train_Loss: 0.01066685
2025/09/16 22:32:48 : Epoch: 1742, Train_Loss: 0.00886497
2025/09/16 22:32:48 : Epoch: 1743, Train_Loss: 0.00997085
2025/09/16 22:32:48 : Epoch: 1744, Train_Loss: 0.00938549
2025/09/16 22:32:48 : Epoch: 1744, Eval_Loss: 0.00526733
2025/09/16 22:32:48 : Epoch: 1745, Train_Loss: 0.00679234
2025/09/16 22:32:49 : Epoch: 1746, Train_Loss: 0.00958605
2025/09/16 22:32:49 : Epoch: 1747, Train_Loss: 0.01192991
2025/09/16 22:32:49 : Epoch: 1748, Train_Loss: 0.01156911
2025/09/16 22:32:49 : Epoch: 1749, Train_Loss: 0.01251304
2025/09/16 22:32:50 : Epoch: 1749, Eval_Loss: 0.00524644
2025/09/16 22:32:50 : Epoch: 1750, Train_Loss: 0.01118543
2025/09/16 22:32:50 : Epoch: 1751, Train_Loss: 0.01118885
2025/09/16 22:32:50 : Epoch: 1752, Train_Loss: 0.00726772
2025/09/16 22:32:50 : Epoch: 1753, Train_Loss: 0.01049930
2025/09/16 22:32:51 : Epoch: 1754, Train_Loss: 0.00922441
2025/09/16 22:32:51 : Epoch: 1754, Eval_Loss: 0.00524655
2025/09/16 22:32:51 : Epoch: 1755, Train_Loss: 0.00769445
2025/09/16 22:32:51 : Epoch: 1756, Train_Loss: 0.00868330
2025/09/16 22:32:51 : Epoch: 1757, Train_Loss: 0.00908445
2025/09/16 22:32:52 : Epoch: 1758, Train_Loss: 0.01425301
2025/09/16 22:32:52 : Epoch: 1759, Train_Loss: 0.01018979
2025/09/16 22:32:52 : Epoch: 1759, Eval_Loss: 0.00524103
2025/09/16 22:32:52 : Epoch: 1760, Train_Loss: 0.01268165
2025/09/16 22:32:53 : Epoch: 1761, Train_Loss: 0.00908238
2025/09/16 22:32:53 : Epoch: 1762, Train_Loss: 0.01364229
2025/09/16 22:32:53 : Epoch: 1763, Train_Loss: 0.00946890
2025/09/16 22:32:53 : Epoch: 1764, Train_Loss: 0.01087465
2025/09/16 22:32:53 : Epoch: 1764, Eval_Loss: 0.00525421
2025/09/16 22:32:54 : Epoch: 1765, Train_Loss: 0.00829353
2025/09/16 22:32:54 : Epoch: 1766, Train_Loss: 0.00864257
2025/09/16 22:32:54 : Epoch: 1767, Train_Loss: 0.01174856
2025/09/16 22:32:54 : Epoch: 1768, Train_Loss: 0.00946327
2025/09/16 22:32:55 : Epoch: 1769, Train_Loss: 0.01177905
2025/09/16 22:32:55 : Epoch: 1769, Eval_Loss: 0.00525087
2025/09/16 22:32:55 : Epoch: 1770, Train_Loss: 0.00778370
2025/09/16 22:32:55 : Epoch: 1771, Train_Loss: 0.01223218
2025/09/16 22:32:55 : Epoch: 1772, Train_Loss: 0.00931143
2025/09/16 22:32:56 : Epoch: 1773, Train_Loss: 0.01058233
2025/09/16 22:32:56 : Epoch: 1774, Train_Loss: 0.00910220
2025/09/16 22:32:56 : Epoch: 1774, Eval_Loss: 0.00525939
2025/09/16 22:32:56 : Epoch: 1775, Train_Loss: 0.01290896
2025/09/16 22:32:57 : Epoch: 1776, Train_Loss: 0.00918054
2025/09/16 22:32:57 : Epoch: 1777, Train_Loss: 0.01182681
2025/09/16 22:32:57 : Epoch: 1778, Train_Loss: 0.01183065
2025/09/16 22:32:57 : Epoch: 1779, Train_Loss: 0.01377275
2025/09/16 22:32:57 : Epoch: 1779, Eval_Loss: 0.00526074
2025/09/16 22:32:58 : Epoch: 1780, Train_Loss: 0.00838643
2025/09/16 22:32:58 : Epoch: 1781, Train_Loss: 0.00821796
2025/09/16 22:32:58 : Epoch: 1782, Train_Loss: 0.01178596
2025/09/16 22:32:58 : Epoch: 1783, Train_Loss: 0.00978659
2025/09/16 22:32:59 : Epoch: 1784, Train_Loss: 0.00860941
2025/09/16 22:32:59 : Epoch: 1784, Eval_Loss: 0.00525758
2025/09/16 22:32:59 : Epoch: 1785, Train_Loss: 0.00750140
2025/09/16 22:32:59 : Epoch: 1786, Train_Loss: 0.01018478
2025/09/16 22:32:59 : Epoch: 1787, Train_Loss: 0.00992134
2025/09/16 22:33:00 : Epoch: 1788, Train_Loss: 0.01123746
2025/09/16 22:33:00 : Epoch: 1789, Train_Loss: 0.01032163
2025/09/16 22:33:00 : Epoch: 1789, Eval_Loss: 0.00524134
2025/09/16 22:33:00 : Epoch: 1790, Train_Loss: 0.01287443
2025/09/16 22:33:00 : Epoch: 1791, Train_Loss: 0.00673926
2025/09/16 22:33:01 : Epoch: 1792, Train_Loss: 0.01072247
2025/09/16 22:33:01 : Epoch: 1793, Train_Loss: 0.00908368
2025/09/16 22:33:01 : Epoch: 1794, Train_Loss: 0.00763767
2025/09/16 22:33:01 : Epoch: 1794, Eval_Loss: 0.00523819
2025/09/16 22:33:02 : Epoch: 1795, Train_Loss: 0.01275470
2025/09/16 22:33:02 : Epoch: 1796, Train_Loss: 0.00921250
2025/09/16 22:33:02 : Epoch: 1797, Train_Loss: 0.01450395
2025/09/16 22:33:02 : Epoch: 1798, Train_Loss: 0.00817323
2025/09/16 22:33:02 : Epoch: 1799, Train_Loss: 0.00976155
2025/09/16 22:33:03 : Epoch: 1799, Eval_Loss: 0.00524107
2025/09/16 22:33:03 : Epoch: 1800, Train_Loss: 0.00743025
2025/09/16 22:33:03 : Epoch: 1801, Train_Loss: 0.01017771
2025/09/16 22:33:03 : Epoch: 1802, Train_Loss: 0.00792635
2025/09/16 22:33:04 : Epoch: 1803, Train_Loss: 0.00874724
2025/09/16 22:33:04 : Epoch: 1804, Train_Loss: 0.00929714
2025/09/16 22:33:04 : Epoch: 1804, Eval_Loss: 0.00523790
2025/09/16 22:33:04 : Epoch: 1805, Train_Loss: 0.00920817
2025/09/16 22:33:04 : Epoch: 1806, Train_Loss: 0.00947016
2025/09/16 22:33:05 : Epoch: 1807, Train_Loss: 0.00841279
2025/09/16 22:33:05 : Epoch: 1808, Train_Loss: 0.00773639
2025/09/16 22:33:05 : Epoch: 1809, Train_Loss: 0.00884313
2025/09/16 22:33:05 : Epoch: 1809, Eval_Loss: 0.00524509
2025/09/16 22:33:05 : Epoch: 1810, Train_Loss: 0.00909615
2025/09/16 22:33:06 : Epoch: 1811, Train_Loss: 0.00836867
2025/09/16 22:33:06 : Epoch: 1812, Train_Loss: 0.00707076
2025/09/16 22:33:06 : Epoch: 1813, Train_Loss: 0.01430905
2025/09/16 22:33:06 : Epoch: 1814, Train_Loss: 0.01231610
2025/09/16 22:33:06 : Epoch: 1814, Eval_Loss: 0.00523575
2025/09/16 22:33:07 : Epoch: 1815, Train_Loss: 0.01280622
2025/09/16 22:33:07 : Epoch: 1816, Train_Loss: 0.00681343
2025/09/16 22:33:07 : Epoch: 1817, Train_Loss: 0.01105549
2025/09/16 22:33:07 : Epoch: 1818, Train_Loss: 0.00899283
2025/09/16 22:33:08 : Epoch: 1819, Train_Loss: 0.01110168
2025/09/16 22:33:08 : Epoch: 1819, Eval_Loss: 0.00525754
2025/09/16 22:33:08 : Epoch: 1820, Train_Loss: 0.00931311
2025/09/16 22:33:08 : Epoch: 1821, Train_Loss: 0.00912406
2025/09/16 22:33:09 : Epoch: 1822, Train_Loss: 0.00951113
2025/09/16 22:33:09 : Epoch: 1823, Train_Loss: 0.00724838
2025/09/16 22:33:09 : Epoch: 1824, Train_Loss: 0.01109329
2025/09/16 22:33:09 : Epoch: 1824, Eval_Loss: 0.00527920
2025/09/16 22:33:09 : Epoch: 1825, Train_Loss: 0.00946696
2025/09/16 22:33:10 : Epoch: 1826, Train_Loss: 0.00677956
2025/09/16 22:33:10 : Epoch: 1827, Train_Loss: 0.01225715
2025/09/16 22:33:10 : Epoch: 1828, Train_Loss: 0.00714166
2025/09/16 22:33:10 : Epoch: 1829, Train_Loss: 0.00790119
2025/09/16 22:33:10 : Epoch: 1829, Eval_Loss: 0.00526439
2025/09/16 22:33:11 : Epoch: 1830, Train_Loss: 0.01099327
2025/09/16 22:33:11 : Epoch: 1831, Train_Loss: 0.00803286
2025/09/16 22:33:11 : Epoch: 1832, Train_Loss: 0.00991002
2025/09/16 22:33:11 : Epoch: 1833, Train_Loss: 0.01107433
2025/09/16 22:33:12 : Epoch: 1834, Train_Loss: 0.01210338
2025/09/16 22:33:12 : Epoch: 1834, Eval_Loss: 0.00525409
2025/09/16 22:33:12 : Epoch: 1835, Train_Loss: 0.01200572
2025/09/16 22:33:12 : Epoch: 1836, Train_Loss: 0.00893171
2025/09/16 22:33:12 : Epoch: 1837, Train_Loss: 0.00941822
2025/09/16 22:33:13 : Epoch: 1838, Train_Loss: 0.00759222
2025/09/16 22:33:13 : Epoch: 1839, Train_Loss: 0.01417350
2025/09/16 22:33:13 : Epoch: 1839, Eval_Loss: 0.00524670
2025/09/16 22:33:13 : Epoch: 1840, Train_Loss: 0.01030299
2025/09/16 22:33:14 : Epoch: 1841, Train_Loss: 0.00786958
2025/09/16 22:33:14 : Epoch: 1842, Train_Loss: 0.01360522
2025/09/16 22:33:14 : Epoch: 1843, Train_Loss: 0.00841839
2025/09/16 22:33:14 : Epoch: 1844, Train_Loss: 0.01013921
2025/09/16 22:33:14 : Epoch: 1844, Eval_Loss: 0.00526869
2025/09/16 22:33:15 : Epoch: 1845, Train_Loss: 0.01226200
2025/09/16 22:33:15 : Epoch: 1846, Train_Loss: 0.00962019
2025/09/16 22:33:15 : Epoch: 1847, Train_Loss: 0.01241322
2025/09/16 22:33:15 : Epoch: 1848, Train_Loss: 0.01153647
2025/09/16 22:33:16 : Epoch: 1849, Train_Loss: 0.00978843
2025/09/16 22:33:16 : Epoch: 1849, Eval_Loss: 0.00525554
2025/09/16 22:33:16 : Epoch: 1850, Train_Loss: 0.00817646
2025/09/16 22:33:16 : Epoch: 1851, Train_Loss: 0.01105155
2025/09/16 22:33:16 : Epoch: 1852, Train_Loss: 0.01155981
2025/09/16 22:33:17 : Epoch: 1853, Train_Loss: 0.01038078
2025/09/16 22:33:17 : Epoch: 1854, Train_Loss: 0.01143407
2025/09/16 22:33:17 : Epoch: 1854, Eval_Loss: 0.00523893
2025/09/16 22:33:17 : Epoch: 1855, Train_Loss: 0.01349556
2025/09/16 22:33:17 : Epoch: 1856, Train_Loss: 0.00917392
2025/09/16 22:33:18 : Epoch: 1857, Train_Loss: 0.01168700
2025/09/16 22:33:18 : Epoch: 1858, Train_Loss: 0.01352509
2025/09/16 22:33:18 : Epoch: 1859, Train_Loss: 0.00707460
2025/09/16 22:33:18 : Epoch: 1859, Eval_Loss: 0.00524066
2025/09/16 22:33:19 : Epoch: 1860, Train_Loss: 0.00851234
2025/09/16 22:33:19 : Epoch: 1861, Train_Loss: 0.01223136
2025/09/16 22:33:19 : Epoch: 1862, Train_Loss: 0.00947623
2025/09/16 22:33:19 : Epoch: 1863, Train_Loss: 0.00885480
2025/09/16 22:33:20 : Epoch: 1864, Train_Loss: 0.01019150
2025/09/16 22:33:20 : Epoch: 1864, Eval_Loss: 0.00524763
2025/09/16 22:33:20 : Epoch: 1865, Train_Loss: 0.01094872
2025/09/16 22:33:20 : Epoch: 1866, Train_Loss: 0.01016601
2025/09/16 22:33:20 : Epoch: 1867, Train_Loss: 0.01064215
2025/09/16 22:33:21 : Epoch: 1868, Train_Loss: 0.00876484
2025/09/16 22:33:21 : Epoch: 1869, Train_Loss: 0.01072192
2025/09/16 22:33:21 : Epoch: 1869, Eval_Loss: 0.00524434
2025/09/16 22:33:21 : Epoch: 1870, Train_Loss: 0.01087087
2025/09/16 22:33:21 : Epoch: 1871, Train_Loss: 0.00775407
2025/09/16 22:33:22 : Epoch: 1872, Train_Loss: 0.01070799
2025/09/16 22:33:22 : Epoch: 1873, Train_Loss: 0.01187020
2025/09/16 22:33:22 : Epoch: 1874, Train_Loss: 0.00766918
2025/09/16 22:33:22 : Epoch: 1874, Eval_Loss: 0.00524289
2025/09/16 22:33:22 : Epoch: 1875, Train_Loss: 0.01089564
2025/09/16 22:33:23 : Epoch: 1876, Train_Loss: 0.01299783
2025/09/16 22:33:23 : Epoch: 1877, Train_Loss: 0.00768659
2025/09/16 22:33:23 : Epoch: 1878, Train_Loss: 0.00789527
2025/09/16 22:33:23 : Epoch: 1879, Train_Loss: 0.01207141
2025/09/16 22:33:23 : Epoch: 1879, Eval_Loss: 0.00524692
2025/09/16 22:33:24 : Epoch: 1880, Train_Loss: 0.00996152
2025/09/16 22:33:24 : Epoch: 1881, Train_Loss: 0.00755103
2025/09/16 22:33:24 : Epoch: 1882, Train_Loss: 0.01184643
2025/09/16 22:33:24 : Epoch: 1883, Train_Loss: 0.00862917
2025/09/16 22:33:25 : Epoch: 1884, Train_Loss: 0.00892408
2025/09/16 22:33:25 : Epoch: 1884, Eval_Loss: 0.00524278
2025/09/16 22:33:25 : Epoch: 1885, Train_Loss: 0.00927487
2025/09/16 22:33:25 : Epoch: 1886, Train_Loss: 0.01170011
2025/09/16 22:33:26 : Epoch: 1887, Train_Loss: 0.01295443
2025/09/16 22:33:26 : Epoch: 1888, Train_Loss: 0.00997066
2025/09/16 22:33:26 : Epoch: 1889, Train_Loss: 0.00859536
2025/09/16 22:33:26 : Epoch: 1889, Eval_Loss: 0.00524268
2025/09/16 22:33:26 : Epoch: 1890, Train_Loss: 0.00981158
2025/09/16 22:33:27 : Epoch: 1891, Train_Loss: 0.00833902
2025/09/16 22:33:27 : Epoch: 1892, Train_Loss: 0.01086246
2025/09/16 22:33:27 : Epoch: 1893, Train_Loss: 0.00803187
2025/09/16 22:33:27 : Epoch: 1894, Train_Loss: 0.01015355
2025/09/16 22:33:27 : Epoch: 1894, Eval_Loss: 0.00524214
2025/09/16 22:33:28 : Epoch: 1895, Train_Loss: 0.01148041
2025/09/16 22:33:28 : Epoch: 1896, Train_Loss: 0.00910671
2025/09/16 22:33:28 : Epoch: 1897, Train_Loss: 0.00985594
2025/09/16 22:33:28 : Epoch: 1898, Train_Loss: 0.00754702
2025/09/16 22:33:29 : Epoch: 1899, Train_Loss: 0.01300731
2025/09/16 22:33:29 : Epoch: 1899, Eval_Loss: 0.00524125
2025/09/16 22:33:29 : Epoch: 1900, Train_Loss: 0.01049069
2025/09/16 22:33:29 : Epoch: 1901, Train_Loss: 0.00687945
2025/09/16 22:33:29 : Epoch: 1902, Train_Loss: 0.00749916
2025/09/16 22:33:30 : Epoch: 1903, Train_Loss: 0.00707589
2025/09/16 22:33:30 : Epoch: 1904, Train_Loss: 0.00901522
2025/09/16 22:33:30 : Epoch: 1904, Eval_Loss: 0.00524152
2025/09/16 22:33:30 : Epoch: 1905, Train_Loss: 0.01025303
2025/09/16 22:33:31 : Epoch: 1906, Train_Loss: 0.01064091
2025/09/16 22:33:31 : Epoch: 1907, Train_Loss: 0.01095295
2025/09/16 22:33:31 : Epoch: 1908, Train_Loss: 0.01001055
2025/09/16 22:33:31 : Epoch: 1909, Train_Loss: 0.00788579
2025/09/16 22:33:31 : Epoch: 1909, Eval_Loss: 0.00523906
2025/09/16 22:33:32 : Epoch: 1910, Train_Loss: 0.01268888
2025/09/16 22:33:32 : Epoch: 1911, Train_Loss: 0.00927866
2025/09/16 22:33:32 : Epoch: 1912, Train_Loss: 0.00722451
2025/09/16 22:33:32 : Epoch: 1913, Train_Loss: 0.00839455
2025/09/16 22:33:33 : Epoch: 1914, Train_Loss: 0.01033239
2025/09/16 22:33:33 : Epoch: 1914, Eval_Loss: 0.00523796
2025/09/16 22:33:33 : Epoch: 1915, Train_Loss: 0.01026128
2025/09/16 22:33:33 : Epoch: 1916, Train_Loss: 0.01075644
2025/09/16 22:33:33 : Epoch: 1917, Train_Loss: 0.01024778
2025/09/16 22:33:34 : Epoch: 1918, Train_Loss: 0.01029606
2025/09/16 22:33:34 : Epoch: 1919, Train_Loss: 0.00831766
2025/09/16 22:33:34 : Epoch: 1919, Eval_Loss: 0.00523627
2025/09/16 22:33:34 : Epoch: 1920, Train_Loss: 0.00840314
2025/09/16 22:33:34 : Epoch: 1921, Train_Loss: 0.01046597
2025/09/16 22:33:35 : Epoch: 1922, Train_Loss: 0.00768850
2025/09/16 22:33:35 : Epoch: 1923, Train_Loss: 0.00884545
2025/09/16 22:33:35 : Epoch: 1924, Train_Loss: 0.00865750
2025/09/16 22:33:35 : Epoch: 1924, Eval_Loss: 0.00523535
2025/09/16 22:33:36 : Epoch: 1925, Train_Loss: 0.00983344
2025/09/16 22:33:36 : Epoch: 1926, Train_Loss: 0.00936042
2025/09/16 22:33:36 : Epoch: 1927, Train_Loss: 0.01053150
2025/09/16 22:33:36 : Epoch: 1928, Train_Loss: 0.01142045
2025/09/16 22:33:37 : Epoch: 1929, Train_Loss: 0.00858056
2025/09/16 22:33:37 : Epoch: 1929, Eval_Loss: 0.00523411
2025/09/16 22:33:37 : Epoch: 1930, Train_Loss: 0.00924688
2025/09/16 22:33:37 : Epoch: 1931, Train_Loss: 0.00953542
2025/09/16 22:33:37 : Epoch: 1932, Train_Loss: 0.00905260
2025/09/16 22:33:38 : Epoch: 1933, Train_Loss: 0.00991788
2025/09/16 22:33:38 : Epoch: 1934, Train_Loss: 0.01035220
2025/09/16 22:33:38 : Epoch: 1934, Eval_Loss: 0.00523367
2025/09/16 22:33:38 : Epoch: 1935, Train_Loss: 0.00837555
2025/09/16 22:33:38 : Epoch: 1936, Train_Loss: 0.00785181
2025/09/16 22:33:39 : Epoch: 1937, Train_Loss: 0.00858716
2025/09/16 22:33:39 : Epoch: 1938, Train_Loss: 0.01000205
2025/09/16 22:33:39 : Epoch: 1939, Train_Loss: 0.00807045
2025/09/16 22:33:39 : Epoch: 1939, Eval_Loss: 0.00523329
2025/09/16 22:33:39 : Epoch: 1940, Train_Loss: 0.00971717
2025/09/16 22:33:40 : Epoch: 1941, Train_Loss: 0.00966572
2025/09/16 22:33:40 : Epoch: 1942, Train_Loss: 0.00833168
2025/09/16 22:33:40 : Epoch: 1943, Train_Loss: 0.00806279
2025/09/16 22:33:40 : Epoch: 1944, Train_Loss: 0.00814768
2025/09/16 22:33:40 : Epoch: 1944, Eval_Loss: 0.00523312
2025/09/16 22:33:41 : Epoch: 1945, Train_Loss: 0.00887396
2025/09/16 22:33:41 : Epoch: 1946, Train_Loss: 0.01529551
2025/09/16 22:33:41 : Epoch: 1947, Train_Loss: 0.01294228
2025/09/16 22:33:41 : Epoch: 1948, Train_Loss: 0.00816894
2025/09/16 22:33:42 : Epoch: 1949, Train_Loss: 0.01150107
2025/09/16 22:33:42 : Epoch: 1949, Eval_Loss: 0.00523595
2025/09/16 22:33:42 : Epoch: 1950, Train_Loss: 0.01126201
2025/09/16 22:33:42 : Epoch: 1951, Train_Loss: 0.01122638
2025/09/16 22:33:43 : Epoch: 1952, Train_Loss: 0.00784798
2025/09/16 22:33:43 : Epoch: 1953, Train_Loss: 0.00769721
2025/09/16 22:33:43 : Epoch: 1954, Train_Loss: 0.00770020
2025/09/16 22:33:43 : Epoch: 1954, Eval_Loss: 0.00525234
2025/09/16 22:33:43 : Epoch: 1955, Train_Loss: 0.01277343
2025/09/16 22:33:44 : Epoch: 1956, Train_Loss: 0.01333341
2025/09/16 22:33:44 : Epoch: 1957, Train_Loss: 0.01308385
2025/09/16 22:33:44 : Epoch: 1958, Train_Loss: 0.00970248
2025/09/16 22:33:44 : Epoch: 1959, Train_Loss: 0.00905851
2025/09/16 22:33:44 : Epoch: 1959, Eval_Loss: 0.00526549
2025/09/16 22:33:45 : Epoch: 1960, Train_Loss: 0.00772448
2025/09/16 22:33:45 : Epoch: 1961, Train_Loss: 0.00788215
2025/09/16 22:33:45 : Epoch: 1962, Train_Loss: 0.01034146
2025/09/16 22:33:45 : Epoch: 1963, Train_Loss: 0.01177160
2025/09/16 22:33:46 : Epoch: 1964, Train_Loss: 0.00775675
2025/09/16 22:33:46 : Epoch: 1964, Eval_Loss: 0.00525639
2025/09/16 22:33:46 : Epoch: 1965, Train_Loss: 0.01523979
2025/09/16 22:33:46 : Epoch: 1966, Train_Loss: 0.00876030
2025/09/16 22:33:46 : Epoch: 1967, Train_Loss: 0.00873434
2025/09/16 22:33:47 : Epoch: 1968, Train_Loss: 0.00979787
2025/09/16 22:33:47 : Epoch: 1969, Train_Loss: 0.00799908
2025/09/16 22:33:47 : Epoch: 1969, Eval_Loss: 0.00525206
2025/09/16 22:33:47 : Epoch: 1970, Train_Loss: 0.01066606
2025/09/16 22:33:48 : Epoch: 1971, Train_Loss: 0.00911348
2025/09/16 22:33:48 : Epoch: 1972, Train_Loss: 0.01014019
2025/09/16 22:33:48 : Epoch: 1973, Train_Loss: 0.01187159
2025/09/16 22:33:48 : Epoch: 1974, Train_Loss: 0.00933444
2025/09/16 22:33:48 : Epoch: 1974, Eval_Loss: 0.00525176
2025/09/16 22:33:49 : Epoch: 1975, Train_Loss: 0.00890788
2025/09/16 22:33:49 : Epoch: 1976, Train_Loss: 0.01135736
2025/09/16 22:33:49 : Epoch: 1977, Train_Loss: 0.01168786
2025/09/16 22:33:49 : Epoch: 1978, Train_Loss: 0.00884043
2025/09/16 22:33:50 : Epoch: 1979, Train_Loss: 0.00892684
2025/09/16 22:33:50 : Epoch: 1979, Eval_Loss: 0.00525420
2025/09/16 22:33:50 : Epoch: 1980, Train_Loss: 0.00798915
2025/09/16 22:33:50 : Epoch: 1981, Train_Loss: 0.01074009
2025/09/16 22:33:50 : Epoch: 1982, Train_Loss: 0.00917582
2025/09/16 22:33:51 : Epoch: 1983, Train_Loss: 0.01326912
2025/09/16 22:33:51 : Epoch: 1984, Train_Loss: 0.01249999
2025/09/16 22:33:51 : Epoch: 1984, Eval_Loss: 0.00524620
2025/09/16 22:33:51 : Epoch: 1985, Train_Loss: 0.01282840
2025/09/16 22:33:52 : Epoch: 1986, Train_Loss: 0.01036864
2025/09/16 22:33:52 : Epoch: 1987, Train_Loss: 0.00832741
2025/09/16 22:33:52 : Epoch: 1988, Train_Loss: 0.01091966
2025/09/16 22:33:52 : Epoch: 1989, Train_Loss: 0.00916100
2025/09/16 22:33:52 : Epoch: 1989, Eval_Loss: 0.00524642
2025/09/16 22:33:53 : Epoch: 1990, Train_Loss: 0.01407555
2025/09/16 22:33:53 : Epoch: 1991, Train_Loss: 0.01149215
2025/09/16 22:33:53 : Epoch: 1992, Train_Loss: 0.01078230
2025/09/16 22:33:53 : Epoch: 1993, Train_Loss: 0.00816457
2025/09/16 22:33:54 : Epoch: 1994, Train_Loss: 0.01067896
2025/09/16 22:33:54 : Epoch: 1994, Eval_Loss: 0.00524878
2025/09/16 22:33:54 : Epoch: 1995, Train_Loss: 0.01226512
2025/09/16 22:33:54 : Epoch: 1996, Train_Loss: 0.01125580
2025/09/16 22:33:54 : Epoch: 1997, Train_Loss: 0.01356515
2025/09/16 22:33:55 : Epoch: 1998, Train_Loss: 0.00799752
2025/09/16 22:33:55 : Epoch: 1999, Train_Loss: 0.01199572
2025/09/16 22:33:55 : Epoch: 1999, Eval_Loss: 0.00525597
2025/09/16 22:33:55 : 
Epoch: 1999, save response figures

