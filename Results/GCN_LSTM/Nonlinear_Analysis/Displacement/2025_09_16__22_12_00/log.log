2025/09/16 22:12:00 : 

** GPU Info **
2025/09/16 22:12:00 : ====================================================================================================
2025/09/16 22:12:00 : My GPU is NVIDIA L40
2025/09/16 22:12:00 : ====================================================================================================
2025/09/16 22:12:21 : 

** Load Data **
2025/09/16 22:12:21 : ====================================================================================================
2025/09/16 22:12:21 : Response Type: Displacement
2025/09/16 22:12:21 : Train dataset: ['./Data/Nonlinear_Analysis/train/ChiChi_DBE', './Data/Nonlinear_Analysis/train/NGAWest2_DBE', './Data/Nonlinear_Analysis/train/ChiChi_MCE', './Data/Nonlinear_Analysis/train/NGAWest2_MCE']
2025/09/16 22:12:21 : Eval dataset: ['./Data/Nonlinear_Analysis/eval/ChiChi_DBE', './Data/Nonlinear_Analysis/eval/NGAWest2_DBE', './Data/Nonlinear_Analysis/eval/ChiChi_MCE', './Data/Nonlinear_Analysis/eval/NGAWest2_MCE']
2025/09/16 22:12:21 : # of effective train data: 20
2025/09/16 22:12:21 : # of effective eval data: 20
2025/09/16 22:12:21 : ====================================================================================================
2025/09/16 22:12:25 : 

** Get Normalization Dictionary **
2025/09/16 22:12:25 : ====================================================================================================
2025/09/16 22:12:25 : 
normalization dictionary: 
{'x': {'XYZ_gridline_num': tensor(8.), 'XYZ_grid_index': tensor(7.), 'period': tensor(1.3262), 'DOF': tensor(1.), 'mass': tensor(0.0255), 'XYZ_inertia': tensor(255288.), 'XYZ_mode_shape': tensor(1.8960)}, 'ground_motion': tensor(10479.9434), 'y': tensor(241.7000), 'edge_attr': {'S_y': tensor(3687090.), 'S_z': tensor(3687090.), 'area': tensor(30774.), 'element_length': tensor(8000.)}, 'response_type': 'Displacement'}
2025/09/16 22:12:25 : ====================================================================================================
2025/09/16 22:12:25 : 

** Model Info **
2025/09/16 22:12:25 : ====================================================================================================
2025/09/16 22:12:25 : GCN_LSTM(
  (GCN_Encoder): GCN_Encoder(
    (relu): ReLU()
    (dropout): Dropout(p=0.2, inplace=False)
    (conv1): GCNConv(15, 512)
    (conv2): GCNConv(512, 1024)
    (conv3): GCNConv(1024, 512)
  )
  (LSTM): LSTM(
    (lstm): LSTM(522, 512, num_layers=2, batch_first=True, dropout=0.2)
    (fc_out): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=8, bias=True)
    )
  )
)
2025/09/16 22:12:25 : ====================================================================================================
2025/09/16 22:12:25 : 

** Train **
2025/09/16 22:12:25 : ====================================================================================================
2025/09/16 22:12:25 :   Packed Mode = True
2025/09/16 22:12:25 :   Compression Rate of Ground Motion = 10
2025/09/16 22:12:25 :   Compression Rate of Response Sequence  = 1
2025/09/16 22:12:25 :   Compressed Seqence Length  = 2000
2025/09/16 22:12:25 :   Num Epochs = 2000
2025/09/16 22:12:25 :   Num Train Examples = 20
2025/09/16 22:12:25 :   Num Eval Examples = 20
2025/09/16 22:12:25 :   Batch Size = 16
2025/09/16 22:12:25 :   Evaluation Interval = 5
2025/09/16 22:12:25 :   Plot Interval = 400
2025/09/16 22:12:25 : ====================================================================================================
2025/09/16 22:12:25 : Epoch: 000, Train_Loss: 5.67746029
2025/09/16 22:12:26 : Epoch: 001, Train_Loss: 0.78506950
2025/09/16 22:12:26 : Epoch: 002, Train_Loss: 0.56585980
2025/09/16 22:12:26 : Epoch: 003, Train_Loss: 1.21982080
2025/09/16 22:12:26 : Epoch: 004, Train_Loss: 0.46342967
2025/09/16 22:12:26 : Epoch: 004, Eval_Loss: 0.28788652
2025/09/16 22:12:26 : Epoch: 004, Save the best checkpoint
2025/09/16 22:12:27 : Epoch: 005, Train_Loss: 0.22403765
2025/09/16 22:12:27 : Epoch: 006, Train_Loss: 0.09562362
2025/09/16 22:12:27 : Epoch: 007, Train_Loss: 0.04258247
2025/09/16 22:12:27 : Epoch: 008, Train_Loss: 0.02033698
2025/09/16 22:12:28 : Epoch: 009, Train_Loss: 0.01169056
2025/09/16 22:12:28 : Epoch: 009, Eval_Loss: 0.00637050
2025/09/16 22:12:28 : Epoch: 009, Save the best checkpoint
2025/09/16 22:12:28 : Epoch: 010, Train_Loss: 0.01123172
2025/09/16 22:12:28 : Epoch: 011, Train_Loss: 0.00848364
2025/09/16 22:12:29 : Epoch: 012, Train_Loss: 0.01510806
2025/09/16 22:12:29 : Epoch: 013, Train_Loss: 0.00782321
2025/09/16 22:12:29 : Epoch: 014, Train_Loss: 0.00994221
2025/09/16 22:12:29 : Epoch: 014, Eval_Loss: 0.00534104
2025/09/16 22:12:29 : Epoch: 014, Save the best checkpoint
2025/09/16 22:12:29 : Epoch: 015, Train_Loss: 0.00767163
2025/09/16 22:12:30 : Epoch: 016, Train_Loss: 0.01546286
2025/09/16 22:12:30 : Epoch: 017, Train_Loss: 0.00845242
2025/09/16 22:12:30 : Epoch: 018, Train_Loss: 0.00957928
2025/09/16 22:12:30 : Epoch: 019, Train_Loss: 0.00894787
2025/09/16 22:12:30 : Epoch: 019, Eval_Loss: 0.00528017
2025/09/16 22:12:30 : Epoch: 019, Save the best checkpoint
2025/09/16 22:12:31 : Epoch: 020, Train_Loss: 0.01235110
2025/09/16 22:12:31 : Epoch: 021, Train_Loss: 0.01265498
2025/09/16 22:12:31 : Epoch: 022, Train_Loss: 0.00922155
2025/09/16 22:12:31 : Epoch: 023, Train_Loss: 0.00885113
2025/09/16 22:12:32 : Epoch: 024, Train_Loss: 0.01004431
2025/09/16 22:12:32 : Epoch: 024, Eval_Loss: 0.00528387
2025/09/16 22:12:32 : Epoch: 025, Train_Loss: 0.01009509
2025/09/16 22:12:32 : Epoch: 026, Train_Loss: 0.00887048
2025/09/16 22:12:33 : Epoch: 027, Train_Loss: 0.01006896
2025/09/16 22:12:33 : Epoch: 028, Train_Loss: 0.00944338
2025/09/16 22:12:33 : Epoch: 029, Train_Loss: 0.00801521
2025/09/16 22:12:33 : Epoch: 029, Eval_Loss: 0.00524499
2025/09/16 22:12:33 : Epoch: 029, Save the best checkpoint
2025/09/16 22:12:33 : Epoch: 030, Train_Loss: 0.00870472
2025/09/16 22:12:34 : Epoch: 031, Train_Loss: 0.00914729
2025/09/16 22:12:34 : Epoch: 032, Train_Loss: 0.00964128
2025/09/16 22:12:34 : Epoch: 033, Train_Loss: 0.00877201
2025/09/16 22:12:34 : Epoch: 034, Train_Loss: 0.00860596
2025/09/16 22:12:34 : Epoch: 034, Eval_Loss: 0.00528352
2025/09/16 22:12:35 : Epoch: 035, Train_Loss: 0.00822694
2025/09/16 22:12:35 : Epoch: 036, Train_Loss: 0.00887203
2025/09/16 22:12:35 : Epoch: 037, Train_Loss: 0.01312584
2025/09/16 22:12:35 : Epoch: 038, Train_Loss: 0.01080952
2025/09/16 22:12:36 : Epoch: 039, Train_Loss: 0.00824017
2025/09/16 22:12:36 : Epoch: 039, Eval_Loss: 0.00523737
2025/09/16 22:12:36 : Epoch: 039, Save the best checkpoint
2025/09/16 22:12:36 : Epoch: 040, Train_Loss: 0.01364623
2025/09/16 22:12:36 : Epoch: 041, Train_Loss: 0.01421162
2025/09/16 22:12:36 : Epoch: 042, Train_Loss: 0.00777168
2025/09/16 22:12:37 : Epoch: 043, Train_Loss: 0.01011882
2025/09/16 22:12:37 : Epoch: 044, Train_Loss: 0.00892060
2025/09/16 22:12:37 : Epoch: 044, Eval_Loss: 0.00535051
2025/09/16 22:12:37 : Epoch: 045, Train_Loss: 0.00948795
2025/09/16 22:12:38 : Epoch: 046, Train_Loss: 0.00826552
2025/09/16 22:12:38 : Epoch: 047, Train_Loss: 0.00838199
2025/09/16 22:12:38 : Epoch: 048, Train_Loss: 0.01056930
2025/09/16 22:12:38 : Epoch: 049, Train_Loss: 0.01267223
2025/09/16 22:12:38 : Epoch: 049, Eval_Loss: 0.00525154
2025/09/16 22:12:39 : Epoch: 050, Train_Loss: 0.00960625
2025/09/16 22:12:39 : Epoch: 051, Train_Loss: 0.00812333
2025/09/16 22:12:39 : Epoch: 052, Train_Loss: 0.01033385
2025/09/16 22:12:39 : Epoch: 053, Train_Loss: 0.00981087
2025/09/16 22:12:40 : Epoch: 054, Train_Loss: 0.01016978
2025/09/16 22:12:40 : Epoch: 054, Eval_Loss: 0.00524355
2025/09/16 22:12:40 : Epoch: 055, Train_Loss: 0.01025665
2025/09/16 22:12:40 : Epoch: 056, Train_Loss: 0.01268426
2025/09/16 22:12:40 : Epoch: 057, Train_Loss: 0.01085060
2025/09/16 22:12:41 : Epoch: 058, Train_Loss: 0.01064323
2025/09/16 22:12:41 : Epoch: 059, Train_Loss: 0.01043094
2025/09/16 22:12:41 : Epoch: 059, Eval_Loss: 0.00524026
2025/09/16 22:12:41 : Epoch: 060, Train_Loss: 0.00862637
2025/09/16 22:12:41 : Epoch: 061, Train_Loss: 0.00801439
2025/09/16 22:12:42 : Epoch: 062, Train_Loss: 0.00976446
2025/09/16 22:12:42 : Epoch: 063, Train_Loss: 0.00818429
2025/09/16 22:12:42 : Epoch: 064, Train_Loss: 0.00882561
2025/09/16 22:12:42 : Epoch: 064, Eval_Loss: 0.00523363
2025/09/16 22:12:42 : Epoch: 064, Save the best checkpoint
2025/09/16 22:12:43 : Epoch: 065, Train_Loss: 0.01266684
2025/09/16 22:12:43 : Epoch: 066, Train_Loss: 0.00836346
2025/09/16 22:12:43 : Epoch: 067, Train_Loss: 0.01007653
2025/09/16 22:12:43 : Epoch: 068, Train_Loss: 0.01086305
2025/09/16 22:12:44 : Epoch: 069, Train_Loss: 0.00797790
2025/09/16 22:12:44 : Epoch: 069, Eval_Loss: 0.00525931
2025/09/16 22:12:44 : Epoch: 070, Train_Loss: 0.01428013
2025/09/16 22:12:44 : Epoch: 071, Train_Loss: 0.00746582
2025/09/16 22:12:44 : Epoch: 072, Train_Loss: 0.00888275
2025/09/16 22:12:45 : Epoch: 073, Train_Loss: 0.00914785
2025/09/16 22:12:45 : Epoch: 074, Train_Loss: 0.00848362
2025/09/16 22:12:45 : Epoch: 074, Eval_Loss: 0.00523679
2025/09/16 22:12:45 : Epoch: 075, Train_Loss: 0.00828543
2025/09/16 22:12:45 : Epoch: 076, Train_Loss: 0.00967199
2025/09/16 22:12:46 : Epoch: 077, Train_Loss: 0.01216500
2025/09/16 22:12:46 : Epoch: 078, Train_Loss: 0.01142088
2025/09/16 22:12:46 : Epoch: 079, Train_Loss: 0.01047752
2025/09/16 22:12:46 : Epoch: 079, Eval_Loss: 0.00531515
2025/09/16 22:12:47 : Epoch: 080, Train_Loss: 0.01067554
2025/09/16 22:12:47 : Epoch: 081, Train_Loss: 0.00961801
2025/09/16 22:12:47 : Epoch: 082, Train_Loss: 0.01200854
2025/09/16 22:12:47 : Epoch: 083, Train_Loss: 0.00961855
2025/09/16 22:12:47 : Epoch: 084, Train_Loss: 0.01124971
2025/09/16 22:12:48 : Epoch: 084, Eval_Loss: 0.00527287
2025/09/16 22:12:48 : Epoch: 085, Train_Loss: 0.00973955
2025/09/16 22:12:48 : Epoch: 086, Train_Loss: 0.00782548
2025/09/16 22:12:48 : Epoch: 087, Train_Loss: 0.01097561
2025/09/16 22:12:49 : Epoch: 088, Train_Loss: 0.00857918
2025/09/16 22:12:49 : Epoch: 089, Train_Loss: 0.00708627
2025/09/16 22:12:49 : Epoch: 089, Eval_Loss: 0.00525585
2025/09/16 22:12:49 : Epoch: 090, Train_Loss: 0.01193776
2025/09/16 22:12:49 : Epoch: 091, Train_Loss: 0.00673466
2025/09/16 22:12:50 : Epoch: 092, Train_Loss: 0.01128814
2025/09/16 22:12:50 : Epoch: 093, Train_Loss: 0.00868598
2025/09/16 22:12:50 : Epoch: 094, Train_Loss: 0.00893306
2025/09/16 22:12:50 : Epoch: 094, Eval_Loss: 0.00526898
2025/09/16 22:12:50 : Epoch: 095, Train_Loss: 0.00843343
2025/09/16 22:12:51 : Epoch: 096, Train_Loss: 0.00849762
2025/09/16 22:12:51 : Epoch: 097, Train_Loss: 0.00999799
2025/09/16 22:12:51 : Epoch: 098, Train_Loss: 0.01065822
2025/09/16 22:12:52 : Epoch: 099, Train_Loss: 0.01184771
2025/09/16 22:12:52 : Epoch: 099, Eval_Loss: 0.00524455
2025/09/16 22:12:52 : Epoch: 100, Train_Loss: 0.00965918
2025/09/16 22:12:52 : Epoch: 101, Train_Loss: 0.01047098
2025/09/16 22:12:52 : Epoch: 102, Train_Loss: 0.01364315
2025/09/16 22:12:53 : Epoch: 103, Train_Loss: 0.01037015
2025/09/16 22:12:53 : Epoch: 104, Train_Loss: 0.01050785
2025/09/16 22:12:53 : Epoch: 104, Eval_Loss: 0.00523895
2025/09/16 22:12:53 : Epoch: 105, Train_Loss: 0.00934477
2025/09/16 22:12:53 : Epoch: 106, Train_Loss: 0.00932815
2025/09/16 22:12:54 : Epoch: 107, Train_Loss: 0.00971432
2025/09/16 22:12:54 : Epoch: 108, Train_Loss: 0.01233358
2025/09/16 22:12:54 : Epoch: 109, Train_Loss: 0.00898713
2025/09/16 22:12:54 : Epoch: 109, Eval_Loss: 0.00523383
2025/09/16 22:12:55 : Epoch: 110, Train_Loss: 0.01105028
2025/09/16 22:12:55 : Epoch: 111, Train_Loss: 0.01040294
2025/09/16 22:12:55 : Epoch: 112, Train_Loss: 0.01508807
2025/09/16 22:12:55 : Epoch: 113, Train_Loss: 0.00824786
2025/09/16 22:12:55 : Epoch: 114, Train_Loss: 0.00937408
2025/09/16 22:12:56 : Epoch: 114, Eval_Loss: 0.00531519
2025/09/16 22:12:56 : Epoch: 115, Train_Loss: 0.00682711
2025/09/16 22:12:56 : Epoch: 116, Train_Loss: 0.00814930
2025/09/16 22:12:56 : Epoch: 117, Train_Loss: 0.00748125
2025/09/16 22:12:57 : Epoch: 118, Train_Loss: 0.01093745
2025/09/16 22:12:57 : Epoch: 119, Train_Loss: 0.00817493
2025/09/16 22:12:57 : Epoch: 119, Eval_Loss: 0.00523370
2025/09/16 22:12:57 : Epoch: 120, Train_Loss: 0.01052442
2025/09/16 22:12:57 : Epoch: 121, Train_Loss: 0.01041086
2025/09/16 22:12:58 : Epoch: 122, Train_Loss: 0.00932288
2025/09/16 22:12:58 : Epoch: 123, Train_Loss: 0.01076896
2025/09/16 22:12:58 : Epoch: 124, Train_Loss: 0.01276001
2025/09/16 22:12:58 : Epoch: 124, Eval_Loss: 0.00523071
2025/09/16 22:12:58 : Epoch: 124, Save the best checkpoint
2025/09/16 22:12:58 : Epoch: 125, Train_Loss: 0.01292943
2025/09/16 22:12:59 : Epoch: 126, Train_Loss: 0.01209416
2025/09/16 22:12:59 : Epoch: 127, Train_Loss: 0.01236448
2025/09/16 22:12:59 : Epoch: 128, Train_Loss: 0.00914604
2025/09/16 22:12:59 : Epoch: 129, Train_Loss: 0.01323812
2025/09/16 22:12:59 : Epoch: 129, Eval_Loss: 0.00536928
2025/09/16 22:13:00 : Epoch: 130, Train_Loss: 0.01119498
2025/09/16 22:13:00 : Epoch: 131, Train_Loss: 0.00783621
2025/09/16 22:13:00 : Epoch: 132, Train_Loss: 0.00955538
2025/09/16 22:13:00 : Epoch: 133, Train_Loss: 0.01425374
2025/09/16 22:13:01 : Epoch: 134, Train_Loss: 0.00709501
2025/09/16 22:13:01 : Epoch: 134, Eval_Loss: 0.00526238
2025/09/16 22:13:01 : Epoch: 135, Train_Loss: 0.00866823
2025/09/16 22:13:01 : Epoch: 136, Train_Loss: 0.01012462
2025/09/16 22:13:01 : Epoch: 137, Train_Loss: 0.01411473
2025/09/16 22:13:02 : Epoch: 138, Train_Loss: 0.00905507
2025/09/16 22:13:02 : Epoch: 139, Train_Loss: 0.00921493
2025/09/16 22:13:02 : Epoch: 139, Eval_Loss: 0.00523118
2025/09/16 22:13:02 : Epoch: 140, Train_Loss: 0.01082185
2025/09/16 22:13:03 : Epoch: 141, Train_Loss: 0.00919628
2025/09/16 22:13:03 : Epoch: 142, Train_Loss: 0.01332134
2025/09/16 22:13:03 : Epoch: 143, Train_Loss: 0.01054773
2025/09/16 22:13:03 : Epoch: 144, Train_Loss: 0.01023188
2025/09/16 22:13:03 : Epoch: 144, Eval_Loss: 0.00524905
2025/09/16 22:13:04 : Epoch: 145, Train_Loss: 0.01452473
2025/09/16 22:13:04 : Epoch: 146, Train_Loss: 0.01249743
2025/09/16 22:13:04 : Epoch: 147, Train_Loss: 0.00726171
2025/09/16 22:13:04 : Epoch: 148, Train_Loss: 0.00983422
2025/09/16 22:13:05 : Epoch: 149, Train_Loss: 0.00721119
2025/09/16 22:13:05 : Epoch: 149, Eval_Loss: 0.00525875
2025/09/16 22:13:05 : Epoch: 150, Train_Loss: 0.00834778
2025/09/16 22:13:05 : Epoch: 151, Train_Loss: 0.00740003
2025/09/16 22:13:05 : Epoch: 152, Train_Loss: 0.00840891
2025/09/16 22:13:06 : Epoch: 153, Train_Loss: 0.01024620
2025/09/16 22:13:06 : Epoch: 154, Train_Loss: 0.01207781
2025/09/16 22:13:06 : Epoch: 154, Eval_Loss: 0.00523386
2025/09/16 22:13:06 : Epoch: 155, Train_Loss: 0.00865205
2025/09/16 22:13:07 : Epoch: 156, Train_Loss: 0.01097438
2025/09/16 22:13:07 : Epoch: 157, Train_Loss: 0.00907661
2025/09/16 22:13:07 : Epoch: 158, Train_Loss: 0.00864989
2025/09/16 22:13:07 : Epoch: 159, Train_Loss: 0.01438416
2025/09/16 22:13:07 : Epoch: 159, Eval_Loss: 0.00524962
2025/09/16 22:13:08 : Epoch: 160, Train_Loss: 0.01031103
2025/09/16 22:13:08 : Epoch: 161, Train_Loss: 0.01071310
2025/09/16 22:13:08 : Epoch: 162, Train_Loss: 0.00895823
2025/09/16 22:13:08 : Epoch: 163, Train_Loss: 0.01096688
2025/09/16 22:13:09 : Epoch: 164, Train_Loss: 0.00795348
2025/09/16 22:13:09 : Epoch: 164, Eval_Loss: 0.00523900
2025/09/16 22:13:09 : Epoch: 165, Train_Loss: 0.01208800
2025/09/16 22:13:09 : Epoch: 166, Train_Loss: 0.00925007
2025/09/16 22:13:09 : Epoch: 167, Train_Loss: 0.01134626
2025/09/16 22:13:10 : Epoch: 168, Train_Loss: 0.00795074
2025/09/16 22:13:10 : Epoch: 169, Train_Loss: 0.00830844
2025/09/16 22:13:10 : Epoch: 169, Eval_Loss: 0.00523511
2025/09/16 22:13:10 : Epoch: 170, Train_Loss: 0.00839544
2025/09/16 22:13:10 : Epoch: 171, Train_Loss: 0.01183085
2025/09/16 22:13:11 : Epoch: 172, Train_Loss: 0.00918268
2025/09/16 22:13:11 : Epoch: 173, Train_Loss: 0.00870250
2025/09/16 22:13:11 : Epoch: 174, Train_Loss: 0.01238579
2025/09/16 22:13:11 : Epoch: 174, Eval_Loss: 0.00530476
2025/09/16 22:13:12 : Epoch: 175, Train_Loss: 0.00904047
2025/09/16 22:13:12 : Epoch: 176, Train_Loss: 0.01119655
2025/09/16 22:13:12 : Epoch: 177, Train_Loss: 0.00669756
2025/09/16 22:13:12 : Epoch: 178, Train_Loss: 0.00902277
2025/09/16 22:13:13 : Epoch: 179, Train_Loss: 0.00914732
2025/09/16 22:13:13 : Epoch: 179, Eval_Loss: 0.00523994
2025/09/16 22:13:13 : Epoch: 180, Train_Loss: 0.01057332
2025/09/16 22:13:13 : Epoch: 181, Train_Loss: 0.00832146
2025/09/16 22:13:13 : Epoch: 182, Train_Loss: 0.00788783
2025/09/16 22:13:14 : Epoch: 183, Train_Loss: 0.01217414
2025/09/16 22:13:14 : Epoch: 184, Train_Loss: 0.00941029
2025/09/16 22:13:14 : Epoch: 184, Eval_Loss: 0.00525150
2025/09/16 22:13:14 : Epoch: 185, Train_Loss: 0.00776531
2025/09/16 22:13:14 : Epoch: 186, Train_Loss: 0.00810490
2025/09/16 22:13:15 : Epoch: 187, Train_Loss: 0.01286929
2025/09/16 22:13:15 : Epoch: 188, Train_Loss: 0.00838686
2025/09/16 22:13:15 : Epoch: 189, Train_Loss: 0.00768794
2025/09/16 22:13:15 : Epoch: 189, Eval_Loss: 0.00527755
2025/09/16 22:13:15 : Epoch: 190, Train_Loss: 0.00717020
2025/09/16 22:13:16 : Epoch: 191, Train_Loss: 0.00769401
2025/09/16 22:13:16 : Epoch: 192, Train_Loss: 0.00784149
2025/09/16 22:13:16 : Epoch: 193, Train_Loss: 0.00857878
2025/09/16 22:13:16 : Epoch: 194, Train_Loss: 0.01104712
2025/09/16 22:13:17 : Epoch: 194, Eval_Loss: 0.00523799
2025/09/16 22:13:17 : Epoch: 195, Train_Loss: 0.01000927
2025/09/16 22:13:17 : Epoch: 196, Train_Loss: 0.00980672
2025/09/16 22:13:17 : Epoch: 197, Train_Loss: 0.01514775
2025/09/16 22:13:17 : Epoch: 198, Train_Loss: 0.01363662
2025/09/16 22:13:18 : Epoch: 199, Train_Loss: 0.00798485
2025/09/16 22:13:18 : Epoch: 199, Eval_Loss: 0.00523996
2025/09/16 22:13:18 : Epoch: 200, Train_Loss: 0.00942426
2025/09/16 22:13:18 : Epoch: 201, Train_Loss: 0.00889670
2025/09/16 22:13:19 : Epoch: 202, Train_Loss: 0.01174771
2025/09/16 22:13:19 : Epoch: 203, Train_Loss: 0.00932205
2025/09/16 22:13:19 : Epoch: 204, Train_Loss: 0.00814605
2025/09/16 22:13:19 : Epoch: 204, Eval_Loss: 0.00527385
2025/09/16 22:13:19 : Epoch: 205, Train_Loss: 0.00893502
2025/09/16 22:13:20 : Epoch: 206, Train_Loss: 0.00930393
2025/09/16 22:13:20 : Epoch: 207, Train_Loss: 0.01025974
2025/09/16 22:13:20 : Epoch: 208, Train_Loss: 0.00796586
2025/09/16 22:13:20 : Epoch: 209, Train_Loss: 0.00948304
2025/09/16 22:13:20 : Epoch: 209, Eval_Loss: 0.00523857
2025/09/16 22:13:21 : Epoch: 210, Train_Loss: 0.01011600
2025/09/16 22:13:21 : Epoch: 211, Train_Loss: 0.01279288
2025/09/16 22:13:21 : Epoch: 212, Train_Loss: 0.00707602
2025/09/16 22:13:21 : Epoch: 213, Train_Loss: 0.00989811
2025/09/16 22:13:22 : Epoch: 214, Train_Loss: 0.00938705
2025/09/16 22:13:22 : Epoch: 214, Eval_Loss: 0.00530964
2025/09/16 22:13:22 : Epoch: 215, Train_Loss: 0.00917142
2025/09/16 22:13:22 : Epoch: 216, Train_Loss: 0.00786971
2025/09/16 22:13:22 : Epoch: 217, Train_Loss: 0.00884391
2025/09/16 22:13:23 : Epoch: 218, Train_Loss: 0.01020798
2025/09/16 22:13:23 : Epoch: 219, Train_Loss: 0.00872870
2025/09/16 22:13:23 : Epoch: 219, Eval_Loss: 0.00526501
2025/09/16 22:13:23 : Epoch: 220, Train_Loss: 0.00914381
2025/09/16 22:13:23 : Epoch: 221, Train_Loss: 0.01152412
2025/09/16 22:13:24 : Epoch: 222, Train_Loss: 0.00904063
2025/09/16 22:13:24 : Epoch: 223, Train_Loss: 0.00805290
2025/09/16 22:13:24 : Epoch: 224, Train_Loss: 0.01180457
2025/09/16 22:13:24 : Epoch: 224, Eval_Loss: 0.00524908
2025/09/16 22:13:25 : Epoch: 225, Train_Loss: 0.00713139
2025/09/16 22:13:25 : Epoch: 226, Train_Loss: 0.00811528
2025/09/16 22:13:25 : Epoch: 227, Train_Loss: 0.00671477
2025/09/16 22:13:25 : Epoch: 228, Train_Loss: 0.00923715
2025/09/16 22:13:26 : Epoch: 229, Train_Loss: 0.01011433
2025/09/16 22:13:26 : Epoch: 229, Eval_Loss: 0.00523140
2025/09/16 22:13:26 : Epoch: 230, Train_Loss: 0.00886995
2025/09/16 22:13:26 : Epoch: 231, Train_Loss: 0.01397952
2025/09/16 22:13:26 : Epoch: 232, Train_Loss: 0.00740775
2025/09/16 22:13:27 : Epoch: 233, Train_Loss: 0.00871931
2025/09/16 22:13:27 : Epoch: 234, Train_Loss: 0.00828738
2025/09/16 22:13:27 : Epoch: 234, Eval_Loss: 0.00523572
2025/09/16 22:13:27 : Epoch: 235, Train_Loss: 0.00971984
2025/09/16 22:13:27 : Epoch: 236, Train_Loss: 0.00957476
2025/09/16 22:13:28 : Epoch: 237, Train_Loss: 0.00849791
2025/09/16 22:13:28 : Epoch: 238, Train_Loss: 0.00983965
2025/09/16 22:13:28 : Epoch: 239, Train_Loss: 0.01015398
2025/09/16 22:13:28 : Epoch: 239, Eval_Loss: 0.00524318
2025/09/16 22:13:28 : Epoch: 240, Train_Loss: 0.01020373
2025/09/16 22:13:29 : Epoch: 241, Train_Loss: 0.01072165
2025/09/16 22:13:29 : Epoch: 242, Train_Loss: 0.01015534
2025/09/16 22:13:29 : Epoch: 243, Train_Loss: 0.00897358
2025/09/16 22:13:29 : Epoch: 244, Train_Loss: 0.01223477
2025/09/16 22:13:30 : Epoch: 244, Eval_Loss: 0.00528321
2025/09/16 22:13:30 : Epoch: 245, Train_Loss: 0.01360066
2025/09/16 22:13:30 : Epoch: 246, Train_Loss: 0.00844808
2025/09/16 22:13:30 : Epoch: 247, Train_Loss: 0.00837195
2025/09/16 22:13:31 : Epoch: 248, Train_Loss: 0.00831848
2025/09/16 22:13:31 : Epoch: 249, Train_Loss: 0.01163499
2025/09/16 22:13:31 : Epoch: 249, Eval_Loss: 0.00525872
2025/09/16 22:13:31 : Epoch: 250, Train_Loss: 0.00756504
2025/09/16 22:13:31 : Epoch: 251, Train_Loss: 0.01039677
2025/09/16 22:13:32 : Epoch: 252, Train_Loss: 0.01034646
2025/09/16 22:13:32 : Epoch: 253, Train_Loss: 0.00799484
2025/09/16 22:13:32 : Epoch: 254, Train_Loss: 0.00875944
2025/09/16 22:13:32 : Epoch: 254, Eval_Loss: 0.00524651
2025/09/16 22:13:32 : Epoch: 255, Train_Loss: 0.00944509
2025/09/16 22:13:33 : Epoch: 256, Train_Loss: 0.01112899
2025/09/16 22:13:33 : Epoch: 257, Train_Loss: 0.00997442
2025/09/16 22:13:33 : Epoch: 258, Train_Loss: 0.00889339
2025/09/16 22:13:33 : Epoch: 259, Train_Loss: 0.01101878
2025/09/16 22:13:33 : Epoch: 259, Eval_Loss: 0.00526333
2025/09/16 22:13:34 : Epoch: 260, Train_Loss: 0.01187777
2025/09/16 22:13:34 : Epoch: 261, Train_Loss: 0.00813908
2025/09/16 22:13:34 : Epoch: 262, Train_Loss: 0.01120635
2025/09/16 22:13:34 : Epoch: 263, Train_Loss: 0.01070157
2025/09/16 22:13:35 : Epoch: 264, Train_Loss: 0.00772642
2025/09/16 22:13:35 : Epoch: 264, Eval_Loss: 0.00533104
2025/09/16 22:13:35 : Epoch: 265, Train_Loss: 0.00818272
2025/09/16 22:13:35 : Epoch: 266, Train_Loss: 0.00668004
2025/09/16 22:13:35 : Epoch: 267, Train_Loss: 0.00798176
2025/09/16 22:13:36 : Epoch: 268, Train_Loss: 0.01447690
2025/09/16 22:13:36 : Epoch: 269, Train_Loss: 0.01212832
2025/09/16 22:13:36 : Epoch: 269, Eval_Loss: 0.00529137
2025/09/16 22:13:36 : Epoch: 270, Train_Loss: 0.00970997
2025/09/16 22:13:36 : Epoch: 271, Train_Loss: 0.01040123
2025/09/16 22:13:37 : Epoch: 272, Train_Loss: 0.00728170
2025/09/16 22:13:37 : Epoch: 273, Train_Loss: 0.01068901
2025/09/16 22:13:37 : Epoch: 274, Train_Loss: 0.00726049
2025/09/16 22:13:37 : Epoch: 274, Eval_Loss: 0.00526491
2025/09/16 22:13:38 : Epoch: 275, Train_Loss: 0.00885006
2025/09/16 22:13:38 : Epoch: 276, Train_Loss: 0.00821075
2025/09/16 22:13:38 : Epoch: 277, Train_Loss: 0.01355737
2025/09/16 22:13:38 : Epoch: 278, Train_Loss: 0.00865789
2025/09/16 22:13:38 : Epoch: 279, Train_Loss: 0.01367978
2025/09/16 22:13:39 : Epoch: 279, Eval_Loss: 0.00525805
2025/09/16 22:13:39 : Epoch: 280, Train_Loss: 0.00990464
2025/09/16 22:13:39 : Epoch: 281, Train_Loss: 0.00824262
2025/09/16 22:13:39 : Epoch: 282, Train_Loss: 0.00970229
2025/09/16 22:13:40 : Epoch: 283, Train_Loss: 0.01061497
2025/09/16 22:13:40 : Epoch: 284, Train_Loss: 0.00892094
2025/09/16 22:13:40 : Epoch: 284, Eval_Loss: 0.00527583
2025/09/16 22:13:40 : Epoch: 285, Train_Loss: 0.00770940
2025/09/16 22:13:40 : Epoch: 286, Train_Loss: 0.00708142
2025/09/16 22:13:41 : Epoch: 287, Train_Loss: 0.00769962
2025/09/16 22:13:41 : Epoch: 288, Train_Loss: 0.00946273
2025/09/16 22:13:41 : Epoch: 289, Train_Loss: 0.00974448
2025/09/16 22:13:41 : Epoch: 289, Eval_Loss: 0.00523582
2025/09/16 22:13:41 : Epoch: 290, Train_Loss: 0.00785512
2025/09/16 22:13:42 : Epoch: 291, Train_Loss: 0.00815985
2025/09/16 22:13:42 : Epoch: 292, Train_Loss: 0.00680457
2025/09/16 22:13:42 : Epoch: 293, Train_Loss: 0.00693177
2025/09/16 22:13:42 : Epoch: 294, Train_Loss: 0.00888907
2025/09/16 22:13:42 : Epoch: 294, Eval_Loss: 0.00523580
2025/09/16 22:13:43 : Epoch: 295, Train_Loss: 0.01325881
2025/09/16 22:13:43 : Epoch: 296, Train_Loss: 0.00871227
2025/09/16 22:13:43 : Epoch: 297, Train_Loss: 0.01029357
2025/09/16 22:13:43 : Epoch: 298, Train_Loss: 0.01285406
2025/09/16 22:13:44 : Epoch: 299, Train_Loss: 0.00822620
2025/09/16 22:13:44 : Epoch: 299, Eval_Loss: 0.00528640
2025/09/16 22:13:44 : Epoch: 300, Train_Loss: 0.00823350
2025/09/16 22:13:44 : Epoch: 301, Train_Loss: 0.01237998
2025/09/16 22:13:44 : Epoch: 302, Train_Loss: 0.01308212
2025/09/16 22:13:45 : Epoch: 303, Train_Loss: 0.00921340
2025/09/16 22:13:45 : Epoch: 304, Train_Loss: 0.00802728
2025/09/16 22:13:45 : Epoch: 304, Eval_Loss: 0.00526574
2025/09/16 22:13:45 : Epoch: 305, Train_Loss: 0.00964120
2025/09/16 22:13:46 : Epoch: 306, Train_Loss: 0.00728300
2025/09/16 22:13:46 : Epoch: 307, Train_Loss: 0.00808305
2025/09/16 22:13:46 : Epoch: 308, Train_Loss: 0.00718644
2025/09/16 22:13:46 : Epoch: 309, Train_Loss: 0.01094703
2025/09/16 22:13:46 : Epoch: 309, Eval_Loss: 0.00524402
2025/09/16 22:13:47 : Epoch: 310, Train_Loss: 0.01344551
2025/09/16 22:13:47 : Epoch: 311, Train_Loss: 0.01106310
2025/09/16 22:13:47 : Epoch: 312, Train_Loss: 0.00882056
2025/09/16 22:13:47 : Epoch: 313, Train_Loss: 0.01103965
2025/09/16 22:13:48 : Epoch: 314, Train_Loss: 0.00809949
2025/09/16 22:13:48 : Epoch: 314, Eval_Loss: 0.00524813
2025/09/16 22:13:48 : Epoch: 315, Train_Loss: 0.01106452
2025/09/16 22:13:48 : Epoch: 316, Train_Loss: 0.00760798
2025/09/16 22:13:48 : Epoch: 317, Train_Loss: 0.01039635
2025/09/16 22:13:49 : Epoch: 318, Train_Loss: 0.00836368
2025/09/16 22:13:49 : Epoch: 319, Train_Loss: 0.00924773
2025/09/16 22:13:49 : Epoch: 319, Eval_Loss: 0.00523605
2025/09/16 22:13:49 : Epoch: 320, Train_Loss: 0.01368260
2025/09/16 22:13:49 : Epoch: 321, Train_Loss: 0.00969449
2025/09/16 22:13:50 : Epoch: 322, Train_Loss: 0.00870500
2025/09/16 22:13:50 : Epoch: 323, Train_Loss: 0.00774660
2025/09/16 22:13:50 : Epoch: 324, Train_Loss: 0.00759814
2025/09/16 22:13:50 : Epoch: 324, Eval_Loss: 0.00524821
2025/09/16 22:13:51 : Epoch: 325, Train_Loss: 0.00983868
2025/09/16 22:13:51 : Epoch: 326, Train_Loss: 0.00932686
2025/09/16 22:13:51 : Epoch: 327, Train_Loss: 0.01457072
2025/09/16 22:13:51 : Epoch: 328, Train_Loss: 0.00889355
2025/09/16 22:13:52 : Epoch: 329, Train_Loss: 0.01159404
2025/09/16 22:13:52 : Epoch: 329, Eval_Loss: 0.00523732
2025/09/16 22:13:52 : Epoch: 330, Train_Loss: 0.00768569
2025/09/16 22:13:52 : Epoch: 331, Train_Loss: 0.00671682
2025/09/16 22:13:52 : Epoch: 332, Train_Loss: 0.01048210
2025/09/16 22:13:53 : Epoch: 333, Train_Loss: 0.01052393
2025/09/16 22:13:53 : Epoch: 334, Train_Loss: 0.01362096
2025/09/16 22:13:53 : Epoch: 334, Eval_Loss: 0.00524927
2025/09/16 22:13:53 : Epoch: 335, Train_Loss: 0.01042052
2025/09/16 22:13:53 : Epoch: 336, Train_Loss: 0.00906887
2025/09/16 22:13:54 : Epoch: 337, Train_Loss: 0.00886479
2025/09/16 22:13:54 : Epoch: 338, Train_Loss: 0.01080854
2025/09/16 22:13:54 : Epoch: 339, Train_Loss: 0.01159316
2025/09/16 22:13:54 : Epoch: 339, Eval_Loss: 0.00525152
2025/09/16 22:13:55 : Epoch: 340, Train_Loss: 0.00872937
2025/09/16 22:13:55 : Epoch: 341, Train_Loss: 0.00812125
2025/09/16 22:13:55 : Epoch: 342, Train_Loss: 0.00846456
2025/09/16 22:13:55 : Epoch: 343, Train_Loss: 0.01031216
2025/09/16 22:13:55 : Epoch: 344, Train_Loss: 0.01403918
2025/09/16 22:13:56 : Epoch: 344, Eval_Loss: 0.00527669
2025/09/16 22:13:56 : Epoch: 345, Train_Loss: 0.00856565
2025/09/16 22:13:56 : Epoch: 346, Train_Loss: 0.00940277
2025/09/16 22:13:56 : Epoch: 347, Train_Loss: 0.00876642
2025/09/16 22:13:57 : Epoch: 348, Train_Loss: 0.01016377
2025/09/16 22:13:57 : Epoch: 349, Train_Loss: 0.00868120
2025/09/16 22:13:57 : Epoch: 349, Eval_Loss: 0.00523755
2025/09/16 22:13:57 : Epoch: 350, Train_Loss: 0.01456893
2025/09/16 22:13:57 : Epoch: 351, Train_Loss: 0.01453112
2025/09/16 22:13:58 : Epoch: 352, Train_Loss: 0.01155104
2025/09/16 22:13:58 : Epoch: 353, Train_Loss: 0.01054257
2025/09/16 22:13:58 : Epoch: 354, Train_Loss: 0.01133199
2025/09/16 22:13:58 : Epoch: 354, Eval_Loss: 0.00526732
2025/09/16 22:13:59 : Epoch: 355, Train_Loss: 0.00893575
2025/09/16 22:13:59 : Epoch: 356, Train_Loss: 0.01136427
2025/09/16 22:13:59 : Epoch: 357, Train_Loss: 0.00954473
2025/09/16 22:13:59 : Epoch: 358, Train_Loss: 0.00897916
2025/09/16 22:14:00 : Epoch: 359, Train_Loss: 0.01131189
2025/09/16 22:14:00 : Epoch: 359, Eval_Loss: 0.00523824
2025/09/16 22:14:00 : Epoch: 360, Train_Loss: 0.01372014
2025/09/16 22:14:00 : Epoch: 361, Train_Loss: 0.00882636
2025/09/16 22:14:00 : Epoch: 362, Train_Loss: 0.00806121
2025/09/16 22:14:01 : Epoch: 363, Train_Loss: 0.00770660
2025/09/16 22:14:01 : Epoch: 364, Train_Loss: 0.00841031
2025/09/16 22:14:01 : Epoch: 364, Eval_Loss: 0.00528041
2025/09/16 22:14:01 : Epoch: 365, Train_Loss: 0.01102802
2025/09/16 22:14:01 : Epoch: 366, Train_Loss: 0.00835116
2025/09/16 22:14:02 : Epoch: 367, Train_Loss: 0.01142949
2025/09/16 22:14:02 : Epoch: 368, Train_Loss: 0.00863223
2025/09/16 22:14:02 : Epoch: 369, Train_Loss: 0.01132903
2025/09/16 22:14:02 : Epoch: 369, Eval_Loss: 0.00524510
2025/09/16 22:14:02 : Epoch: 370, Train_Loss: 0.00932288
2025/09/16 22:14:03 : Epoch: 371, Train_Loss: 0.00760458
2025/09/16 22:14:03 : Epoch: 372, Train_Loss: 0.01122893
2025/09/16 22:14:03 : Epoch: 373, Train_Loss: 0.00949280
2025/09/16 22:14:03 : Epoch: 374, Train_Loss: 0.00675764
2025/09/16 22:14:03 : Epoch: 374, Eval_Loss: 0.00523764
2025/09/16 22:14:04 : Epoch: 375, Train_Loss: 0.01000117
2025/09/16 22:14:04 : Epoch: 376, Train_Loss: 0.01175747
2025/09/16 22:14:04 : Epoch: 377, Train_Loss: 0.00935944
2025/09/16 22:14:04 : Epoch: 378, Train_Loss: 0.00949910
2025/09/16 22:14:05 : Epoch: 379, Train_Loss: 0.00965430
2025/09/16 22:14:05 : Epoch: 379, Eval_Loss: 0.00523543
2025/09/16 22:14:05 : Epoch: 380, Train_Loss: 0.01168242
2025/09/16 22:14:05 : Epoch: 381, Train_Loss: 0.01010440
2025/09/16 22:14:06 : Epoch: 382, Train_Loss: 0.00802866
2025/09/16 22:14:06 : Epoch: 383, Train_Loss: 0.01035125
2025/09/16 22:14:06 : Epoch: 384, Train_Loss: 0.01398149
2025/09/16 22:14:06 : Epoch: 384, Eval_Loss: 0.00528524
2025/09/16 22:14:06 : Epoch: 385, Train_Loss: 0.01022039
2025/09/16 22:14:07 : Epoch: 386, Train_Loss: 0.00870893
2025/09/16 22:14:07 : Epoch: 387, Train_Loss: 0.01014490
2025/09/16 22:14:07 : Epoch: 388, Train_Loss: 0.00840431
2025/09/16 22:14:07 : Epoch: 389, Train_Loss: 0.00935836
2025/09/16 22:14:07 : Epoch: 389, Eval_Loss: 0.00523560
2025/09/16 22:14:08 : Epoch: 390, Train_Loss: 0.00934050
2025/09/16 22:14:08 : Epoch: 391, Train_Loss: 0.00880456
2025/09/16 22:14:08 : Epoch: 392, Train_Loss: 0.01042788
2025/09/16 22:14:08 : Epoch: 393, Train_Loss: 0.01002200
2025/09/16 22:14:09 : Epoch: 394, Train_Loss: 0.01095398
2025/09/16 22:14:09 : Epoch: 394, Eval_Loss: 0.00523612
2025/09/16 22:14:09 : Epoch: 395, Train_Loss: 0.01060153
2025/09/16 22:14:09 : Epoch: 396, Train_Loss: 0.01244505
2025/09/16 22:14:10 : Epoch: 397, Train_Loss: 0.00877063
2025/09/16 22:14:10 : Epoch: 398, Train_Loss: 0.01011263
2025/09/16 22:14:10 : Epoch: 399, Train_Loss: 0.00715345
2025/09/16 22:14:10 : Epoch: 399, Eval_Loss: 0.00524164
2025/09/16 22:14:10 : 
Epoch: 399, save response figures

2025/09/16 22:14:22 : Epoch: 400, Train_Loss: 0.00869912
2025/09/16 22:14:22 : Epoch: 401, Train_Loss: 0.00976038
2025/09/16 22:14:23 : Epoch: 402, Train_Loss: 0.00959426
2025/09/16 22:14:23 : Epoch: 403, Train_Loss: 0.00823658
2025/09/16 22:14:23 : Epoch: 404, Train_Loss: 0.00865690
2025/09/16 22:14:23 : Epoch: 404, Eval_Loss: 0.00523287
2025/09/16 22:14:24 : Epoch: 405, Train_Loss: 0.00923075
2025/09/16 22:14:24 : Epoch: 406, Train_Loss: 0.01113394
2025/09/16 22:14:24 : Epoch: 407, Train_Loss: 0.01200216
2025/09/16 22:14:24 : Epoch: 408, Train_Loss: 0.01128077
2025/09/16 22:14:25 : Epoch: 409, Train_Loss: 0.00879778
2025/09/16 22:14:25 : Epoch: 409, Eval_Loss: 0.00527586
2025/09/16 22:14:25 : Epoch: 410, Train_Loss: 0.00719182
2025/09/16 22:14:25 : Epoch: 411, Train_Loss: 0.01211292
2025/09/16 22:14:25 : Epoch: 412, Train_Loss: 0.00912457
2025/09/16 22:14:26 : Epoch: 413, Train_Loss: 0.00845724
2025/09/16 22:14:26 : Epoch: 414, Train_Loss: 0.00786837
2025/09/16 22:14:26 : Epoch: 414, Eval_Loss: 0.00524614
2025/09/16 22:14:26 : Epoch: 415, Train_Loss: 0.00869728
2025/09/16 22:14:26 : Epoch: 416, Train_Loss: 0.01084651
2025/09/16 22:14:27 : Epoch: 417, Train_Loss: 0.00767699
2025/09/16 22:14:27 : Epoch: 418, Train_Loss: 0.01209949
2025/09/16 22:14:27 : Epoch: 419, Train_Loss: 0.00764819
2025/09/16 22:14:27 : Epoch: 419, Eval_Loss: 0.00525569
2025/09/16 22:14:27 : Epoch: 420, Train_Loss: 0.00772428
2025/09/16 22:14:28 : Epoch: 421, Train_Loss: 0.00841580
2025/09/16 22:14:28 : Epoch: 422, Train_Loss: 0.00987986
2025/09/16 22:14:28 : Epoch: 423, Train_Loss: 0.01013189
2025/09/16 22:14:28 : Epoch: 424, Train_Loss: 0.00796186
2025/09/16 22:14:29 : Epoch: 424, Eval_Loss: 0.00523632
2025/09/16 22:14:29 : Epoch: 425, Train_Loss: 0.00960246
2025/09/16 22:14:29 : Epoch: 426, Train_Loss: 0.00899539
2025/09/16 22:14:29 : Epoch: 427, Train_Loss: 0.01216532
2025/09/16 22:14:30 : Epoch: 428, Train_Loss: 0.00722431
2025/09/16 22:14:30 : Epoch: 429, Train_Loss: 0.01098902
2025/09/16 22:14:30 : Epoch: 429, Eval_Loss: 0.00525567
2025/09/16 22:14:30 : Epoch: 430, Train_Loss: 0.01188020
2025/09/16 22:14:30 : Epoch: 431, Train_Loss: 0.00835359
2025/09/16 22:14:31 : Epoch: 432, Train_Loss: 0.01174175
2025/09/16 22:14:31 : Epoch: 433, Train_Loss: 0.01113760
2025/09/16 22:14:31 : Epoch: 434, Train_Loss: 0.00948095
2025/09/16 22:14:31 : Epoch: 434, Eval_Loss: 0.00530373
2025/09/16 22:14:31 : Epoch: 435, Train_Loss: 0.00852674
2025/09/16 22:14:32 : Epoch: 436, Train_Loss: 0.00930463
2025/09/16 22:14:32 : Epoch: 437, Train_Loss: 0.01052291
2025/09/16 22:14:32 : Epoch: 438, Train_Loss: 0.01152966
2025/09/16 22:14:32 : Epoch: 439, Train_Loss: 0.00755027
2025/09/16 22:14:32 : Epoch: 439, Eval_Loss: 0.00525998
2025/09/16 22:14:33 : Epoch: 440, Train_Loss: 0.00912650
2025/09/16 22:14:33 : Epoch: 441, Train_Loss: 0.00815712
2025/09/16 22:14:33 : Epoch: 442, Train_Loss: 0.01031365
2025/09/16 22:14:33 : Epoch: 443, Train_Loss: 0.00914434
2025/09/16 22:14:34 : Epoch: 444, Train_Loss: 0.00876285
2025/09/16 22:14:34 : Epoch: 444, Eval_Loss: 0.00525051
2025/09/16 22:14:34 : Epoch: 445, Train_Loss: 0.00810954
2025/09/16 22:14:34 : Epoch: 446, Train_Loss: 0.00864730
2025/09/16 22:14:35 : Epoch: 447, Train_Loss: 0.00843259
2025/09/16 22:14:35 : Epoch: 448, Train_Loss: 0.00873383
2025/09/16 22:14:35 : Epoch: 449, Train_Loss: 0.00866684
2025/09/16 22:14:35 : Epoch: 449, Eval_Loss: 0.00524482
2025/09/16 22:14:35 : Epoch: 450, Train_Loss: 0.01119479
2025/09/16 22:14:36 : Epoch: 451, Train_Loss: 0.00934229
2025/09/16 22:14:36 : Epoch: 452, Train_Loss: 0.00843679
2025/09/16 22:14:36 : Epoch: 453, Train_Loss: 0.00709106
2025/09/16 22:14:36 : Epoch: 454, Train_Loss: 0.01051753
2025/09/16 22:14:36 : Epoch: 454, Eval_Loss: 0.00523756
2025/09/16 22:14:37 : Epoch: 455, Train_Loss: 0.01414877
2025/09/16 22:14:37 : Epoch: 456, Train_Loss: 0.00902027
2025/09/16 22:14:37 : Epoch: 457, Train_Loss: 0.00891649
2025/09/16 22:14:37 : Epoch: 458, Train_Loss: 0.01201590
2025/09/16 22:14:38 : Epoch: 459, Train_Loss: 0.00934535
2025/09/16 22:14:38 : Epoch: 459, Eval_Loss: 0.00525009
2025/09/16 22:14:38 : Epoch: 460, Train_Loss: 0.00865527
2025/09/16 22:14:38 : Epoch: 461, Train_Loss: 0.00961996
2025/09/16 22:14:38 : Epoch: 462, Train_Loss: 0.00951972
2025/09/16 22:14:39 : Epoch: 463, Train_Loss: 0.00906873
2025/09/16 22:14:39 : Epoch: 464, Train_Loss: 0.01218882
2025/09/16 22:14:39 : Epoch: 464, Eval_Loss: 0.00523981
2025/09/16 22:14:39 : Epoch: 465, Train_Loss: 0.00768643
2025/09/16 22:14:40 : Epoch: 466, Train_Loss: 0.01136186
2025/09/16 22:14:40 : Epoch: 467, Train_Loss: 0.01063148
2025/09/16 22:14:40 : Epoch: 468, Train_Loss: 0.01178040
2025/09/16 22:14:40 : Epoch: 469, Train_Loss: 0.00668965
2025/09/16 22:14:40 : Epoch: 469, Eval_Loss: 0.00525289
2025/09/16 22:14:41 : Epoch: 470, Train_Loss: 0.01063636
2025/09/16 22:14:41 : Epoch: 471, Train_Loss: 0.01426733
2025/09/16 22:14:41 : Epoch: 472, Train_Loss: 0.00878109
2025/09/16 22:14:41 : Epoch: 473, Train_Loss: 0.01146030
2025/09/16 22:14:42 : Epoch: 474, Train_Loss: 0.00804561
2025/09/16 22:14:42 : Epoch: 474, Eval_Loss: 0.00526711
2025/09/16 22:14:42 : Epoch: 475, Train_Loss: 0.00763689
2025/09/16 22:14:42 : Epoch: 476, Train_Loss: 0.00967069
2025/09/16 22:14:42 : Epoch: 477, Train_Loss: 0.00837552
2025/09/16 22:14:43 : Epoch: 478, Train_Loss: 0.00864038
2025/09/16 22:14:43 : Epoch: 479, Train_Loss: 0.00769959
2025/09/16 22:14:43 : Epoch: 479, Eval_Loss: 0.00524992
2025/09/16 22:14:43 : Epoch: 480, Train_Loss: 0.01248772
2025/09/16 22:14:43 : Epoch: 481, Train_Loss: 0.01104824
2025/09/16 22:14:44 : Epoch: 482, Train_Loss: 0.00907294
2025/09/16 22:14:44 : Epoch: 483, Train_Loss: 0.01151236
2025/09/16 22:14:44 : Epoch: 484, Train_Loss: 0.00725876
2025/09/16 22:14:44 : Epoch: 484, Eval_Loss: 0.00523629
2025/09/16 22:14:44 : Epoch: 485, Train_Loss: 0.01166987
2025/09/16 22:14:45 : Epoch: 486, Train_Loss: 0.00770484
2025/09/16 22:14:45 : Epoch: 487, Train_Loss: 0.01122261
2025/09/16 22:14:45 : Epoch: 488, Train_Loss: 0.01220647
2025/09/16 22:14:45 : Epoch: 489, Train_Loss: 0.00725369
2025/09/16 22:14:46 : Epoch: 489, Eval_Loss: 0.00529887
2025/09/16 22:14:46 : Epoch: 490, Train_Loss: 0.00735805
2025/09/16 22:14:46 : Epoch: 491, Train_Loss: 0.01232411
2025/09/16 22:14:46 : Epoch: 492, Train_Loss: 0.00920751
2025/09/16 22:14:47 : Epoch: 493, Train_Loss: 0.01058317
2025/09/16 22:14:47 : Epoch: 494, Train_Loss: 0.01038809
2025/09/16 22:14:47 : Epoch: 494, Eval_Loss: 0.00527311
2025/09/16 22:14:47 : Epoch: 495, Train_Loss: 0.00860900
2025/09/16 22:14:47 : Epoch: 496, Train_Loss: 0.00977024
2025/09/16 22:14:48 : Epoch: 497, Train_Loss: 0.00820340
2025/09/16 22:14:48 : Epoch: 498, Train_Loss: 0.00882218
2025/09/16 22:14:48 : Epoch: 499, Train_Loss: 0.00920131
2025/09/16 22:14:48 : Epoch: 499, Eval_Loss: 0.00526349
2025/09/16 22:14:48 : Epoch: 500, Train_Loss: 0.00920372
2025/09/16 22:14:49 : Epoch: 501, Train_Loss: 0.01058479
2025/09/16 22:14:49 : Epoch: 502, Train_Loss: 0.00866845
2025/09/16 22:14:49 : Epoch: 503, Train_Loss: 0.01000525
2025/09/16 22:14:49 : Epoch: 504, Train_Loss: 0.00820078
2025/09/16 22:14:49 : Epoch: 504, Eval_Loss: 0.00523918
2025/09/16 22:14:50 : Epoch: 505, Train_Loss: 0.01101877
2025/09/16 22:14:50 : Epoch: 506, Train_Loss: 0.00948550
2025/09/16 22:14:50 : Epoch: 507, Train_Loss: 0.00730699
2025/09/16 22:14:50 : Epoch: 508, Train_Loss: 0.01257234
2025/09/16 22:14:51 : Epoch: 509, Train_Loss: 0.01154566
2025/09/16 22:14:51 : Epoch: 509, Eval_Loss: 0.00524751
2025/09/16 22:14:51 : Epoch: 510, Train_Loss: 0.01141265
2025/09/16 22:14:51 : Epoch: 511, Train_Loss: 0.00699232
2025/09/16 22:14:52 : Epoch: 512, Train_Loss: 0.01226713
2025/09/16 22:14:52 : Epoch: 513, Train_Loss: 0.01073260
2025/09/16 22:14:52 : Epoch: 514, Train_Loss: 0.00924314
2025/09/16 22:14:52 : Epoch: 514, Eval_Loss: 0.00533305
2025/09/16 22:14:52 : Epoch: 515, Train_Loss: 0.01245367
2025/09/16 22:14:53 : Epoch: 516, Train_Loss: 0.00779340
2025/09/16 22:14:53 : Epoch: 517, Train_Loss: 0.00701631
2025/09/16 22:14:53 : Epoch: 518, Train_Loss: 0.01236920
2025/09/16 22:14:53 : Epoch: 519, Train_Loss: 0.01085328
2025/09/16 22:14:53 : Epoch: 519, Eval_Loss: 0.00524154
2025/09/16 22:14:54 : Epoch: 520, Train_Loss: 0.01133470
2025/09/16 22:14:54 : Epoch: 521, Train_Loss: 0.00909731
2025/09/16 22:14:54 : Epoch: 522, Train_Loss: 0.00790373
2025/09/16 22:14:54 : Epoch: 523, Train_Loss: 0.01167093
2025/09/16 22:14:55 : Epoch: 524, Train_Loss: 0.00769352
2025/09/16 22:14:55 : Epoch: 524, Eval_Loss: 0.00524839
2025/09/16 22:14:55 : Epoch: 525, Train_Loss: 0.00890039
2025/09/16 22:14:55 : Epoch: 526, Train_Loss: 0.00793396
2025/09/16 22:14:55 : Epoch: 527, Train_Loss: 0.00708570
2025/09/16 22:14:56 : Epoch: 528, Train_Loss: 0.00828716
2025/09/16 22:14:56 : Epoch: 529, Train_Loss: 0.00765930
2025/09/16 22:14:56 : Epoch: 529, Eval_Loss: 0.00523514
2025/09/16 22:14:56 : Epoch: 530, Train_Loss: 0.01235888
2025/09/16 22:14:56 : Epoch: 531, Train_Loss: 0.00850252
2025/09/16 22:14:57 : Epoch: 532, Train_Loss: 0.01160965
2025/09/16 22:14:57 : Epoch: 533, Train_Loss: 0.00849676
2025/09/16 22:14:57 : Epoch: 534, Train_Loss: 0.01060348
2025/09/16 22:14:57 : Epoch: 534, Eval_Loss: 0.00531437
2025/09/16 22:14:58 : Epoch: 535, Train_Loss: 0.00979233
2025/09/16 22:14:58 : Epoch: 536, Train_Loss: 0.00804346
2025/09/16 22:14:58 : Epoch: 537, Train_Loss: 0.00757903
2025/09/16 22:14:58 : Epoch: 538, Train_Loss: 0.00981842
2025/09/16 22:14:59 : Epoch: 539, Train_Loss: 0.01209048
2025/09/16 22:14:59 : Epoch: 539, Eval_Loss: 0.00524021
2025/09/16 22:14:59 : Epoch: 540, Train_Loss: 0.01302114
2025/09/16 22:14:59 : Epoch: 541, Train_Loss: 0.01556383
2025/09/16 22:14:59 : Epoch: 542, Train_Loss: 0.00948672
2025/09/16 22:15:00 : Epoch: 543, Train_Loss: 0.00984726
2025/09/16 22:15:00 : Epoch: 544, Train_Loss: 0.01095207
2025/09/16 22:15:00 : Epoch: 544, Eval_Loss: 0.00525976
2025/09/16 22:15:00 : Epoch: 545, Train_Loss: 0.01147228
2025/09/16 22:15:00 : Epoch: 546, Train_Loss: 0.01043200
2025/09/16 22:15:01 : Epoch: 547, Train_Loss: 0.00819372
2025/09/16 22:15:01 : Epoch: 548, Train_Loss: 0.01179104
2025/09/16 22:15:01 : Epoch: 549, Train_Loss: 0.01066343
2025/09/16 22:15:01 : Epoch: 549, Eval_Loss: 0.00524108
2025/09/16 22:15:01 : Epoch: 550, Train_Loss: 0.01305917
2025/09/16 22:15:02 : Epoch: 551, Train_Loss: 0.01068999
2025/09/16 22:15:02 : Epoch: 552, Train_Loss: 0.00755481
2025/09/16 22:15:02 : Epoch: 553, Train_Loss: 0.01047644
2025/09/16 22:15:02 : Epoch: 554, Train_Loss: 0.00875531
2025/09/16 22:15:03 : Epoch: 554, Eval_Loss: 0.00523708
2025/09/16 22:15:03 : Epoch: 555, Train_Loss: 0.00770893
2025/09/16 22:15:03 : Epoch: 556, Train_Loss: 0.01277205
2025/09/16 22:15:03 : Epoch: 557, Train_Loss: 0.01271406
2025/09/16 22:15:04 : Epoch: 558, Train_Loss: 0.01009654
2025/09/16 22:15:04 : Epoch: 559, Train_Loss: 0.00821593
2025/09/16 22:15:04 : Epoch: 559, Eval_Loss: 0.00524230
2025/09/16 22:15:04 : Epoch: 560, Train_Loss: 0.00969120
2025/09/16 22:15:04 : Epoch: 561, Train_Loss: 0.01172377
2025/09/16 22:15:05 : Epoch: 562, Train_Loss: 0.01085447
2025/09/16 22:15:05 : Epoch: 563, Train_Loss: 0.01011925
2025/09/16 22:15:05 : Epoch: 564, Train_Loss: 0.01310068
2025/09/16 22:15:05 : Epoch: 564, Eval_Loss: 0.00523968
2025/09/16 22:15:05 : Epoch: 565, Train_Loss: 0.00775922
2025/09/16 22:15:06 : Epoch: 566, Train_Loss: 0.01143846
2025/09/16 22:15:06 : Epoch: 567, Train_Loss: 0.01124143
2025/09/16 22:15:06 : Epoch: 568, Train_Loss: 0.01050722
2025/09/16 22:15:06 : Epoch: 569, Train_Loss: 0.00859631
2025/09/16 22:15:07 : Epoch: 569, Eval_Loss: 0.00530650
2025/09/16 22:15:07 : Epoch: 570, Train_Loss: 0.01333967
2025/09/16 22:15:07 : Epoch: 571, Train_Loss: 0.01428988
2025/09/16 22:15:07 : Epoch: 572, Train_Loss: 0.00961796
2025/09/16 22:15:08 : Epoch: 573, Train_Loss: 0.00857603
2025/09/16 22:15:08 : Epoch: 574, Train_Loss: 0.00778683
2025/09/16 22:15:08 : Epoch: 574, Eval_Loss: 0.00526142
2025/09/16 22:15:08 : Epoch: 575, Train_Loss: 0.01185696
2025/09/16 22:15:08 : Epoch: 576, Train_Loss: 0.01105216
2025/09/16 22:15:09 : Epoch: 577, Train_Loss: 0.01363974
2025/09/16 22:15:09 : Epoch: 578, Train_Loss: 0.01101841
2025/09/16 22:15:09 : Epoch: 579, Train_Loss: 0.00842061
2025/09/16 22:15:09 : Epoch: 579, Eval_Loss: 0.00526262
2025/09/16 22:15:09 : Epoch: 580, Train_Loss: 0.00842253
2025/09/16 22:15:10 : Epoch: 581, Train_Loss: 0.00795051
2025/09/16 22:15:10 : Epoch: 582, Train_Loss: 0.00865590
2025/09/16 22:15:10 : Epoch: 583, Train_Loss: 0.00793181
2025/09/16 22:15:10 : Epoch: 584, Train_Loss: 0.00757107
2025/09/16 22:15:10 : Epoch: 584, Eval_Loss: 0.00524756
2025/09/16 22:15:11 : Epoch: 585, Train_Loss: 0.00884098
2025/09/16 22:15:11 : Epoch: 586, Train_Loss: 0.00765917
2025/09/16 22:15:11 : Epoch: 587, Train_Loss: 0.01080525
2025/09/16 22:15:11 : Epoch: 588, Train_Loss: 0.00932621
2025/09/16 22:15:12 : Epoch: 589, Train_Loss: 0.01137138
2025/09/16 22:15:12 : Epoch: 589, Eval_Loss: 0.00524818
2025/09/16 22:15:12 : Epoch: 590, Train_Loss: 0.01269793
2025/09/16 22:15:12 : Epoch: 591, Train_Loss: 0.01111477
2025/09/16 22:15:13 : Epoch: 592, Train_Loss: 0.01242525
2025/09/16 22:15:13 : Epoch: 593, Train_Loss: 0.01003775
2025/09/16 22:15:13 : Epoch: 594, Train_Loss: 0.01138302
2025/09/16 22:15:13 : Epoch: 594, Eval_Loss: 0.00527481
2025/09/16 22:15:13 : Epoch: 595, Train_Loss: 0.01103542
2025/09/16 22:15:14 : Epoch: 596, Train_Loss: 0.01002254
2025/09/16 22:15:14 : Epoch: 597, Train_Loss: 0.00753408
2025/09/16 22:15:14 : Epoch: 598, Train_Loss: 0.00792001
2025/09/16 22:15:14 : Epoch: 599, Train_Loss: 0.01075030
2025/09/16 22:15:15 : Epoch: 599, Eval_Loss: 0.00526449
2025/09/16 22:15:15 : Epoch: 600, Train_Loss: 0.00851225
2025/09/16 22:15:15 : Epoch: 601, Train_Loss: 0.00927994
2025/09/16 22:15:15 : Epoch: 602, Train_Loss: 0.00868067
2025/09/16 22:15:16 : Epoch: 603, Train_Loss: 0.01039992
2025/09/16 22:15:16 : Epoch: 604, Train_Loss: 0.00940706
2025/09/16 22:15:16 : Epoch: 604, Eval_Loss: 0.00529204
2025/09/16 22:15:16 : Epoch: 605, Train_Loss: 0.01333029
2025/09/16 22:15:16 : Epoch: 606, Train_Loss: 0.00887446
2025/09/16 22:15:17 : Epoch: 607, Train_Loss: 0.01116601
2025/09/16 22:15:17 : Epoch: 608, Train_Loss: 0.01197157
2025/09/16 22:15:17 : Epoch: 609, Train_Loss: 0.00997511
2025/09/16 22:15:17 : Epoch: 609, Eval_Loss: 0.00525207
2025/09/16 22:15:17 : Epoch: 610, Train_Loss: 0.01107569
2025/09/16 22:15:18 : Epoch: 611, Train_Loss: 0.01094351
2025/09/16 22:15:18 : Epoch: 612, Train_Loss: 0.00759273
2025/09/16 22:15:18 : Epoch: 613, Train_Loss: 0.01149007
2025/09/16 22:15:18 : Epoch: 614, Train_Loss: 0.01071083
2025/09/16 22:15:18 : Epoch: 614, Eval_Loss: 0.00526413
2025/09/16 22:15:19 : Epoch: 615, Train_Loss: 0.00958916
2025/09/16 22:15:19 : Epoch: 616, Train_Loss: 0.01042851
2025/09/16 22:15:19 : Epoch: 617, Train_Loss: 0.00741000
2025/09/16 22:15:19 : Epoch: 618, Train_Loss: 0.00895916
2025/09/16 22:15:20 : Epoch: 619, Train_Loss: 0.01030624
2025/09/16 22:15:20 : Epoch: 619, Eval_Loss: 0.00524162
2025/09/16 22:15:20 : Epoch: 620, Train_Loss: 0.00846731
2025/09/16 22:15:20 : Epoch: 621, Train_Loss: 0.01137312
2025/09/16 22:15:20 : Epoch: 622, Train_Loss: 0.00812836
2025/09/16 22:15:21 : Epoch: 623, Train_Loss: 0.00669208
2025/09/16 22:15:21 : Epoch: 624, Train_Loss: 0.00994286
2025/09/16 22:15:21 : Epoch: 624, Eval_Loss: 0.00524313
2025/09/16 22:15:21 : Epoch: 625, Train_Loss: 0.01093042
2025/09/16 22:15:21 : Epoch: 626, Train_Loss: 0.00984455
2025/09/16 22:15:22 : Epoch: 627, Train_Loss: 0.00967365
2025/09/16 22:15:22 : Epoch: 628, Train_Loss: 0.00928995
2025/09/16 22:15:22 : Epoch: 629, Train_Loss: 0.00701493
2025/09/16 22:15:22 : Epoch: 629, Eval_Loss: 0.00523910
2025/09/16 22:15:23 : Epoch: 630, Train_Loss: 0.01322624
2025/09/16 22:15:23 : Epoch: 631, Train_Loss: 0.00718997
2025/09/16 22:15:23 : Epoch: 632, Train_Loss: 0.00987907
2025/09/16 22:15:23 : Epoch: 633, Train_Loss: 0.00840151
2025/09/16 22:15:24 : Epoch: 634, Train_Loss: 0.00769007
2025/09/16 22:15:24 : Epoch: 634, Eval_Loss: 0.00523913
2025/09/16 22:15:24 : Epoch: 635, Train_Loss: 0.01371866
2025/09/16 22:15:24 : Epoch: 636, Train_Loss: 0.00982620
2025/09/16 22:15:24 : Epoch: 637, Train_Loss: 0.00664850
2025/09/16 22:15:25 : Epoch: 638, Train_Loss: 0.01353957
2025/09/16 22:15:25 : Epoch: 639, Train_Loss: 0.00961805
2025/09/16 22:15:25 : Epoch: 639, Eval_Loss: 0.00527095
2025/09/16 22:15:25 : Epoch: 640, Train_Loss: 0.00845548
2025/09/16 22:15:25 : Epoch: 641, Train_Loss: 0.01261811
2025/09/16 22:15:26 : Epoch: 642, Train_Loss: 0.00936828
2025/09/16 22:15:26 : Epoch: 643, Train_Loss: 0.01017302
2025/09/16 22:15:26 : Epoch: 644, Train_Loss: 0.00968373
2025/09/16 22:15:26 : Epoch: 644, Eval_Loss: 0.00523984
2025/09/16 22:15:26 : Epoch: 645, Train_Loss: 0.01022914
2025/09/16 22:15:27 : Epoch: 646, Train_Loss: 0.00753185
2025/09/16 22:15:27 : Epoch: 647, Train_Loss: 0.00888273
2025/09/16 22:15:27 : Epoch: 648, Train_Loss: 0.01101087
2025/09/16 22:15:27 : Epoch: 649, Train_Loss: 0.00914919
2025/09/16 22:15:27 : Epoch: 649, Eval_Loss: 0.00524087
2025/09/16 22:15:28 : Epoch: 650, Train_Loss: 0.00835545
2025/09/16 22:15:28 : Epoch: 651, Train_Loss: 0.00825200
2025/09/16 22:15:28 : Epoch: 652, Train_Loss: 0.00878179
2025/09/16 22:15:28 : Epoch: 653, Train_Loss: 0.00809344
2025/09/16 22:15:29 : Epoch: 654, Train_Loss: 0.01203016
2025/09/16 22:15:29 : Epoch: 654, Eval_Loss: 0.00523405
2025/09/16 22:15:29 : Epoch: 655, Train_Loss: 0.00823745
2025/09/16 22:15:29 : Epoch: 656, Train_Loss: 0.01211730
2025/09/16 22:15:30 : Epoch: 657, Train_Loss: 0.00965266
2025/09/16 22:15:30 : Epoch: 658, Train_Loss: 0.01223974
2025/09/16 22:15:30 : Epoch: 659, Train_Loss: 0.01114563
2025/09/16 22:15:30 : Epoch: 659, Eval_Loss: 0.00528628
2025/09/16 22:15:30 : Epoch: 660, Train_Loss: 0.00777665
2025/09/16 22:15:31 : Epoch: 661, Train_Loss: 0.00940593
2025/09/16 22:15:31 : Epoch: 662, Train_Loss: 0.00839226
2025/09/16 22:15:31 : Epoch: 663, Train_Loss: 0.00781461
2025/09/16 22:15:31 : Epoch: 664, Train_Loss: 0.00669658
2025/09/16 22:15:31 : Epoch: 664, Eval_Loss: 0.00523428
2025/09/16 22:15:32 : Epoch: 665, Train_Loss: 0.01240588
2025/09/16 22:15:32 : Epoch: 666, Train_Loss: 0.00924599
2025/09/16 22:15:32 : Epoch: 667, Train_Loss: 0.01597382
2025/09/16 22:15:32 : Epoch: 668, Train_Loss: 0.01409622
2025/09/16 22:15:33 : Epoch: 669, Train_Loss: 0.01425408
2025/09/16 22:15:33 : Epoch: 669, Eval_Loss: 0.00524323
2025/09/16 22:15:33 : Epoch: 670, Train_Loss: 0.00810947
2025/09/16 22:15:33 : Epoch: 671, Train_Loss: 0.00979727
2025/09/16 22:15:33 : Epoch: 672, Train_Loss: 0.00975209
2025/09/16 22:15:34 : Epoch: 673, Train_Loss: 0.00837751
2025/09/16 22:15:34 : Epoch: 674, Train_Loss: 0.01433018
2025/09/16 22:15:34 : Epoch: 674, Eval_Loss: 0.00524729
2025/09/16 22:15:34 : Epoch: 675, Train_Loss: 0.01019646
2025/09/16 22:15:34 : Epoch: 676, Train_Loss: 0.01138209
2025/09/16 22:15:35 : Epoch: 677, Train_Loss: 0.00773238
2025/09/16 22:15:35 : Epoch: 678, Train_Loss: 0.00792982
2025/09/16 22:15:35 : Epoch: 679, Train_Loss: 0.00937255
2025/09/16 22:15:35 : Epoch: 679, Eval_Loss: 0.00524797
2025/09/16 22:15:36 : Epoch: 680, Train_Loss: 0.00893729
2025/09/16 22:15:36 : Epoch: 681, Train_Loss: 0.00975656
2025/09/16 22:15:36 : Epoch: 682, Train_Loss: 0.00849588
2025/09/16 22:15:36 : Epoch: 683, Train_Loss: 0.01176714
2025/09/16 22:15:37 : Epoch: 684, Train_Loss: 0.01128283
2025/09/16 22:15:37 : Epoch: 684, Eval_Loss: 0.00523712
2025/09/16 22:15:37 : Epoch: 685, Train_Loss: 0.01407665
2025/09/16 22:15:37 : Epoch: 686, Train_Loss: 0.01025921
2025/09/16 22:15:37 : Epoch: 687, Train_Loss: 0.00677744
2025/09/16 22:15:38 : Epoch: 688, Train_Loss: 0.00937857
2025/09/16 22:15:38 : Epoch: 689, Train_Loss: 0.00882665
2025/09/16 22:15:38 : Epoch: 689, Eval_Loss: 0.00523791
2025/09/16 22:15:38 : Epoch: 690, Train_Loss: 0.00840848
2025/09/16 22:15:38 : Epoch: 691, Train_Loss: 0.00984829
2025/09/16 22:15:39 : Epoch: 692, Train_Loss: 0.01413268
2025/09/16 22:15:39 : Epoch: 693, Train_Loss: 0.01029822
2025/09/16 22:15:39 : Epoch: 694, Train_Loss: 0.00889909
2025/09/16 22:15:39 : Epoch: 694, Eval_Loss: 0.00527194
2025/09/16 22:15:39 : Epoch: 695, Train_Loss: 0.01028352
2025/09/16 22:15:40 : Epoch: 696, Train_Loss: 0.00963585
2025/09/16 22:15:40 : Epoch: 697, Train_Loss: 0.01236512
2025/09/16 22:15:40 : Epoch: 698, Train_Loss: 0.01004585
2025/09/16 22:15:40 : Epoch: 699, Train_Loss: 0.00949728
2025/09/16 22:15:41 : Epoch: 699, Eval_Loss: 0.00528590
2025/09/16 22:15:41 : Epoch: 700, Train_Loss: 0.00915014
2025/09/16 22:15:41 : Epoch: 701, Train_Loss: 0.01179222
2025/09/16 22:15:41 : Epoch: 702, Train_Loss: 0.01082693
2025/09/16 22:15:41 : Epoch: 703, Train_Loss: 0.00943066
2025/09/16 22:15:42 : Epoch: 704, Train_Loss: 0.00723728
2025/09/16 22:15:42 : Epoch: 704, Eval_Loss: 0.00525243
2025/09/16 22:15:42 : Epoch: 705, Train_Loss: 0.01085671
2025/09/16 22:15:42 : Epoch: 706, Train_Loss: 0.00930717
2025/09/16 22:15:43 : Epoch: 707, Train_Loss: 0.01425115
2025/09/16 22:15:43 : Epoch: 708, Train_Loss: 0.00969200
2025/09/16 22:15:43 : Epoch: 709, Train_Loss: 0.00923329
2025/09/16 22:15:43 : Epoch: 709, Eval_Loss: 0.00523537
2025/09/16 22:15:43 : Epoch: 710, Train_Loss: 0.01268353
2025/09/16 22:15:44 : Epoch: 711, Train_Loss: 0.01328117
2025/09/16 22:15:44 : Epoch: 712, Train_Loss: 0.00884662
2025/09/16 22:15:44 : Epoch: 713, Train_Loss: 0.00818336
2025/09/16 22:15:44 : Epoch: 714, Train_Loss: 0.00952671
2025/09/16 22:15:44 : Epoch: 714, Eval_Loss: 0.00531261
2025/09/16 22:15:45 : Epoch: 715, Train_Loss: 0.00775055
2025/09/16 22:15:45 : Epoch: 716, Train_Loss: 0.00863205
2025/09/16 22:15:45 : Epoch: 717, Train_Loss: 0.00824956
2025/09/16 22:15:45 : Epoch: 718, Train_Loss: 0.01242516
2025/09/16 22:15:46 : Epoch: 719, Train_Loss: 0.00948690
2025/09/16 22:15:46 : Epoch: 719, Eval_Loss: 0.00523740
2025/09/16 22:15:46 : Epoch: 720, Train_Loss: 0.00932584
2025/09/16 22:15:46 : Epoch: 721, Train_Loss: 0.00871431
2025/09/16 22:15:47 : Epoch: 722, Train_Loss: 0.01200118
2025/09/16 22:15:47 : Epoch: 723, Train_Loss: 0.00926014
2025/09/16 22:15:47 : Epoch: 724, Train_Loss: 0.00798633
2025/09/16 22:15:47 : Epoch: 724, Eval_Loss: 0.00525221
2025/09/16 22:15:47 : Epoch: 725, Train_Loss: 0.00855051
2025/09/16 22:15:48 : Epoch: 726, Train_Loss: 0.01203346
2025/09/16 22:15:48 : Epoch: 727, Train_Loss: 0.00875827
2025/09/16 22:15:48 : Epoch: 728, Train_Loss: 0.00983983
2025/09/16 22:15:48 : Epoch: 729, Train_Loss: 0.00785195
2025/09/16 22:15:48 : Epoch: 729, Eval_Loss: 0.00525171
2025/09/16 22:15:49 : Epoch: 730, Train_Loss: 0.01189598
2025/09/16 22:15:49 : Epoch: 731, Train_Loss: 0.00861267
2025/09/16 22:15:49 : Epoch: 732, Train_Loss: 0.00971325
2025/09/16 22:15:49 : Epoch: 733, Train_Loss: 0.01181279
2025/09/16 22:15:50 : Epoch: 734, Train_Loss: 0.01093053
2025/09/16 22:15:50 : Epoch: 734, Eval_Loss: 0.00524410
2025/09/16 22:15:50 : Epoch: 735, Train_Loss: 0.01368234
2025/09/16 22:15:50 : Epoch: 736, Train_Loss: 0.00971274
2025/09/16 22:15:50 : Epoch: 737, Train_Loss: 0.01260697
2025/09/16 22:15:51 : Epoch: 738, Train_Loss: 0.01177068
2025/09/16 22:15:51 : Epoch: 739, Train_Loss: 0.00678893
2025/09/16 22:15:51 : Epoch: 739, Eval_Loss: 0.00525570
2025/09/16 22:15:51 : Epoch: 740, Train_Loss: 0.00862887
2025/09/16 22:15:51 : Epoch: 741, Train_Loss: 0.00915423
2025/09/16 22:15:52 : Epoch: 742, Train_Loss: 0.01078056
2025/09/16 22:15:52 : Epoch: 743, Train_Loss: 0.01197715
2025/09/16 22:15:52 : Epoch: 744, Train_Loss: 0.00817135
2025/09/16 22:15:52 : Epoch: 744, Eval_Loss: 0.00523262
2025/09/16 22:15:53 : Epoch: 745, Train_Loss: 0.01081400
2025/09/16 22:15:53 : Epoch: 746, Train_Loss: 0.00991450
2025/09/16 22:15:53 : Epoch: 747, Train_Loss: 0.00848987
2025/09/16 22:15:53 : Epoch: 748, Train_Loss: 0.00788789
2025/09/16 22:15:54 : Epoch: 749, Train_Loss: 0.00919095
2025/09/16 22:15:54 : Epoch: 749, Eval_Loss: 0.00524093
2025/09/16 22:15:54 : Epoch: 750, Train_Loss: 0.01099019
2025/09/16 22:15:54 : Epoch: 751, Train_Loss: 0.00715569
2025/09/16 22:15:54 : Epoch: 752, Train_Loss: 0.01318284
2025/09/16 22:15:55 : Epoch: 753, Train_Loss: 0.01102205
2025/09/16 22:15:55 : Epoch: 754, Train_Loss: 0.01209586
2025/09/16 22:15:55 : Epoch: 754, Eval_Loss: 0.00527186
2025/09/16 22:15:55 : Epoch: 755, Train_Loss: 0.00757891
2025/09/16 22:15:55 : Epoch: 756, Train_Loss: 0.00760401
2025/09/16 22:15:56 : Epoch: 757, Train_Loss: 0.00898362
2025/09/16 22:15:56 : Epoch: 758, Train_Loss: 0.00821876
2025/09/16 22:15:56 : Epoch: 759, Train_Loss: 0.00888224
2025/09/16 22:15:56 : Epoch: 759, Eval_Loss: 0.00525657
2025/09/16 22:15:56 : Epoch: 760, Train_Loss: 0.00769353
2025/09/16 22:15:57 : Epoch: 761, Train_Loss: 0.00805342
2025/09/16 22:15:57 : Epoch: 762, Train_Loss: 0.00912130
2025/09/16 22:15:57 : Epoch: 763, Train_Loss: 0.01010879
2025/09/16 22:15:57 : Epoch: 764, Train_Loss: 0.01107766
2025/09/16 22:15:58 : Epoch: 764, Eval_Loss: 0.00523348
2025/09/16 22:15:58 : Epoch: 765, Train_Loss: 0.00825905
2025/09/16 22:15:58 : Epoch: 766, Train_Loss: 0.00808661
2025/09/16 22:15:58 : Epoch: 767, Train_Loss: 0.00907190
2025/09/16 22:15:58 : Epoch: 768, Train_Loss: 0.01364600
2025/09/16 22:15:59 : Epoch: 769, Train_Loss: 0.00701501
2025/09/16 22:15:59 : Epoch: 769, Eval_Loss: 0.00524582
2025/09/16 22:15:59 : Epoch: 770, Train_Loss: 0.01364242
2025/09/16 22:15:59 : Epoch: 771, Train_Loss: 0.00874186
2025/09/16 22:16:00 : Epoch: 772, Train_Loss: 0.01011780
2025/09/16 22:16:00 : Epoch: 773, Train_Loss: 0.00919806
2025/09/16 22:16:00 : Epoch: 774, Train_Loss: 0.01348247
2025/09/16 22:16:00 : Epoch: 774, Eval_Loss: 0.00527608
2025/09/16 22:16:00 : Epoch: 775, Train_Loss: 0.01157191
2025/09/16 22:16:01 : Epoch: 776, Train_Loss: 0.00659453
2025/09/16 22:16:01 : Epoch: 777, Train_Loss: 0.00786373
2025/09/16 22:16:01 : Epoch: 778, Train_Loss: 0.01415164
2025/09/16 22:16:01 : Epoch: 779, Train_Loss: 0.00783882
2025/09/16 22:16:01 : Epoch: 779, Eval_Loss: 0.00528657
2025/09/16 22:16:02 : Epoch: 780, Train_Loss: 0.01201827
2025/09/16 22:16:02 : Epoch: 781, Train_Loss: 0.01350726
2025/09/16 22:16:02 : Epoch: 782, Train_Loss: 0.00815437
2025/09/16 22:16:02 : Epoch: 783, Train_Loss: 0.00983752
2025/09/16 22:16:03 : Epoch: 784, Train_Loss: 0.00855202
2025/09/16 22:16:03 : Epoch: 784, Eval_Loss: 0.00527434
2025/09/16 22:16:03 : Epoch: 785, Train_Loss: 0.01059750
2025/09/16 22:16:03 : Epoch: 786, Train_Loss: 0.01026369
2025/09/16 22:16:04 : Epoch: 787, Train_Loss: 0.00981704
2025/09/16 22:16:04 : Epoch: 788, Train_Loss: 0.01011644
2025/09/16 22:16:04 : Epoch: 789, Train_Loss: 0.00893310
2025/09/16 22:16:04 : Epoch: 789, Eval_Loss: 0.00526686
2025/09/16 22:16:04 : Epoch: 790, Train_Loss: 0.00877341
2025/09/16 22:16:05 : Epoch: 791, Train_Loss: 0.00936955
2025/09/16 22:16:05 : Epoch: 792, Train_Loss: 0.01472178
2025/09/16 22:16:05 : Epoch: 793, Train_Loss: 0.00895332
2025/09/16 22:16:05 : Epoch: 794, Train_Loss: 0.01198687
2025/09/16 22:16:05 : Epoch: 794, Eval_Loss: 0.00524478
2025/09/16 22:16:06 : Epoch: 795, Train_Loss: 0.00941816
2025/09/16 22:16:06 : Epoch: 796, Train_Loss: 0.01347258
2025/09/16 22:16:06 : Epoch: 797, Train_Loss: 0.01030201
2025/09/16 22:16:06 : Epoch: 798, Train_Loss: 0.00936661
2025/09/16 22:16:07 : Epoch: 799, Train_Loss: 0.00719809
2025/09/16 22:16:07 : Epoch: 799, Eval_Loss: 0.00528811
2025/09/16 22:16:07 : 
Epoch: 799, save response figures

2025/09/16 22:16:19 : Epoch: 800, Train_Loss: 0.00921811
2025/09/16 22:16:19 : Epoch: 801, Train_Loss: 0.00870321
2025/09/16 22:16:19 : Epoch: 802, Train_Loss: 0.00951579
2025/09/16 22:16:20 : Epoch: 803, Train_Loss: 0.00904764
2025/09/16 22:16:20 : Epoch: 804, Train_Loss: 0.00813508
2025/09/16 22:16:20 : Epoch: 804, Eval_Loss: 0.00524626
2025/09/16 22:16:20 : Epoch: 805, Train_Loss: 0.00816923
2025/09/16 22:16:21 : Epoch: 806, Train_Loss: 0.00749790
2025/09/16 22:16:21 : Epoch: 807, Train_Loss: 0.01036440
2025/09/16 22:16:21 : Epoch: 808, Train_Loss: 0.00726301
2025/09/16 22:16:21 : Epoch: 809, Train_Loss: 0.00717142
2025/09/16 22:16:21 : Epoch: 809, Eval_Loss: 0.00523739
2025/09/16 22:16:22 : Epoch: 810, Train_Loss: 0.01258024
2025/09/16 22:16:22 : Epoch: 811, Train_Loss: 0.01061979
2025/09/16 22:16:22 : Epoch: 812, Train_Loss: 0.01102482
2025/09/16 22:16:22 : Epoch: 813, Train_Loss: 0.00765998
2025/09/16 22:16:23 : Epoch: 814, Train_Loss: 0.00838782
2025/09/16 22:16:23 : Epoch: 814, Eval_Loss: 0.00524531
2025/09/16 22:16:23 : Epoch: 815, Train_Loss: 0.00852544
2025/09/16 22:16:23 : Epoch: 816, Train_Loss: 0.01411991
2025/09/16 22:16:23 : Epoch: 817, Train_Loss: 0.00972554
2025/09/16 22:16:24 : Epoch: 818, Train_Loss: 0.00943924
2025/09/16 22:16:24 : Epoch: 819, Train_Loss: 0.00861086
2025/09/16 22:16:24 : Epoch: 819, Eval_Loss: 0.00524747
2025/09/16 22:16:24 : Epoch: 820, Train_Loss: 0.00992522
2025/09/16 22:16:24 : Epoch: 821, Train_Loss: 0.00789412
2025/09/16 22:16:25 : Epoch: 822, Train_Loss: 0.00866834
2025/09/16 22:16:25 : Epoch: 823, Train_Loss: 0.01417084
2025/09/16 22:16:25 : Epoch: 824, Train_Loss: 0.01075718
2025/09/16 22:16:25 : Epoch: 824, Eval_Loss: 0.00524027
2025/09/16 22:16:26 : Epoch: 825, Train_Loss: 0.00865168
2025/09/16 22:16:26 : Epoch: 826, Train_Loss: 0.00843190
2025/09/16 22:16:26 : Epoch: 827, Train_Loss: 0.01066146
2025/09/16 22:16:26 : Epoch: 828, Train_Loss: 0.00773492
2025/09/16 22:16:27 : Epoch: 829, Train_Loss: 0.00839972
2025/09/16 22:16:27 : Epoch: 829, Eval_Loss: 0.00524190
2025/09/16 22:16:27 : Epoch: 830, Train_Loss: 0.00854728
2025/09/16 22:16:27 : Epoch: 831, Train_Loss: 0.00825600
2025/09/16 22:16:27 : Epoch: 832, Train_Loss: 0.00986038
2025/09/16 22:16:28 : Epoch: 833, Train_Loss: 0.00994037
2025/09/16 22:16:28 : Epoch: 834, Train_Loss: 0.00970097
2025/09/16 22:16:28 : Epoch: 834, Eval_Loss: 0.00523436
2025/09/16 22:16:28 : Epoch: 835, Train_Loss: 0.00816095
2025/09/16 22:16:28 : Epoch: 836, Train_Loss: 0.01002675
2025/09/16 22:16:29 : Epoch: 837, Train_Loss: 0.01119845
2025/09/16 22:16:29 : Epoch: 838, Train_Loss: 0.00934045
2025/09/16 22:16:29 : Epoch: 839, Train_Loss: 0.01365836
2025/09/16 22:16:29 : Epoch: 839, Eval_Loss: 0.00524056
2025/09/16 22:16:30 : Epoch: 840, Train_Loss: 0.01257930
2025/09/16 22:16:30 : Epoch: 841, Train_Loss: 0.01020567
2025/09/16 22:16:30 : Epoch: 842, Train_Loss: 0.00932843
2025/09/16 22:16:30 : Epoch: 843, Train_Loss: 0.00859857
2025/09/16 22:16:30 : Epoch: 844, Train_Loss: 0.00913644
2025/09/16 22:16:31 : Epoch: 844, Eval_Loss: 0.00525451
2025/09/16 22:16:31 : Epoch: 845, Train_Loss: 0.00871951
2025/09/16 22:16:31 : Epoch: 846, Train_Loss: 0.00924759
2025/09/16 22:16:31 : Epoch: 847, Train_Loss: 0.00768132
2025/09/16 22:16:32 : Epoch: 848, Train_Loss: 0.00755884
2025/09/16 22:16:32 : Epoch: 849, Train_Loss: 0.00833817
2025/09/16 22:16:32 : Epoch: 849, Eval_Loss: 0.00524043
2025/09/16 22:16:32 : Epoch: 850, Train_Loss: 0.01152294
2025/09/16 22:16:32 : Epoch: 851, Train_Loss: 0.00778051
2025/09/16 22:16:33 : Epoch: 852, Train_Loss: 0.00970394
2025/09/16 22:16:33 : Epoch: 853, Train_Loss: 0.01526236
2025/09/16 22:16:33 : Epoch: 854, Train_Loss: 0.00758064
2025/09/16 22:16:33 : Epoch: 854, Eval_Loss: 0.00524263
2025/09/16 22:16:33 : Epoch: 855, Train_Loss: 0.01023608
2025/09/16 22:16:34 : Epoch: 856, Train_Loss: 0.00879086
2025/09/16 22:16:34 : Epoch: 857, Train_Loss: 0.01012192
2025/09/16 22:16:34 : Epoch: 858, Train_Loss: 0.00851772
2025/09/16 22:16:34 : Epoch: 859, Train_Loss: 0.01250856
2025/09/16 22:16:34 : Epoch: 859, Eval_Loss: 0.00525222
2025/09/16 22:16:35 : Epoch: 860, Train_Loss: 0.00938849
2025/09/16 22:16:35 : Epoch: 861, Train_Loss: 0.00908798
2025/09/16 22:16:35 : Epoch: 862, Train_Loss: 0.01131453
2025/09/16 22:16:35 : Epoch: 863, Train_Loss: 0.00858957
2025/09/16 22:16:36 : Epoch: 864, Train_Loss: 0.00950180
2025/09/16 22:16:36 : Epoch: 864, Eval_Loss: 0.00524773
2025/09/16 22:16:36 : Epoch: 865, Train_Loss: 0.01182880
2025/09/16 22:16:36 : Epoch: 866, Train_Loss: 0.00956674
2025/09/16 22:16:37 : Epoch: 867, Train_Loss: 0.00854361
2025/09/16 22:16:37 : Epoch: 868, Train_Loss: 0.01183780
2025/09/16 22:16:37 : Epoch: 869, Train_Loss: 0.00821611
2025/09/16 22:16:37 : Epoch: 869, Eval_Loss: 0.00531236
2025/09/16 22:16:37 : Epoch: 870, Train_Loss: 0.00954794
2025/09/16 22:16:38 : Epoch: 871, Train_Loss: 0.00867853
2025/09/16 22:16:38 : Epoch: 872, Train_Loss: 0.00952758
2025/09/16 22:16:38 : Epoch: 873, Train_Loss: 0.00886221
2025/09/16 22:16:38 : Epoch: 874, Train_Loss: 0.00993070
2025/09/16 22:16:38 : Epoch: 874, Eval_Loss: 0.00524877
2025/09/16 22:16:39 : Epoch: 875, Train_Loss: 0.00675611
2025/09/16 22:16:39 : Epoch: 876, Train_Loss: 0.00891849
2025/09/16 22:16:39 : Epoch: 877, Train_Loss: 0.00870306
2025/09/16 22:16:39 : Epoch: 878, Train_Loss: 0.01095205
2025/09/16 22:16:40 : Epoch: 879, Train_Loss: 0.00737168
2025/09/16 22:16:40 : Epoch: 879, Eval_Loss: 0.00523484
2025/09/16 22:16:40 : Epoch: 880, Train_Loss: 0.01224985
2025/09/16 22:16:40 : Epoch: 881, Train_Loss: 0.00833150
2025/09/16 22:16:40 : Epoch: 882, Train_Loss: 0.00983118
2025/09/16 22:16:41 : Epoch: 883, Train_Loss: 0.00728078
2025/09/16 22:16:41 : Epoch: 884, Train_Loss: 0.00705452
2025/09/16 22:16:41 : Epoch: 884, Eval_Loss: 0.00523765
2025/09/16 22:16:41 : Epoch: 885, Train_Loss: 0.00823922
2025/09/16 22:16:41 : Epoch: 886, Train_Loss: 0.00970625
2025/09/16 22:16:42 : Epoch: 887, Train_Loss: 0.00806559
2025/09/16 22:16:42 : Epoch: 888, Train_Loss: 0.01170864
2025/09/16 22:16:42 : Epoch: 889, Train_Loss: 0.00986801
2025/09/16 22:16:42 : Epoch: 889, Eval_Loss: 0.00524002
2025/09/16 22:16:43 : Epoch: 890, Train_Loss: 0.00835057
2025/09/16 22:16:43 : Epoch: 891, Train_Loss: 0.00794716
2025/09/16 22:16:43 : Epoch: 892, Train_Loss: 0.01277785
2025/09/16 22:16:43 : Epoch: 893, Train_Loss: 0.00941333
2025/09/16 22:16:44 : Epoch: 894, Train_Loss: 0.00976028
2025/09/16 22:16:44 : Epoch: 894, Eval_Loss: 0.00523692
2025/09/16 22:16:44 : Epoch: 895, Train_Loss: 0.00726232
2025/09/16 22:16:44 : Epoch: 896, Train_Loss: 0.01135785
2025/09/16 22:16:44 : Epoch: 897, Train_Loss: 0.01178949
2025/09/16 22:16:45 : Epoch: 898, Train_Loss: 0.00869095
2025/09/16 22:16:45 : Epoch: 899, Train_Loss: 0.01326880
2025/09/16 22:16:45 : Epoch: 899, Eval_Loss: 0.00523551
2025/09/16 22:16:45 : Epoch: 900, Train_Loss: 0.01337702
2025/09/16 22:16:45 : Epoch: 901, Train_Loss: 0.01457427
2025/09/16 22:16:46 : Epoch: 902, Train_Loss: 0.01127522
2025/09/16 22:16:46 : Epoch: 903, Train_Loss: 0.00846321
2025/09/16 22:16:46 : Epoch: 904, Train_Loss: 0.01020381
2025/09/16 22:16:46 : Epoch: 904, Eval_Loss: 0.00526465
2025/09/16 22:16:47 : Epoch: 905, Train_Loss: 0.01146687
2025/09/16 22:16:47 : Epoch: 906, Train_Loss: 0.00867747
2025/09/16 22:16:47 : Epoch: 907, Train_Loss: 0.00977494
2025/09/16 22:16:47 : Epoch: 908, Train_Loss: 0.00838378
2025/09/16 22:16:47 : Epoch: 909, Train_Loss: 0.00911992
2025/09/16 22:16:48 : Epoch: 909, Eval_Loss: 0.00524909
2025/09/16 22:16:48 : Epoch: 910, Train_Loss: 0.00942485
2025/09/16 22:16:48 : Epoch: 911, Train_Loss: 0.01056957
2025/09/16 22:16:48 : Epoch: 912, Train_Loss: 0.00914256
2025/09/16 22:16:49 : Epoch: 913, Train_Loss: 0.00839350
2025/09/16 22:16:49 : Epoch: 914, Train_Loss: 0.01450422
2025/09/16 22:16:49 : Epoch: 914, Eval_Loss: 0.00524408
2025/09/16 22:16:49 : Epoch: 915, Train_Loss: 0.01006964
2025/09/16 22:16:49 : Epoch: 916, Train_Loss: 0.01067344
2025/09/16 22:16:50 : Epoch: 917, Train_Loss: 0.00785062
2025/09/16 22:16:50 : Epoch: 918, Train_Loss: 0.01021544
2025/09/16 22:16:50 : Epoch: 919, Train_Loss: 0.00933330
2025/09/16 22:16:50 : Epoch: 919, Eval_Loss: 0.00525362
2025/09/16 22:16:50 : Epoch: 920, Train_Loss: 0.01033129
2025/09/16 22:16:51 : Epoch: 921, Train_Loss: 0.00835378
2025/09/16 22:16:51 : Epoch: 922, Train_Loss: 0.01311583
2025/09/16 22:16:51 : Epoch: 923, Train_Loss: 0.00984105
2025/09/16 22:16:51 : Epoch: 924, Train_Loss: 0.00911255
2025/09/16 22:16:51 : Epoch: 924, Eval_Loss: 0.00523531
2025/09/16 22:16:52 : Epoch: 925, Train_Loss: 0.01281572
2025/09/16 22:16:52 : Epoch: 926, Train_Loss: 0.01105285
2025/09/16 22:16:52 : Epoch: 927, Train_Loss: 0.00983280
2025/09/16 22:16:52 : Epoch: 928, Train_Loss: 0.00881874
2025/09/16 22:16:53 : Epoch: 929, Train_Loss: 0.01509097
2025/09/16 22:16:53 : Epoch: 929, Eval_Loss: 0.00523472
2025/09/16 22:16:53 : Epoch: 930, Train_Loss: 0.01074742
2025/09/16 22:16:53 : Epoch: 931, Train_Loss: 0.00985908
2025/09/16 22:16:54 : Epoch: 932, Train_Loss: 0.00758789
2025/09/16 22:16:54 : Epoch: 933, Train_Loss: 0.00921324
2025/09/16 22:16:54 : Epoch: 934, Train_Loss: 0.01203716
2025/09/16 22:16:54 : Epoch: 934, Eval_Loss: 0.00524213
2025/09/16 22:16:54 : Epoch: 935, Train_Loss: 0.01145198
2025/09/16 22:16:55 : Epoch: 936, Train_Loss: 0.00771031
2025/09/16 22:16:55 : Epoch: 937, Train_Loss: 0.01236156
2025/09/16 22:16:55 : Epoch: 938, Train_Loss: 0.00951722
2025/09/16 22:16:55 : Epoch: 939, Train_Loss: 0.01055114
2025/09/16 22:16:55 : Epoch: 939, Eval_Loss: 0.00526513
2025/09/16 22:16:56 : Epoch: 940, Train_Loss: 0.01337377
2025/09/16 22:16:56 : Epoch: 941, Train_Loss: 0.01176779
2025/09/16 22:16:56 : Epoch: 942, Train_Loss: 0.00973936
2025/09/16 22:16:56 : Epoch: 943, Train_Loss: 0.00841982
2025/09/16 22:16:57 : Epoch: 944, Train_Loss: 0.00653087
2025/09/16 22:16:57 : Epoch: 944, Eval_Loss: 0.00526381
2025/09/16 22:16:57 : Epoch: 945, Train_Loss: 0.01009392
2025/09/16 22:16:57 : Epoch: 946, Train_Loss: 0.00935689
2025/09/16 22:16:58 : Epoch: 947, Train_Loss: 0.01355506
2025/09/16 22:16:58 : Epoch: 948, Train_Loss: 0.00978397
2025/09/16 22:16:58 : Epoch: 949, Train_Loss: 0.00740730
2025/09/16 22:16:58 : Epoch: 949, Eval_Loss: 0.00524312
2025/09/16 22:16:58 : Epoch: 950, Train_Loss: 0.00841245
2025/09/16 22:16:59 : Epoch: 951, Train_Loss: 0.00717348
2025/09/16 22:16:59 : Epoch: 952, Train_Loss: 0.01164846
2025/09/16 22:16:59 : Epoch: 953, Train_Loss: 0.01249363
2025/09/16 22:16:59 : Epoch: 954, Train_Loss: 0.00783732
2025/09/16 22:16:59 : Epoch: 954, Eval_Loss: 0.00523674
2025/09/16 22:17:00 : Epoch: 955, Train_Loss: 0.00724828
2025/09/16 22:17:00 : Epoch: 956, Train_Loss: 0.00930823
2025/09/16 22:17:00 : Epoch: 957, Train_Loss: 0.01274111
2025/09/16 22:17:00 : Epoch: 958, Train_Loss: 0.00906296
2025/09/16 22:17:01 : Epoch: 959, Train_Loss: 0.01295185
2025/09/16 22:17:01 : Epoch: 959, Eval_Loss: 0.00523770
2025/09/16 22:17:01 : Epoch: 960, Train_Loss: 0.01271616
2025/09/16 22:17:01 : Epoch: 961, Train_Loss: 0.00823737
2025/09/16 22:17:01 : Epoch: 962, Train_Loss: 0.00923411
2025/09/16 22:17:02 : Epoch: 963, Train_Loss: 0.00843015
2025/09/16 22:17:02 : Epoch: 964, Train_Loss: 0.00989952
2025/09/16 22:17:02 : Epoch: 964, Eval_Loss: 0.00531940
2025/09/16 22:17:02 : Epoch: 965, Train_Loss: 0.00918610
2025/09/16 22:17:03 : Epoch: 966, Train_Loss: 0.01009334
2025/09/16 22:17:03 : Epoch: 967, Train_Loss: 0.01029986
2025/09/16 22:17:03 : Epoch: 968, Train_Loss: 0.01121203
2025/09/16 22:17:03 : Epoch: 969, Train_Loss: 0.00986772
2025/09/16 22:17:03 : Epoch: 969, Eval_Loss: 0.00524310
2025/09/16 22:17:04 : Epoch: 970, Train_Loss: 0.01410925
2025/09/16 22:17:04 : Epoch: 971, Train_Loss: 0.00822459
2025/09/16 22:17:04 : Epoch: 972, Train_Loss: 0.00853881
2025/09/16 22:17:04 : Epoch: 973, Train_Loss: 0.01318589
2025/09/16 22:17:05 : Epoch: 974, Train_Loss: 0.00917688
2025/09/16 22:17:05 : Epoch: 974, Eval_Loss: 0.00523918
2025/09/16 22:17:05 : Epoch: 975, Train_Loss: 0.01435435
2025/09/16 22:17:05 : Epoch: 976, Train_Loss: 0.00893114
2025/09/16 22:17:05 : Epoch: 977, Train_Loss: 0.00997373
2025/09/16 22:17:06 : Epoch: 978, Train_Loss: 0.01117086
2025/09/16 22:17:06 : Epoch: 979, Train_Loss: 0.00991338
2025/09/16 22:17:06 : Epoch: 979, Eval_Loss: 0.00524420
2025/09/16 22:17:06 : Epoch: 980, Train_Loss: 0.01016800
2025/09/16 22:17:06 : Epoch: 981, Train_Loss: 0.00956578
2025/09/16 22:17:07 : Epoch: 982, Train_Loss: 0.00911644
2025/09/16 22:17:07 : Epoch: 983, Train_Loss: 0.00916815
2025/09/16 22:17:07 : Epoch: 984, Train_Loss: 0.00814888
2025/09/16 22:17:07 : Epoch: 984, Eval_Loss: 0.00523989
2025/09/16 22:17:08 : Epoch: 985, Train_Loss: 0.00901217
2025/09/16 22:17:08 : Epoch: 986, Train_Loss: 0.01356918
2025/09/16 22:17:08 : Epoch: 987, Train_Loss: 0.01293443
2025/09/16 22:17:08 : Epoch: 988, Train_Loss: 0.01059917
2025/09/16 22:17:09 : Epoch: 989, Train_Loss: 0.01018550
2025/09/16 22:17:09 : Epoch: 989, Eval_Loss: 0.00524999
2025/09/16 22:17:09 : Epoch: 990, Train_Loss: 0.01210434
2025/09/16 22:17:09 : Epoch: 991, Train_Loss: 0.01303064
2025/09/16 22:17:09 : Epoch: 992, Train_Loss: 0.01017753
2025/09/16 22:17:10 : Epoch: 993, Train_Loss: 0.01039804
2025/09/16 22:17:10 : Epoch: 994, Train_Loss: 0.00914964
2025/09/16 22:17:10 : Epoch: 994, Eval_Loss: 0.00528216
2025/09/16 22:17:10 : Epoch: 995, Train_Loss: 0.00768165
2025/09/16 22:17:10 : Epoch: 996, Train_Loss: 0.01097210
2025/09/16 22:17:11 : Epoch: 997, Train_Loss: 0.00893176
2025/09/16 22:17:11 : Epoch: 998, Train_Loss: 0.01124855
2025/09/16 22:17:11 : Epoch: 999, Train_Loss: 0.01019576
2025/09/16 22:17:11 : Epoch: 999, Eval_Loss: 0.00524897
2025/09/16 22:17:11 : Epoch: 1000, Train_Loss: 0.00898256
2025/09/16 22:17:12 : Epoch: 1001, Train_Loss: 0.00758711
2025/09/16 22:17:12 : Epoch: 1002, Train_Loss: 0.00797236
2025/09/16 22:17:12 : Epoch: 1003, Train_Loss: 0.00657646
2025/09/16 22:17:12 : Epoch: 1004, Train_Loss: 0.00853301
2025/09/16 22:17:13 : Epoch: 1004, Eval_Loss: 0.00524938
2025/09/16 22:17:13 : Epoch: 1005, Train_Loss: 0.00997653
2025/09/16 22:17:13 : Epoch: 1006, Train_Loss: 0.00840071
2025/09/16 22:17:13 : Epoch: 1007, Train_Loss: 0.00678130
2025/09/16 22:17:13 : Epoch: 1008, Train_Loss: 0.00869555
2025/09/16 22:17:14 : Epoch: 1009, Train_Loss: 0.00960095
2025/09/16 22:17:14 : Epoch: 1009, Eval_Loss: 0.00524909
2025/09/16 22:17:14 : Epoch: 1010, Train_Loss: 0.01064491
2025/09/16 22:17:14 : Epoch: 1011, Train_Loss: 0.00809776
2025/09/16 22:17:15 : Epoch: 1012, Train_Loss: 0.00752781
2025/09/16 22:17:15 : Epoch: 1013, Train_Loss: 0.01027670
2025/09/16 22:17:15 : Epoch: 1014, Train_Loss: 0.01148153
2025/09/16 22:17:15 : Epoch: 1014, Eval_Loss: 0.00524010
2025/09/16 22:17:15 : Epoch: 1015, Train_Loss: 0.01049479
2025/09/16 22:17:16 : Epoch: 1016, Train_Loss: 0.00847740
2025/09/16 22:17:16 : Epoch: 1017, Train_Loss: 0.00996032
2025/09/16 22:17:16 : Epoch: 1018, Train_Loss: 0.01294198
2025/09/16 22:17:16 : Epoch: 1019, Train_Loss: 0.00761316
2025/09/16 22:17:17 : Epoch: 1019, Eval_Loss: 0.00524674
2025/09/16 22:17:17 : Epoch: 1020, Train_Loss: 0.00758154
2025/09/16 22:17:17 : Epoch: 1021, Train_Loss: 0.00860852
2025/09/16 22:17:17 : Epoch: 1022, Train_Loss: 0.01045312
2025/09/16 22:17:17 : Epoch: 1023, Train_Loss: 0.01008395
2025/09/16 22:17:18 : Epoch: 1024, Train_Loss: 0.01067701
2025/09/16 22:17:18 : Epoch: 1024, Eval_Loss: 0.00523827
2025/09/16 22:17:18 : Epoch: 1025, Train_Loss: 0.01034299
2025/09/16 22:17:18 : Epoch: 1026, Train_Loss: 0.00827928
2025/09/16 22:17:19 : Epoch: 1027, Train_Loss: 0.01356935
2025/09/16 22:17:19 : Epoch: 1028, Train_Loss: 0.00986619
2025/09/16 22:17:19 : Epoch: 1029, Train_Loss: 0.01100502
2025/09/16 22:17:19 : Epoch: 1029, Eval_Loss: 0.00523633
2025/09/16 22:17:19 : Epoch: 1030, Train_Loss: 0.00874463
2025/09/16 22:17:20 : Epoch: 1031, Train_Loss: 0.01241354
2025/09/16 22:17:20 : Epoch: 1032, Train_Loss: 0.01104314
2025/09/16 22:17:20 : Epoch: 1033, Train_Loss: 0.00740805
2025/09/16 22:17:20 : Epoch: 1034, Train_Loss: 0.01048707
2025/09/16 22:17:20 : Epoch: 1034, Eval_Loss: 0.00523965
2025/09/16 22:17:21 : Epoch: 1035, Train_Loss: 0.00991705
2025/09/16 22:17:21 : Epoch: 1036, Train_Loss: 0.00835262
2025/09/16 22:17:21 : Epoch: 1037, Train_Loss: 0.01163326
2025/09/16 22:17:21 : Epoch: 1038, Train_Loss: 0.00869589
2025/09/16 22:17:22 : Epoch: 1039, Train_Loss: 0.01237662
2025/09/16 22:17:22 : Epoch: 1039, Eval_Loss: 0.00523973
2025/09/16 22:17:22 : Epoch: 1040, Train_Loss: 0.00883417
2025/09/16 22:17:22 : Epoch: 1041, Train_Loss: 0.01268990
2025/09/16 22:17:22 : Epoch: 1042, Train_Loss: 0.01113316
2025/09/16 22:17:23 : Epoch: 1043, Train_Loss: 0.01432585
2025/09/16 22:17:23 : Epoch: 1044, Train_Loss: 0.01093329
2025/09/16 22:17:23 : Epoch: 1044, Eval_Loss: 0.00527876
2025/09/16 22:17:23 : Epoch: 1045, Train_Loss: 0.01380449
2025/09/16 22:17:24 : Epoch: 1046, Train_Loss: 0.00820149
2025/09/16 22:17:24 : Epoch: 1047, Train_Loss: 0.01000059
2025/09/16 22:17:24 : Epoch: 1048, Train_Loss: 0.00816837
2025/09/16 22:17:24 : Epoch: 1049, Train_Loss: 0.00772393
2025/09/16 22:17:24 : Epoch: 1049, Eval_Loss: 0.00528373
2025/09/16 22:17:25 : Epoch: 1050, Train_Loss: 0.00896552
2025/09/16 22:17:25 : Epoch: 1051, Train_Loss: 0.01245342
2025/09/16 22:17:25 : Epoch: 1052, Train_Loss: 0.01294989
2025/09/16 22:17:25 : Epoch: 1053, Train_Loss: 0.01158214
2025/09/16 22:17:26 : Epoch: 1054, Train_Loss: 0.01005203
2025/09/16 22:17:26 : Epoch: 1054, Eval_Loss: 0.00525095
2025/09/16 22:17:26 : Epoch: 1055, Train_Loss: 0.01118509
2025/09/16 22:17:26 : Epoch: 1056, Train_Loss: 0.01088682
2025/09/16 22:17:26 : Epoch: 1057, Train_Loss: 0.01058598
2025/09/16 22:17:27 : Epoch: 1058, Train_Loss: 0.01078759
2025/09/16 22:17:27 : Epoch: 1059, Train_Loss: 0.00809785
2025/09/16 22:17:27 : Epoch: 1059, Eval_Loss: 0.00523625
2025/09/16 22:17:27 : Epoch: 1060, Train_Loss: 0.00941544
2025/09/16 22:17:27 : Epoch: 1061, Train_Loss: 0.00880501
2025/09/16 22:17:28 : Epoch: 1062, Train_Loss: 0.01175266
2025/09/16 22:17:28 : Epoch: 1063, Train_Loss: 0.01033915
2025/09/16 22:17:28 : Epoch: 1064, Train_Loss: 0.00849427
2025/09/16 22:17:28 : Epoch: 1064, Eval_Loss: 0.00523511
2025/09/16 22:17:29 : Epoch: 1065, Train_Loss: 0.01360827
2025/09/16 22:17:29 : Epoch: 1066, Train_Loss: 0.00752465
2025/09/16 22:17:29 : Epoch: 1067, Train_Loss: 0.00830596
2025/09/16 22:17:29 : Epoch: 1068, Train_Loss: 0.01261570
2025/09/16 22:17:30 : Epoch: 1069, Train_Loss: 0.00950347
2025/09/16 22:17:30 : Epoch: 1069, Eval_Loss: 0.00524516
2025/09/16 22:17:30 : Epoch: 1070, Train_Loss: 0.00994081
2025/09/16 22:17:30 : Epoch: 1071, Train_Loss: 0.01072241
2025/09/16 22:17:30 : Epoch: 1072, Train_Loss: 0.01070358
2025/09/16 22:17:31 : Epoch: 1073, Train_Loss: 0.01061628
2025/09/16 22:17:31 : Epoch: 1074, Train_Loss: 0.00711992
2025/09/16 22:17:31 : Epoch: 1074, Eval_Loss: 0.00524075
2025/09/16 22:17:31 : Epoch: 1075, Train_Loss: 0.00911494
2025/09/16 22:17:31 : Epoch: 1076, Train_Loss: 0.01200983
2025/09/16 22:17:32 : Epoch: 1077, Train_Loss: 0.00880580
2025/09/16 22:17:32 : Epoch: 1078, Train_Loss: 0.00863976
2025/09/16 22:17:32 : Epoch: 1079, Train_Loss: 0.00996238
2025/09/16 22:17:32 : Epoch: 1079, Eval_Loss: 0.00525901
2025/09/16 22:17:32 : Epoch: 1080, Train_Loss: 0.01012417
2025/09/16 22:17:33 : Epoch: 1081, Train_Loss: 0.00979156
2025/09/16 22:17:33 : Epoch: 1082, Train_Loss: 0.00669584
2025/09/16 22:17:33 : Epoch: 1083, Train_Loss: 0.01393933
2025/09/16 22:17:33 : Epoch: 1084, Train_Loss: 0.00782179
2025/09/16 22:17:34 : Epoch: 1084, Eval_Loss: 0.00524744
2025/09/16 22:17:34 : Epoch: 1085, Train_Loss: 0.01232754
2025/09/16 22:17:34 : Epoch: 1086, Train_Loss: 0.01036883
2025/09/16 22:17:34 : Epoch: 1087, Train_Loss: 0.00825205
2025/09/16 22:17:34 : Epoch: 1088, Train_Loss: 0.00737782
2025/09/16 22:17:35 : Epoch: 1089, Train_Loss: 0.00943865
2025/09/16 22:17:35 : Epoch: 1089, Eval_Loss: 0.00526095
2025/09/16 22:17:35 : Epoch: 1090, Train_Loss: 0.00949928
2025/09/16 22:17:35 : Epoch: 1091, Train_Loss: 0.01122071
2025/09/16 22:17:36 : Epoch: 1092, Train_Loss: 0.00979663
2025/09/16 22:17:36 : Epoch: 1093, Train_Loss: 0.00766392
2025/09/16 22:17:36 : Epoch: 1094, Train_Loss: 0.00917932
2025/09/16 22:17:36 : Epoch: 1094, Eval_Loss: 0.00524242
2025/09/16 22:17:36 : Epoch: 1095, Train_Loss: 0.01190712
2025/09/16 22:17:37 : Epoch: 1096, Train_Loss: 0.00876582
2025/09/16 22:17:37 : Epoch: 1097, Train_Loss: 0.01112786
2025/09/16 22:17:37 : Epoch: 1098, Train_Loss: 0.00884910
2025/09/16 22:17:37 : Epoch: 1099, Train_Loss: 0.00950947
2025/09/16 22:17:37 : Epoch: 1099, Eval_Loss: 0.00524427
2025/09/16 22:17:38 : Epoch: 1100, Train_Loss: 0.00892071
2025/09/16 22:17:38 : Epoch: 1101, Train_Loss: 0.00989709
2025/09/16 22:17:38 : Epoch: 1102, Train_Loss: 0.00796246
2025/09/16 22:17:38 : Epoch: 1103, Train_Loss: 0.01100423
2025/09/16 22:17:39 : Epoch: 1104, Train_Loss: 0.00870355
2025/09/16 22:17:39 : Epoch: 1104, Eval_Loss: 0.00524905
2025/09/16 22:17:39 : Epoch: 1105, Train_Loss: 0.00924022
2025/09/16 22:17:39 : Epoch: 1106, Train_Loss: 0.01283819
2025/09/16 22:17:40 : Epoch: 1107, Train_Loss: 0.01481392
2025/09/16 22:17:40 : Epoch: 1108, Train_Loss: 0.00679584
2025/09/16 22:17:40 : Epoch: 1109, Train_Loss: 0.00903169
2025/09/16 22:17:40 : Epoch: 1109, Eval_Loss: 0.00524174
2025/09/16 22:17:40 : Epoch: 1110, Train_Loss: 0.01082049
2025/09/16 22:17:41 : Epoch: 1111, Train_Loss: 0.00922266
2025/09/16 22:17:41 : Epoch: 1112, Train_Loss: 0.01118880
2025/09/16 22:17:41 : Epoch: 1113, Train_Loss: 0.01193609
2025/09/16 22:17:41 : Epoch: 1114, Train_Loss: 0.01179841
2025/09/16 22:17:41 : Epoch: 1114, Eval_Loss: 0.00524531
2025/09/16 22:17:42 : Epoch: 1115, Train_Loss: 0.00758083
2025/09/16 22:17:42 : Epoch: 1116, Train_Loss: 0.00942375
2025/09/16 22:17:42 : Epoch: 1117, Train_Loss: 0.01098665
2025/09/16 22:17:42 : Epoch: 1118, Train_Loss: 0.00783993
2025/09/16 22:17:43 : Epoch: 1119, Train_Loss: 0.00924799
2025/09/16 22:17:43 : Epoch: 1119, Eval_Loss: 0.00523823
2025/09/16 22:17:43 : Epoch: 1120, Train_Loss: 0.01366857
2025/09/16 22:17:43 : Epoch: 1121, Train_Loss: 0.01062801
2025/09/16 22:17:43 : Epoch: 1122, Train_Loss: 0.01098109
2025/09/16 22:17:44 : Epoch: 1123, Train_Loss: 0.01095529
2025/09/16 22:17:44 : Epoch: 1124, Train_Loss: 0.01067358
2025/09/16 22:17:44 : Epoch: 1124, Eval_Loss: 0.00525710
2025/09/16 22:17:44 : Epoch: 1125, Train_Loss: 0.00890008
2025/09/16 22:17:45 : Epoch: 1126, Train_Loss: 0.01302241
2025/09/16 22:17:45 : Epoch: 1127, Train_Loss: 0.00893080
2025/09/16 22:17:45 : Epoch: 1128, Train_Loss: 0.00793626
2025/09/16 22:17:45 : Epoch: 1129, Train_Loss: 0.00963679
2025/09/16 22:17:45 : Epoch: 1129, Eval_Loss: 0.00524715
2025/09/16 22:17:46 : Epoch: 1130, Train_Loss: 0.01013134
2025/09/16 22:17:46 : Epoch: 1131, Train_Loss: 0.01274713
2025/09/16 22:17:46 : Epoch: 1132, Train_Loss: 0.01034087
2025/09/16 22:17:46 : Epoch: 1133, Train_Loss: 0.00949840
2025/09/16 22:17:47 : Epoch: 1134, Train_Loss: 0.00926226
2025/09/16 22:17:47 : Epoch: 1134, Eval_Loss: 0.00523400
2025/09/16 22:17:47 : Epoch: 1135, Train_Loss: 0.00957189
2025/09/16 22:17:47 : Epoch: 1136, Train_Loss: 0.01035117
2025/09/16 22:17:47 : Epoch: 1137, Train_Loss: 0.00860850
2025/09/16 22:17:48 : Epoch: 1138, Train_Loss: 0.00864828
2025/09/16 22:17:48 : Epoch: 1139, Train_Loss: 0.01082732
2025/09/16 22:17:48 : Epoch: 1139, Eval_Loss: 0.00523753
2025/09/16 22:17:48 : Epoch: 1140, Train_Loss: 0.01241467
2025/09/16 22:17:48 : Epoch: 1141, Train_Loss: 0.00955815
2025/09/16 22:17:49 : Epoch: 1142, Train_Loss: 0.01093261
2025/09/16 22:17:49 : Epoch: 1143, Train_Loss: 0.00846455
2025/09/16 22:17:49 : Epoch: 1144, Train_Loss: 0.01081027
2025/09/16 22:17:49 : Epoch: 1144, Eval_Loss: 0.00524001
2025/09/16 22:17:50 : Epoch: 1145, Train_Loss: 0.00759328
2025/09/16 22:17:50 : Epoch: 1146, Train_Loss: 0.00908568
2025/09/16 22:17:50 : Epoch: 1147, Train_Loss: 0.00883781
2025/09/16 22:17:50 : Epoch: 1148, Train_Loss: 0.00827545
2025/09/16 22:17:51 : Epoch: 1149, Train_Loss: 0.01341606
2025/09/16 22:17:51 : Epoch: 1149, Eval_Loss: 0.00523298
2025/09/16 22:17:51 : Epoch: 1150, Train_Loss: 0.00787379
2025/09/16 22:17:51 : Epoch: 1151, Train_Loss: 0.00965272
2025/09/16 22:17:51 : Epoch: 1152, Train_Loss: 0.01033204
2025/09/16 22:17:52 : Epoch: 1153, Train_Loss: 0.01176584
2025/09/16 22:17:52 : Epoch: 1154, Train_Loss: 0.00773446
2025/09/16 22:17:52 : Epoch: 1154, Eval_Loss: 0.00523924
2025/09/16 22:17:52 : Epoch: 1155, Train_Loss: 0.00888918
2025/09/16 22:17:52 : Epoch: 1156, Train_Loss: 0.00941422
2025/09/16 22:17:53 : Epoch: 1157, Train_Loss: 0.00778600
2025/09/16 22:17:53 : Epoch: 1158, Train_Loss: 0.00868133
2025/09/16 22:17:53 : Epoch: 1159, Train_Loss: 0.00904151
2025/09/16 22:17:53 : Epoch: 1159, Eval_Loss: 0.00524342
2025/09/16 22:17:53 : Epoch: 1160, Train_Loss: 0.01368624
2025/09/16 22:17:54 : Epoch: 1161, Train_Loss: 0.01058298
2025/09/16 22:17:54 : Epoch: 1162, Train_Loss: 0.00691660
2025/09/16 22:17:54 : Epoch: 1163, Train_Loss: 0.01160127
2025/09/16 22:17:54 : Epoch: 1164, Train_Loss: 0.01325120
2025/09/16 22:17:54 : Epoch: 1164, Eval_Loss: 0.00524140
2025/09/16 22:17:55 : Epoch: 1165, Train_Loss: 0.00952175
2025/09/16 22:17:55 : Epoch: 1166, Train_Loss: 0.00964131
2025/09/16 22:17:55 : Epoch: 1167, Train_Loss: 0.01067641
2025/09/16 22:17:55 : Epoch: 1168, Train_Loss: 0.00687814
2025/09/16 22:17:56 : Epoch: 1169, Train_Loss: 0.01130934
2025/09/16 22:17:56 : Epoch: 1169, Eval_Loss: 0.00524543
2025/09/16 22:17:56 : Epoch: 1170, Train_Loss: 0.00825549
2025/09/16 22:17:56 : Epoch: 1171, Train_Loss: 0.01259411
2025/09/16 22:17:56 : Epoch: 1172, Train_Loss: 0.00763345
2025/09/16 22:17:57 : Epoch: 1173, Train_Loss: 0.00752687
2025/09/16 22:17:57 : Epoch: 1174, Train_Loss: 0.01041001
2025/09/16 22:17:57 : Epoch: 1174, Eval_Loss: 0.00523834
2025/09/16 22:17:57 : Epoch: 1175, Train_Loss: 0.01082755
2025/09/16 22:17:58 : Epoch: 1176, Train_Loss: 0.01013085
2025/09/16 22:17:58 : Epoch: 1177, Train_Loss: 0.01073411
2025/09/16 22:17:58 : Epoch: 1178, Train_Loss: 0.01380079
2025/09/16 22:17:58 : Epoch: 1179, Train_Loss: 0.01004166
2025/09/16 22:17:58 : Epoch: 1179, Eval_Loss: 0.00523648
2025/09/16 22:17:59 : Epoch: 1180, Train_Loss: 0.00773524
2025/09/16 22:17:59 : Epoch: 1181, Train_Loss: 0.00962984
2025/09/16 22:17:59 : Epoch: 1182, Train_Loss: 0.01007944
2025/09/16 22:17:59 : Epoch: 1183, Train_Loss: 0.00867531
2025/09/16 22:18:00 : Epoch: 1184, Train_Loss: 0.01315061
2025/09/16 22:18:00 : Epoch: 1184, Eval_Loss: 0.00523725
2025/09/16 22:18:00 : Epoch: 1185, Train_Loss: 0.01073241
2025/09/16 22:18:00 : Epoch: 1186, Train_Loss: 0.00818437
2025/09/16 22:18:00 : Epoch: 1187, Train_Loss: 0.01001348
2025/09/16 22:18:01 : Epoch: 1188, Train_Loss: 0.00909915
2025/09/16 22:18:01 : Epoch: 1189, Train_Loss: 0.00913273
2025/09/16 22:18:01 : Epoch: 1189, Eval_Loss: 0.00524836
2025/09/16 22:18:01 : Epoch: 1190, Train_Loss: 0.00886252
2025/09/16 22:18:01 : Epoch: 1191, Train_Loss: 0.00740507
2025/09/16 22:18:02 : Epoch: 1192, Train_Loss: 0.00875190
2025/09/16 22:18:02 : Epoch: 1193, Train_Loss: 0.01085608
2025/09/16 22:18:02 : Epoch: 1194, Train_Loss: 0.00827946
2025/09/16 22:18:02 : Epoch: 1194, Eval_Loss: 0.00523642
2025/09/16 22:18:03 : Epoch: 1195, Train_Loss: 0.01459004
2025/09/16 22:18:03 : Epoch: 1196, Train_Loss: 0.01016079
2025/09/16 22:18:03 : Epoch: 1197, Train_Loss: 0.00978910
2025/09/16 22:18:03 : Epoch: 1198, Train_Loss: 0.00746083
2025/09/16 22:18:04 : Epoch: 1199, Train_Loss: 0.00879747
2025/09/16 22:18:04 : Epoch: 1199, Eval_Loss: 0.00523635
2025/09/16 22:18:04 : 
Epoch: 1199, save response figures

2025/09/16 22:18:16 : Epoch: 1200, Train_Loss: 0.00857686
2025/09/16 22:18:16 : Epoch: 1201, Train_Loss: 0.01366499
2025/09/16 22:18:16 : Epoch: 1202, Train_Loss: 0.00947453
2025/09/16 22:18:16 : Epoch: 1203, Train_Loss: 0.01506163
2025/09/16 22:18:17 : Epoch: 1204, Train_Loss: 0.01229562
2025/09/16 22:18:17 : Epoch: 1204, Eval_Loss: 0.00523992
2025/09/16 22:18:17 : Epoch: 1205, Train_Loss: 0.00764950
2025/09/16 22:18:17 : Epoch: 1206, Train_Loss: 0.00767498
2025/09/16 22:18:18 : Epoch: 1207, Train_Loss: 0.00927597
2025/09/16 22:18:18 : Epoch: 1208, Train_Loss: 0.00824033
2025/09/16 22:18:18 : Epoch: 1209, Train_Loss: 0.01171708
2025/09/16 22:18:18 : Epoch: 1209, Eval_Loss: 0.00524527
2025/09/16 22:18:18 : Epoch: 1210, Train_Loss: 0.00927634
2025/09/16 22:18:19 : Epoch: 1211, Train_Loss: 0.00754485
2025/09/16 22:18:19 : Epoch: 1212, Train_Loss: 0.01268958
2025/09/16 22:18:19 : Epoch: 1213, Train_Loss: 0.00808424
2025/09/16 22:18:19 : Epoch: 1214, Train_Loss: 0.00804777
2025/09/16 22:18:19 : Epoch: 1214, Eval_Loss: 0.00523631
2025/09/16 22:18:20 : Epoch: 1215, Train_Loss: 0.00708928
2025/09/16 22:18:20 : Epoch: 1216, Train_Loss: 0.00992914
2025/09/16 22:18:20 : Epoch: 1217, Train_Loss: 0.01303835
2025/09/16 22:18:20 : Epoch: 1218, Train_Loss: 0.01071426
2025/09/16 22:18:21 : Epoch: 1219, Train_Loss: 0.00877250
2025/09/16 22:18:21 : Epoch: 1219, Eval_Loss: 0.00524266
2025/09/16 22:18:21 : Epoch: 1220, Train_Loss: 0.00792692
2025/09/16 22:18:21 : Epoch: 1221, Train_Loss: 0.01278257
2025/09/16 22:18:21 : Epoch: 1222, Train_Loss: 0.00870995
2025/09/16 22:18:22 : Epoch: 1223, Train_Loss: 0.00767190
2025/09/16 22:18:22 : Epoch: 1224, Train_Loss: 0.00748352
2025/09/16 22:18:22 : Epoch: 1224, Eval_Loss: 0.00523401
2025/09/16 22:18:22 : Epoch: 1225, Train_Loss: 0.00741695
2025/09/16 22:18:23 : Epoch: 1226, Train_Loss: 0.01382631
2025/09/16 22:18:23 : Epoch: 1227, Train_Loss: 0.00979241
2025/09/16 22:18:23 : Epoch: 1228, Train_Loss: 0.01030634
2025/09/16 22:18:23 : Epoch: 1229, Train_Loss: 0.01193619
2025/09/16 22:18:23 : Epoch: 1229, Eval_Loss: 0.00523402
2025/09/16 22:18:24 : Epoch: 1230, Train_Loss: 0.00938259
2025/09/16 22:18:24 : Epoch: 1231, Train_Loss: 0.00815099
2025/09/16 22:18:24 : Epoch: 1232, Train_Loss: 0.00960763
2025/09/16 22:18:24 : Epoch: 1233, Train_Loss: 0.00705105
2025/09/16 22:18:25 : Epoch: 1234, Train_Loss: 0.01047144
2025/09/16 22:18:25 : Epoch: 1234, Eval_Loss: 0.00523606
2025/09/16 22:18:25 : Epoch: 1235, Train_Loss: 0.00886202
2025/09/16 22:18:25 : Epoch: 1236, Train_Loss: 0.00771792
2025/09/16 22:18:25 : Epoch: 1237, Train_Loss: 0.00942684
2025/09/16 22:18:26 : Epoch: 1238, Train_Loss: 0.01239998
2025/09/16 22:18:26 : Epoch: 1239, Train_Loss: 0.00708036
2025/09/16 22:18:26 : Epoch: 1239, Eval_Loss: 0.00523342
2025/09/16 22:18:26 : Epoch: 1240, Train_Loss: 0.00834797
2025/09/16 22:18:26 : Epoch: 1241, Train_Loss: 0.00969953
2025/09/16 22:18:27 : Epoch: 1242, Train_Loss: 0.00730249
2025/09/16 22:18:27 : Epoch: 1243, Train_Loss: 0.00863544
2025/09/16 22:18:27 : Epoch: 1244, Train_Loss: 0.00885416
2025/09/16 22:18:27 : Epoch: 1244, Eval_Loss: 0.00523551
2025/09/16 22:18:27 : Epoch: 1245, Train_Loss: 0.00931919
2025/09/16 22:18:28 : Epoch: 1246, Train_Loss: 0.00816991
2025/09/16 22:18:28 : Epoch: 1247, Train_Loss: 0.01038700
2025/09/16 22:18:28 : Epoch: 1248, Train_Loss: 0.01017065
2025/09/16 22:18:28 : Epoch: 1249, Train_Loss: 0.01219106
2025/09/16 22:18:28 : Epoch: 1249, Eval_Loss: 0.00524409
2025/09/16 22:18:29 : Epoch: 1250, Train_Loss: 0.01194137
2025/09/16 22:18:29 : Epoch: 1251, Train_Loss: 0.01121988
2025/09/16 22:18:29 : Epoch: 1252, Train_Loss: 0.01206482
2025/09/16 22:18:29 : Epoch: 1253, Train_Loss: 0.01041674
2025/09/16 22:18:30 : Epoch: 1254, Train_Loss: 0.00793946
2025/09/16 22:18:30 : Epoch: 1254, Eval_Loss: 0.00524244
2025/09/16 22:18:30 : Epoch: 1255, Train_Loss: 0.00987470
2025/09/16 22:18:30 : Epoch: 1256, Train_Loss: 0.00910231
2025/09/16 22:18:31 : Epoch: 1257, Train_Loss: 0.01033964
2025/09/16 22:18:31 : Epoch: 1258, Train_Loss: 0.01082559
2025/09/16 22:18:31 : Epoch: 1259, Train_Loss: 0.00830591
2025/09/16 22:18:31 : Epoch: 1259, Eval_Loss: 0.00523746
2025/09/16 22:18:31 : Epoch: 1260, Train_Loss: 0.01315338
2025/09/16 22:18:32 : Epoch: 1261, Train_Loss: 0.00858588
2025/09/16 22:18:32 : Epoch: 1262, Train_Loss: 0.01159724
2025/09/16 22:18:32 : Epoch: 1263, Train_Loss: 0.00762350
2025/09/16 22:18:32 : Epoch: 1264, Train_Loss: 0.00809395
2025/09/16 22:18:32 : Epoch: 1264, Eval_Loss: 0.00523447
2025/09/16 22:18:33 : Epoch: 1265, Train_Loss: 0.00903470
2025/09/16 22:18:33 : Epoch: 1266, Train_Loss: 0.00671984
2025/09/16 22:18:33 : Epoch: 1267, Train_Loss: 0.01273293
2025/09/16 22:18:33 : Epoch: 1268, Train_Loss: 0.01250530
2025/09/16 22:18:34 : Epoch: 1269, Train_Loss: 0.00963101
2025/09/16 22:18:34 : Epoch: 1269, Eval_Loss: 0.00524066
2025/09/16 22:18:34 : Epoch: 1270, Train_Loss: 0.01050551
2025/09/16 22:18:34 : Epoch: 1271, Train_Loss: 0.00782063
2025/09/16 22:18:34 : Epoch: 1272, Train_Loss: 0.00915340
2025/09/16 22:18:35 : Epoch: 1273, Train_Loss: 0.00702654
2025/09/16 22:18:35 : Epoch: 1274, Train_Loss: 0.00827025
2025/09/16 22:18:35 : Epoch: 1274, Eval_Loss: 0.00525292
2025/09/16 22:18:35 : Epoch: 1275, Train_Loss: 0.01001811
2025/09/16 22:18:36 : Epoch: 1276, Train_Loss: 0.01564021
2025/09/16 22:18:36 : Epoch: 1277, Train_Loss: 0.01039288
2025/09/16 22:18:36 : Epoch: 1278, Train_Loss: 0.00910115
2025/09/16 22:18:36 : Epoch: 1279, Train_Loss: 0.01240935
2025/09/16 22:18:36 : Epoch: 1279, Eval_Loss: 0.00524318
2025/09/16 22:18:37 : Epoch: 1280, Train_Loss: 0.00932253
2025/09/16 22:18:37 : Epoch: 1281, Train_Loss: 0.00790706
2025/09/16 22:18:37 : Epoch: 1282, Train_Loss: 0.01015367
2025/09/16 22:18:37 : Epoch: 1283, Train_Loss: 0.00840487
2025/09/16 22:18:38 : Epoch: 1284, Train_Loss: 0.01106935
2025/09/16 22:18:38 : Epoch: 1284, Eval_Loss: 0.00523902
2025/09/16 22:18:38 : Epoch: 1285, Train_Loss: 0.00681744
2025/09/16 22:18:38 : Epoch: 1286, Train_Loss: 0.00746260
2025/09/16 22:18:38 : Epoch: 1287, Train_Loss: 0.00880014
2025/09/16 22:18:39 : Epoch: 1288, Train_Loss: 0.01009055
2025/09/16 22:18:39 : Epoch: 1289, Train_Loss: 0.00842356
2025/09/16 22:18:39 : Epoch: 1289, Eval_Loss: 0.00523619
2025/09/16 22:18:39 : Epoch: 1290, Train_Loss: 0.01170309
2025/09/16 22:18:39 : Epoch: 1291, Train_Loss: 0.00706837
2025/09/16 22:18:40 : Epoch: 1292, Train_Loss: 0.01110332
2025/09/16 22:18:40 : Epoch: 1293, Train_Loss: 0.01105445
2025/09/16 22:18:40 : Epoch: 1294, Train_Loss: 0.01320534
2025/09/16 22:18:40 : Epoch: 1294, Eval_Loss: 0.00524349
2025/09/16 22:18:40 : Epoch: 1295, Train_Loss: 0.00865830
2025/09/16 22:18:41 : Epoch: 1296, Train_Loss: 0.00796800
2025/09/16 22:18:41 : Epoch: 1297, Train_Loss: 0.01094509
2025/09/16 22:18:41 : Epoch: 1298, Train_Loss: 0.00820695
2025/09/16 22:18:41 : Epoch: 1299, Train_Loss: 0.01463785
2025/09/16 22:18:41 : Epoch: 1299, Eval_Loss: 0.00524260
2025/09/16 22:18:42 : Epoch: 1300, Train_Loss: 0.00768767
2025/09/16 22:18:42 : Epoch: 1301, Train_Loss: 0.01224178
2025/09/16 22:18:42 : Epoch: 1302, Train_Loss: 0.00962859
2025/09/16 22:18:42 : Epoch: 1303, Train_Loss: 0.01046843
2025/09/16 22:18:43 : Epoch: 1304, Train_Loss: 0.00823782
2025/09/16 22:18:43 : Epoch: 1304, Eval_Loss: 0.00524318
2025/09/16 22:18:43 : Epoch: 1305, Train_Loss: 0.01167240
2025/09/16 22:18:43 : Epoch: 1306, Train_Loss: 0.01317435
2025/09/16 22:18:44 : Epoch: 1307, Train_Loss: 0.01031867
2025/09/16 22:18:44 : Epoch: 1308, Train_Loss: 0.01207259
2025/09/16 22:18:44 : Epoch: 1309, Train_Loss: 0.00922383
2025/09/16 22:18:44 : Epoch: 1309, Eval_Loss: 0.00525596
2025/09/16 22:18:44 : Epoch: 1310, Train_Loss: 0.00852652
2025/09/16 22:18:45 : Epoch: 1311, Train_Loss: 0.00905954
2025/09/16 22:18:45 : Epoch: 1312, Train_Loss: 0.01026682
2025/09/16 22:18:45 : Epoch: 1313, Train_Loss: 0.00789180
2025/09/16 22:18:45 : Epoch: 1314, Train_Loss: 0.00981634
2025/09/16 22:18:45 : Epoch: 1314, Eval_Loss: 0.00523921
2025/09/16 22:18:46 : Epoch: 1315, Train_Loss: 0.00934341
2025/09/16 22:18:46 : Epoch: 1316, Train_Loss: 0.01426728
2025/09/16 22:18:46 : Epoch: 1317, Train_Loss: 0.00850552
2025/09/16 22:18:46 : Epoch: 1318, Train_Loss: 0.01020546
2025/09/16 22:18:47 : Epoch: 1319, Train_Loss: 0.00836794
2025/09/16 22:18:47 : Epoch: 1319, Eval_Loss: 0.00523674
2025/09/16 22:18:47 : Epoch: 1320, Train_Loss: 0.01203097
2025/09/16 22:18:47 : Epoch: 1321, Train_Loss: 0.01274345
2025/09/16 22:18:47 : Epoch: 1322, Train_Loss: 0.01384755
2025/09/16 22:18:48 : Epoch: 1323, Train_Loss: 0.01117725
2025/09/16 22:18:48 : Epoch: 1324, Train_Loss: 0.01258616
2025/09/16 22:18:48 : Epoch: 1324, Eval_Loss: 0.00524426
2025/09/16 22:18:48 : Epoch: 1325, Train_Loss: 0.00975457
2025/09/16 22:18:49 : Epoch: 1326, Train_Loss: 0.00712553
2025/09/16 22:18:49 : Epoch: 1327, Train_Loss: 0.01429053
2025/09/16 22:18:49 : Epoch: 1328, Train_Loss: 0.00916269
2025/09/16 22:18:49 : Epoch: 1329, Train_Loss: 0.00932467
2025/09/16 22:18:49 : Epoch: 1329, Eval_Loss: 0.00526572
2025/09/16 22:18:50 : Epoch: 1330, Train_Loss: 0.01104479
2025/09/16 22:18:50 : Epoch: 1331, Train_Loss: 0.01219196
2025/09/16 22:18:50 : Epoch: 1332, Train_Loss: 0.01011312
2025/09/16 22:18:50 : Epoch: 1333, Train_Loss: 0.00883536
2025/09/16 22:18:51 : Epoch: 1334, Train_Loss: 0.01102952
2025/09/16 22:18:51 : Epoch: 1334, Eval_Loss: 0.00524738
2025/09/16 22:18:51 : Epoch: 1335, Train_Loss: 0.00916733
2025/09/16 22:18:51 : Epoch: 1336, Train_Loss: 0.01087740
2025/09/16 22:18:51 : Epoch: 1337, Train_Loss: 0.01080124
2025/09/16 22:18:52 : Epoch: 1338, Train_Loss: 0.00787834
2025/09/16 22:18:52 : Epoch: 1339, Train_Loss: 0.01331762
2025/09/16 22:18:52 : Epoch: 1339, Eval_Loss: 0.00523912
2025/09/16 22:18:52 : Epoch: 1340, Train_Loss: 0.00885205
2025/09/16 22:18:52 : Epoch: 1341, Train_Loss: 0.00734095
2025/09/16 22:18:53 : Epoch: 1342, Train_Loss: 0.00927631
2025/09/16 22:18:53 : Epoch: 1343, Train_Loss: 0.01234962
2025/09/16 22:18:53 : Epoch: 1344, Train_Loss: 0.01194919
2025/09/16 22:18:53 : Epoch: 1344, Eval_Loss: 0.00524589
2025/09/16 22:18:54 : Epoch: 1345, Train_Loss: 0.01143204
2025/09/16 22:18:54 : Epoch: 1346, Train_Loss: 0.00851432
2025/09/16 22:18:54 : Epoch: 1347, Train_Loss: 0.00973263
2025/09/16 22:18:54 : Epoch: 1348, Train_Loss: 0.01184900
2025/09/16 22:18:55 : Epoch: 1349, Train_Loss: 0.00958211
2025/09/16 22:18:55 : Epoch: 1349, Eval_Loss: 0.00525684
2025/09/16 22:18:55 : Epoch: 1350, Train_Loss: 0.01325786
2025/09/16 22:18:55 : Epoch: 1351, Train_Loss: 0.01030478
2025/09/16 22:18:55 : Epoch: 1352, Train_Loss: 0.01113577
2025/09/16 22:18:56 : Epoch: 1353, Train_Loss: 0.00758200
2025/09/16 22:18:56 : Epoch: 1354, Train_Loss: 0.01053652
2025/09/16 22:18:56 : Epoch: 1354, Eval_Loss: 0.00526742
2025/09/16 22:18:56 : Epoch: 1355, Train_Loss: 0.01103629
2025/09/16 22:18:56 : Epoch: 1356, Train_Loss: 0.01138353
2025/09/16 22:18:57 : Epoch: 1357, Train_Loss: 0.01100004
2025/09/16 22:18:57 : Epoch: 1358, Train_Loss: 0.00913476
2025/09/16 22:18:57 : Epoch: 1359, Train_Loss: 0.01127139
2025/09/16 22:18:57 : Epoch: 1359, Eval_Loss: 0.00524924
2025/09/16 22:18:57 : Epoch: 1360, Train_Loss: 0.00814808
2025/09/16 22:18:58 : Epoch: 1361, Train_Loss: 0.01175614
2025/09/16 22:18:58 : Epoch: 1362, Train_Loss: 0.01241479
2025/09/16 22:18:58 : Epoch: 1363, Train_Loss: 0.01103726
2025/09/16 22:18:59 : Epoch: 1364, Train_Loss: 0.00838453
2025/09/16 22:18:59 : Epoch: 1364, Eval_Loss: 0.00525338
2025/09/16 22:18:59 : Epoch: 1365, Train_Loss: 0.01183233
2025/09/16 22:18:59 : Epoch: 1366, Train_Loss: 0.01196949
2025/09/16 22:18:59 : Epoch: 1367, Train_Loss: 0.01328540
2025/09/16 22:19:00 : Epoch: 1368, Train_Loss: 0.01142928
2025/09/16 22:19:00 : Epoch: 1369, Train_Loss: 0.01040668
2025/09/16 22:19:00 : Epoch: 1369, Eval_Loss: 0.00531669
2025/09/16 22:19:00 : Epoch: 1370, Train_Loss: 0.00903257
2025/09/16 22:19:00 : Epoch: 1371, Train_Loss: 0.00989925
2025/09/16 22:19:01 : Epoch: 1372, Train_Loss: 0.00997075
2025/09/16 22:19:01 : Epoch: 1373, Train_Loss: 0.01148911
2025/09/16 22:19:01 : Epoch: 1374, Train_Loss: 0.00998630
2025/09/16 22:19:01 : Epoch: 1374, Eval_Loss: 0.00528614
2025/09/16 22:19:01 : Epoch: 1375, Train_Loss: 0.00927007
2025/09/16 22:19:02 : Epoch: 1376, Train_Loss: 0.01086911
2025/09/16 22:19:02 : Epoch: 1377, Train_Loss: 0.00773804
2025/09/16 22:19:02 : Epoch: 1378, Train_Loss: 0.00820185
2025/09/16 22:19:02 : Epoch: 1379, Train_Loss: 0.01250958
2025/09/16 22:19:03 : Epoch: 1379, Eval_Loss: 0.00524724
2025/09/16 22:19:03 : Epoch: 1380, Train_Loss: 0.00771978
2025/09/16 22:19:03 : Epoch: 1381, Train_Loss: 0.00900388
2025/09/16 22:19:03 : Epoch: 1382, Train_Loss: 0.01341355
2025/09/16 22:19:04 : Epoch: 1383, Train_Loss: 0.00817005
2025/09/16 22:19:04 : Epoch: 1384, Train_Loss: 0.00817196
2025/09/16 22:19:04 : Epoch: 1384, Eval_Loss: 0.00524436
2025/09/16 22:19:04 : Epoch: 1385, Train_Loss: 0.00776922
2025/09/16 22:19:04 : Epoch: 1386, Train_Loss: 0.00958608
2025/09/16 22:19:05 : Epoch: 1387, Train_Loss: 0.01012087
2025/09/16 22:19:05 : Epoch: 1388, Train_Loss: 0.00896522
2025/09/16 22:19:05 : Epoch: 1389, Train_Loss: 0.01344761
2025/09/16 22:19:05 : Epoch: 1389, Eval_Loss: 0.00523495
2025/09/16 22:19:05 : Epoch: 1390, Train_Loss: 0.00723336
2025/09/16 22:19:06 : Epoch: 1391, Train_Loss: 0.00784202
2025/09/16 22:19:06 : Epoch: 1392, Train_Loss: 0.00875957
2025/09/16 22:19:06 : Epoch: 1393, Train_Loss: 0.01110386
2025/09/16 22:19:06 : Epoch: 1394, Train_Loss: 0.00847392
2025/09/16 22:19:06 : Epoch: 1394, Eval_Loss: 0.00524101
2025/09/16 22:19:07 : Epoch: 1395, Train_Loss: 0.00754762
2025/09/16 22:19:07 : Epoch: 1396, Train_Loss: 0.01034368
2025/09/16 22:19:07 : Epoch: 1397, Train_Loss: 0.01092663
2025/09/16 22:19:07 : Epoch: 1398, Train_Loss: 0.01171860
2025/09/16 22:19:08 : Epoch: 1399, Train_Loss: 0.00890977
2025/09/16 22:19:08 : Epoch: 1399, Eval_Loss: 0.00524561
2025/09/16 22:19:08 : Epoch: 1400, Train_Loss: 0.01179627
2025/09/16 22:19:08 : Epoch: 1401, Train_Loss: 0.00986425
2025/09/16 22:19:08 : Epoch: 1402, Train_Loss: 0.01055890
2025/09/16 22:19:09 : Epoch: 1403, Train_Loss: 0.00720510
2025/09/16 22:19:09 : Epoch: 1404, Train_Loss: 0.00974260
2025/09/16 22:19:09 : Epoch: 1404, Eval_Loss: 0.00524594
2025/09/16 22:19:09 : Epoch: 1405, Train_Loss: 0.00856926
2025/09/16 22:19:10 : Epoch: 1406, Train_Loss: 0.01019827
2025/09/16 22:19:10 : Epoch: 1407, Train_Loss: 0.01256989
2025/09/16 22:19:10 : Epoch: 1408, Train_Loss: 0.01218682
2025/09/16 22:19:10 : Epoch: 1409, Train_Loss: 0.00757032
2025/09/16 22:19:10 : Epoch: 1409, Eval_Loss: 0.00524884
2025/09/16 22:19:11 : Epoch: 1410, Train_Loss: 0.00754276
2025/09/16 22:19:11 : Epoch: 1411, Train_Loss: 0.00873233
2025/09/16 22:19:11 : Epoch: 1412, Train_Loss: 0.00962414
2025/09/16 22:19:11 : Epoch: 1413, Train_Loss: 0.00953773
2025/09/16 22:19:12 : Epoch: 1414, Train_Loss: 0.00992476
2025/09/16 22:19:12 : Epoch: 1414, Eval_Loss: 0.00524670
2025/09/16 22:19:12 : Epoch: 1415, Train_Loss: 0.01184378
2025/09/16 22:19:12 : Epoch: 1416, Train_Loss: 0.01090849
2025/09/16 22:19:12 : Epoch: 1417, Train_Loss: 0.00764051
2025/09/16 22:19:13 : Epoch: 1418, Train_Loss: 0.00932059
2025/09/16 22:19:13 : Epoch: 1419, Train_Loss: 0.01179394
2025/09/16 22:19:13 : Epoch: 1419, Eval_Loss: 0.00523935
2025/09/16 22:19:13 : Epoch: 1420, Train_Loss: 0.01202034
2025/09/16 22:19:14 : Epoch: 1421, Train_Loss: 0.00897308
2025/09/16 22:19:14 : Epoch: 1422, Train_Loss: 0.00853130
2025/09/16 22:19:14 : Epoch: 1423, Train_Loss: 0.00877687
2025/09/16 22:19:14 : Epoch: 1424, Train_Loss: 0.00943986
2025/09/16 22:19:14 : Epoch: 1424, Eval_Loss: 0.00524287
2025/09/16 22:19:15 : Epoch: 1425, Train_Loss: 0.00934200
2025/09/16 22:19:15 : Epoch: 1426, Train_Loss: 0.01362398
2025/09/16 22:19:15 : Epoch: 1427, Train_Loss: 0.00799213
2025/09/16 22:19:15 : Epoch: 1428, Train_Loss: 0.01053612
2025/09/16 22:19:16 : Epoch: 1429, Train_Loss: 0.00917338
2025/09/16 22:19:16 : Epoch: 1429, Eval_Loss: 0.00524647
2025/09/16 22:19:16 : Epoch: 1430, Train_Loss: 0.01254447
2025/09/16 22:19:16 : Epoch: 1431, Train_Loss: 0.01290876
2025/09/16 22:19:16 : Epoch: 1432, Train_Loss: 0.01327755
2025/09/16 22:19:17 : Epoch: 1433, Train_Loss: 0.00859900
2025/09/16 22:19:17 : Epoch: 1434, Train_Loss: 0.01077652
2025/09/16 22:19:17 : Epoch: 1434, Eval_Loss: 0.00525652
2025/09/16 22:19:17 : Epoch: 1435, Train_Loss: 0.00726701
2025/09/16 22:19:17 : Epoch: 1436, Train_Loss: 0.00853410
2025/09/16 22:19:18 : Epoch: 1437, Train_Loss: 0.00977067
2025/09/16 22:19:18 : Epoch: 1438, Train_Loss: 0.00892487
2025/09/16 22:19:18 : Epoch: 1439, Train_Loss: 0.01025725
2025/09/16 22:19:18 : Epoch: 1439, Eval_Loss: 0.00524253
2025/09/16 22:19:19 : Epoch: 1440, Train_Loss: 0.00826455
2025/09/16 22:19:19 : Epoch: 1441, Train_Loss: 0.01225006
2025/09/16 22:19:19 : Epoch: 1442, Train_Loss: 0.01322205
2025/09/16 22:19:19 : Epoch: 1443, Train_Loss: 0.01284425
2025/09/16 22:19:20 : Epoch: 1444, Train_Loss: 0.00818813
2025/09/16 22:19:20 : Epoch: 1444, Eval_Loss: 0.00523459
2025/09/16 22:19:20 : Epoch: 1445, Train_Loss: 0.00931259
2025/09/16 22:19:20 : Epoch: 1446, Train_Loss: 0.00875662
2025/09/16 22:19:20 : Epoch: 1447, Train_Loss: 0.00745891
2025/09/16 22:19:21 : Epoch: 1448, Train_Loss: 0.00901493
2025/09/16 22:19:21 : Epoch: 1449, Train_Loss: 0.00896672
2025/09/16 22:19:21 : Epoch: 1449, Eval_Loss: 0.00523443
2025/09/16 22:19:21 : Epoch: 1450, Train_Loss: 0.00834582
2025/09/16 22:19:21 : Epoch: 1451, Train_Loss: 0.00899088
2025/09/16 22:19:22 : Epoch: 1452, Train_Loss: 0.00949224
2025/09/16 22:19:22 : Epoch: 1453, Train_Loss: 0.01206276
2025/09/16 22:19:22 : Epoch: 1454, Train_Loss: 0.00854361
2025/09/16 22:19:22 : Epoch: 1454, Eval_Loss: 0.00523351
2025/09/16 22:19:22 : Epoch: 1455, Train_Loss: 0.01184838
2025/09/16 22:19:23 : Epoch: 1456, Train_Loss: 0.00757452
2025/09/16 22:19:23 : Epoch: 1457, Train_Loss: 0.00791766
2025/09/16 22:19:23 : Epoch: 1458, Train_Loss: 0.00932766
2025/09/16 22:19:23 : Epoch: 1459, Train_Loss: 0.01405994
2025/09/16 22:19:24 : Epoch: 1459, Eval_Loss: 0.00523645
2025/09/16 22:19:24 : Epoch: 1460, Train_Loss: 0.00962299
2025/09/16 22:19:24 : Epoch: 1461, Train_Loss: 0.01437277
2025/09/16 22:19:24 : Epoch: 1462, Train_Loss: 0.00784188
2025/09/16 22:19:25 : Epoch: 1463, Train_Loss: 0.01063081
2025/09/16 22:19:25 : Epoch: 1464, Train_Loss: 0.00888536
2025/09/16 22:19:25 : Epoch: 1464, Eval_Loss: 0.00523877
2025/09/16 22:19:25 : Epoch: 1465, Train_Loss: 0.01085700
2025/09/16 22:19:25 : Epoch: 1466, Train_Loss: 0.00756994
2025/09/16 22:19:26 : Epoch: 1467, Train_Loss: 0.00805195
2025/09/16 22:19:26 : Epoch: 1468, Train_Loss: 0.01164758
2025/09/16 22:19:26 : Epoch: 1469, Train_Loss: 0.00726727
2025/09/16 22:19:26 : Epoch: 1469, Eval_Loss: 0.00523950
2025/09/16 22:19:26 : Epoch: 1470, Train_Loss: 0.00962140
2025/09/16 22:19:27 : Epoch: 1471, Train_Loss: 0.00926274
2025/09/16 22:19:27 : Epoch: 1472, Train_Loss: 0.00783905
2025/09/16 22:19:27 : Epoch: 1473, Train_Loss: 0.01108314
2025/09/16 22:19:27 : Epoch: 1474, Train_Loss: 0.01135007
2025/09/16 22:19:27 : Epoch: 1474, Eval_Loss: 0.00524157
2025/09/16 22:19:28 : Epoch: 1475, Train_Loss: 0.00979879
2025/09/16 22:19:28 : Epoch: 1476, Train_Loss: 0.00844929
2025/09/16 22:19:28 : Epoch: 1477, Train_Loss: 0.00986246
2025/09/16 22:19:28 : Epoch: 1478, Train_Loss: 0.01125139
2025/09/16 22:19:29 : Epoch: 1479, Train_Loss: 0.00960165
2025/09/16 22:19:29 : Epoch: 1479, Eval_Loss: 0.00523437
2025/09/16 22:19:29 : Epoch: 1480, Train_Loss: 0.00687921
2025/09/16 22:19:29 : Epoch: 1481, Train_Loss: 0.00853798
2025/09/16 22:19:29 : Epoch: 1482, Train_Loss: 0.00988677
2025/09/16 22:19:30 : Epoch: 1483, Train_Loss: 0.00781288
2025/09/16 22:19:30 : Epoch: 1484, Train_Loss: 0.00677221
2025/09/16 22:19:30 : Epoch: 1484, Eval_Loss: 0.00523291
2025/09/16 22:19:30 : Epoch: 1485, Train_Loss: 0.00770788
2025/09/16 22:19:30 : Epoch: 1486, Train_Loss: 0.00756282
2025/09/16 22:19:31 : Epoch: 1487, Train_Loss: 0.00840649
2025/09/16 22:19:31 : Epoch: 1488, Train_Loss: 0.01224915
2025/09/16 22:19:31 : Epoch: 1489, Train_Loss: 0.00969073
2025/09/16 22:19:31 : Epoch: 1489, Eval_Loss: 0.00523283
2025/09/16 22:19:32 : Epoch: 1490, Train_Loss: 0.00907869
2025/09/16 22:19:32 : Epoch: 1491, Train_Loss: 0.01058716
2025/09/16 22:19:32 : Epoch: 1492, Train_Loss: 0.00708933
2025/09/16 22:19:32 : Epoch: 1493, Train_Loss: 0.00832997
2025/09/16 22:19:33 : Epoch: 1494, Train_Loss: 0.01248386
2025/09/16 22:19:33 : Epoch: 1494, Eval_Loss: 0.00523669
2025/09/16 22:19:33 : Epoch: 1495, Train_Loss: 0.01048788
2025/09/16 22:19:33 : Epoch: 1496, Train_Loss: 0.01051533
2025/09/16 22:19:33 : Epoch: 1497, Train_Loss: 0.00830583
2025/09/16 22:19:34 : Epoch: 1498, Train_Loss: 0.00921663
2025/09/16 22:19:34 : Epoch: 1499, Train_Loss: 0.01319569
2025/09/16 22:19:34 : Epoch: 1499, Eval_Loss: 0.00523869
2025/09/16 22:19:34 : Epoch: 1500, Train_Loss: 0.00969161
2025/09/16 22:19:34 : Epoch: 1501, Train_Loss: 0.00767252
2025/09/16 22:19:35 : Epoch: 1502, Train_Loss: 0.00775021
2025/09/16 22:19:35 : Epoch: 1503, Train_Loss: 0.01039560
2025/09/16 22:19:35 : Epoch: 1504, Train_Loss: 0.01556710
2025/09/16 22:19:35 : Epoch: 1504, Eval_Loss: 0.00523996
2025/09/16 22:19:36 : Epoch: 1505, Train_Loss: 0.00905799
2025/09/16 22:19:36 : Epoch: 1506, Train_Loss: 0.01305913
2025/09/16 22:19:36 : Epoch: 1507, Train_Loss: 0.00897171
2025/09/16 22:19:36 : Epoch: 1508, Train_Loss: 0.01141777
2025/09/16 22:19:36 : Epoch: 1509, Train_Loss: 0.00945593
2025/09/16 22:19:37 : Epoch: 1509, Eval_Loss: 0.00524399
2025/09/16 22:19:37 : Epoch: 1510, Train_Loss: 0.01200003
2025/09/16 22:19:37 : Epoch: 1511, Train_Loss: 0.01089822
2025/09/16 22:19:37 : Epoch: 1512, Train_Loss: 0.00808269
2025/09/16 22:19:38 : Epoch: 1513, Train_Loss: 0.00763748
2025/09/16 22:19:38 : Epoch: 1514, Train_Loss: 0.01311026
2025/09/16 22:19:38 : Epoch: 1514, Eval_Loss: 0.00523659
2025/09/16 22:19:38 : Epoch: 1515, Train_Loss: 0.01062899
2025/09/16 22:19:38 : Epoch: 1516, Train_Loss: 0.01159840
2025/09/16 22:19:39 : Epoch: 1517, Train_Loss: 0.01131328
2025/09/16 22:19:39 : Epoch: 1518, Train_Loss: 0.01146894
2025/09/16 22:19:39 : Epoch: 1519, Train_Loss: 0.01240571
2025/09/16 22:19:39 : Epoch: 1519, Eval_Loss: 0.00523889
2025/09/16 22:19:39 : Epoch: 1520, Train_Loss: 0.00841067
2025/09/16 22:19:40 : Epoch: 1521, Train_Loss: 0.00893307
2025/09/16 22:19:40 : Epoch: 1522, Train_Loss: 0.01001870
2025/09/16 22:19:40 : Epoch: 1523, Train_Loss: 0.00965458
2025/09/16 22:19:40 : Epoch: 1524, Train_Loss: 0.00941534
2025/09/16 22:19:41 : Epoch: 1524, Eval_Loss: 0.00524530
2025/09/16 22:19:41 : Epoch: 1525, Train_Loss: 0.00816688
2025/09/16 22:19:41 : Epoch: 1526, Train_Loss: 0.00721009
2025/09/16 22:19:41 : Epoch: 1527, Train_Loss: 0.00790344
2025/09/16 22:19:41 : Epoch: 1528, Train_Loss: 0.01239692
2025/09/16 22:19:42 : Epoch: 1529, Train_Loss: 0.00747416
2025/09/16 22:19:42 : Epoch: 1529, Eval_Loss: 0.00523639
2025/09/16 22:19:42 : Epoch: 1530, Train_Loss: 0.01366531
2025/09/16 22:19:42 : Epoch: 1531, Train_Loss: 0.01061541
2025/09/16 22:19:43 : Epoch: 1532, Train_Loss: 0.01294458
2025/09/16 22:19:43 : Epoch: 1533, Train_Loss: 0.00929763
2025/09/16 22:19:43 : Epoch: 1534, Train_Loss: 0.01066501
2025/09/16 22:19:43 : Epoch: 1534, Eval_Loss: 0.00524430
2025/09/16 22:19:43 : Epoch: 1535, Train_Loss: 0.01121078
2025/09/16 22:19:44 : Epoch: 1536, Train_Loss: 0.01111924
2025/09/16 22:19:44 : Epoch: 1537, Train_Loss: 0.00702972
2025/09/16 22:19:44 : Epoch: 1538, Train_Loss: 0.01182412
2025/09/16 22:19:44 : Epoch: 1539, Train_Loss: 0.00963321
2025/09/16 22:19:44 : Epoch: 1539, Eval_Loss: 0.00524034
2025/09/16 22:19:45 : Epoch: 1540, Train_Loss: 0.00895737
2025/09/16 22:19:45 : Epoch: 1541, Train_Loss: 0.01369959
2025/09/16 22:19:45 : Epoch: 1542, Train_Loss: 0.01451035
2025/09/16 22:19:45 : Epoch: 1543, Train_Loss: 0.00908142
2025/09/16 22:19:46 : Epoch: 1544, Train_Loss: 0.01445970
2025/09/16 22:19:46 : Epoch: 1544, Eval_Loss: 0.00524055
2025/09/16 22:19:46 : Epoch: 1545, Train_Loss: 0.00870885
2025/09/16 22:19:46 : Epoch: 1546, Train_Loss: 0.01237513
2025/09/16 22:19:46 : Epoch: 1547, Train_Loss: 0.00863866
2025/09/16 22:19:47 : Epoch: 1548, Train_Loss: 0.00868920
2025/09/16 22:19:47 : Epoch: 1549, Train_Loss: 0.01014339
2025/09/16 22:19:47 : Epoch: 1549, Eval_Loss: 0.00526671
2025/09/16 22:19:47 : Epoch: 1550, Train_Loss: 0.00895287
2025/09/16 22:19:47 : Epoch: 1551, Train_Loss: 0.01259641
2025/09/16 22:19:48 : Epoch: 1552, Train_Loss: 0.00900390
2025/09/16 22:19:48 : Epoch: 1553, Train_Loss: 0.00906705
2025/09/16 22:19:48 : Epoch: 1554, Train_Loss: 0.00976408
2025/09/16 22:19:48 : Epoch: 1554, Eval_Loss: 0.00526483
2025/09/16 22:19:49 : Epoch: 1555, Train_Loss: 0.01185022
2025/09/16 22:19:49 : Epoch: 1556, Train_Loss: 0.00884532
2025/09/16 22:19:49 : Epoch: 1557, Train_Loss: 0.00744684
2025/09/16 22:19:49 : Epoch: 1558, Train_Loss: 0.01051757
2025/09/16 22:19:50 : Epoch: 1559, Train_Loss: 0.00792804
2025/09/16 22:19:50 : Epoch: 1559, Eval_Loss: 0.00524108
2025/09/16 22:19:50 : Epoch: 1560, Train_Loss: 0.00923225
2025/09/16 22:19:50 : Epoch: 1561, Train_Loss: 0.00941588
2025/09/16 22:19:50 : Epoch: 1562, Train_Loss: 0.00863680
2025/09/16 22:19:51 : Epoch: 1563, Train_Loss: 0.01374412
2025/09/16 22:19:51 : Epoch: 1564, Train_Loss: 0.00954950
2025/09/16 22:19:51 : Epoch: 1564, Eval_Loss: 0.00523477
2025/09/16 22:19:51 : Epoch: 1565, Train_Loss: 0.01196647
2025/09/16 22:19:51 : Epoch: 1566, Train_Loss: 0.00840679
2025/09/16 22:19:52 : Epoch: 1567, Train_Loss: 0.00835054
2025/09/16 22:19:52 : Epoch: 1568, Train_Loss: 0.01184754
2025/09/16 22:19:52 : Epoch: 1569, Train_Loss: 0.00826345
2025/09/16 22:19:52 : Epoch: 1569, Eval_Loss: 0.00523794
2025/09/16 22:19:52 : Epoch: 1570, Train_Loss: 0.00777014
2025/09/16 22:19:53 : Epoch: 1571, Train_Loss: 0.00810297
2025/09/16 22:19:53 : Epoch: 1572, Train_Loss: 0.01067493
2025/09/16 22:19:53 : Epoch: 1573, Train_Loss: 0.00994707
2025/09/16 22:19:53 : Epoch: 1574, Train_Loss: 0.01011094
2025/09/16 22:19:54 : Epoch: 1574, Eval_Loss: 0.00523888
2025/09/16 22:19:54 : Epoch: 1575, Train_Loss: 0.01052263
2025/09/16 22:19:54 : Epoch: 1576, Train_Loss: 0.01025354
2025/09/16 22:19:54 : Epoch: 1577, Train_Loss: 0.00807944
2025/09/16 22:19:55 : Epoch: 1578, Train_Loss: 0.00901944
2025/09/16 22:19:55 : Epoch: 1579, Train_Loss: 0.00667523
2025/09/16 22:19:55 : Epoch: 1579, Eval_Loss: 0.00523523
2025/09/16 22:19:55 : Epoch: 1580, Train_Loss: 0.00673769
2025/09/16 22:19:55 : Epoch: 1581, Train_Loss: 0.00964441
2025/09/16 22:19:56 : Epoch: 1582, Train_Loss: 0.00908005
2025/09/16 22:19:56 : Epoch: 1583, Train_Loss: 0.00750220
2025/09/16 22:19:56 : Epoch: 1584, Train_Loss: 0.00741773
2025/09/16 22:19:56 : Epoch: 1584, Eval_Loss: 0.00523377
2025/09/16 22:19:56 : Epoch: 1585, Train_Loss: 0.01369029
2025/09/16 22:19:57 : Epoch: 1586, Train_Loss: 0.01082097
2025/09/16 22:19:57 : Epoch: 1587, Train_Loss: 0.01388685
2025/09/16 22:19:57 : Epoch: 1588, Train_Loss: 0.00889934
2025/09/16 22:19:57 : Epoch: 1589, Train_Loss: 0.01053147
2025/09/16 22:19:57 : Epoch: 1589, Eval_Loss: 0.00523851
2025/09/16 22:19:58 : Epoch: 1590, Train_Loss: 0.01000492
2025/09/16 22:19:58 : Epoch: 1591, Train_Loss: 0.00702742
2025/09/16 22:19:58 : Epoch: 1592, Train_Loss: 0.01018185
2025/09/16 22:19:58 : Epoch: 1593, Train_Loss: 0.01028504
2025/09/16 22:19:59 : Epoch: 1594, Train_Loss: 0.00667778
2025/09/16 22:19:59 : Epoch: 1594, Eval_Loss: 0.00523949
2025/09/16 22:19:59 : Epoch: 1595, Train_Loss: 0.00841194
2025/09/16 22:19:59 : Epoch: 1596, Train_Loss: 0.00866300
2025/09/16 22:19:59 : Epoch: 1597, Train_Loss: 0.00979170
2025/09/16 22:20:00 : Epoch: 1598, Train_Loss: 0.01034027
2025/09/16 22:20:00 : Epoch: 1599, Train_Loss: 0.00938683
2025/09/16 22:20:00 : Epoch: 1599, Eval_Loss: 0.00523610
2025/09/16 22:20:00 : 
Epoch: 1599, save response figures

2025/09/16 22:20:12 : Epoch: 1600, Train_Loss: 0.01059333
2025/09/16 22:20:13 : Epoch: 1601, Train_Loss: 0.01341163
2025/09/16 22:20:13 : Epoch: 1602, Train_Loss: 0.00889566
2025/09/16 22:20:13 : Epoch: 1603, Train_Loss: 0.00862806
2025/09/16 22:20:13 : Epoch: 1604, Train_Loss: 0.01198798
2025/09/16 22:20:13 : Epoch: 1604, Eval_Loss: 0.00523912
2025/09/16 22:20:14 : Epoch: 1605, Train_Loss: 0.00968854
2025/09/16 22:20:14 : Epoch: 1606, Train_Loss: 0.00821223
2025/09/16 22:20:14 : Epoch: 1607, Train_Loss: 0.00950170
2025/09/16 22:20:14 : Epoch: 1608, Train_Loss: 0.00856741
2025/09/16 22:20:15 : Epoch: 1609, Train_Loss: 0.01273525
2025/09/16 22:20:15 : Epoch: 1609, Eval_Loss: 0.00524638
2025/09/16 22:20:15 : Epoch: 1610, Train_Loss: 0.00936714
2025/09/16 22:20:15 : Epoch: 1611, Train_Loss: 0.00860286
2025/09/16 22:20:15 : Epoch: 1612, Train_Loss: 0.00971243
2025/09/16 22:20:16 : Epoch: 1613, Train_Loss: 0.00950434
2025/09/16 22:20:16 : Epoch: 1614, Train_Loss: 0.01402928
2025/09/16 22:20:16 : Epoch: 1614, Eval_Loss: 0.00525149
2025/09/16 22:20:16 : Epoch: 1615, Train_Loss: 0.00793565
2025/09/16 22:20:17 : Epoch: 1616, Train_Loss: 0.00950159
2025/09/16 22:20:17 : Epoch: 1617, Train_Loss: 0.00884112
2025/09/16 22:20:17 : Epoch: 1618, Train_Loss: 0.01123809
2025/09/16 22:20:17 : Epoch: 1619, Train_Loss: 0.00758287
2025/09/16 22:20:17 : Epoch: 1619, Eval_Loss: 0.00525032
2025/09/16 22:20:18 : Epoch: 1620, Train_Loss: 0.01037824
2025/09/16 22:20:18 : Epoch: 1621, Train_Loss: 0.01198560
2025/09/16 22:20:18 : Epoch: 1622, Train_Loss: 0.00969049
2025/09/16 22:20:18 : Epoch: 1623, Train_Loss: 0.00927476
2025/09/16 22:20:19 : Epoch: 1624, Train_Loss: 0.01309294
2025/09/16 22:20:19 : Epoch: 1624, Eval_Loss: 0.00523827
2025/09/16 22:20:19 : Epoch: 1625, Train_Loss: 0.01315034
2025/09/16 22:20:19 : Epoch: 1626, Train_Loss: 0.01011385
2025/09/16 22:20:19 : Epoch: 1627, Train_Loss: 0.00776055
2025/09/16 22:20:20 : Epoch: 1628, Train_Loss: 0.00898037
2025/09/16 22:20:20 : Epoch: 1629, Train_Loss: 0.00859008
2025/09/16 22:20:20 : Epoch: 1629, Eval_Loss: 0.00524169
2025/09/16 22:20:20 : Epoch: 1630, Train_Loss: 0.00957092
2025/09/16 22:20:20 : Epoch: 1631, Train_Loss: 0.01072577
2025/09/16 22:20:21 : Epoch: 1632, Train_Loss: 0.01432550
2025/09/16 22:20:21 : Epoch: 1633, Train_Loss: 0.00760663
2025/09/16 22:20:21 : Epoch: 1634, Train_Loss: 0.01010017
2025/09/16 22:20:21 : Epoch: 1634, Eval_Loss: 0.00524276
2025/09/16 22:20:21 : Epoch: 1635, Train_Loss: 0.00926531
2025/09/16 22:20:22 : Epoch: 1636, Train_Loss: 0.00859150
2025/09/16 22:20:22 : Epoch: 1637, Train_Loss: 0.00797502
2025/09/16 22:20:22 : Epoch: 1638, Train_Loss: 0.01099753
2025/09/16 22:20:22 : Epoch: 1639, Train_Loss: 0.01324289
2025/09/16 22:20:23 : Epoch: 1639, Eval_Loss: 0.00523971
2025/09/16 22:20:23 : Epoch: 1640, Train_Loss: 0.00816251
2025/09/16 22:20:23 : Epoch: 1641, Train_Loss: 0.01100984
2025/09/16 22:20:23 : Epoch: 1642, Train_Loss: 0.01270586
2025/09/16 22:20:24 : Epoch: 1643, Train_Loss: 0.00892996
2025/09/16 22:20:24 : Epoch: 1644, Train_Loss: 0.00784987
2025/09/16 22:20:24 : Epoch: 1644, Eval_Loss: 0.00523886
2025/09/16 22:20:24 : Epoch: 1645, Train_Loss: 0.01203638
2025/09/16 22:20:24 : Epoch: 1646, Train_Loss: 0.01232150
2025/09/16 22:20:25 : Epoch: 1647, Train_Loss: 0.00732229
2025/09/16 22:20:25 : Epoch: 1648, Train_Loss: 0.00769884
2025/09/16 22:20:25 : Epoch: 1649, Train_Loss: 0.01306527
2025/09/16 22:20:25 : Epoch: 1649, Eval_Loss: 0.00524594
2025/09/16 22:20:25 : Epoch: 1650, Train_Loss: 0.01049600
2025/09/16 22:20:26 : Epoch: 1651, Train_Loss: 0.01198368
2025/09/16 22:20:26 : Epoch: 1652, Train_Loss: 0.01016619
2025/09/16 22:20:26 : Epoch: 1653, Train_Loss: 0.01187450
2025/09/16 22:20:26 : Epoch: 1654, Train_Loss: 0.01032096
2025/09/16 22:20:27 : Epoch: 1654, Eval_Loss: 0.00524788
2025/09/16 22:20:27 : Epoch: 1655, Train_Loss: 0.00795319
2025/09/16 22:20:27 : Epoch: 1656, Train_Loss: 0.01090124
2025/09/16 22:20:27 : Epoch: 1657, Train_Loss: 0.00905109
2025/09/16 22:20:28 : Epoch: 1658, Train_Loss: 0.01104645
2025/09/16 22:20:28 : Epoch: 1659, Train_Loss: 0.01095701
2025/09/16 22:20:28 : Epoch: 1659, Eval_Loss: 0.00524001
2025/09/16 22:20:28 : Epoch: 1660, Train_Loss: 0.01296267
2025/09/16 22:20:28 : Epoch: 1661, Train_Loss: 0.00890873
2025/09/16 22:20:29 : Epoch: 1662, Train_Loss: 0.01141268
2025/09/16 22:20:29 : Epoch: 1663, Train_Loss: 0.00920167
2025/09/16 22:20:29 : Epoch: 1664, Train_Loss: 0.00821673
2025/09/16 22:20:29 : Epoch: 1664, Eval_Loss: 0.00523872
2025/09/16 22:20:29 : Epoch: 1665, Train_Loss: 0.00789879
2025/09/16 22:20:30 : Epoch: 1666, Train_Loss: 0.01116919
2025/09/16 22:20:30 : Epoch: 1667, Train_Loss: 0.01186933
2025/09/16 22:20:30 : Epoch: 1668, Train_Loss: 0.00824592
2025/09/16 22:20:30 : Epoch: 1669, Train_Loss: 0.01000557
2025/09/16 22:20:31 : Epoch: 1669, Eval_Loss: 0.00523799
2025/09/16 22:20:31 : Epoch: 1670, Train_Loss: 0.00879037
2025/09/16 22:20:31 : Epoch: 1671, Train_Loss: 0.00819229
2025/09/16 22:20:31 : Epoch: 1672, Train_Loss: 0.01367780
2025/09/16 22:20:32 : Epoch: 1673, Train_Loss: 0.01335600
2025/09/16 22:20:32 : Epoch: 1674, Train_Loss: 0.01026081
2025/09/16 22:20:32 : Epoch: 1674, Eval_Loss: 0.00523869
2025/09/16 22:20:32 : Epoch: 1675, Train_Loss: 0.01024015
2025/09/16 22:20:32 : Epoch: 1676, Train_Loss: 0.00983427
2025/09/16 22:20:33 : Epoch: 1677, Train_Loss: 0.01367495
2025/09/16 22:20:33 : Epoch: 1678, Train_Loss: 0.00931535
2025/09/16 22:20:33 : Epoch: 1679, Train_Loss: 0.00981086
2025/09/16 22:20:33 : Epoch: 1679, Eval_Loss: 0.00523959
2025/09/16 22:20:33 : Epoch: 1680, Train_Loss: 0.01016581
2025/09/16 22:20:34 : Epoch: 1681, Train_Loss: 0.00836950
2025/09/16 22:20:34 : Epoch: 1682, Train_Loss: 0.01114851
2025/09/16 22:20:34 : Epoch: 1683, Train_Loss: 0.01034410
2025/09/16 22:20:34 : Epoch: 1684, Train_Loss: 0.00868612
2025/09/16 22:20:34 : Epoch: 1684, Eval_Loss: 0.00524178
2025/09/16 22:20:35 : Epoch: 1685, Train_Loss: 0.00914435
2025/09/16 22:20:35 : Epoch: 1686, Train_Loss: 0.01056823
2025/09/16 22:20:35 : Epoch: 1687, Train_Loss: 0.01085474
2025/09/16 22:20:35 : Epoch: 1688, Train_Loss: 0.00915180
2025/09/16 22:20:36 : Epoch: 1689, Train_Loss: 0.00758627
2025/09/16 22:20:36 : Epoch: 1689, Eval_Loss: 0.00524524
2025/09/16 22:20:36 : Epoch: 1690, Train_Loss: 0.00911433
2025/09/16 22:20:36 : Epoch: 1691, Train_Loss: 0.00834821
2025/09/16 22:20:37 : Epoch: 1692, Train_Loss: 0.00866770
2025/09/16 22:20:37 : Epoch: 1693, Train_Loss: 0.00909123
2025/09/16 22:20:37 : Epoch: 1694, Train_Loss: 0.00774689
2025/09/16 22:20:37 : Epoch: 1694, Eval_Loss: 0.00524307
2025/09/16 22:20:37 : Epoch: 1695, Train_Loss: 0.00786472
2025/09/16 22:20:38 : Epoch: 1696, Train_Loss: 0.00969095
2025/09/16 22:20:38 : Epoch: 1697, Train_Loss: 0.00915412
2025/09/16 22:20:38 : Epoch: 1698, Train_Loss: 0.00948600
2025/09/16 22:20:38 : Epoch: 1699, Train_Loss: 0.01134435
2025/09/16 22:20:38 : Epoch: 1699, Eval_Loss: 0.00523696
2025/09/16 22:20:39 : Epoch: 1700, Train_Loss: 0.00807915
2025/09/16 22:20:39 : Epoch: 1701, Train_Loss: 0.01105768
2025/09/16 22:20:39 : Epoch: 1702, Train_Loss: 0.00826981
2025/09/16 22:20:39 : Epoch: 1703, Train_Loss: 0.00840903
2025/09/16 22:20:40 : Epoch: 1704, Train_Loss: 0.01083241
2025/09/16 22:20:40 : Epoch: 1704, Eval_Loss: 0.00523693
2025/09/16 22:20:40 : Epoch: 1705, Train_Loss: 0.01270117
2025/09/16 22:20:40 : Epoch: 1706, Train_Loss: 0.00704092
2025/09/16 22:20:40 : Epoch: 1707, Train_Loss: 0.00752930
2025/09/16 22:20:41 : Epoch: 1708, Train_Loss: 0.00767293
2025/09/16 22:20:41 : Epoch: 1709, Train_Loss: 0.00792814
2025/09/16 22:20:41 : Epoch: 1709, Eval_Loss: 0.00523764
2025/09/16 22:20:41 : Epoch: 1710, Train_Loss: 0.00800044
2025/09/16 22:20:42 : Epoch: 1711, Train_Loss: 0.01296857
2025/09/16 22:20:42 : Epoch: 1712, Train_Loss: 0.01105327
2025/09/16 22:20:42 : Epoch: 1713, Train_Loss: 0.00951618
2025/09/16 22:20:42 : Epoch: 1714, Train_Loss: 0.01265813
2025/09/16 22:20:42 : Epoch: 1714, Eval_Loss: 0.00524113
2025/09/16 22:20:43 : Epoch: 1715, Train_Loss: 0.01388439
2025/09/16 22:20:43 : Epoch: 1716, Train_Loss: 0.01235047
2025/09/16 22:20:43 : Epoch: 1717, Train_Loss: 0.01513636
2025/09/16 22:20:43 : Epoch: 1718, Train_Loss: 0.01318729
2025/09/16 22:20:44 : Epoch: 1719, Train_Loss: 0.00821290
2025/09/16 22:20:44 : Epoch: 1719, Eval_Loss: 0.00528210
2025/09/16 22:20:44 : Epoch: 1720, Train_Loss: 0.00948857
2025/09/16 22:20:44 : Epoch: 1721, Train_Loss: 0.00840789
2025/09/16 22:20:44 : Epoch: 1722, Train_Loss: 0.01039195
2025/09/16 22:20:45 : Epoch: 1723, Train_Loss: 0.00778409
2025/09/16 22:20:45 : Epoch: 1724, Train_Loss: 0.00856540
2025/09/16 22:20:45 : Epoch: 1724, Eval_Loss: 0.00529532
2025/09/16 22:20:45 : Epoch: 1725, Train_Loss: 0.01155751
2025/09/16 22:20:46 : Epoch: 1726, Train_Loss: 0.00955090
2025/09/16 22:20:46 : Epoch: 1727, Train_Loss: 0.00820107
2025/09/16 22:20:46 : Epoch: 1728, Train_Loss: 0.01523724
2025/09/16 22:20:46 : Epoch: 1729, Train_Loss: 0.01416056
2025/09/16 22:20:46 : Epoch: 1729, Eval_Loss: 0.00528160
2025/09/16 22:20:47 : Epoch: 1730, Train_Loss: 0.01315559
2025/09/16 22:20:47 : Epoch: 1731, Train_Loss: 0.01219891
2025/09/16 22:20:47 : Epoch: 1732, Train_Loss: 0.01132418
2025/09/16 22:20:47 : Epoch: 1733, Train_Loss: 0.01188727
2025/09/16 22:20:48 : Epoch: 1734, Train_Loss: 0.00807783
2025/09/16 22:20:48 : Epoch: 1734, Eval_Loss: 0.00531096
2025/09/16 22:20:48 : Epoch: 1735, Train_Loss: 0.00837001
2025/09/16 22:20:48 : Epoch: 1736, Train_Loss: 0.00809601
2025/09/16 22:20:48 : Epoch: 1737, Train_Loss: 0.01283624
2025/09/16 22:20:49 : Epoch: 1738, Train_Loss: 0.01075677
2025/09/16 22:20:49 : Epoch: 1739, Train_Loss: 0.01343969
2025/09/16 22:20:49 : Epoch: 1739, Eval_Loss: 0.00530318
2025/09/16 22:20:49 : Epoch: 1740, Train_Loss: 0.00762571
2025/09/16 22:20:50 : Epoch: 1741, Train_Loss: 0.01067431
2025/09/16 22:20:50 : Epoch: 1742, Train_Loss: 0.00887296
2025/09/16 22:20:50 : Epoch: 1743, Train_Loss: 0.00997710
2025/09/16 22:20:50 : Epoch: 1744, Train_Loss: 0.00940521
2025/09/16 22:20:50 : Epoch: 1744, Eval_Loss: 0.00527560
2025/09/16 22:20:51 : Epoch: 1745, Train_Loss: 0.00680255
2025/09/16 22:20:51 : Epoch: 1746, Train_Loss: 0.00959309
2025/09/16 22:20:51 : Epoch: 1747, Train_Loss: 0.01188111
2025/09/16 22:20:51 : Epoch: 1748, Train_Loss: 0.01157431
2025/09/16 22:20:51 : Epoch: 1749, Train_Loss: 0.01246941
2025/09/16 22:20:52 : Epoch: 1749, Eval_Loss: 0.00525014
2025/09/16 22:20:52 : Epoch: 1750, Train_Loss: 0.01118998
2025/09/16 22:20:52 : Epoch: 1751, Train_Loss: 0.01118785
2025/09/16 22:20:52 : Epoch: 1752, Train_Loss: 0.00726553
2025/09/16 22:20:53 : Epoch: 1753, Train_Loss: 0.01049677
2025/09/16 22:20:53 : Epoch: 1754, Train_Loss: 0.00922168
2025/09/16 22:20:53 : Epoch: 1754, Eval_Loss: 0.00524393
2025/09/16 22:20:53 : Epoch: 1755, Train_Loss: 0.00769291
2025/09/16 22:20:53 : Epoch: 1756, Train_Loss: 0.00868237
2025/09/16 22:20:54 : Epoch: 1757, Train_Loss: 0.00908440
2025/09/16 22:20:54 : Epoch: 1758, Train_Loss: 0.01425094
2025/09/16 22:20:54 : Epoch: 1759, Train_Loss: 0.01018930
2025/09/16 22:20:54 : Epoch: 1759, Eval_Loss: 0.00524079
2025/09/16 22:20:54 : Epoch: 1760, Train_Loss: 0.01269303
2025/09/16 22:20:55 : Epoch: 1761, Train_Loss: 0.00907247
2025/09/16 22:20:55 : Epoch: 1762, Train_Loss: 0.01364994
2025/09/16 22:20:55 : Epoch: 1763, Train_Loss: 0.00946898
2025/09/16 22:20:55 : Epoch: 1764, Train_Loss: 0.01085400
2025/09/16 22:20:55 : Epoch: 1764, Eval_Loss: 0.00524664
2025/09/16 22:20:56 : Epoch: 1765, Train_Loss: 0.00828679
2025/09/16 22:20:56 : Epoch: 1766, Train_Loss: 0.00862863
2025/09/16 22:20:56 : Epoch: 1767, Train_Loss: 0.01176235
2025/09/16 22:20:56 : Epoch: 1768, Train_Loss: 0.00945912
2025/09/16 22:20:57 : Epoch: 1769, Train_Loss: 0.01179113
2025/09/16 22:20:57 : Epoch: 1769, Eval_Loss: 0.00524746
2025/09/16 22:20:57 : Epoch: 1770, Train_Loss: 0.00777488
2025/09/16 22:20:57 : Epoch: 1771, Train_Loss: 0.01224795
2025/09/16 22:20:58 : Epoch: 1772, Train_Loss: 0.00930429
2025/09/16 22:20:58 : Epoch: 1773, Train_Loss: 0.01057769
2025/09/16 22:20:58 : Epoch: 1774, Train_Loss: 0.00909652
2025/09/16 22:20:58 : Epoch: 1774, Eval_Loss: 0.00525308
2025/09/16 22:20:58 : Epoch: 1775, Train_Loss: 0.01292339
2025/09/16 22:20:59 : Epoch: 1776, Train_Loss: 0.00917523
2025/09/16 22:20:59 : Epoch: 1777, Train_Loss: 0.01180374
2025/09/16 22:20:59 : Epoch: 1778, Train_Loss: 0.01184361
2025/09/16 22:20:59 : Epoch: 1779, Train_Loss: 0.01378050
2025/09/16 22:20:59 : Epoch: 1779, Eval_Loss: 0.00525570
2025/09/16 22:21:00 : Epoch: 1780, Train_Loss: 0.00838361
2025/09/16 22:21:00 : Epoch: 1781, Train_Loss: 0.00821451
2025/09/16 22:21:00 : Epoch: 1782, Train_Loss: 0.01177291
2025/09/16 22:21:00 : Epoch: 1783, Train_Loss: 0.00978278
2025/09/16 22:21:01 : Epoch: 1784, Train_Loss: 0.00860506
2025/09/16 22:21:01 : Epoch: 1784, Eval_Loss: 0.00525503
2025/09/16 22:21:01 : Epoch: 1785, Train_Loss: 0.00750023
2025/09/16 22:21:01 : Epoch: 1786, Train_Loss: 0.01018481
2025/09/16 22:21:01 : Epoch: 1787, Train_Loss: 0.00992882
2025/09/16 22:21:02 : Epoch: 1788, Train_Loss: 0.01123337
2025/09/16 22:21:02 : Epoch: 1789, Train_Loss: 0.01032280
2025/09/16 22:21:02 : Epoch: 1789, Eval_Loss: 0.00524305
2025/09/16 22:21:02 : Epoch: 1790, Train_Loss: 0.01281395
2025/09/16 22:21:03 : Epoch: 1791, Train_Loss: 0.00673869
2025/09/16 22:21:03 : Epoch: 1792, Train_Loss: 0.01071901
2025/09/16 22:21:03 : Epoch: 1793, Train_Loss: 0.00908576
2025/09/16 22:21:03 : Epoch: 1794, Train_Loss: 0.00763954
2025/09/16 22:21:03 : Epoch: 1794, Eval_Loss: 0.00524036
2025/09/16 22:21:04 : Epoch: 1795, Train_Loss: 0.01275280
2025/09/16 22:21:04 : Epoch: 1796, Train_Loss: 0.00921000
2025/09/16 22:21:04 : Epoch: 1797, Train_Loss: 0.01450463
2025/09/16 22:21:04 : Epoch: 1798, Train_Loss: 0.00817284
2025/09/16 22:21:05 : Epoch: 1799, Train_Loss: 0.00974899
2025/09/16 22:21:05 : Epoch: 1799, Eval_Loss: 0.00524017
2025/09/16 22:21:05 : Epoch: 1800, Train_Loss: 0.00742933
2025/09/16 22:21:05 : Epoch: 1801, Train_Loss: 0.01016901
2025/09/16 22:21:05 : Epoch: 1802, Train_Loss: 0.00792690
2025/09/16 22:21:06 : Epoch: 1803, Train_Loss: 0.00874664
2025/09/16 22:21:06 : Epoch: 1804, Train_Loss: 0.00929764
2025/09/16 22:21:06 : Epoch: 1804, Eval_Loss: 0.00523966
2025/09/16 22:21:06 : Epoch: 1805, Train_Loss: 0.00921417
2025/09/16 22:21:06 : Epoch: 1806, Train_Loss: 0.00948160
2025/09/16 22:21:07 : Epoch: 1807, Train_Loss: 0.00841807
2025/09/16 22:21:07 : Epoch: 1808, Train_Loss: 0.00773378
2025/09/16 22:21:07 : Epoch: 1809, Train_Loss: 0.00883981
2025/09/16 22:21:07 : Epoch: 1809, Eval_Loss: 0.00524282
2025/09/16 22:21:07 : Epoch: 1810, Train_Loss: 0.00909205
2025/09/16 22:21:08 : Epoch: 1811, Train_Loss: 0.00837530
2025/09/16 22:21:08 : Epoch: 1812, Train_Loss: 0.00706337
2025/09/16 22:21:08 : Epoch: 1813, Train_Loss: 0.01424630
2025/09/16 22:21:08 : Epoch: 1814, Train_Loss: 0.01227938
2025/09/16 22:21:09 : Epoch: 1814, Eval_Loss: 0.00523924
2025/09/16 22:21:09 : Epoch: 1815, Train_Loss: 0.01279997
2025/09/16 22:21:09 : Epoch: 1816, Train_Loss: 0.00681234
2025/09/16 22:21:09 : Epoch: 1817, Train_Loss: 0.01109091
2025/09/16 22:21:10 : Epoch: 1818, Train_Loss: 0.00899114
2025/09/16 22:21:10 : Epoch: 1819, Train_Loss: 0.01114505
2025/09/16 22:21:10 : Epoch: 1819, Eval_Loss: 0.00524376
2025/09/16 22:21:10 : Epoch: 1820, Train_Loss: 0.00930277
2025/09/16 22:21:10 : Epoch: 1821, Train_Loss: 0.00910967
2025/09/16 22:21:11 : Epoch: 1822, Train_Loss: 0.00950583
2025/09/16 22:21:11 : Epoch: 1823, Train_Loss: 0.00722545
2025/09/16 22:21:11 : Epoch: 1824, Train_Loss: 0.01107618
2025/09/16 22:21:11 : Epoch: 1824, Eval_Loss: 0.00526210
2025/09/16 22:21:11 : Epoch: 1825, Train_Loss: 0.00943046
2025/09/16 22:21:12 : Epoch: 1826, Train_Loss: 0.00676236
2025/09/16 22:21:12 : Epoch: 1827, Train_Loss: 0.01227570
2025/09/16 22:21:12 : Epoch: 1828, Train_Loss: 0.00713229
2025/09/16 22:21:12 : Epoch: 1829, Train_Loss: 0.00789231
2025/09/16 22:21:12 : Epoch: 1829, Eval_Loss: 0.00525702
2025/09/16 22:21:13 : Epoch: 1830, Train_Loss: 0.01100481
2025/09/16 22:21:13 : Epoch: 1831, Train_Loss: 0.00802812
2025/09/16 22:21:13 : Epoch: 1832, Train_Loss: 0.00990350
2025/09/16 22:21:13 : Epoch: 1833, Train_Loss: 0.01106952
2025/09/16 22:21:14 : Epoch: 1834, Train_Loss: 0.01209786
2025/09/16 22:21:14 : Epoch: 1834, Eval_Loss: 0.00525175
2025/09/16 22:21:14 : Epoch: 1835, Train_Loss: 0.01200063
2025/09/16 22:21:14 : Epoch: 1836, Train_Loss: 0.00893165
2025/09/16 22:21:15 : Epoch: 1837, Train_Loss: 0.00941575
2025/09/16 22:21:15 : Epoch: 1838, Train_Loss: 0.00759203
2025/09/16 22:21:15 : Epoch: 1839, Train_Loss: 0.01417173
2025/09/16 22:21:15 : Epoch: 1839, Eval_Loss: 0.00524286
2025/09/16 22:21:15 : Epoch: 1840, Train_Loss: 0.01030014
2025/09/16 22:21:16 : Epoch: 1841, Train_Loss: 0.00786960
2025/09/16 22:21:16 : Epoch: 1842, Train_Loss: 0.01361605
2025/09/16 22:21:16 : Epoch: 1843, Train_Loss: 0.00841056
2025/09/16 22:21:16 : Epoch: 1844, Train_Loss: 0.01012484
2025/09/16 22:21:16 : Epoch: 1844, Eval_Loss: 0.00523936
2025/09/16 22:21:17 : Epoch: 1845, Train_Loss: 0.01233442
2025/09/16 22:21:17 : Epoch: 1846, Train_Loss: 0.00958910
2025/09/16 22:21:17 : Epoch: 1847, Train_Loss: 0.01223027
2025/09/16 22:21:17 : Epoch: 1848, Train_Loss: 0.01159474
2025/09/16 22:21:18 : Epoch: 1849, Train_Loss: 0.00978756
2025/09/16 22:21:18 : Epoch: 1849, Eval_Loss: 0.00524058
2025/09/16 22:21:18 : Epoch: 1850, Train_Loss: 0.00815756
2025/09/16 22:21:18 : Epoch: 1851, Train_Loss: 0.01106640
2025/09/16 22:21:19 : Epoch: 1852, Train_Loss: 0.01153317
2025/09/16 22:21:19 : Epoch: 1853, Train_Loss: 0.01036899
2025/09/16 22:21:19 : Epoch: 1854, Train_Loss: 0.01144474
2025/09/16 22:21:19 : Epoch: 1854, Eval_Loss: 0.00524324
2025/09/16 22:21:19 : Epoch: 1855, Train_Loss: 0.01345512
2025/09/16 22:21:20 : Epoch: 1856, Train_Loss: 0.00918640
2025/09/16 22:21:20 : Epoch: 1857, Train_Loss: 0.01164535
2025/09/16 22:21:20 : Epoch: 1858, Train_Loss: 0.01348415
2025/09/16 22:21:20 : Epoch: 1859, Train_Loss: 0.00707645
2025/09/16 22:21:20 : Epoch: 1859, Eval_Loss: 0.00524844
2025/09/16 22:21:21 : Epoch: 1860, Train_Loss: 0.00851844
2025/09/16 22:21:21 : Epoch: 1861, Train_Loss: 0.01218641
2025/09/16 22:21:21 : Epoch: 1862, Train_Loss: 0.00947976
2025/09/16 22:21:21 : Epoch: 1863, Train_Loss: 0.00885504
2025/09/16 22:21:22 : Epoch: 1864, Train_Loss: 0.01022102
2025/09/16 22:21:22 : Epoch: 1864, Eval_Loss: 0.00525799
2025/09/16 22:21:22 : Epoch: 1865, Train_Loss: 0.01095049
2025/09/16 22:21:22 : Epoch: 1866, Train_Loss: 0.01017989
2025/09/16 22:21:22 : Epoch: 1867, Train_Loss: 0.01064325
2025/09/16 22:21:23 : Epoch: 1868, Train_Loss: 0.00877560
2025/09/16 22:21:23 : Epoch: 1869, Train_Loss: 0.01069823
2025/09/16 22:21:23 : Epoch: 1869, Eval_Loss: 0.00525095
2025/09/16 22:21:23 : Epoch: 1870, Train_Loss: 0.01088561
2025/09/16 22:21:23 : Epoch: 1871, Train_Loss: 0.00775626
2025/09/16 22:21:24 : Epoch: 1872, Train_Loss: 0.01072215
2025/09/16 22:21:24 : Epoch: 1873, Train_Loss: 0.01185151
2025/09/16 22:21:24 : Epoch: 1874, Train_Loss: 0.00767122
2025/09/16 22:21:24 : Epoch: 1874, Eval_Loss: 0.00524671
2025/09/16 22:21:25 : Epoch: 1875, Train_Loss: 0.01089759
2025/09/16 22:21:25 : Epoch: 1876, Train_Loss: 0.01298349
2025/09/16 22:21:25 : Epoch: 1877, Train_Loss: 0.00768665
2025/09/16 22:21:25 : Epoch: 1878, Train_Loss: 0.00789446
2025/09/16 22:21:26 : Epoch: 1879, Train_Loss: 0.01207137
2025/09/16 22:21:26 : Epoch: 1879, Eval_Loss: 0.00525024
2025/09/16 22:21:26 : Epoch: 1880, Train_Loss: 0.00997053
2025/09/16 22:21:26 : Epoch: 1881, Train_Loss: 0.00755290
2025/09/16 22:21:26 : Epoch: 1882, Train_Loss: 0.01185459
2025/09/16 22:21:27 : Epoch: 1883, Train_Loss: 0.00863013
2025/09/16 22:21:27 : Epoch: 1884, Train_Loss: 0.00892594
2025/09/16 22:21:27 : Epoch: 1884, Eval_Loss: 0.00524409
2025/09/16 22:21:27 : Epoch: 1885, Train_Loss: 0.00927502
2025/09/16 22:21:27 : Epoch: 1886, Train_Loss: 0.01169974
2025/09/16 22:21:28 : Epoch: 1887, Train_Loss: 0.01295471
2025/09/16 22:21:28 : Epoch: 1888, Train_Loss: 0.00997106
2025/09/16 22:21:28 : Epoch: 1889, Train_Loss: 0.00859563
2025/09/16 22:21:28 : Epoch: 1889, Eval_Loss: 0.00524354
2025/09/16 22:21:28 : Epoch: 1890, Train_Loss: 0.00981181
2025/09/16 22:21:29 : Epoch: 1891, Train_Loss: 0.00833865
2025/09/16 22:21:29 : Epoch: 1892, Train_Loss: 0.01086261
2025/09/16 22:21:29 : Epoch: 1893, Train_Loss: 0.00803188
2025/09/16 22:21:29 : Epoch: 1894, Train_Loss: 0.01015695
2025/09/16 22:21:30 : Epoch: 1894, Eval_Loss: 0.00524302
2025/09/16 22:21:30 : Epoch: 1895, Train_Loss: 0.01147830
2025/09/16 22:21:30 : Epoch: 1896, Train_Loss: 0.00910746
2025/09/16 22:21:30 : Epoch: 1897, Train_Loss: 0.00985877
2025/09/16 22:21:31 : Epoch: 1898, Train_Loss: 0.00754680
2025/09/16 22:21:31 : Epoch: 1899, Train_Loss: 0.01300845
2025/09/16 22:21:31 : Epoch: 1899, Eval_Loss: 0.00524160
2025/09/16 22:21:31 : Epoch: 1900, Train_Loss: 0.01049198
2025/09/16 22:21:31 : Epoch: 1901, Train_Loss: 0.00687931
2025/09/16 22:21:32 : Epoch: 1902, Train_Loss: 0.00749923
2025/09/16 22:21:32 : Epoch: 1903, Train_Loss: 0.00707599
2025/09/16 22:21:32 : Epoch: 1904, Train_Loss: 0.00901581
2025/09/16 22:21:32 : Epoch: 1904, Eval_Loss: 0.00524162
2025/09/16 22:21:32 : Epoch: 1905, Train_Loss: 0.01025347
2025/09/16 22:21:33 : Epoch: 1906, Train_Loss: 0.01064096
2025/09/16 22:21:33 : Epoch: 1907, Train_Loss: 0.01095215
2025/09/16 22:21:33 : Epoch: 1908, Train_Loss: 0.01000936
2025/09/16 22:21:33 : Epoch: 1909, Train_Loss: 0.00788610
2025/09/16 22:21:33 : Epoch: 1909, Eval_Loss: 0.00523890
2025/09/16 22:21:34 : Epoch: 1910, Train_Loss: 0.01269592
2025/09/16 22:21:34 : Epoch: 1911, Train_Loss: 0.00927885
2025/09/16 22:21:34 : Epoch: 1912, Train_Loss: 0.00722481
2025/09/16 22:21:34 : Epoch: 1913, Train_Loss: 0.00839485
2025/09/16 22:21:35 : Epoch: 1914, Train_Loss: 0.01033253
2025/09/16 22:21:35 : Epoch: 1914, Eval_Loss: 0.00523786
2025/09/16 22:21:35 : Epoch: 1915, Train_Loss: 0.01026136
2025/09/16 22:21:35 : Epoch: 1916, Train_Loss: 0.01075740
2025/09/16 22:21:36 : Epoch: 1917, Train_Loss: 0.01024703
2025/09/16 22:21:36 : Epoch: 1918, Train_Loss: 0.01029631
2025/09/16 22:21:36 : Epoch: 1919, Train_Loss: 0.00831794
2025/09/16 22:21:36 : Epoch: 1919, Eval_Loss: 0.00523645
2025/09/16 22:21:36 : Epoch: 1920, Train_Loss: 0.00840234
2025/09/16 22:21:37 : Epoch: 1921, Train_Loss: 0.01046475
2025/09/16 22:21:37 : Epoch: 1922, Train_Loss: 0.00768806
2025/09/16 22:21:37 : Epoch: 1923, Train_Loss: 0.00884511
2025/09/16 22:21:37 : Epoch: 1924, Train_Loss: 0.00865737
2025/09/16 22:21:37 : Epoch: 1924, Eval_Loss: 0.00523599
2025/09/16 22:21:38 : Epoch: 1925, Train_Loss: 0.00983604
2025/09/16 22:21:38 : Epoch: 1926, Train_Loss: 0.00935947
2025/09/16 22:21:38 : Epoch: 1927, Train_Loss: 0.01053218
2025/09/16 22:21:38 : Epoch: 1928, Train_Loss: 0.01142684
2025/09/16 22:21:39 : Epoch: 1929, Train_Loss: 0.00858091
2025/09/16 22:21:39 : Epoch: 1929, Eval_Loss: 0.00523480
2025/09/16 22:21:39 : Epoch: 1930, Train_Loss: 0.00924748
2025/09/16 22:21:39 : Epoch: 1931, Train_Loss: 0.00953539
2025/09/16 22:21:39 : Epoch: 1932, Train_Loss: 0.00905293
2025/09/16 22:21:40 : Epoch: 1933, Train_Loss: 0.00991839
2025/09/16 22:21:40 : Epoch: 1934, Train_Loss: 0.01035248
2025/09/16 22:21:40 : Epoch: 1934, Eval_Loss: 0.00523451
2025/09/16 22:21:40 : Epoch: 1935, Train_Loss: 0.00837602
2025/09/16 22:21:40 : Epoch: 1936, Train_Loss: 0.00785188
2025/09/16 22:21:41 : Epoch: 1937, Train_Loss: 0.00858772
2025/09/16 22:21:41 : Epoch: 1938, Train_Loss: 0.01000258
2025/09/16 22:21:41 : Epoch: 1939, Train_Loss: 0.00807111
2025/09/16 22:21:41 : Epoch: 1939, Eval_Loss: 0.00523427
2025/09/16 22:21:42 : Epoch: 1940, Train_Loss: 0.00971778
2025/09/16 22:21:42 : Epoch: 1941, Train_Loss: 0.00966637
2025/09/16 22:21:42 : Epoch: 1942, Train_Loss: 0.00833203
2025/09/16 22:21:42 : Epoch: 1943, Train_Loss: 0.00806312
2025/09/16 22:21:43 : Epoch: 1944, Train_Loss: 0.00814779
2025/09/16 22:21:43 : Epoch: 1944, Eval_Loss: 0.00523425
2025/09/16 22:21:43 : Epoch: 1945, Train_Loss: 0.00887483
2025/09/16 22:21:43 : Epoch: 1946, Train_Loss: 0.01529172
2025/09/16 22:21:43 : Epoch: 1947, Train_Loss: 0.01293781
2025/09/16 22:21:44 : Epoch: 1948, Train_Loss: 0.00817036
2025/09/16 22:21:44 : Epoch: 1949, Train_Loss: 0.01149162
2025/09/16 22:21:44 : Epoch: 1949, Eval_Loss: 0.00523792
2025/09/16 22:21:44 : Epoch: 1950, Train_Loss: 0.01125053
2025/09/16 22:21:44 : Epoch: 1951, Train_Loss: 0.01121110
2025/09/16 22:21:45 : Epoch: 1952, Train_Loss: 0.00784988
2025/09/16 22:21:45 : Epoch: 1953, Train_Loss: 0.00769635
2025/09/16 22:21:45 : Epoch: 1954, Train_Loss: 0.00770539
2025/09/16 22:21:45 : Epoch: 1954, Eval_Loss: 0.00526024
2025/09/16 22:21:46 : Epoch: 1955, Train_Loss: 0.01275216
2025/09/16 22:21:46 : Epoch: 1956, Train_Loss: 0.01331079
2025/09/16 22:21:46 : Epoch: 1957, Train_Loss: 0.01311153
2025/09/16 22:21:46 : Epoch: 1958, Train_Loss: 0.00971206
2025/09/16 22:21:47 : Epoch: 1959, Train_Loss: 0.00906781
2025/09/16 22:21:47 : Epoch: 1959, Eval_Loss: 0.00527661
2025/09/16 22:21:47 : Epoch: 1960, Train_Loss: 0.00773866
2025/09/16 22:21:47 : Epoch: 1961, Train_Loss: 0.00789017
2025/09/16 22:21:47 : Epoch: 1962, Train_Loss: 0.01035319
2025/09/16 22:21:48 : Epoch: 1963, Train_Loss: 0.01175640
2025/09/16 22:21:48 : Epoch: 1964, Train_Loss: 0.00776021
2025/09/16 22:21:48 : Epoch: 1964, Eval_Loss: 0.00526147
2025/09/16 22:21:48 : Epoch: 1965, Train_Loss: 0.01523774
2025/09/16 22:21:48 : Epoch: 1966, Train_Loss: 0.00876371
2025/09/16 22:21:49 : Epoch: 1967, Train_Loss: 0.00873661
2025/09/16 22:21:49 : Epoch: 1968, Train_Loss: 0.00979955
2025/09/16 22:21:49 : Epoch: 1969, Train_Loss: 0.00800103
2025/09/16 22:21:49 : Epoch: 1969, Eval_Loss: 0.00525363
2025/09/16 22:21:49 : Epoch: 1970, Train_Loss: 0.01066164
2025/09/16 22:21:50 : Epoch: 1971, Train_Loss: 0.00911496
2025/09/16 22:21:50 : Epoch: 1972, Train_Loss: 0.01014014
2025/09/16 22:21:50 : Epoch: 1973, Train_Loss: 0.01186965
2025/09/16 22:21:50 : Epoch: 1974, Train_Loss: 0.00933423
2025/09/16 22:21:51 : Epoch: 1974, Eval_Loss: 0.00525231
2025/09/16 22:21:51 : Epoch: 1975, Train_Loss: 0.00890869
2025/09/16 22:21:51 : Epoch: 1976, Train_Loss: 0.01135696
2025/09/16 22:21:51 : Epoch: 1977, Train_Loss: 0.01168792
2025/09/16 22:21:52 : Epoch: 1978, Train_Loss: 0.00884032
2025/09/16 22:21:52 : Epoch: 1979, Train_Loss: 0.00892694
2025/09/16 22:21:52 : Epoch: 1979, Eval_Loss: 0.00525376
2025/09/16 22:21:52 : Epoch: 1980, Train_Loss: 0.00798915
2025/09/16 22:21:52 : Epoch: 1981, Train_Loss: 0.01073836
2025/09/16 22:21:53 : Epoch: 1982, Train_Loss: 0.00917642
2025/09/16 22:21:53 : Epoch: 1983, Train_Loss: 0.01326884
2025/09/16 22:21:53 : Epoch: 1984, Train_Loss: 0.01249860
2025/09/16 22:21:53 : Epoch: 1984, Eval_Loss: 0.00524511
2025/09/16 22:21:53 : Epoch: 1985, Train_Loss: 0.01282773
2025/09/16 22:21:54 : Epoch: 1986, Train_Loss: 0.01037103
2025/09/16 22:21:54 : Epoch: 1987, Train_Loss: 0.00832791
2025/09/16 22:21:54 : Epoch: 1988, Train_Loss: 0.01091914
2025/09/16 22:21:54 : Epoch: 1989, Train_Loss: 0.00915969
2025/09/16 22:21:55 : Epoch: 1989, Eval_Loss: 0.00524407
2025/09/16 22:21:55 : Epoch: 1990, Train_Loss: 0.01407446
2025/09/16 22:21:55 : Epoch: 1991, Train_Loss: 0.01149185
2025/09/16 22:21:55 : Epoch: 1992, Train_Loss: 0.01078121
2025/09/16 22:21:56 : Epoch: 1993, Train_Loss: 0.00816326
2025/09/16 22:21:56 : Epoch: 1994, Train_Loss: 0.01068221
2025/09/16 22:21:56 : Epoch: 1994, Eval_Loss: 0.00524687
2025/09/16 22:21:56 : Epoch: 1995, Train_Loss: 0.01226884
2025/09/16 22:21:56 : Epoch: 1996, Train_Loss: 0.01125193
2025/09/16 22:21:57 : Epoch: 1997, Train_Loss: 0.01357077
2025/09/16 22:21:57 : Epoch: 1998, Train_Loss: 0.00799613
2025/09/16 22:21:57 : Epoch: 1999, Train_Loss: 0.01199242
2025/09/16 22:21:57 : Epoch: 1999, Eval_Loss: 0.00525413
2025/09/16 22:21:57 : 
Epoch: 1999, save response figures

